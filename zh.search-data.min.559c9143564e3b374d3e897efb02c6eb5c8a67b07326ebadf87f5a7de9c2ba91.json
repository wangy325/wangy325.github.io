[{"id":0,"href":"/zh/docs/note/course/operating_system_peking/1_intro/","title":"引论","section":"操作系统原理","content":" 1 操作系统的定义和作用 # 1.1 操作系统定义 # 操作系统是计算机中的一个系统软件，是一系列程序模块的集合。\n它们能尽可能以有效 、合理的方式组织和管理计算机的软硬件资源； 合理地组织计算机的工作流程，控制程序的执行并向用户提供各种服务功能； 使得用户更加灵活、方便的使用计算机，使整个计算机系统高效运行； 有效：指系统效率，资源利用率。如cpu利用率是否充足，I/O设备是否忙碌等。\n合理：软硬件资源的管理是否公平合理。\n1.2 操作系统的作用 # 资源的管理者 向用户提供各种服务 对硬件机器的拓展 1.2.1 OS是资源的管理者 # 自底向上，操作系统是资源的管理者。\n资源：\n硬件（CPU，内存，设备（I/O设备，磁盘，时钟，网卡等）） 软件（磁盘上的文件，各类管理信息） 1.2.2 OS如何管理资源 # 跟踪资源的使用情况 （数据结构） 哪些资源空闲，分配给谁，允许使用多长时间等 资源分配策略 （算法） 静态分配策略 动态分配策略（被采纳） 实施资源的分配和回收 提高资源的利用率 保护资源的使用 协调多个进程对资源请求的冲突 1.2.3 OS的5大功能——从资源管理的角度 # 进程/线程管理（CPU管理） 进程线程状态、控制、同步互斥、通信、调度… 存储管理 分配/回收、地址转换、存储保护、内存扩充… 文件管理 文件目录、文件操作、磁盘空间、文件存取控制… 设备管理 设备驱动、分配回收、缓冲技术… 用户接口 系统命令、编程接口 1.2.4 OS是系统各种系统服务的提供者 # 从用户的角度，操作系统提供了一组功能强大、方便易用的命令或系统调用。 操作系统提供的典型服务，如进程的创建、执行，文件和目录的操作，I/O设备的使用，各类统计信息等等。 1.2.5 OS是硬件之上的第一层软件 # 操作系统在应用程序和硬件之间建立了一个等价的扩展机器 对硬件抽象，提高可移植性，相比对底层硬件更容易编程 2 操作系统的主要特征 # 并发（concurrency） 共享（sharing） 虚拟（virtual） 随机（random） 2.1 并发 # 并发（concurrency）：处理多个同时性活动的能力。\n并发引发的问题： 活动切换、保护、相互依赖的活动间的同步。\n计算机系统中同时存在多个程序运行，单CPU上，\n宏观上，这些程序在同时运行 微观上，任何时刻都只有一个程序在执行（时间片） 并行（parallel）：与并行相似，但指不同程序同时在多个硬件部件上执行。\n2.2 共享 # 操作系统与多个用户的程序共同使用计算机系统的资源（共享有限的系统资源）。\n操作系统要对系统资源进行合理分配和使用。\n资源在同一时间段内交替被多个进程所用。\n根据资源被使用的特性，共享可以分为\n互斥共享（如打印机） 同时共享（如可重入代码、磁盘文件） 问题：资源分配难以达到最优化，以及如何保护资源完整性…\n2.3 虚拟 # 一个物理实体映射为若干个对应的逻辑实体——分时或者分空间 虚拟是操作系统管理系统资源的重要手段，可以提高资源利用率 CPU——每个进程的”虚处理机“；\n存储器——每个进程都有独立的虚拟地址空间（代码+数据+堆栈）；\n显示设备——多窗口或虚拟终端\n2.4 随机 # 操作系统必须随时对以不可预测的次序发生的事件作出响应并处理。\n进程运行的速度不可预知：多个进程并发运行，无法预知每个进程的运行推进的快慢。\n难以重现系统在某个时刻的状态（包括重现运行中的错误）。\n3 典型操作系统的架构 # 3.1 Windows # Reference: Windows操作系统的体系结构\n核心概念-自底向上：\n硬件接口 内核态 HAL 硬件抽象层 kernel 内核 设备/文件驱动 图形设备 I/O管理 … 用户态 系统支持服务 应用程序 环境子系统 Ntdll.dll 3.2 Unix/Linux # Reference: Unix/Linux的体系架构-简书\n4 操作系统分类 # 4.1 传统操作系统分类 # 批处理操作系统 实时操作系统 网络操作系统 嵌入式操作系统 分时系统 个人计算机操作系统 分布式操作系统 4.1.1 批处理操作系统 # 基本概念 # 工作方式：\n用户将作业交给系统操作员； 系统操作员将许多用户的作业组成一个作业，输入到计算机系统中，在系统中形成一个自动转接的连续的作业流； 启动操作系统； 系统自动、依次执行每个作业； 操作员将作业结果交给用户。 追求目标： 提供系统资源利用率，增加作业处理吞吐量。\n作业的内含：\n用户程序 数据 作业说明书（用作业控制语言编写-类脚本） 成批： 通常由多个作业组成，用户提交作业后，只能等待处理结果，不能干预自己作业的执行。\n批处理作业：\n对一批作业中的每个作业进行相同的处理：从磁带读取用户作业和编译链接程序，编译链接用户作业以生成可执行程序；启动执行；执行并输出结果。\n不足：慢速的输入输出直接由主机完成，此过程中CPU出于等待状态，造成资源浪费。\n解决方案：使用卫星机，仅仅完成输入输出的工作，处理结果暂存在磁带或磁盘上。\nSPOOLING技术 # 批处理系统的实现通常采用的技术 1961年，🇬🇧曼切斯特大学，Atalas机（原型） Simultaneous Peripheral Operation On-Line （同时的外围设备联机操作，又称假脱机技术） 思想：利用磁盘作为缓冲，将输入、计算、输出分别组成独立的任务流，使I/O和计算真正并行 工作原理：\n现今打印机的打印队列使用了Spooling技术。\n4.1.2 分时操作系统 # 时间片（time slice）\n操作系统将CPU的时间划分为若干个片段，称为时间片\n操作系统以时间片为单位，轮流为每个终端用户服务，每次服务一个时间片； 其特点是利用人的错觉（？），使用户感觉不到计算机在服务多人。 分时操作系统追求即时响应。\n通用型操作系统：\n分时系统与批处理系统的结合； 原则：分时优先，批处理在后 ”前台”：需要频繁交互的作业 - 分时处理 “后台”：时间性要求不严的作业- 批处理 4.1.3 实时操作系统 # 计算机能够及时响应外部事件的请求，在规定的严格时间内完成对该事件的处理，并控制所有实时设备和实时任务协调一致地工作。\n分类：\n第一类：实时过程控制\n工业控制，航空，军事控制…\n第二类：实时通信（信息）处理\n电讯（自动交换机），银行，飞机订票，股市行情…\n要求（目标）：\n对外部请求在严格时间范围内作出响应 高可靠性 4.1.4 个人计算机操作系统 # 某一时间内为单一用户服务。界面友好，使用方便，丰富的应用软件支持。\n4.1.5 网络操作系统 # 基于计算机网络，在计算机网络系统上，按网络体系结构协议标准开发的软件。\n功能：\n网络管理，通信，安全，资源共享，以及各种网络应用。\n目标：\n互相通信，资源共享。\n4.1.6 分布式操作系统 # 分布式系统：或以计算机网络为基础，或以多处理机为基础，基本特征是处理分布在不同计算机上。 分布式操作系统：是一个统一的操作系统，允许若干计算机可相互协作共同完成一项任务。操作系统可以将各种系统任务在分布式系统中的任何处理机上运行，自动实现全系统范围内的任务分配、自动调度、均衡各处理机的工作负载。 处理能力更强，速度更快，可靠性增强， 4.1.7 嵌入式操作系统 # 嵌入式系统： 在各种设备（汽车、手机、电视、mp3…）、装置或系统中，完成特定功能的软硬件系统。 它们是一个大设备、装置或者系统中的一部分，这个大设备，可以不是计算机。 通常工作在反应式或对处理时间有较严格要求的环境中。 嵌入式操作系统： 运行在嵌入式系统环境中，对整个嵌入式系统及其操作、控制的各种部件装置等资源进行统一协调、调度、指挥和控制的系统软件。 4.1.8 智能卡操作系统（补充） # 智能卡： 一种包含一块CPU芯片的卡片\n特点：\n非常严格的运行能耗和存储空间的限制，有些智能卡只有单项功能，如电子支付 有专用的操作系统 有些智能卡是面向Java的，即智能卡的ROM中有一个Java虚拟机解释器。\n5 本章重点 # 掌握操作系统的概念 理解 操作系统的不同作用 理解 操作系统的主要特征 掌握重要的操作系统技术 SPOOLing技术 了解操作系统架构 了解 操作系统的分类 "},{"id":1,"href":"/zh/docs/note/pys/1_flow_control/","title":"流程控制语句","section":"Python","content":" "},{"id":2,"href":"/zh/docs/craft/design_pattern/behaviour/1_command/","title":"命令模式","section":"行为型","content":" 命令模式 # 命令模式将\u0026quot;请求\u0026quot;封装成（命令）对象，以便使用不同的请求、队列或者日志来参数化其他对象。 命令模式也支持撤销的操作。\n命令模式是一种行为设计模式，它可将请求转换为一个包含与请求相关的所有信息的独立对象。 该转换让你能根据不同的请求将方法参数化、延迟请求执行或将其放入队列中，且能实现可撤销操作。\n设计原则 # 解耦：命令模式使发起者和接收者解耦。发起者不关心具体的接收者，只需要根据已知的命令对象 执行execute()方法即可。 UML简图 # classDiagram class Invoker { +Command command +invoke() } Invoker *..\u003e Command class Command { \u003c\u003c interface \u003e\u003e +execute() +undo() } ConcreteCommand ..|\u003e Command class ConcreteCommand { Receiver receiver +execute() +undo() } Receiver \u003c--* ConcreteCommand class Receiver { +someOperation() } classDiagram class Invoker { +Command command +invoke() } Invoker *..\u0026gt; Command class Command { \u0026lt;\u0026lt; interface \u0026gt;\u0026gt; +execute() +undo() } ConcreteCommand ..|\u0026gt; Command class ConcreteCommand { Receiver receiver +execute() +undo() } Receiver \u0026lt;--* ConcreteCommand class Receiver { +someOperation() } 要点 # 命令模式将发出请求的对象（调用者）和接收请求的对象（接收者）解耦。 被解耦的对象之间通过命令对象沟通，命令对象封装了接收者和一个或者一组动作。 调用者通过执行命令对象的execute()方法发出请求，这会使得接收者的动作被调用。 调用者接收命令作为参数。甚至可以在运行时动态地进行。 命令支持撤销。 宏命令是命令的简单延伸，允许一次调用多个命令。宏命令也支持撤销。 命令也可以用来实现日志和事务系统。How to? 示例代码 # 命令接口 # // command public interface Command { void execute(); void undo(); } 命令执行器 # // invoker public class RemoteControl { private Command command; public RemoteControl(Command command) { this.command = command; } public void onButtonPress(){ command.execute(); } public void redoCommand(){ command.undo(); } } 具体的命令实现 # // concrete command public class AcOffCommand implements Command { private AirConditioner ac; public AcOffCommand(AirConditioner ac) { this.ac = ac; } @Override public void execute() { ac.off(); } @Override public void undo() { ac.on(); } } 命令接收器 # // receiver public class AirConditioner { public void on(){ System.out.println(\u0026#34;AC on.\u0026#34;); } public void off(){ System.out.println(\u0026#34;AC off.\u0026#34;); } } 更加完整的代码\n"},{"id":3,"href":"/zh/docs/craft/design_pattern/creation/1_singleton/","title":"单例模式","section":"创建型","content":" 单例模式 # by Head First 设计模式\n单例模式确保一个类只有一个实例，并且提供一个全局访问点。\nby Dive into Design Patterns\nSingleton is a creational design pattern that lets you ensure that a class has only one instance, while providing a global access point to this instance.\n模式特点 # 单例模式确保程序中一个类只有一个实例。 单例模式提供类的全局访问点。 Java实现单例需要私有构造器、静态方法和静态变量。 确定在性能和资源上的限制，再采用合适的方法来实现单例模式，以确保在多线程下的安全性。 如果使用多个类加载器，可能导致单例模式失效而出现多个实例。[例证？] UML简图 # classDiagram class Singleton { -Singleton instance -Singleton() Singleton +getInstance()$ Singleton } classDiagram class Singleton { -Singleton instance -Singleton() Singleton +getInstance()$ Singleton } 实现 # 1. 典型但线程不安全实现 # public class Singleton { private static Singleton INSTANCE = null; private Singleton() { } public static Singleton getInstance() { if (INSTANCE == null) { INSTANCE = new Singleton(); } return INSTANCE; } } 典型的单例实现，但多线程下不适用。\n2. 提前实例化 # public class Singleton { private static final Singleton INSTANCE = new Singleton(); private Singleton() { } public static Singleton getInstance() { return INSTANCE; } } 它是线程安全的，因为静态变量只在类初始化时初始化。它只有一个缺点：如果是资源紧张 的情况，提前实例化有一点点的资源浪费（如果用不到的话）。\n3. 使用同步方法（重量级锁） # 对方法1的改进：\npublic class Singleton { private static Singleton INSTANCE = null; private Singleton() { } public synchronized static Singleton getInstance() { if (INSTANCE == null) { INSTANCE = new Singleton(); } return INSTANCE; } } 此方法是可行的。但是，它存在很严重的性能浪费，使用synchronized对方法加锁， 可能导致代码执行效率低1000倍！\n4. 使用DCL (Double-Check-Locking) # 对方法3的改进。既然不推荐使用重量级锁，那么是否有更好的加锁方式呢？\npublic class Singleton { private volatile static Singleton INSTANCE = null; private Singleton() { } public static Singleton getInstance() { if (INSTANCE == null) { synchronized (Singleton.class) { if (INSTANCE == null) { INSTANCE = new Singleton(); } } } return INSTANCE; } } DCL中使用了volatile关键字，这是必须的。第一次的null判定减少了上锁的 概率，第二次的null判定才是保证线程安全根本。\n注意，这个方式并不一定是百分百安全的，volatile关键字的语义在1.4版本之前 的Java中存在bug。\nOne thing to keep in mind with this pattern is that the field needs to be volatile to prevent cache incoherence issues. In fact, the Java memory model allows the publication of partially initialized objects and this may lead in turn to subtle bugs.\n5. 延迟实例化（按需加载） # 对方法2的小小优化。\npublic class Singleton { private static class InstanceHolder { private static final Singleton INSTANCE = new Singleton(); } private Singleton() { } public static Singleton getInstance() { return InstanceHolder.INSTANCE; } } 与方法2的区别是，单例对象只有在调用getInstance()方法时，才会初始化。\n6. 使用枚举 # 枚举类只有指定的实例，并没有其他办法来创建其他实例，因此可以用来实现单例。\npublic enum Singleton { INSTANCE(\u0026#34;unique\u0026#34;); private String abbr; private Singleton(String abbr) { this.abbr = abbr; } } 讨论 # 单例模式是一个简单的设计模式，但是可别滥用它。使用时想一想，是否一定需要 一个单例对象，才能满足需求？\n单例模式实际上违法了单一职责原则：单例保证了实例的唯一性，同时还要提供 全局访问入口。\n同时，单例代码使得测试工作变得麻烦。\n上文提及的单例模式创建方法，实际上只有early initializatin和 lazy initialization两种，使用DCL可能会由于编译器优化存在细微的问题， 而枚举类单例的形式，是[Effective Java]中推荐使用的。\n不管怎样，使用枚举来实现复杂的单例，看起来很怪。\n另外，使用单例可能还会有其他一些问题：\n如果是在分布式环境中，基于JVM唯一的单例如何保证？ 注意你的类加载器，不同的类加载器可能会导致多例。 要防止单例对象被回收。 参考 # Medium: 5 ways to write singleton Baeldung：Singletons in Java Baeldung: Double-Check-Locking with singleton "},{"id":4,"href":"/zh/docs/craft/algo/%E5%90%8C%E4%BD%99%E5%AE%9A%E7%90%86%E4%B8%8E%E4%BA%8C%E8%BF%9B%E5%88%B6%E8%A1%A5%E7%A0%81/","title":"同余定理与二进制补码","section":"算法讨论","content":"我们知道，计算机使用2的补码（Two\u0026rsquo;s complements）来表示负数。这样有一个好处：可以使用同一种运算规则来处理正负数的运算，否则，二进制的正数和负数相加，将会得到错误的结果。为了处理这个讹误，必须为负数设计一套“加法器”。关于这一部分的讨论，参照 关于2的补码。\n而补码使正负数使用同一套“加法器/乘法器”规则，实际上利用了同余运算的性质。\n1. 同余定理 # 1.1 定义 # 同余定理是 初等数论中讨论的内容，之所以在这里涉及，是为了解释计算机中采用补码来表示负数的设计原因。\n同余定理的基本概念：给定一个正整数m（m\u0026gt;1），如果两个整数a和b满足a-b能被m整除，记作m|(a-b)，即(a-b)/m得到一个整数，那么就称整数a与b对模m同余，记作a≡b(mod m)。\n亦即：对于 m\u0026gt;1，若有m|(a-b)，则a≡b(mod m)。\n负数作为被除数，正数作为除数，它们的余数可以是正数也可以是负数。\n比如 -8/3，其余数可以是1：(-3*3)+1，或者-2：(-2*3)-2。\n这里就可以得出，-8≡-2≡1(mod 3)。\n当然，这里还可以找出很多和-8同余的数。如-5，4，\u0026hellip;\n1.2 证明 # 充分性 若有m|(a-b)，证明a≡b(mod m):\n因 m|(a-b)， 故有 a-b = pm； 设 a = p1*m + r1， b = p2*m + r2, 其中 0 \u0026lt; r1 \u0026lt; m，0 \u0026lt; r2 \u0026lt; m 故有 (p1-p2) * m + (r1 -r2) = pm 即 (r1 - r2) = p3 * m 又 0 \u0026lt; r1 \u0026lt; m， 0 \u0026lt; r2 \u0026lt; m 故r1 = r2 得证 必要性 若有 a % m = r， b % m = r，求证 (a-b) % m = 0\n原式 = (q0*m + r - q1*m -r) % m = (q0-q1)m % m = 0 得证 1.3 同于定理的基本性质 # 反身性：a≡a(mod m) 对称性：若a≡b(mod m)，则b≡a(mod m) 传递性：若a≡b(mod m)，b≡c(mod m)，则a≡c(mod m) 同余相加：若a≡b(mod m)，c≡d(mod m)，则a±c≡b±d(mod m) 同余相乘: 若a≡b(mod m)，c≡d(mod m)，则ac≡bd(mod m) 幂运算：若a≡b(mod m)，b≡c(mod m)，则an≡bn(mod m) 除法：若ac≡bc(mod m) (c≠0)，则a≡b(mod m/gcd(c,m))，其中gcd(c,m)表示c和m的最大公约数 性质1、2、3显而易见。性质6可由性质5推导出，性质7不在此文中讨论。以下简单证明性质5，6：\n求证 (a+c-b-d) % m = 0 原式 = (q1*m +q2*m) % m = (q1+q2)m % m = 0 得证 求证 (ac-bd) % m = 0 原式= (ac-bc+bc-bd) % m = [(a-b)c + (c-d)b] % m = (q1c + q2b)m % m = 0 得证 理解同余运算，及同余运算的基本性质，对于理解计算机使用反码来表示负数，以实现一种“加法器/乘法器”的内含。\n2. 补码 # 计算机语言中，定义\n正数的原码，反码，补码相等；\n负数的原码，反码，补码各不相同；\n原码：为其对应的正数的原码，不过最高位符号位由0变为1，表示负数； 反码：为其原码除符号位外按位取反的结果； 补码：为其反码 + 1的结果； 由上可知，负数在二进制中的表示为其正数“按位取反加1”的形式。\n补码的本质是利用一个环，来实现同余运算，同余运算的性质告诉我们，它忽略符号。\n以下的论述以8位机为前提。\n在8位数情况下，可表示的数值范围是0~255共256个，在这个范围内取得的任意数，都是256的余数，你可以很清晰的看到:\n若 a ≡ 1(mod 256) b ≡ 2(mod 256) 则 r = a+b ≡ 3(mod 256) 如果想表示一个负数 -1，\nx ≡ -1(mod 256)\n即 256|(x+1)，在0~255范围呢，x只能是255。\n即 255 ≡ -1(mod 256) ≡ 255(mod 256)\n也就是说可以用255表示-1。\n那么要表示一半正数，一半负数，恰好将二进制的最高位置为1就表示负数，置为0则表示正数，那么0~255就可以表示〔-127~127〕(-128?)的数值了。\n那补码为什么是“取反+1”呢？\n我们用~x表示x的按位取反值，那么可知 x + ~x = 255，则\nx + ~x ≡255(mod 256) ≡ -1(mod 256)\n即有\nx + ~x + 1 ≡ 0(mod 256)\n-x ≡ (~x + 1)(mod 256)\n推导过程使用了同余定理的加法性质\n以上。\n可以看到，-x和~x+1模256同余，即我们可以用“取反加1”表示负数。\n等等\u0026hellip;\n让我们讨论一下边际条件。\n0~255一共256个数，-127~127一共255个数（不考虑-0的情况下），那么还多一个数128，128的二进制表示是10000000，最高位是1，按照高位1是负数，0是正数的原则，显然不能表示+128，那么它表示什么？\n“-0的补码” # -0的原码是10000000，我们通过“取反加1”的计算规则求得补码：\n原 1000 0000 反 1111 1111 + 1 --------------- 补 1 0000 0000 得到-0的补码是00000000，即还是0。\n额外地，不妨使用上面的同余运算公式代入：\n-0 ≡ (~0 + 1)(mod 256) -0 ≡ (255 +1)(mod 256) -0 ≡ 256(mod 256) ≡ 0(mod 256) 因此，0在二进制中没有正负之分。\n虽然+0和-0的补码都是0，但是，0和-0的原码占用了00000000和10000000存储位置，似乎有“浪费资源”之嫌。完全可以让-0表示另一个数，实际上计算机也是这么做的。\n由同余定理我们知道：\n-128 ≡ 128(mod/256)\n因此，计算机中使用10000000表示-128。\n实际上我们可以通过计算规则证明这一点：\n补 1000 0000 - 1 ---------------- 反 0111 1111 原 1000 0000 上述计算式证明了 [10000000]~补~ = [10000000]~原~，和同余定理的论证吻合。\n因此，在8位机中，可表示的数值范围就是[-128，127]。\n参考 # 为什么-0的补码是00000000？ 为什么1字节表示的数值范围是 -128 ～ -127？ 同余定理 关于2的补码 "},{"id":5,"href":"/zh/docs/java/jvm/Java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E8%AF%A6%E8%A7%A3/","title":"Java内存区域详解(转)","section":"JVM","content":" 如果没有特殊说明，都是针对的是 HotSpot 虚拟机。\n1 概述 # 对于 Java 程序员来说，在虚拟机自动内存管理机制下，不再需要像 C/C++程序开发程序员这样为每一个 new 操作去写对应的 delete/free 操作，不容易出现内存泄漏和内存溢出问题。正是因为 Java 程序员把内存控制权利交给 Java 虚拟机，一旦出现内存泄漏和溢出方面的问题，如果不了解虚拟机是怎样使用内存的，那么排查错误将会是一个非常艰巨的任务。\n2 运行时数据区域 # Java 虚拟机在执行 Java 程序的过程中会把它管理的内存划分成若干个不同的数据区域。JDK. 1.8 和之前的版本略有不同，下面会介绍到。\nJDK 1.8 之前：\nJDK 1.8 ：\n线程私有的：\n程序计数器 虚拟机栈 本地方法栈 线程共享的：\n堆 方法区 直接内存 (非运行时数据区的一部分) 2.1 程序计数器 # 程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完成。\n另外，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。\n从上面的介绍中我们知道程序计数器主要有两个作用：\n字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 注意：程序计数器是唯一一个不会出现 OutOfMemoryError 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。\n2.2 Java 虚拟机栈 # 与程序计数器一样，Java 虚拟机栈也是线程私有的，它的生命周期和线程相同，描述的是 Java 方法执行的内存模型，每次方法调用的数据都是通过栈传递的。\nJava 内存可以粗糙的区分为堆内存（Heap）和栈内存 (Stack),其中栈就是现在说的虚拟机栈，或者说是虚拟机栈中局部变量表部分。 （实际上，Java 虚拟机栈是由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法出口信息。）\n局部变量表主要存放了编译期可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）。\nJava 虚拟机栈会出现两种错误：StackOverFlowError 和 OutOfMemoryError。\nStackOverFlowError： 若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。 OutOfMemoryError： 若 Java 虚拟机堆中没有空闲内存，并且垃圾回收器也无法提供更多内存的话。就会抛出 OutOfMemoryError 错误。 Java 虚拟机栈也是线程私有的，每个线程都有各自的 Java 虚拟机栈，而且随着线程的创建而创建，随着线程的死亡而死亡。\n扩展：那么方法/函数如何调用？\nJava 栈可用类比数据结构中栈，Java 栈中保存的主要内容是栈帧，每一次函数调用都会有一个对应的栈帧被压入 Java 栈，每一个函数调用结束后，都会有一个栈帧被弹出。\nJava 方法有两种返回方式：\nreturn 语句。 抛出异常。 不管哪种返回方式都会导致栈帧被弹出。\n2.3 本地方法栈 # 和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。\n本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。\n方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 StackOverFlowError 和 OutOfMemoryError 两种错误。\n2.4 堆 # Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。\nJava世界中“几乎”所有的对象都在堆中分配，但是，随着JIT编译期的发展与逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不那么“绝对”了。从jdk 1.7开始已经默认开启逃逸分析，如果某些方法中的对象引用没有被返回或者未被外面使用（也就是未逃逸出去），那么对象可以直接在栈上分配内存。\nJava 堆是垃圾收集器管理的主要区域，因此也被称作GC 堆（Garbage Collected Heap）.从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代：再细致一点有：Eden 空间、From Survivor、To Survivor 空间等。进一步划分的目的是更好地回收内存，或者更快地分配内存。\n在 JDK 7 版本及JDK 7 版本之前，堆内存被通常被分为下面三部分：\n新生代内存(Young Generation) 老生代(Old Generation) 永生代(Permanent Generation) JDK 8 版本之后方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是直接内存。\n上图所示的 Eden 区、两个 Survivor 区都属于新生代（为了区分，这两个 Survivor 区域按照顺序被命名为 from 和 to），中间一层属于老年代。\n大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 s0 或者 s1，并且对象的年龄还会加 1(Eden 区-\u0026gt;Survivor 区后对象的初始年龄变为 1)，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。\n修正（ issue552）：“Hotspot遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了survivor区的一半时，取这个年龄和MaxTenuringThreshold中更小的一个值，作为新的晋升年龄阈值”。\n动态年龄计算的代码如下\nuint ageTable::compute_tenuring_threshold(size_t survivor_capacity) { //survivor_capacity是survivor空间的大小 size_t desired_survivor_size = (size_t) ((((double) survivor_capacity)*TargetSurvivorRatio)/100); size_t total = 0; uint age = 1; while (age \u0026lt; table_size) { total += sizes[age];//sizes数组是每个年龄段对象大小 if (total \u0026gt; desired_survivor_size) break; age++; } uint result = age \u0026lt; MaxTenuringThreshold ? age : MaxTenuringThreshold; //... } 堆这里最容易出现的就是 OutOfMemoryError 错误，并且出现这种错误之后的表现形式还会有几种，比如：\nOutOfMemoryError: GC Overhead Limit Exceeded ： 当JVM花太多时间执行垃圾回收并且只能回收很少的堆空间时，就会发生此错误。 java.lang.OutOfMemoryError: Java heap space :假如在创建新的对象时, 堆内存中的空间不足以存放新创建的对象, 就会引发java.lang.OutOfMemoryError: Java heap space 错误。(和本机物理内存无关，和你配置的内存大小有关！) \u0026hellip;\u0026hellip; 2.5 方法区 # 方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。\n方法区也被称为永久代。很多人都会分不清方法区和永久代的关系，为此我也查阅了文献。\n2.5.1 方法区和永久代的关系 # 《Java 虚拟机规范》只是规定了有方法区这么个概念和它的作用，并没有规定如何去实现它。那么，在不同的 JVM 上方法区的实现肯定是不同的了。 方法区和永久代的关系很像 Java 中接口和类的关系，类实现了接口，而永久代就是 HotSpot 虚拟机对虚拟机规范中方法区的一种实现方式。 也就是说，永久代是 HotSpot 的概念，方法区是 Java 虚拟机规范中的定义，是一种规范，而永久代是一种实现，一个是标准一个是实现，其他的虚拟机实现并没有永久代这一说法。\n2.5.2 常用参数 # JDK 1.8 之前永久代还没被彻底移除的时候通常通过下面这些参数来调节方法区大小\n-XX:PermSize=N //方法区 (永久代) 初始大小 -XX:MaxPermSize=N //方法区 (永久代) 最大大小,超过这个值将会抛出 OutOfMemoryError 异常: //java.lang.OutOfMemoryError: PermGen 相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入方法区后就“永久存在”了。\nJDK 1.8 的时候，方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是直接内存。\n下面是一些常用参数：\n-XX:MetaspaceSize=N //设置 Metaspace 的初始（和最小大小） -XX:MaxMetaspaceSize=N //设置 Metaspace 的最大大小 与永久代很大的不同就是，如果不指定大小的话，随着更多类的创建，虚拟机会耗尽所有可用的系统内存。\n2.5.3 为什么要将永久代 (PermGen) 替换为元空间 (MetaSpace) 呢? # 整个永久代有一个 JVM 本身设置固定大小上限，无法进行调整，而元空间使用的是直接内存，受本机可用内存的限制，虽然元空间仍旧可能溢出，但是比原来出现的几率会更小。\n当你元空间溢出时会得到如下错误： java.lang.OutOfMemoryError: MetaSpace\n你可以使用 -XX：MaxMetaspaceSize 标志设置最大元空间大小，默认值为 unlimited，这意味着它只受系统内存的限制。-XX：MetaspaceSize 调整标志定义元空间的初始大小如果未指定此标志，则 Metaspace 将根据运行时的应用程序需求动态地重新调整大小。\n元空间里面存放的是类的元数据，这样加载多少类的元数据就不由 MaxPermSize 控制了, 而由系统的实际可用空间来控制，这样能加载的类就更多了。\n在 JDK8，合并 HotSpot 和 JRockit 的代码时, JRockit 从来没有一个叫永久代的东西, 合并之后就没有必要额外的设置这么一个永久代的地方了。\n2.6 运行时常量池 # 运行时常量池是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有常量池表（用于存放编译期生成的各种字面量和符号引用）\n既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 错误。\nJDK1.7 及之后版本的 JVM 已经将运行时常量池从方法区中移了出来，在 Java 堆（Heap）中开辟了一块区域存放运行时常量池。\n修正( issue747， reference)：\nJDK1.7之前运行时常量池逻辑包含字符串常量池存放在方法区, 此时hotspot虚拟机对方法区的实现为永久代 JDK1.7 字符串常量池被从方法区拿到了堆中, 这里没有提到运行时常量池,也就是说字符串常量池被单独拿到堆,运行时常量池剩下的东西还在方法区, 也就是hotspot中的永久代 。 JDK1.8 hotspot移除了永久代用元空间(Metaspace)取而代之, 这时候字符串常量池还在堆, 运行时常量池还在方法区, 只不过方法区的实现从永久代变成了元空间(Metaspace) 相关问题：JVM 常量池中存储的是对象还是引用呢？： https://www.zhihu.com/question/57109429/answer/151717241 by RednaxelaFX\n2.7 直接内存 # 直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 OutOfMemoryError 错误出现。\nJDK1.4 中新加入的 NIO(New Input/Output) 类，引入了一种基于通道（Channel） 与缓存区（Buffer） 的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据。\n本机直接内存的分配不会受到 Java 堆的限制，但是，既然是内存就会受到本机总内存大小以及处理器寻址空间的限制。\n3 HotSpot 虚拟机对象探秘 # 通过上面的介绍我们大概知道了虚拟机的内存情况，下面我们来详细的了解一下 HotSpot 虚拟机在 Java 堆中对象分配、布局和访问的全过程。\n3.1 对象的创建 # 下图便是 Java 对象的创建过程，我建议最好是能默写出来，并且要掌握每一步在做什么。\ngraph LR A[类加载检查] --\u0026gt;B[分配内存] --\u0026gt;C[初始化0值] --\u0026gt;D[设置对象头] --\u0026gt;E[执行init方法] 3.1.1 类加载检查 # 虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。\n3.1.2 分配内存 # 在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择哪种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。\n内存分配的两种方式：（补充内容，需要掌握）\n选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是\u0026quot;标记-清除\u0026quot;，还是\u0026quot;标记-整理\u0026quot;（也称作\u0026quot;标记-压缩\u0026quot;），值得注意的是，复制算法内存也是规整的\n\\|指针碰撞 空闲列表 适用场合 堆内存规整，没有内存碎片 堆内存不规整的情况下 原理 用过的内存整理到一边，没用过的内存整理到另一边，使用分界值指针，只要向没使用过的内存方向将指针移动对象内存大小的位置即可 虚拟机维护一个列表，该列表记录那些内存块是可用的，分配一块足够大的内存块给新对象，然后更新列表 收集器 serial， parNew CMS 内存分配并发问题（补充内容，需要掌握）\n在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全：\nCAS+失败重试： CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。 TLAB： 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配 3.1.3 初始化零值 # 内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。\n3.1.4 设置对象头 # 初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。\n3.1.5 执行 init 方法 # 在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，\u0026lt;init\u0026gt; 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 \u0026lt;init\u0026gt; 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。\n3.2 对象的内存布局 # 在 Hotspot 虚拟机中，对象在内存中的布局可以分为 3 块区域：对象头、实例数据和对齐填充。\nHotspot 虚拟机的对象头包括两部分信息，第一部分用于存储对象自身的运行时数据（哈希码、GC 分代年龄、锁状态标志等等），另一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是那个类的实例。\n实例数据部分是对象真正存储的有效信息，也是在程序中所定义的各种类型的字段内容。\n对齐填充部分不是必然存在的，也没有什么特别的含义，仅仅起占位作用。 因为 Hotspot 虚拟机的自动内存管理系统要求对象起始地址必须是 8 字节的整数倍，换句话说就是对象的大小必须是 8 字节的整数倍。而对象头部分正好是 8 字节的倍数（1 倍或 2 倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。\n3.3 对象的访问定位 # 建立对象就是为了使用对象，我们的 Java 程序通过栈上的 reference 数据来操作堆上的具体对象。对象的访问方式由虚拟机实现而定，目前主流的访问方式有①使用句柄和②直接指针两种：\n句柄： 如果使用句柄的话，那么 Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息；\n直接指针： 如果使用直接指针访问，那么 Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而 reference 中存储的直接就是对象的地址。\n这两种对象访问方式各有优势。使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销。\n4 补充内容 # 4.1 String类和常量池 # String 对象的两种创建方式：\nString str1 = \u0026#34;abcd\u0026#34;;//先检查字符串常量池中有没有\u0026#34;abcd\u0026#34;，如果字符串常量池中没有， //则创建一个，然后 str1 指向字符串常量池中的对象，如果有，则直接将 str1 指向\u0026#34;abcd\u0026#34;\u0026#34;； String str2 = new String(\u0026#34;abcd\u0026#34;);//堆中创建一个新的对象 String str3 = new String(\u0026#34;abcd\u0026#34;);//堆中创建一个新的对象 System.out.println(str1==str2);//false System.out.println(str2==str3);//false 这两种不同的创建方法是有差别的。\n第一种方式是在常量池中拿对象； 第二种方式是直接在堆内存空间创建一个新的对象。 记住一点：只要使用 new 方法，便需要创建新的对象。\n再给大家一个图应该更容易理解，图片来源： https://www.journaldev.com/797/what-is-java-string-pool：\nString 类型的常量池比较特殊。它的主要使用方法有两种：\n直接使用双引号声明出来的 String 对象会直接存储在常量池中。 如果不是用双引号声明的 String 对象，可以使用 String 提供的 intern 方法。String.intern() 是一个 Native 方法，它的作用是：如果运行时常量池中已经包含一个等于此 String 对象内容的字符串，则返回常量池中该字符串的引用；如果没有，JDK1.7之前（不包含1.7）的处理方式是在常量池中创建与此 String 内容相同的字符串，并返回常量池中创建的字符串的引用，JDK1.7以及之后的处理方式是在常量池中记录此字符串的引用，并返回该引用。 String s1 = new String(\u0026#34;计算机\u0026#34;); String s2 = s1.intern(); String s3 = \u0026#34;计算机\u0026#34;; System.out.println(s2);//计算机 System.out.println(s1 == s2);//false，因为一个是堆内存中的 String 对象一个是常量池中的 String 对象， System.out.println(s3 == s2);//true，因为两个都是常量池中的 String 对象 字符串拼接:\nString str1 = \u0026#34;str\u0026#34;; String str2 = \u0026#34;ing\u0026#34;; String str3 = \u0026#34;str\u0026#34; + \u0026#34;ing\u0026#34;;//常量池中的对象 String str4 = str1 + str2; //在堆上创建的新的对象\tString str5 = \u0026#34;string\u0026#34;;//常量池中的对象 System.out.println(str3 == str4);//false System.out.println(str3 == str5);//true System.out.println(str4 == str5);//false 尽量避免多个字符串拼接，因为这样会重新创建对象。如果需要改变字符串的话，可以使用 StringBuilder 或者 StringBuffer。\n4.2 String s1 = new String(\u0026ldquo;abc\u0026rdquo;);这句话创建了几个字符串对象？ # 将创建 1 或 2 个字符串。如果池中已存在字符串常量“abc”，则只会在堆空间创建一个字符串常量“abc”。如果池中没有字符串常量“abc”，那么它将首先在池中创建，然后在堆空间中创建，因此将创建总共 2 个字符串对象。\n验证：\nString s1 = new String(\u0026#34;abc\u0026#34;);// 堆内存的地址值 String s2 = \u0026#34;abc\u0026#34;; System.out.println(s1 == s2);// 输出 false,因为一个是堆内存，一个是常量池的内存，故两者是不同的。 System.out.println(s1.equals(s2));// 输出 true 4.3 八种基本类型的包装类和常量池 # Java 基本类型的包装类的大部分都实现了常量池技术，即 Byte,Short,Integer,Long,Character,Boolean；前面 4 种包装类默认创建了数值[-128，127] 的相应类型的缓存数据，Character创建了数值在[0,127]范围的缓存数据，Boolean 直接返回True Or False。如果超出对应范围仍然会去创建新的对象。 为啥把缓存设置为[-128，127]区间？（ 参见issue/461）性能和资源之间的权衡。\npublic static Boolean valueOf(boolean b) { return (b ? TRUE : FALSE); } private static class CharacterCache { private CharacterCache(){} static final Character cache[] = new Character[127 + 1]; static { for (int i = 0; i \u0026lt; cache.length; i++) cache[i] = new Character((char)i); } } 两种浮点数类型的包装类 Float,Double 并没有实现常量池技术。\nInteger i1 = 33; Integer i2 = 33; System.out.println(i1 == i2); // true Integer i11 = 333; Integer i22 = 333; System.out.println(i11 == i22);\t// false Double i3 = 1.2; Double i4 = 1.2; System.out.println(i3 == i4); // false Integer 缓存源代码：\n/** *此方法将始终缓存-128 到 127（包括端点）范围内的值，并可以缓存此范围之外的其他值。 */ public static Integer valueOf(int i) { if (i \u0026gt;= IntegerCache.low \u0026amp;\u0026amp; i \u0026lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); } 应用场景：\nInteger i1=40；Java 在编译的时候会直接将代码封装成 Integer i1=Integer.valueOf(40);，从而使用常量池中的对象。 Integer i1 = new Integer(40);这种情况下会创建新的对象。 Integer i1 = 40; Integer i2 = new Integer(40); System.out.println(i1==i2);//输出 false Integer 比较更丰富的一个例子:\nInteger i1 = 40; Integer i2 = 40; Integer i3 = 0; Integer i4 = new Integer(40); Integer i5 = new Integer(40); Integer i6 = new Integer(0); System.out.println(\u0026#34;i1=i2 \u0026#34; + (i1 == i2));\t// true System.out.println(\u0026#34;i1=i2+i3 \u0026#34; + (i1 == i2 + i3));\t// true System.out.println(\u0026#34;i1=i4 \u0026#34; + (i1 == i4));\t// false System.out.println(\u0026#34;i4=i5 \u0026#34; + (i4 == i5));\t// false System.out.println(\u0026#34;i4=i5+i6 \u0026#34; + (i4 == i5 + i6)); // true 自动拆箱 System.out.println(\u0026#34;40=i5+i6 \u0026#34; + (40 == i5 + i6)); // true 解释：\n语句 i4 == i5 + i6，因为+这个操作符不适用于 Integer 对象，首先 i5 和 i6 进行自动拆箱操作，进行数值相加，即 i4 == 40。然后 Integer 对象无法与数值进行直接比较，所以 i4 自动拆箱转为 int 值 40，最终这条语句转为 40 == 40 进行数值比较。\n参考 # 《深入理解 Java 虚拟机：JVM 高级特性与最佳实践（第二版》 《实战 java 虚拟机》 https://docs.oracle.com/javase/specs/index.html http://www.pointsoftware.ch/en/under-the-hood-runtime-data-areas-javas-memory-model/ https://dzone.com/articles/jvm-permgen-%E2%80%93-where-art-thou https://stackoverflow.com/questions/9095748/method-area-and-permgen 深入解析String#intern https://tech.meituan.com/2014/03/06/in-depth-understanding-string-intern.html 点击查看原文\n"},{"id":6,"href":"/zh/docs/craft/db/redis/redis-all/","title":"redis必知必会(转)","section":"redis","content":"简单来说 Redis 就是一个使用 C 语言开发的数据库，不过与传统数据库不同的是 Redis 的数据是存在内存中的 ，也就是它是内存数据库，所以读写速度非常快，因此 Redis 被广泛应用于缓存方向。\n另外，Redis 除了做缓存之外，Redis 也经常用来做分布式锁，甚至是消息队列。\nRedis 提供了多种数据类型来支持不同的业务场景。Redis 还支持事务 、持久化、Lua 脚本、多种集群方案。\n2. 分布式缓存常见的技术选型方案有哪些？ # 分布式缓存的话，使用的比较多的主要是 Memcached 和 Redis。不过，现在基本没有看过还有项目使用 Memcached 来做缓存，都是直接用 Redis。\nMemcached 是分布式缓存最开始兴起的那会，比较常用的。后来，随着 Redis 的发展，大家慢慢都转而使用更加强大的 Redis 了。\n分布式缓存主要解决的是单机缓存的容量受服务器限制并且无法保存通用的信息。因为，本地缓存只在当前服务里有效，比如如果你部署了两个相同的服务，他们两者之间的缓存数据是无法共同的。\n3. 说一下 Redis 和 Memcached 的区别和共同点 # 现在公司一般都是用 Redis 来实现缓存，而且 Redis 自身也越来越强大了！不过，了解 Redis 和 Memcached 的区别和共同点，有助于我们在做相应的技术选型的时候，能够做到有理有据！\n共同点 ：\n都是基于内存的数据库，一般都用来当做缓存使用。 都有过期策略。 两者的性能都非常高。 区别 ：\nRedis 支持更丰富的数据类型（支持更复杂的应用场景）。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。 Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memecache 把数据全部存在内存之中。 Redis 有灾难恢复机制。 因为可以把缓存中的数据持久化到磁盘上。 Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。 Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的. Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。 （Redis 6.0 引入了多线程 IO ） Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。 Memcached过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。 相信看了上面的对比之后，我们已经没有什么理由可以选择使用 Memcached 来作为自己项目的分布式缓存了。\n4. 缓存数据的处理流程是怎样的？ # 作为暖男一号，我给大家画了一个草图。\ngraph TD A[User] --\u003e|Query data| B{In cache} B --\u003e|Y|C[Return data] B --\u003e|N|D{In DB} D --\u003e|Y|E[Update cache] --\u003eC D --\u003e|N|F[Return null] 简单来说就是:\n如果用户请求的数据在缓存中就直接返回。 缓存中不存在的话就看数据库中是否存在。 数据库中存在的话就更新缓存中的数据。 数据库中不存在的话就返回空数据。 5. 为什么要用 Redis/为什么要用缓存？ # 简单，来说使用缓存主要是为了提升用户体验以及应对更多的用户。\n下面我们主要从“高性能”和“高并发”这两点来看待这个问题。\ngraph TD A[User] --\u003e|Load Balance| B(nginx) B --\u003e|1|C[Business 1] B --\u003e|2|D[Business 2] C \u0026 D--\u003eE[(Cache)] E --\u003e F[(DataBase)] 高性能 ：\n对照上面 👆 我画的图。我们设想这样的场景：\n假如用户第一次访问数据库中的某些数据的话，这个过程是比较慢，毕竟是从硬盘中读取的。但是，如果说，用户访问的数据属于高频数据并且不会经常改变的话，那么我们就可以很放心地将该用户访问的数据存在缓存中。\n这样有什么好处呢？ 那就是保证用户下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。\n不过，要保持数据库和缓存中的数据的一致性。 如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据即可！\n高并发：\n一般像 MySQL 这类的数据库的 QPS 大概都在 1w 左右（4 核 8g） ，但是使用 Redis 缓存之后很容易达到 10w+，甚至最高能达到 30w+（就单机 redis 的情况，redis 集群的话会更高）。\nQPS（Query Per Second）：服务器每秒可以执行的查询次数；\n所以，直接操作缓存能够承受的数据库请求数量是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。进而，我们也就提高的系统整体的并发。\n6. Redis 常见数据结构以及使用场景分析 # 你可以自己本机安装 redis 或者通过 redis 官网提供的 在线 redis 环境。\n6.1. string # 介绍 ：string 数据结构是简单的 key-value 类型。虽然 Redis 是用 C 语言写的，但是 Redis 并没有使用 C 的字符串表示，而是自己构建了一种 简单动态字符串（simple dynamic string，SDS）。相比于 C 的原生字符串，Redis 的 SDS 不光可以保存文本数据还可以保存二进制数据，并且获取字符串长度复杂度为 O(1)（C 字符串为 O(N)）,除此之外,Redis 的 SDS API 是安全的，不会造成缓冲区溢出。 常用命令: set,get,strlen,exists,dect,incr,setex 等等。 应用场景 ：一般常用在需要计数的场景，比如用户的访问次数、热点文章的点赞转发数量等等。 下面我们简单看看它的使用！\n普通字符串的基本操作：\n127.0.0.1:6379\u0026gt; set key value #设置 key-value 类型的值 OK 127.0.0.1:6379\u0026gt; get key # 根据 key 获得对应的 value \u0026#34;value\u0026#34; 127.0.0.1:6379\u0026gt; exists key # 判断某个 key 是否存在 (integer) 1 127.0.0.1:6379\u0026gt; strlen key # 返回 key 所储存的字符串值的长度。 (integer) 5 127.0.0.1:6379\u0026gt; del key # 删除某个 key 对应的值 (integer) 1 127.0.0.1:6379\u0026gt; get key (nil) 批量设置 :\n127.0.0.1:6379\u0026gt; mset key1 value1 key2 value2 # 批量设置 key-value 类型的值 OK 127.0.0.1:6379\u0026gt; mget key1 key2 # 批量获取多个 key 对应的 value 1) \u0026#34;value1\u0026#34; 2) \u0026#34;value2\u0026#34; 计数器（字符串的内容为整数的时候可以使用）：\n127.0.0.1:6379\u0026gt; set number 1 OK 127.0.0.1:6379\u0026gt; incr number # 将 key 中储存的数字值增一 (integer) 2 127.0.0.1:6379\u0026gt; get number \u0026#34;2\u0026#34; 127.0.0.1:6379\u0026gt; decr number # 将 key 中储存的数字值减一 (integer) 1 127.0.0.1:6379\u0026gt; get number \u0026#34;1\u0026#34; 过期：\n127.0.0.1:6379\u0026gt; expire key 60 # 数据在 60s 后过期 (integer) 1 127.0.0.1:6379\u0026gt; setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire) OK 127.0.0.1:6379\u0026gt; ttl key # 查看数据还有多久过期 (integer) 56 6.2. list # 介绍 ：list 即是 链表。链表是一种非常常见的数据结构，特点是易于数据元素的插入和删除并且且可以灵活调整链表长度，但是链表的随机访问困难。许多高级编程语言都内置了链表的实现比如 Java 中的 LinkedList，但是 C 语言并没有实现链表，所以 Redis 实现了自己的链表数据结构。Redis 的 list 的实现为一个 双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。 常用命令: rpush,lpop,lpush,rpop,lrange、llen 等。 应用场景: 发布与订阅或者说消息队列、慢查询。 下面我们简单看看它的使用！\n通过 rpush/lpop 实现队列：\n127.0.0.1:6379\u0026gt; rpush myList value1 # 向 list 的头部（右边）添加元素 (integer) 1 127.0.0.1:6379\u0026gt; rpush myList value2 value3 # 向list的头部（最右边）添加多个元素 (integer) 3 127.0.0.1:6379\u0026gt; lpop myList # 将 list的尾部(最左边)元素取出 \u0026#34;value1\u0026#34; 127.0.0.1:6379\u0026gt; lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end 1) \u0026#34;value2\u0026#34; 2) \u0026#34;value3\u0026#34; 127.0.0.1:6379\u0026gt; lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一 1) \u0026#34;value2\u0026#34; 2) \u0026#34;value3\u0026#34; 通过 rpush/rpop 实现栈：\n127.0.0.1:6379\u0026gt; rpush myList2 value1 value2 value3 (integer) 3 127.0.0.1:6379\u0026gt; rpop myList2 # 将 list的头部(最右边)元素取出 \u0026#34;value3\u0026#34; 我专门花了一个图方便小伙伴们来理解：\n通过 lrange 查看对应下标范围的列表元素：\n127.0.0.1:6379\u0026gt; rpush myList value1 value2 value3 (integer) 3 127.0.0.1:6379\u0026gt; lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end 1) \u0026#34;value1\u0026#34; 2) \u0026#34;value2\u0026#34; 127.0.0.1:6379\u0026gt; lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一 1) \u0026#34;value1\u0026#34; 2) \u0026#34;value2\u0026#34; 3) \u0026#34;value3\u0026#34; 通过 lrange 命令，你可以基于 list 实现分页查询，性能非常高！\n通过 llen 查看链表长度：\n127.0.0.1:6379\u0026gt; llen myList (integer) 3 6.3. hash # 介绍 ：hash 类似于 JDK1.8 前的 HashMap，内部实现也差不多(数组 + 链表)。不过，Redis 的 hash 做了更多优化。另外，hash 是一个 string 类型的 field 和 value 的映射表，特别适合用于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。 比如我们可以 hash 数据结构来存储用户信息，商品信息等等。 常用命令： hset,hmset,hexists,hget,hgetall,hkeys,hvals 等。 应用场景: 系统中对象数据的存储。 下面我们简单看看它的使用！\n127.0.0.1:6379\u0026gt; hset userInfoKey name \u0026#34;guide\u0026#34; description \u0026#34;dev\u0026#34; age \u0026#34;24\u0026#34; OK 127.0.0.1:6379\u0026gt; hexists userInfoKey name # 查看 key 对应的 value中指定的字段是否存在。 (integer) 1 127.0.0.1:6379\u0026gt; hget userInfoKey name # 获取存储在哈希表中指定字段的值。 \u0026#34;guide\u0026#34; 127.0.0.1:6379\u0026gt; hget userInfoKey age \u0026#34;24\u0026#34; 127.0.0.1:6379\u0026gt; hgetall userInfoKey # 获取在哈希表中指定 key 的所有字段和值 1) \u0026#34;name\u0026#34; 2) \u0026#34;guide\u0026#34; 3) \u0026#34;description\u0026#34; 4) \u0026#34;dev\u0026#34; 5) \u0026#34;age\u0026#34; 6) \u0026#34;24\u0026#34; 127.0.0.1:6379\u0026gt; hkeys userInfoKey # 获取 key 列表 1) \u0026#34;name\u0026#34; 2) \u0026#34;description\u0026#34; 3) \u0026#34;age\u0026#34; 127.0.0.1:6379\u0026gt; hvals userInfoKey # 获取 value 列表 1) \u0026#34;guide\u0026#34; 2) \u0026#34;dev\u0026#34; 3) \u0026#34;24\u0026#34; 127.0.0.1:6379\u0026gt; hset userInfoKey name \u0026#34;GuideGeGe\u0026#34; # 修改某个字段对应的值 127.0.0.1:6379\u0026gt; hget userInfoKey name \u0026#34;GuideGeGe\u0026#34; 6.4. set # 介绍 ： set 类似于 Java 中的 HashSet 。Redis 中的 set 类型是一种无序集合，集合中的元素没有先后顺序。当你需要存储一个列表数据，又不希望出现重复数据时，set 是一个很好的选择，并且 set 提供了判断某个成员是否在一个 set 集合内的重要接口，这个也是 list 所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。比如：你可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis 可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程。 常用命令： sadd,spop,smembers,sismember,scard,sinterstore,sunion 等。 应用场景: 需要存放的数据不能重复以及需要获取多个数据源交集和并集等场景 下面我们简单看看它的使用！\n127.0.0.1:6379\u0026gt; sadd mySet value1 value2 # 添加元素进去 (integer) 2 127.0.0.1:6379\u0026gt; sadd mySet value1 # 不允许有重复元素 (integer) 0 127.0.0.1:6379\u0026gt; smembers mySet # 查看 set 中所有的元素 1) \u0026#34;value1\u0026#34; 2) \u0026#34;value2\u0026#34; 127.0.0.1:6379\u0026gt; scard mySet # 查看 set 的长度 (integer) 2 127.0.0.1:6379\u0026gt; sismember mySet value1 # 检查某个元素是否存在set 中，只能接收单个元素 (integer) 1 127.0.0.1:6379\u0026gt; sadd mySet2 value2 value3 (integer) 2 127.0.0.1:6379\u0026gt; sinterstore mySet3 mySet mySet2 # 获取 mySet 和 mySet2 的交集并存放在 mySet3 中 (integer) 1 127.0.0.1:6379\u0026gt; smembers mySet3 1) \u0026#34;value2\u0026#34; 6.5. sorted set # 介绍： 和 set 相比，sorted set 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。有点像是 Java 中 HashMap 和 TreeSet 的结合体。 常用命令： zadd,zcard,zscore,zrange,zrevrange,zrem 等。 应用场景： 需要对数据根据某个权重进行排序的场景。比如在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息。 127.0.0.1:6379\u0026gt; zadd myZset 3.0 value1 # 添加元素到 sorted set 中 3.0 为权重 (integer) 1 127.0.0.1:6379\u0026gt; zadd myZset 2.0 value2 1.0 value3 # 一次添加多个元素 (integer) 2 127.0.0.1:6379\u0026gt; zcard myZset # 查看 sorted set 中的元素数量 (integer) 3 127.0.0.1:6379\u0026gt; zscore myZset value1 # 查看某个 value 的权重 \u0026#34;3\u0026#34; 127.0.0.1:6379\u0026gt; zrange myZset 0 -1 # 顺序输出某个范围区间的元素，0 -1 表示输出所有元素 1) \u0026#34;value3\u0026#34; 2) \u0026#34;value2\u0026#34; 3) \u0026#34;value1\u0026#34; 127.0.0.1:6379\u0026gt; zrange myZset 0 1 # 顺序输出某个范围区间的元素，0 为 start 1 为 stop 1) \u0026#34;value3\u0026#34; 2) \u0026#34;value2\u0026#34; 127.0.0.1:6379\u0026gt; zrevrange myZset 0 1 # 逆序输出某个范围区间的元素，0 为 start 1 为 stop 1) \u0026#34;value1\u0026#34; 2) \u0026#34;value2\u0026#34; 7. Redis 单线程模型详解 # Redis 基于 Reactor 模式来设计开发了自己的一套高效的事件处理模型 （Netty 的线程模型也基于 Reactor 模式，Reactor 模式不愧是高性能 IO 的基石），这套事件处理模型对应的是 Redis 中的文件事件处理器（file event handler）。由于文件事件处理器（file event handler）是单线程方式运行的，所以我们一般都说 Redis 是单线程模型。\n既然是单线程，那怎么监听大量的客户端连接呢？\nRedis 通过IO 多路复用程序 来监听来自客户端的大量连接（或者说是监听多个 socket），它会将感兴趣的事件及类型(读、写）注册到内核中并监听每个事件是否发生。\n这样的好处非常明显： I/O 多路复用技术的使用让 Redis 不需要额外创建多余的线程来监听客户端的大量连接，降低了资源的消耗（和 NIO 中的 Selector 组件很像）。\n另外， Redis 服务器是一个事件驱动程序，服务器需要处理两类事件： 1. 文件事件; 2. 时间事件。\n时间事件不需要多花时间了解，我们接触最多的还是 文件事件（客户端进行读取写入等操作，涉及一系列网络通信）。\n《Redis 设计与实现》有一段话是如是介绍文件事件的，我觉得写得挺不错。\nRedis 基于 Reactor 模式开发了自己的网络事件处理器：这个处理器被称为文件事件处理器（file event handler）。文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字，并根据 套接字目前执行的任务来为套接字关联不同的事件处理器。\n当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关 闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。\n虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。\n可以看出，文件事件处理器（file event handler）主要是包含 4 个部分：\n多个 socket（客户端连接） IO 多路复用程序（支持多个客户端连接的关键） 文件事件分派器（将 socket 关联到相应的事件处理器） 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器） 《Redis设计与实现：12章》\n8. Redis 没有使用多线程？为什么不使用多线程？ # 虽然说 Redis 是单线程模型，但是， 实际上，Redis 在 4.0 之后的版本中就已经加入了对多线程的支持。\n不过，Redis 4.0 增加的多线程主要是针对一些大键值对的删除操作的命令，使用这些命令就会使用主处理之外的其他线程来“异步处理”。\n大体上来说，Redis 6.0 之前主要还是单线程处理。\n那，Redis6.0 之前 为什么不使用多线程？\n我觉得主要原因有下面 3 个：\n单线程编程容易并且更容易维护； Redis 的性能瓶颈不再 CPU ，主要在内存和网络； 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。 9. Redis6.0 之后为何引入了多线程？ # Redis6.0 引入多线程主要是为了提高网络 IO 读写性能，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。\n虽然，Redis6.0 引入了多线程，但是 Redis 的多线程只是在网络数据的读写这类耗时操作上使用了， 执行命令仍然是单线程顺序执行。因此，你也不需要担心线程安全问题。\nRedis6.0 的多线程默认是禁用的，只使用主线程。如需开启需要修改 redis 配置文件 redis.conf ：\nio-threads-do-reads yes 开启多线程后，还需要设置线程数，否则是不生效的。同样需要修改 redis 配置文件 redis.conf :\nio-threads 4 #官网建议4核的机器建议设置为2或3个线程，8核的建议设置为6个线程 推荐阅读：\nRedis 6.0 新特性-多线程连环 13 问！ 为什么 Redis 选择单线程模型 10. Redis 给缓存数据设置过期时间有啥用？ # 一般情况下，我们设置保存的缓存数据的时候都会设置一个过期时间。为什么呢？\n因为内存是有限的，如果缓存中的所有数据都是一直保存的话，分分钟直接Out of memory。\nRedis 自带了给缓存数据设置过期时间的功能，比如：\n127.0.0.1:6379\u0026gt; exp key 60 # 数据在 60s 后过期 (integer) 1 127.0.0.1:6379\u0026gt; setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire) OK 127.0.0.1:6379\u0026gt; ttl key # 查看数据还有多久过期 (integer) 56 注意：**Redis中除了字符串类型有自己独有设置过期时间的命令 setex 外，其他方法都需要依靠 expire 命令来设置过期时间 。另外， persist 命令可以移除一个键的过期时间： **\n过期时间除了有助于缓解内存的消耗，还有什么其他用么？\n很多时候，我们的业务场景就是需要某个数据只在某一时间段内存在，比如我们的短信验证码可能只在1分钟内有效，用户登录的 token 可能只在 1 天内有效。\n如果使用传统的数据库来处理的话，一般都是自己判断过期，这样更麻烦并且性能要差很多。\n11. Redis是如何判断数据是否过期的呢？ # Redis 通过一个叫做过期字典（可以看作是hash表）来保存数据过期的时间。过期字典的键指向Redis数据库中的某个key(键)，过期字典的值是一个long long类型的整数，这个整数保存了key所指向的数据库键的过期时间（毫秒精度的UNIX时间戳）。\n过期字典是存储在redisDb这个结构里的：\ntypedef struct redisDb { ... dict *dict; //数据库键空间,保存着数据库中所有键值对 dict *expires // 过期字典,保存着键的过期时间 ... } redisDb; 12. 过期的数据的删除策略了解么？ # 如果假设你设置了一批 key 只能存活 1 分钟，那么 1 分钟后，Redis 是怎么对这批 key 进行删除的呢？\n常用的过期数据的删除策略就两个（重要！自己造缓存轮子的时候需要格外考虑的东西）：\n惰性删除 ：只会在取出key的时候才对数据进行过期检查。这样对CPU最友好，但是可能会造成太多过期 key 没有被删除。 定期删除 ： 每隔一段时间抽取一批 key 执行删除过期key操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。 定期删除对内存更加友好，惰性删除对CPU更加友好。两者各有千秋，所以Redis 采用的是 定期删除+惰性/懒汉式删除 。\n但是，仅仅通过给 key 设置过期时间还是有问题的。因为还是可能存在定期删除和惰性删除漏掉了很多过期 key 的情况。这样就导致大量过期 key 堆积在内存里，然后就Out of memory了。\n怎么解决这个问题呢？答案就是： Redis 内存淘汰机制。\n13. Redis 内存淘汰机制了解么？ # 相关问题：MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，如何保证 Redis 中的数据都是热点数据?\nRedis 提供 6 种数据淘汰策略：\nvolatile-lru（least recently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru（least recently used）：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的） allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！ 4.0 版本后增加以下两种：\nvolatile-lfu（least frequently used）：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰 allkeys-lfu（least frequently used）：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key 14. Redis 持久化机制(怎么保证 Redis 挂掉之后再重启数据可以进行恢复) # 很多时候我们需要持久化数据也就是将内存中的数据写入到硬盘里面，大部分原因是为了之后重用数据（比如重启机器、机器故障之后恢复数据），或者是为了防止系统故障而将数据备份到一个远程位置。\nRedis 不同于 Memcached 的很重要一点就是，Redis 支持持久化，而且支持两种不同的持久化操作。Redis 的一种持久化方式叫快照（snapshotting，RDB），另一种方式是只追加文件（append-only file, AOF）。这两种方法各有千秋，下面我会详细这两种持久化方法是什么，怎么用，如何选择适合自己的持久化方法。\n快照（snapshotting）持久化（RDB）\nRedis 可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis 创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能），还可以将快照留在原地以便重启服务器的时候使用。\n快照持久化是 Redis 默认采用的持久化方式，在 Redis.conf 配置文件中默认有此下配置：\nsave 900 1 #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 save 300 10 #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 save 60 10000 #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 AOF（append-only file）持久化\n与快照持久化相比，AOF 持久化 的实时性更好，因此已成为主流的持久化方案。默认情况下 Redis 没有开启 AOF（append only file）方式的持久化，可以通过 appendonly 参数开启：\nappendonly yes 开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入硬盘中的 AOF 文件。AOF 文件的保存位置和 RDB 文件的位置相同，都是通过 dir 参数设置的，默认的文件名是 appendonly.aof。\n在 Redis 的配置文件中存在三种不同的 AOF 持久化方式，它们分别是：\nappendfsync always #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度 appendfsync everysec #每秒钟同步一次，显示地将多个写命令同步到硬盘 appendfsync no #让操作系统决定何时进行同步 为了兼顾数据和写入性能，用户可以考虑 appendfsync everysec 选项 ，让 Redis 每秒同步一次 AOF 文件，Redis 性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis 还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。\n相关 issue ： 783：Redis 的 AOF 方式\n拓展：Redis 4.0 对于持久化机制的优化\nRedis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 aof-use-rdb-preamble 开启）。\n如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。\n补充内容：AOF 重写\nAOF 重写可以产生一个新的 AOF 文件，这个新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。\nAOF 重写是一个有歧义的名字，该功能是通过读取数据库中的键值对来实现的，程序无须对现有 AOF 文件进行任何读入、分析或者写入操作。\n在执行 BGREWRITEAOF 命令时，Redis 服务器会维护一个 AOF 重写缓冲区，该缓冲区会在子进程创建新 AOF 文件期间，记录服务器执行的所有写命令。当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾，使得新旧两个 AOF 文件所保存的数据库状态一致。最后，服务器用新的 AOF 文件替换旧的 AOF 文件，以此来完成 AOF 文件重写操作\n15. Redis 事务 # Redis 可以通过 MULTI，EXEC，DISCARD 和 WATCH 等命令来实现事务(transaction)功能。\n\u0026gt; MULTI OK \u0026gt; INCR foo QUEUED \u0026gt; INCR bar QUEUED \u0026gt; EXEC 1) (integer) 1 2) (integer) 1 使用 MULTI命令后可以输入多个命令。Redis不会立即执行这些命令，而是将它们放到队列，当调用了 EXEC命令将执行所有命令。\nRedis官网相关介绍 https://redis.io/topics/transactions 如下：\n但是，Redis 的事务和我们平时理解的关系型数据库的事务不同。我们知道事务具有四大特性： 1. 原子性，2. 隔离性，3. 持久性，4. 一致性。\n原子性（Atomicity）： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 隔离性（Isolation）： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性（Durability）： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 一致性（Consistency）： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的； Redis 是不支持 roll back 的，因而不满足原子性的（而且不满足持久性）。\nRedis官网也解释了自己为啥不支持回滚。简单来说就是Redis开发者们觉得没必要支持回滚，这样更简单便捷并且性能更好。Redis开发者觉得即使命令执行错误也应该在开发过程中就被发现而不是生产过程中。\n你可以将Redis中的事务就理解为 ：Redis事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断。\n相关issue : issue452: 关于 Redis 事务不满足原子性的问题 ，推荐阅读： https://zhuanlan.zhihu.com/p/43897838 。\n16. 缓存穿透 # 16.1. 什么是缓存穿透？ # 缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。\n16.2. 缓存穿透情况的处理流程是怎样的？ # 如下图所示，用户的请求最终都要跑到数据库中查询一遍。\ngraph TD A[User] --\u003e|Query data|B{In cache} B --\u003e|N|C[(DataBase)] 16.3. 有哪些解决办法？ # 最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。\n1）缓存无效 key\n如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，具体命令如下： SET key value EX 10086 。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。\n另外，这里多说一嘴，一般情况下我们是这样设计 key 的： 表名:列名:主键名:主键值 。\n如果用 Java 代码展示的话，差不多是下面这样的：\npublic Object getObjectInclNullById(Integer id) { // 从缓存中获取数据 Object cacheValue = cache.get(id); // 缓存为空 if (cacheValue == null) { // 从数据库中获取 Object storageValue = storage.get(key); // 缓存空对象 cache.set(key, storageValue); // 如果存储数据为空，需要设置一个过期时间(300秒) if (storageValue == null) { // 必须设置过期时间，否则有被攻击的风险 cache.expire(key, 60 * 5); } return storageValue; } return cacheValue; } 2）布隆过滤器\n布隆过滤器是一个非常神奇的数据结构，通过它我们可以非常方便地判断一个给定数据是否存在于海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要找的那个“人”。\n具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。\n加入布隆过滤器之后的缓存处理流程图如下。\ngraph TD A[User] --\u003e|Query data|B{Bloom filter} B --\u003e|valid key|C[Query Cache] B --\u003e|unexist key|D([Return illegal request]) C --\u003e F[Continue...] 但是，需要注意的是布隆过滤器可能会存在误判的情况。总结来说就是： 布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。\n为什么会出现误判的情况呢? 我们还要从布隆过滤器的原理来说！\n我们先来看一下，当一个元素加入布隆过滤器中的时候，会进行哪些操作：\n使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。 根据得到的哈希值，在位数组中把对应下标的值置为 1。 我们再来看一下，当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行哪些操作：\n对给定元素再次进行相同的哈希计算； 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。 然后，一定会出现这样一种情况：不同的字符串可能哈希出来的位置相同。 （可以适当增加位数组大小或者调整我们的哈希函数来降低概率）\n更多关于布隆过滤器的内容可以看我的这篇原创： 《不了解布隆过滤器？一文给你整的明明白白！》 ，强烈推荐，个人感觉网上应该找不到总结的这么明明白白的文章了。\n17. 缓存雪崩 # 17.1. 什么是缓存雪崩？ # 我发现缓存雪崩这名字起的有点意思，哈哈。\n实际上，缓存雪崩描述的就是这样一个简单的场景：缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。 这就好比雪崩一样，摧枯拉朽之势，数据库的压力可想而知，可能直接就被这么多请求弄宕机了。\n举个例子：系统的缓存模块出了问题比如宕机导致不可用。造成系统的所有访问，都要走数据库。\n还有一种缓存雪崩的场景是：有一些被大量访问数据（热点缓存）在某一时刻大面积失效，导致对应的请求直接落到了数据库上。 这样的情况，有下面几种解决办法：\n举个例子 ：秒杀开始 12 个小时之前，我们统一存放了一批商品到 Redis 中，设置的缓存过期时间也是 12 个小时，那么秒杀开始的时候，这些秒杀的商品的访问直接就失效了。导致的情况就是，相应的请求直接就落到了数据库上，就像雪崩一样可怕。\n17.2. 有哪些解决办法？ # 针对 Redis 服务不可用的情况：\n采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。 限流，避免同时处理大量的请求。 针对热点缓存失效的情况：\n设置不同的失效时间比如随机设置缓存的失效时间。 缓存永不失效。 18. 如何保证缓存和数据库数据的一致性？ # 细说的话可以扯很多，但是我觉得其实没太大必要（小声BB：很多解决方案我也没太弄明白）。我个人觉得引入缓存之后，如果为了短时间的不一致性问题，选择让系统设计变得更加复杂的话，完全没必要。\n下面单独对 Cache Aside Pattern（旁路缓存模式） 来聊聊。\nCache Aside Pattern 中遇到写请求是这样的：更新 DB，然后直接删除 cache 。\n如果更新数据库成功，而删除缓存这一步失败的情况的话，简单说两个解决方案：\n缓存失效时间变短（不推荐，治标不治本） ：我们让缓存数据的过期时间变短，这样的话缓存就会从数据库中加载数据。另外，这种解决办法对于先操作缓存后操作数据库的场景不适用。 增加cache更新重试机制（常用）： 如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将 缓存中对应的 key 删除即可。 19. 参考 # 《Redis 开发与运维》 《Redis 设计与实现》 Redis 命令总结：http://Redisdoc.com/string/set.html 通俗易懂的 Redis 数据结构基础教程： https://juejin.im/post/5b53ee7e5188251aaa2d2e16 WHY Redis choose single thread (vs multi threads): https://medium.com/@jychen7/sharing-redis-single-thread-vs-multi-threads-5870bd44d153 点击查看原文\n"},{"id":7,"href":"/zh/docs/java/concurrency/1%E7%BA%BF%E7%A8%8B%E4%B8%8E%E4%BB%BB%E5%8A%A1_1/","title":"线程与任务(一)","section":"并发编程","content":"并发的本质是多个线程同时处理某个任务1，不同于进程，线程可以访问同一共享资源（临界资源），当程序不够健壮时，使用多线程就可能带来问题，这是要反复讨论并发的原因之一。\n在Java中，必须明白一点：线程由Thread类启动，但Thread类并不执行任何操作，它只是驱动赋予它的任务。因此将线程与任务的概念区分开，有利于理解并发。\n实际上，开发过程中线程与任务（的联系）被隔离的更加明显，往往不需要显式地声明(创建)线程，然后将任务（声明任务是必须的）分配给线程，并由线程负责驱动（ allocate task to thread to execute ），这一过程通常由线程池完成 。\n任务 # 任务是由线程驱动的，因此声明任务然后将其交给线程即可。\n可以使用Runnable2接口来声明任务，Runnable是一个函数式接口，定义了一个run()方法，因此常见的创建线程的方式就是：\nnew Thread(()-\u0026gt;{ //do some thing }) Thread类实际上实现了Runnable接口。\n将其还原为普通类，那就是一个实现了Runnable接口的类可以作为任务分配给线程，重要的是你需要定义好“任务要做什么”——重写run()方法：\nclass LiftOff implements Runnable { private static int taskCount = 0; protected int countDown = 10; private final int id = taskCount++; public LiftOff() { } public LiftOff(int countDown) { this.countDown = countDown; } public String status() { return \u0026#34;#\u0026#34; + id + \u0026#34;(\u0026#34; + (countDown \u0026gt; 0 ? countDown : \u0026#34;LiftOff!\u0026#34;) + \u0026#34;), \u0026#34;; } // 线程运行的核心代码 @Override public void run() { while (countDown-- \u0026gt; 0) { System.out.print(status()); // 线程调度 Thread.yield(); } } } 上例中的LiftOff类实现了Runnable接口，但是你无法再将其转化为lambda，因为其是一个“更为丰富的类”：有区分实例的id，有构造器以及实例方法。\n通常，run()方法被设计为某种形式的循环甚至无限循环。\nThread.yield()是Java的线程调度机制之一，它声明“当前线程可以让出CPU时间，其他线程需要运行的就去运行吧”，遗憾的是它仅仅是一个建议，其他线程不一定真的会获取CPU时间并运行。\n因此，从Runnable导出的类，除了必须声明run()方法之外，其不会产生任何的线程能力，要实现线程行为，必须显式地将其分配给线程。\nnew LiftOff().run()可以直接调用，但这并不会开启一个单独线程，而是在当前线程中顺序执行的。\n可以将Runnable接口理解为必需声明的任务。\n线程 # Thread即线程。将Runnable转为 工作任务 的传统方法就是将其提交给Thread类构造器：\nprivate static void single() { Thread t = new Thread(new LiftOff()); t.start(); System.out.println(\u0026#34;waiting for liftoff\u0026#34;); } /* output: waiting for liftoff #0(9), #0(8), #0(7), #0(6), #0(5), #0(4), #0(3), #0(2), #0(1), #0(LiftOff!), *///:~ 从输出可以看到，start()迅速地返回了，而由start()开启的新线程的工作任务还在执行，此例中，main线程（主线程）与LiftOff.run()线程“同时”执行。\n可以很容易地利用循环创建多个线程去驱动更多任务3：\nstatic void multi() { for (int i = 0; i \u0026lt; 5; i++) { new Thread(new LiftOff()).start(); } System.out.println(\u0026#34;waiting for liftoff\u0026#34;); } /* output:（sample） #1(9), #4(9), waiting for liftoff #3(9), #2(9), #0(9), #2(8), #0(8), #3(8), #4(8), #1(8), #4(7), #3(7), #4(6), #2(7), #0(7), #2(6), #4(5), #3(6), #1(7), #3(5), #4(4), #2(5), #0(6), #2(4), #4(3), #3(4), #1(6), #3(3), #4(2), #2(3), #0(5), #2(2), #4(1), #3(2), #1(5), #3(1), #4(LiftOff!), #2(1), #0(4), #2(LiftOff!), #3(LiftOff!), #1(4), #0(3), #0(2), #1(3), #0(1), #1(2), #0(LiftOff!), #1(1), #1(LiftOff!), *///:~ 可以看到，不同任务的执行时混乱无序的，这是由线程调度自动控制的。\n线程生命周期 # 生命周期 描述 NEW 线程被创建。 RUNNABLE 调用start()方法之后，这个线程可能在或不在运行，因为其要等等CPU时间。 BLOCKED 当一个线程尝试获取对象的内部锁失败时，该线程进入阻塞状态。 WAITING 当线程等待另一个线程通知调度器一个条件时，它自己进入等待状态。如调用Object.wait()、Thread.join()、Thread.sleep()方法时，或等待Lock/Condition时。这个状态下的线程响应中断。 TIMED_WAITING 带有超时参数的方法调用时会让线程进入超时等待。这个状态下的线程响应中断。 TERMINATED 1）run()方法正常退出，2）没有捕获的异常终止了run()方法。 线程的状态转换示意图\n线程优先级 # 线程的优先级将线程的重要性传递给调度器，尽管CPU处理线程的顺序是不确定的，但是调度器倾向于优先让优先级高的线程执行4。\nJava语言中，每个线程都有一个优先级，默认情况下，一个线程的优先级继承自其父线程。\n在绝大多数时间里，线程都应该以默认优先级在运行，试图利用优先级操纵线程是愚蠢的行为。\npublic class SimplePrioroites implements Runnable { private int countDown = 2; private volatile double d; private int priority; public SimplePrioroites(int priority) { this.priority = priority; } @Override public String toString() { return Thread.currentThread() + \u0026#34;: \u0026#34; + countDown; } @Override public void run() { Thread.currentThread().setPriority(priority); while (true) { for (int i = 0; i \u0026lt; 100000; i++) { // 耗时操作 d += (Math.PI + Math.E) / (double) i; if (i % 1000 == 0) { Thread.yield(); } } System.out.println(this); if (--countDown == 0) { return; } } } public static void main(String[] args) { ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i \u0026lt; 5 ; i++) { executorService.execute(new SimplePrioroites(Thread.MIN_PRIORITY)); } executorService.execute(new SimplePrioroites(Thread.MAX_PRIORITY)); executorService.shutdown(); } } /* output: Thread[pool-1-thread-2,1,main]: 2 Thread[pool-1-thread-5,1,main]: 2 Thread[pool-1-thread-3,1,main]: 2 Thread[pool-1-thread-1,1,main]: 2 Thread[pool-1-thread-4,1,main]: 2 Thread[pool-1-thread-6,10,main]: 2 Thread[pool-1-thread-3,1,main]: 1 Thread[pool-1-thread-2,1,main]: 1 Thread[pool-1-thread-5,1,main]: 1 Thread[pool-1-thread-1,1,main]: 1 Thread[pool-1-thread-4,1,main]: 1 Thread[pool-1-thread-6,10,main]: 1 *///:~ 事实上，尽管设置了线程优先级，并且使用了10w次浮点运算来尝试让线程调度优先选择优先级高的线程[^8]，实际上却没有收到预期效果，说明线程优先级并不能准确地调度线程。\n守护线程 # 有些地方称之为后台（daemon）线程，一般在程序运行时在后台提供通用服务，守护线程在程序开发中并不是必不可少的。\n当所有的非后台线程终止时，程序也会终止，同时也会杀死所有的守护线程。\n不要误用守护线程，不应该使用守护线程去访问资源——一旦主程序结束，守护线程也会被杀死。\n在守护线程里创建的线程一定也是守护线程。\n可以使用setDaemon(true)在start()之前将线程设置为守护线程，同时可以使用isDaemon()查看线程是否为守护线程：\npublic class Daemons { public static void main(String[] args) { Thread t =new Thread(new Daemon()); t.setDaemon(true); t.start(); try { TimeUnit.MILLISECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } } static class Daemon implements Runnable { private List\u0026lt;Thread\u0026gt; threads = new ArrayList\u0026lt;\u0026gt;(); @Override public void run() { for (int i = 0; i \u0026lt; Integer.MAX_VALUE; i++) { threads.add(i, new Thread(new ThreadSpawn())); threads.get(i).start(); // System.out.println(\u0026#34;ThreadSpawn \u0026#34; + i + \u0026#34; started\u0026#34;); System.out.println(\u0026#34;thread[\u0026#34;+i+\u0026#34;].isDaemon: \u0026#34; + threads.get(i).isDaemon()); } // while (true) Thread.yield(); } } static class ThreadSpawn implements Runnable { @Override public void run() { Thread.yield(); } } } /* output: (sample) thread[0].isDaemon: true thread[1].isDaemon: true thread[2].isDaemon: true thread[3].isDaemon: true thread[4].isDaemon: true *///:~ 上例中，Daemon被设置为守护线程，其派生出的许多线程虽然没有被显示的声明为守护线程，其也确实是守护线程。注意到，Daemon线程的run()方法是一个“很大”的循环，但实际上只循环了几次，那是因为主线程结束了，守护线程于是也被杀死了。\n守护线程不会执行finally子句，这是因为守护线程被设计为“强制关闭“的，一旦所有的非守护线程终止，守护线程就会”突然“关闭，不允许存在执行finally块这样”优雅“的行为。\nThe Java Virtual Machine exits when the only threads running are all daemon threads.\n当只有守护线程在运行时，JVM就会退出。所以，上述示例在主线程结束休眠后立刻结束运行了。\nGC垃圾收集器就是使用了守护线程的特性。\n线程的中断状态 # 这是一个比较晦涩的概念。\n当run()方法正常返回或遇到异常时，线程终止运行，除此之外，无法强制终止线程5。\n但是，线程有一个中断状态（ interrupted state ），调用Thread.interrup()方法时，线程的中断状态将被设置（ interrupt status will be set ）。\n若线程调用 wait()、join()、sleep()、park()等及其重载方法进入等待，在此线程上调用interrupt()方法将抛出中断异常（InterruptedException），并且线程不会设置中断状态。\n若线程先调用intercerupt()设置中断状态，再调用wait()、join()、sleep()、park()及其重载方法，同样会抛出中断异常 ，线程的中断状态会被清除。\n下例演示了中断和休眠的关系：\npublic class InterruptAndSleep { public static void main(String[] args) { Thread apple = new Thread(new InnerThread(), \u0026#34;apple\u0026#34;); Thread google = new Thread(new InnerThread(), \u0026#34;google\u0026#34;); apple.start(); google.start(); apple.interrupt(); } static class InnerThread implements Runnable { private static int count = 0; private final int id = count++; private int countDown = 2; public InnerThread() { } public void info() { System.out.println(\u0026#34;id(\u0026#34; + id + \u0026#34; \u0026#34; + Thread.currentThread() + \u0026#34;) \u0026#34;); } @Override public void run() { try { while (countDown-- \u0026gt; 0) { // Thread.sleep(100); // Java SE5 or later style TimeUnit.MILLISECONDS.sleep(100); info(); } } catch (InterruptedException e) { System.out.println(\u0026#34;id(\u0026#34; + id + \u0026#34; \u0026#34;+ Thread.currentThread() + \u0026#34;) is\u0026#34; + \u0026#34; interrupted\u0026#34;); } } } } /* output: id(0 Thread[apple,5,main]) is interrupted id(1 Thread[google,5,main]) id(1 Thread[google,5,main]) *///:~ 上例说明了线程被中断（调用interrupted()方法）之后，再调用sleep()方法会抛出 InterruptedException。\n但是线程被中断并不意味线程终止了，其还有再次运行的能力，将上例中run()方法的循环稍作修改：\n// try this while (countDown-- \u0026gt; 0) { try { TimeUnit.MILLISECONDS.sleep(100); info(); } catch (InterruptedException e) { System.out.println(\u0026#34;id(\u0026#34; + id + \u0026#34; \u0026#34; + Thread.currentThread() + \u0026#34;) is\u0026#34; + \u0026#34; interrupted\u0026#34;); } } /* output: id(0 Thread[apple,5,main]) is interrupted id(0 Thread[apple,5,main]) id(1 Thread[google,5,main]) id(1 Thread[google,5,main]) *///:~ 这说明，尽管调用sleep()抛出中断异常，线程并没有终止，并且线程的中断状态还被清除了，再次循环时程序正常运行。\n同样地，当线程休眠(TIMED_WAITING)时尝试中断线程的表现和上面差不多：\npublic class InterruptAndSleep { public static void main(String[] args) { Thread apple = new Thread(new InnerThread(), \u0026#34;apple\u0026#34;); apple.start(); try { Thread.sleep(200); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(apple.getState()); apple.interrupt(); } static class InnerThread implements Runnable { private static int count = 0; private final int id = count++; private int countDown = 3; public InnerThread() { } public void info() { System.out.println(\u0026#34;id(\u0026#34; + id + \u0026#34; \u0026#34; + Thread.currentThread() + \u0026#34;) \u0026#34;); } @Override public void run() { while (countDown-- \u0026gt; 0) { try { // Thread.sleep(100); // Java SE5 or later style TimeUnit.MILLISECONDS.sleep(100); info(); } catch (InterruptedException e) { // e.printStackTrace(); System.out.println(\u0026#34;id(\u0026#34; + id + \u0026#34; \u0026#34; + Thread.currentThread() + \u0026#34;) is\u0026#34; + \u0026#34; interrupted\u0026#34;); } } } } } /* output: id(0 Thread[apple,5,main]) TIMED_WAITING id(0 Thread[apple,5,main]) is interrupted id(0 Thread[apple,5,main]) *///:~ 可以看到，当线程休眠时，调用interrupted()方法也会抛出异常，并且清除中断状态。\n使用isInterrupted()和interrupted()方法都可以获取线程的中断状态，二者的区别在于isInterrupted()方法不会清除线程的中断状态（ interrupted status of the thread is unaffected ）；但interrupted()方法会清除线程的中断状态，且该方法是静态方法。\n多处理器下尤其如此，单处理器下Java的调度机制是“抢占式”的，谁获取CPU时间片谁运行。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n该系列后续文章会提到，这并不是创建任务的唯一方式。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n此例中，只有一个主线程去创建LiftOff线程，如果有多个主线程去创建LiftOff线程，那么可能就会出现重复id的LiftOff实例。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n和yield()方法一样，倾向性并不是绝对的。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n早期版本中，可以使用stop()方法终止线程，这个方法已经过时了。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":8,"href":"/zh/docs/java/collections/1_List_arraylist/","title":"ArrayList","section":"集合框架","content":"ArrayList是Java集合框架中使用最为频繁的实现，其本质是一个有序的可自由扩容的对象数组。它实现了RandomAccess这个标记接口，意味着其在随机访问性能上有一定优势。\nArrayList继承关系\n初始化及扩容机制 # ArrayList初始化为一个空的对象数组，如果不在构造对象时指定初始容量大小，那么ArrayList的默认初始化一个容量为10的对象数组，其扩容规则是每当新增加对象超出对象数组的容量时，将对象数组的容量增加当前容量的1/2。\n参考如下示例：\nstatic void initializeTest() throws NoSuchFieldException, IllegalAccessException { List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); // initial size = 10 for (int i = 0; i \u0026lt;16; i++){ list.add(new Random().nextInt(100)); // 本体是elementData Field field = list.getClass().getDeclaredField(\u0026#34;elementData\u0026#34;); field.setAccessible(true); // 获取list的“elementData” Object[] o = (Object[]) field.get(list); // size是ArrayList的长度，length是elementData的长度 System.out.println(\u0026#34;size = \u0026#34; + (i+1) + \u0026#34;, length = \u0026#34; + o.length + \u0026#34; , element = \u0026#34; + Arrays.toString(o)); } } /* output: size = 1, length = 10 ,element = [15, ...] size = 2, length = 10 ,element = [15, ...] size = 3, length = 10 ,element = [15, ...] size = 4, length = 10 ,element = [15, ...] size = 5, length = 10 ,element = [15, ...] size = 6, length = 10 ,element = [15, ...] size = 7, length = 10 ,element = [15, ...] size = 8, length = 10 ,element = [15, ...] size = 9, length = 10 ,element = [15, ...] size = 10, length = 10 ,element = [15, ...] size = 11, length = 15 ,element = [15, ...] size = 12, length = 15 ,element = [15, ...] size = 13, length = 15 ,element = [15, ...] size = 14, length = 15 ,element = [15, ...] size = 15, length = 15 ,element = [15, ...] size = 16, length = 22 ,element = [15, ...] *///:~ ArrayList的内容存储在elementData对象数组中，通过在运行时获取对象信息，能够窥视ArrayList的初始化过程：\nelementData初始化为容量默认为10，内容为空的对象数组new Object[10] = {}\n添加第10个元素时，此时elementData的容量也是10，无法容纳更多元素，需扩容，源码如下：\nif (minCapacity - elementData.length \u0026gt; 0){ int oldCapacity = elementData.length; // 扩容 扩容方式为将容量增加一半 int newCapacity = oldCapacity + (oldCapacity \u0026gt;\u0026gt; 1); if (newCapacity - minCapacity \u0026lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE \u0026gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); } 使用Arrays.copyOf()方法将elementData重新引用至新的拷贝数组——这一过程去尾。数组扩容也有一定的开销，实际使用过程中最好预估并定义ArrayList的初始容量，避免因数据增长频繁扩容。\n迭代器 # 集合框架的继承关系图显示，Collection接口继承了 Iterable 接口，这意味着所有的集合实现都可以使用迭代器操作集合。\n作为使用最广的集合实现，ArrayList可以获取 Iterator 和 ListIterator 的实现，后者继承了前者，在前者的基础上新增了一些用于可逆迭代（ cursor在集合中来回穿梭 ）的特性，如previous()，previousIndex()等方法。\n迭代器方法表\n下面代码简单展示了迭代器的使用：\nstatic void iteratorTest() { List\u0026lt;String\u0026gt; a = new ArrayList\u0026lt;String\u0026gt;() {{ add(\u0026#34;apple\u0026#34;); add(\u0026#34;google\u0026#34;); add(\u0026#34;amazon\u0026#34;); add(\u0026#34;cisco\u0026#34;); add(\u0026#34;facebook\u0026#34;); add(\u0026#34;twitter\u0026#34;); }}; Iterator\u0026lt;String\u0026gt; iterator = a.iterator(); a.remove(2); // throw ConcurrentModificationException // System.out.println(iterator.next()); // 重新获取迭代器，避免上述异常 Iterator\u0026lt;String\u0026gt; newIterator = a.iterator(); newIterator.next(); // Java 8新增方法，迭代剩余元素 newIterator.forEachRemaining(s -\u0026gt; { s= s.replaceFirst(\u0026#34;g\u0026#34;,\u0026#34;G\u0026#34;); System.out.println(s); }); } /* output: Google cisco facebook twitter *///:~ static void listIteratorTest() { ListIterator\u0026lt;String\u0026gt; listIterator = a.listIterator(); listIterator.next(); // do not change cursor listIterator.set(\u0026#34;Apple\u0026#34;); listIterator.previous(); while (listIterator.hasNext()) { System.out.println(listIterator.next()); } System.out.println(\u0026#34;-------\u0026#34;); // cursor changed listIterator.remove(); listIterator.add(\u0026#34;TWITTER\u0026#34;); // cursor in the end // reverse output while (listIterator.hasPrevious()) { System.out.println(listIterator.previous()); } } /* output: Apple google twitter ------- TWITTER google Apple *///:~ 关于集合的迭代器1，作如下说明：\n当集合和迭代器持有的“计数器”不一致时，迭代器的 ConcurrentModificationException 出现：\n计数器：记录发生集合结构性变化的次数，一般指集合元素增删，更新集合元素值一般不会被视作结构性变化2；迭代器也维护一个计数器，此数字初始化为原集合计数器的值。\n需要记住的是，迭代器的计数器只能通过迭代器维护（ 调用迭代器的add()，remove()等方法会更新计数器 ，因此不会抛出上述异常），而集合的计数器却可以通过迭代器和集合维护，亦即通过迭代器更新的计数器会同步更新集合的计数器（ 因为迭代器方法也是通过集合方法实现的 ）；反之不亦然，记住，在获取迭代器之后，在使用集合而非迭代器的方法修改集合结构，那么迭代器会发生异常（ 2个计数器值不一致 ）\n参考ArrayList.Itr.remove()3源码：\npublic void remove() { if (lastRet \u0026lt; 0) throw new IllegalStateException(); checkForComodification(); try { ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; // 更新计数器 expectedModCount = modCount; } catch (IndexOutOfBoundsException ex) { throw new ConcurrentModificationException(); } } final void checkForComodification() { // 一致性检查 if (modCount != expectedModCount) throw new ConcurrentModificationException(); } 不论是 Iterator 或 ListIterator 接口在Java集合框架中都没有独立的实现类，都是作为集合具体实现的内部类存在的，这种机制使得不同的集合类型，拥有“定制”的迭代器类型，这意味着方法表并不是一成不变的，如ArrayList.ListIterator就缺失hasNext()方法。\nLinkedList(左)和ArrayList(右)内部ListIterator的实现差异\n这种只定义接口而使用内部类实现的现象在Java集合框架中非常常见，理解这一点有利于理解集合视图( Collection view )，接下来这个概念将多次出现。\n按照理论，ListItr实现了ListIterator接口应该覆盖所有方法，Intellij IDEA编译器对于ArrayList的内部类ListItr给出了 method should be defined since the class is not abstract的批注，这或许是Java源码的豁免权。\n实际上，ArrayList.ListItr同时也继承了ArrayList.Itr，因此，ListItr缺失的方法由Itr实现了。\nJava 8的改进\nJava 8 新增的函数式接口，在集合框架中得到广泛使用，关于Java 8对集合框架的优化，后文将单独说明（挖坑？）。\n例如在迭代器 Iterator 接口中，新增了一个方法：\ndefault void forEachRemaining(Consumer\u0026lt;? super E\u0026gt; action) { Objects.requireNonNull(action); while (hasNext()) action.accept(next()); } 这是一 默认方法，其接受一个 Consumer 参数，用来对元素执行操作，需要注意的是此迭代器的指针( cursor )并不是0，而是当前实际的指针，亦即此法用于迭代还未被此迭代器迭代的元素\nSubList(集合视图) # SubList是ArrayList的内部类，是方法subList(int fromIndex, int toIndex)的返回对象，也就是说，ArrayList.subList()的返回不是一个ArrayList实例，而是一个视图。\npublic List\u0026lt;E\u0026gt; subList(int fromIndex, int toIndex) { subListRangeCheck(fromIndex, toIndex, size); return new SubList\u0026lt;\u0026gt;(this, fromIndex, toIndex); } 所谓集合视图，可以通俗的理解为集合的内部类4，如Sublist，其一个主要的特点是可以更改原集合（作用可以理解为原集合的一个代理）。\nprivate class SubList extends AbstractList\u0026lt;E\u0026gt; implements RandomAccess { //... } SubList可以看作一个\u0026quot;类ArrayList\u0026quot;，方法也有很多共性，而往往只需要注意差异即可。\n参考下例：\nstatic void subListTest(){ List\u0026lt;String\u0026gt; a = new ArrayList\u0026lt;String\u0026gt;() {{ add(\u0026#34;apple\u0026#34;); add(\u0026#34;google\u0026#34;); add(\u0026#34;amazon\u0026#34;); add(\u0026#34;cisco\u0026#34;); }}; List\u0026lt;String\u0026gt; strings = a.subList(1, 2); // [google] System.out.println(\u0026#34;Is subList instance of ArrayList? \u0026#34; + (strings instanceof ArrayList) + \u0026#34;\\n-------\u0026#34;); // a.add(\u0026#34;Java\u0026#34;) // ERROR! cause ConcurrentModificationException for subList ListIterator\u0026lt;String\u0026gt; subIterator = strings.listIterator(); while (subIterator.hasNext()){ subIterator.set(subIterator.next().toUpperCase() + \u0026#34; revised by subList\u0026#34;); } // 增加元素 subIterator.add(\u0026#34;foobar added by subList\u0026#34;); a.forEach(System.out::println); // 删除子集，父集也删除元素 strings.clear(); System.out.println(\u0026#34;-------\u0026#34;); a.forEach(System.out::println); } /* output: Is subList instance of ArrayList? false ------- apple GOOGLE revised by subList foobar added by subList amazon cisco ------- apple amazon cisco *///:~ 之所以将其称为视图，一个很重要的原因就是，这个类所有有利数据全部来自外围类(ArrayList)，其能够修改外围类的能力来自于直接对外围类方法的调用5：\npublic void add(int index, E e) { rangeCheckForAdd(index); checkForComodification(); // 实际上调用的就是外围类的方法 parent.add(parentOffset + index, e); this.modCount = parent.modCount; this.size++; } 实际上，可以将SubList理解为ArrayList实用工具的巧妙封装。\n和迭代器一样，获取SubList之后，对原集合进行结构性改变，也会引起ConcurrentModificationException。\n插入与删除 # 前文提到，尽管ArrayList因实现了Random接口而具有很好的随机读取性，但是ArrayList也有一些缺点，比如差强人意的插入和删除。\nArrayList方法：\npublic void add(int index, E e) {...} public E remove(int index) {...} public boolean remove(Object o) {...} ... 实现了从插入集合到指定索引为止或从集合中删除（指定索引）元素，但这些操作并不是ArrayList的强项，以add(int index, E e)为例：\npublic void add(int index, E element) { rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! // 拷贝数组--实际上是将数组index位置以后的所有元素”后移一位“ System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; } 同理，从ArrayList的删除相关方法中也可以看到类似的操作，这意味着在操作大量数据的时候，ArrayList可能会遇到性能问题。在对象数组长度很小时，这种影响一般可以忽略。\n集合框架所有实现的迭代器都是如此\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n这一论点的普适性有待验证\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n这只是一种表述形式，实际上ArrayList的迭代器是私有内部类，无法使用该语法访问，下同\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n是否一直如此？集合框架中的视图（子集、键集、条目映射、Collections视图等等）都是基于基本接口的内部类实现\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSubList并没有集合视图的共性，其操作集合的方法是独特的；它被称为集合视图的原因是其不是标准的Java集合框架成员\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":9,"href":"/zh/docs/java/basic/1_%E8%AE%BF%E9%97%AE%E6%9D%83%E9%99%90%E4%BF%AE%E9%A5%B0%E7%AC%A6/","title":"访问权限修饰符","section":"面向对象","content":" 访问权限修饰符 # 本系列内容主要来自TIJ，Java核心技术卷以及Java SE 8 API\n介绍了Java的public、default、protected、private四种访问权限修饰符。\n包访问权限 # 当前包中的所有其他类对该包内的某个类的成员具有访问权限，但这并不意味着能够访问到。是否访问到还要取决于类的成员的修饰符。若类的成员也是包访问权限或者public，那才能够访问到； 当前包中的所有类对这个包之外的所有非public权限的类没有访问权限； 类控制着哪些代码能够访问自己的成员，具体能否访问还需要看成员的权限。 接口访问权限 \u0026ndash;public # 使用public，意味着public之后声明的成员对每个人都是可用的。 你无法访问 \u0026ndash;private # 使用private，意味着除了包含该成员的类之外，其他任何类都无法访问这个成员； 私有构造器可以阻止继承。 继承访问 \u0026ndash;protected # protected也提供包访问权限，也就是说同一包内的其他类可以访问protected修饰的元素；\nprotected实际上处理的是继承的概念，试看如下例子：\n// base class Cookie in package access.dessert package access.dessert; public class Cookie{ public Cookie(){ System.out.print(\u0026#34;Cookie constructor\u0026#34;); } void bite(){System.out.print(\u0026#34;bite\u0026#34;)}; } // sub-class ChocolateChip in package access package access; import access.dessert.*; public class ChocolateChip extends Cookie{ public ChocolateChip(){ System.out.print(\u0026#34;ChocolateChip constructor\u0026#34;); } public void chomp(){ // bite(); // can\u0026#39;t access } public void static void main(String[] args){ ChocolateChip x = new ChocolateChip(); x.chomp; } } /* output: Cookie constructor ChocolateChip constructor *///:~ 继承了Cookie的ChocolateChip不和父类在同一个包下，尽管bite()具有包访问权限，ChocolateChip也无法访问bite()方法，一个可能的办法是将bite()修改为public，但是这样并不是很合适，所以我们可以使用propected来修饰bite()方法：\n// base class Cookie in package access.dessert package access.dessert; public class Cookie{ public Cookie(){ System.out.print(\u0026#34;Cookie constructor\u0026#34;); } protected void bite(){System.out.print(\u0026#34;bite\u0026#34;)}; } // sub-class ChocolateChip in package access package access; import access.dessert.*; public class ChocolateChip2 extends Cookie2{ public ChocolateChip2(){ System.out.print(\u0026#34;ChocolateChip2 constructor\u0026#34;); } public void chomp(){ bite(); } public void static void main(String[] args){ ChocolateChip2 x = new ChocolateChip2(); x.chomp; } } /* output: Cookie constructor ChocolateChip2 constructor bite *///:~ protected 保护了继承的访问权限。\n"},{"id":10,"href":"/zh/docs/java/spring/SpringBoot-aop-demo/","title":"SpringBoot使用AOP的简单示例","section":"Spring","content":"有一个cd接口，其实体类用于播放歌曲，同时我们想在播放歌曲的时候记录每个曲目的播放次数。看起来，记录次数这个事和播放曲目是不相干的事情，当然，我们可以在每首歌曲播放完成之后记录，但是更好的办法是使用一个切面，切入到播放方法中，来完成这件事，这样可以减少无关逻辑对代码的侵入。\n此程序分别使用了基于@Aspect注解和基于XML配置文件2种方式进行了切面注入，2种方式效果是等同的。\n此程序使用的是Spring AOP，并没有使用功能更加丰富的AspectJ，Spring AOP很大部分借鉴了AspectJ，如果只是简单的方法层面的织入，那么Spring AOP就能够满足需求。如果需要构造器或者属性拦截，或者需要为spring bean引入新方法，那么就需要使用AspectJ了。\n1 开始 # 从 start.spring.io下载空项目，引入Spring AOP依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-aop\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 2 配置 # 2.1 基于JavaBean+注解的配置 # 2.1.1 注入Bean # @Configuration @Profile(\u0026#34;jc\u0026#34;) public class DiskConfig { @Bean(\u0026#34;jcd\u0026#34;) public CompactDisk saveRock() { BlankDisk cd = new BlankDisk(); cd.setArtist(\u0026#34;Fall Out Boy\u0026#34;); cd.setTitle(\u0026#34;Save Rock And Roll\u0026#34;); List\u0026lt;String\u0026gt; tracks = new ArrayList\u0026lt;\u0026gt;(); tracks.add(\u0026#34;The Phoenix\u0026#34;); tracks.add(\u0026#34;My Songs Know What You Did In the Dark (Light Em Up)\u0026#34;); tracks.add(\u0026#34;Alone Together\u0026#34;); tracks.add(\u0026#34;Where Did the Party Go\u0026#34;); tracks.add(\u0026#34;Just One Yesterday (feat. Foxes)\u0026#34;); tracks.add(\u0026#34;The Mighty Fall (feat. Big Sean)\u0026#34;); tracks.add(\u0026#34;Missing You\u0026#34;); tracks.add(\u0026#34;Death Valley\u0026#34;); cd.setTracks(tracks); return cd; } @Bean(\u0026#34;jtc\u0026#34;) public TrackCounter trackCounter() { return new TrackCounter(); } } 2.1.2 创建切面 # 使用注解@Aspect可以将一个Bean声明为切面：\n@Aspect @Slf4j public class TrackCounter { private Map\u0026lt;Integer, Integer\u0026gt; trackCounts = new HashMap\u0026lt;\u0026gt;(); public int getPlayCount(int trackNumber) { return trackCounts.getOrDefault(trackNumber, 0); } @Pointcut(\u0026#34;execution( * com.wangy.aop.disk.BlankDisk.playTrack(..)) \u0026amp;\u0026amp; args(trackNumber)\u0026#34;) public void pc1(int trackNumber){ } @Pointcut(\u0026#34;execution(* com.wangy.aop.disk.BlankDisk.playTrack(int))\u0026#34;) public void pc2(){} @Before(value = \u0026#34;pc2()\u0026#34;) public void init(){ // do something log.info(\u0026#34;start playing\u0026#34;); } @AfterReturning(value = \u0026#34;pc1(trackNumber)\u0026#34;) public void countTrack(int trackNumber) { log.info(\u0026#34;Track {} played\u0026#34;, trackNumber); trackCounts.put(trackNumber, getPlayCount(trackNumber) + 1); } @AfterThrowing(value = \u0026#34;pc1(trackNumber)\u0026#34;) public void skipTrack(int trackNumber) { log.info(\u0026#34;track {} skipped\u0026#34;, trackNumber); } @After(value = \u0026#34;pc2()\u0026#34;) public void after(){ // do something } @Around(value = \u0026#34;pc1(trackNumber)\u0026#34;) public void aroundTest(ProceedingJoinPoint jp, int trackNumber) throws Throwable { int pl = 2; // do some judgement if (getPlayCount(trackNumber) \u0026gt; pl) { log.info(\u0026#34;track {} has been played more than twice, skip this track\u0026#34;, trackNumber); // change the behavior of pointcut method CompactDisk target = (CompactDisk) jp.getTarget(); target.playTrack(-1); }else{ jp.proceed(); } } } 使用@Aspect注解将TrackCounter bean声明为一个切面，同时使用@Pointcut注解声明切点，再使用对应的通知注解声明通知\n@Before @After @AfterReturning @AfterThrowing @Around 若使用xml配置切面，那么TrackCounter类看起来和普通的java bean没有差别，稍后会在xml配置文件中将其配置为一个切面\n注意上面的切面表达式：\nexecution( * com.wangy.aop.disk.BlankDisk.playTrack(int)) \u0026amp;\u0026amp; args(trackNumber) 前半部分是常见的切面表达式，用于指定切入点；\n第一个 * 指示任意返回类型 使用全限定名指定类和方法名，括号内的int指定参数列表，可以使用(..)来匹配任意参数 更多关于切入点表达式的内容：\nhttps://www.cnblogs.com/liaojie970/p/7883687.html https://howtodoinjava.com/spring-aop/aspectj-pointcut-expressions/ https://www.baeldung.com/spring-aop-pointcut-tutorial \u0026amp;\u0026amp;连接符后面的内容是什么意思？\n这里需要提及的是， Spring AOP支持AspectJ切点指示器的子集，除了最常用的execution()指示器之外，还有其他的指示器：\nAspectJ指示器 描述 args() 限制连接点匹配参数为指定类型的执行方法 @args() 限制连接点匹配参数由指定注解标注的执行方法 execution() 用于匹配是连接点的执行方法 this() 限制连接点匹配AOP代理的bean引用为指定类型的类 target 限制连接点匹配目标对象为指定类型的类 @target() 限制连接点匹配特定的执行对象，这些对象对应的类需要有指定类型的注解 within() 限制连接点匹配指定的类型 @within() 限制连接点匹配指定注解所标注的类型（当使用Spring AOP时，方法定义在由指定的注解所标注的类里） @annotation 限制匹配带有指定注解的连接点 这里的arg(trackNumber)限定符，表明传递给连接点（切入点）playTrack(int)的int类型参数也会传递到通知中去。\n关于args()条件的作用，sping官方文档有说明： https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#aop-ataspectj-advice-params\n需要注意到启动类中使用了@EnableAspectJAutoProxy注解， 这意味着开启AspectJ自动代理，使得Spring框架拥有AOP能力：\n@SpringBootApplication @EnableAspectJAutoProxy public class AopApplication { public static void main(String[] args) { SpringApplication.run(AopApplication.class, args); } } 2.2 基于xml文件的配置 # xml配置如下1：\n\u0026lt;beans profile=\u0026#34;xc\u0026#34;\u0026gt; \u0026lt;aop:aspectj-autoproxy/\u0026gt; \u0026lt;bean id=\u0026#34;xtrackCounter\u0026#34; class=\u0026#34;com.wangy.aop.TrackCounter\u0026#34; name=\u0026#34;xtc\u0026#34;/\u0026gt; \u0026lt;bean id=\u0026#34;xcd\u0026#34; class=\u0026#34;com.wangy.aop.disk.BlankDisk\u0026#34; name=\u0026#34;xcd\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;title\u0026#34; value=\u0026#34;Save Rock And Roll\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;artist\u0026#34; value=\u0026#34;Fall Out Boy\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;tracks\u0026#34;\u0026gt; \u0026lt;list\u0026gt; \u0026lt;value\u0026gt;The Phoenix\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;My Songs Know What You Did In the Dark (Light Em Up)\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;Alone Together\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;Where Did the Party Go\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;Just One Yesterday (feat. Foxes)\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;The Mighty Fall (feat. Big Sean)\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;Missing You\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;Death Valley\u0026lt;/value\u0026gt; \u0026lt;/list\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;aop:config\u0026gt; \u0026lt;aop:aspect ref=\u0026#34;xtrackCounter\u0026#34;\u0026gt; \u0026lt;aop:pointcut id=\u0026#34;tc\u0026#34; expression=\u0026#34;execution(* com.wangy.aop.disk.BlankDisk.playTrack(int)) and args(trackNumber))\u0026#34;/\u0026gt; \u0026lt;aop:after-returning pointcut-ref=\u0026#34;tc\u0026#34; method=\u0026#34;countTrack\u0026#34;/\u0026gt; \u0026lt;aop:around method=\u0026#34;aroundTest\u0026#34; pointcut-ref=\u0026#34;tc\u0026#34;/\u0026gt; \u0026lt;/aop:aspect\u0026gt; \u0026lt;/aop:config\u0026gt; \u0026lt;/beans\u0026gt; 对应前文中的JavaBean配置中使用的profile，在xml中将所有的配置声明为一个叫\u0026rsquo;xc\u0026rsquo;的profile。\n3 测试 # 测试包中提供了2个测试类，分别用于测试基于JavaBean+注解、基于xml文件的aop配置；\n[TrackCounterTest]用于测试基于javaBean和注解实现的aop，这是推荐的方式 [TrackCountTestWithXml]用于测试基于xml配置的aop，在运行此测试时，需要注释掉TrackCount类上的@Aspect注解，以免Application Context注入2个切面 以下是使用xml配置的测试样例：\n@SpringBootTest @SpringJUnitConfig(locations = {\u0026#34;classpath:spring-aop.xml\u0026#34;}) @ActiveProfiles(\u0026#34;xc\u0026#34;) public class TrackCountTestWithXml { @Autowired private CompactDisk cd; @Autowired private TrackCounter tc; @Test public void testTc() { cd.playTrack(1); cd.playTrack(1); cd.playTrack(1); cd.playTrack(2); cd.playTrack(4); cd.playTrack(4); cd.playTrack(6); cd.playTrack(6); cd.playTrack(6); try { cd.playTrack(6); } catch (Exception e) { //ignore } assertEquals(3, tc.getPlayCount(1)); assertEquals(1, tc.getPlayCount(2)); assertEquals(0, tc.getPlayCount(3)); assertEquals(2, tc.getPlayCount(4)); assertEquals(0, tc.getPlayCount(5)); assertEquals(3, tc.getPlayCount(6)); } } 4 参考 # demo地址：https://github.com/wangy325/simple_springboot_aop_demo\n切入点表达式使用总结：https://www.cnblogs.com/zhangxufeng/p/9160869.html\nxml配置并未使用TrackCounter中的全部通知\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":11,"href":"/zh/docs/craft/db/sql/1_%E5%9C%A8centOS%E4%B8%8A%E5%AE%89%E8%A3%85%E5%B9%B6%E9%85%8D%E7%BD%AEmysql%E6%95%B0%E6%8D%AE%E5%BA%93/","title":"CentOS安装并配置MySQL","section":"mysql","content":"文章介绍了在centOS7上安装mysql数据库服务的配置及简单优化过程。在服务器上安装mysql服务网络上能够找到的资源很多了，因此本文没有作详细介绍，本文的重点在于后续的优化配置方面。\n安装MySQL # 在centOS上安装mysql 5.7-juejin 通过yum命令安装并进行初始化设置-dev.mysql.com 配置 # mysql的配置文件在/etc/my.cnf， 只是简单地配置了数据库编码为utf8；\n### my.cnf配置内容 # For advice on how to change settings please see # http://dev.mysql.com/doc/refman/5.7/en/server-configuration-defaults.html [client] default-character-set=utf8 [mysql] default-character-set=utf8 [mysqld] collation-server = utf8_unicode_ci collation-server = utf8_bin collation-server = utf8_general_ci init-connect=\u0026#39;SET NAMES utf8\u0026#39; character-set-server = utf8 default-storage-engine = INNODB datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock mysql有默认配置账户以及测试数据库， root账户也会默认分配密码， 安装 指引链接2官方文档中说明了默认账户密码:\n1） 在 /var/log/mysqld.log中记录了mysql root账户的默认密码\n[root@simple ~] cat /var/log/mysqld.log | grep -i \u0026#39;temporary password\u0026#39; # 2019-10-15T07:08:33.627866Z 1 [Note] A temporary password is generated for # root@localhost: I6cpDa!wj.6\u0026amp; 2） 可以使用mysql_secure_installation命令进行初始化设置，程序会询问一些默认设置，包括重置密码，删除匿名账户，禁止root远程登录等等配置\n[root@simple ~] mysql_secure_installation ... 还可以通过set password或者\u0026gt; mysqladmin修改密码:\nSET PASSWORD FOR \u0026#39;username\u0026#39;@\u0026#39;scope\u0026#39; = PASSWORD(\u0026#39;newpasswd\u0026#39;) 或者 mysqladmin -uroot -poldpass password newpass; 其他的配置 比如设置数据库时间为服务器时间(默认为UTC时间)并没有成功\n账户与权限 # 前已述及，mysql默认配置root账户，并且已经只能本地登录(出于安全考虑)，并且不建议使用root账户进行数据库连接；\n因此，需要新账户，并且要控制账户权限，防止一些不可预见的错误出现；\n同时，账户创建之后需赋予适当的权限；\n账户 # 使用以下命令创建账户:\ncreate user username@\u0026#39;scope\u0026#39; IDENTIFIED BY \u0026#39;passwd@\u0026#39;; 关于账户说明\nmysql 5.7加入了validate_password机制，该机制迫使用户使用[强密码]\u0026ndash;至少8位，且至少包含一个大写字母，一个小写字母，一个数字，一个特殊符号；若想关闭此功能，可在my.cnf中的[mysqld]栏下配置validate_password=Off；\nscope项指定用户可以从哪里登录，一般localhost只允许本地(或ssh登录)，%允许任意ip位置登录，\n权限 # mysql的权限可以简单介绍为:\n权限 描述 全局权限 privilege for all schemas； 信息保存在mysql.user表中 schema权限 privilege for all tables； 信息保存在mysql.db中 table权限 privilege for all columns； 信息保存在mysql.tables_priv中 column权限 privilege for column；信息保存在mysql.columns_priv中 子程序权限 ? 权限的细致说明以及，各类权限所保存的表，可参考:\nMySQL 查看用户授予的权限 Privileges Provided by MySQL Grant Tables 最简单的查看用户权限的方法\nshow grants for user; show grants for user@\u0026#39;localhost\u0026#39;; # 查看root的权限 mysql\u0026gt; show grants for root@\u0026#39;localhost\u0026#39;; +---------------------------------------------------------------------+ | Grants for root@localhost | +---------------------------------------------------------------------+ | GRANT ALL PRIVILEGES ON *.* TO \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; WITH GRANT OPTION | | GRANT PROXY ON \u0026#39;\u0026#39;@\u0026#39;\u0026#39; TO \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; WITH GRANT OPTION | +---------------------------------------------------------------------+ 2 rows in set (0.00 sec) 从上面可以看出，root有[*.*的所有权限]，至于*.*，代表了ALLDB.ALLTABLES-即所有数据库的所有表，这是最高权限。\n或者，可以通过查询mysql.user表来获取权限信息\nselect * from mysql.user where user=\u0026#39;root\u0026#39;\\G; *************************** 1. row *************************** Host: localhost User: root Select_priv: Y Insert_priv: Y Update_priv: Y Delete_priv: Y # ignore others 给用户授予权限 # 假设我们创建了一个用户test，并且没有授予任何权限，name，这个用户的权限是这样的；\nmysql\u0026gt; show grants for test; +---------------------------------------+ | Grants for hc_future@% | +---------------------------------------+ | GRANT USAGE ON *.* TO \u0026#39;hc_future\u0026#39;@\u0026#39;%\u0026#39; | +---------------------------------------+ 1 row in set (0.00 sec) 可以看到，实际上test并没有任何权限；\nmysql\u0026gt; select * from user where user=\u0026#39;test\u0026#39;\\G; *************************** 1. row *************************** Host: % User: hc_future Select_priv: N Insert_priv: N Update_priv: N Delete_priv: N *************************** 1. row *************************** 尝试使用该账户对mysql进行任何操作都会得到一个错误信息：\n[42000][1044] Access denied for user \u0026#39;hc_future\u0026#39;@\u0026#39;%\u0026#39; to database \u0026#39;test\u0026#39; 显然，我们应该给用户授予部分权限，已让其完成操作，mysql使用grant来给用户授予权限\n若我想给test授予全局select，update权限:\nmysql\u0026gt; grant select， update on *.* to test@\u0026#39;%\u0026#39; identified by \u0026#39;testT123!@#\u0026#39;; Query OK， 0 rows affected， 1 warning (0.00 sec) mysql\u0026gt; show grants for test; +------------------------------------------------+ | Grants for test@% | +------------------------------------------------+ | GRANT SELECT， UPDATE ON *.* TO \u0026#39;test\u0026#39;@\u0026#39;%\u0026#39; | +------------------------------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select * from user where user =\u0026#39;test\u0026#39;\\G; *************************** 1. row *************************** Host: % User: hc_future Select_priv: Y Insert_priv: N Update_priv: Y Delete_priv: N Create_priv: N # ignore others mysql 5.7.28中， 如果grant命令执行的用户没有被创建，会默认创建该用户\n更多关于grant的使用，参考官方文档 GRANT Syntax\n数据备份与导入 # 主要使用mysqldump和source来进行数据库的备份和恢复\n数据库的备份主要分为结构和数据的备份，备份为x.sql形式的文件\n从备份的结果来看，\n备份结构主要生成create table语句 备份数据生成insert into语句 除此之外，备份的范围可从库到表之间多级变化， 总言之， mysqldump满足绝大多数备份需求；\n需要说明的是，若数据库中有视图，则需要谨慎行事了， 因为视图中存在一些对原数据库表的引用以及对 执行用户的DEFINER， 若恢复的数据库和备份的数据库名字以及用户一致，则不会存在问题，否则可能会出现找不到表的错误\n而数据库的恢复则简单了，source x.sql即可\n更多关于数据库备份恢复的细节，查看: mysqldump 导入/导出 结构\u0026amp;数据\u0026amp;存储过程\u0026amp;函数\u0026amp;事件\u0026amp;触发器\n使用SSL加密连接 # 在jdbc连接数据库的过程中可能会出现这样的警告:\nEstablishing SSL connection without server\u0026rsquo;s identity verification is not recommended. According to MySQL 5.5.45+， 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn\u0026rsquo;t set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to \u0026lsquo;false\u0026rsquo;. You need either to explicitly disable SSL by setting useSSL=false， or set useSSL=true and provide truststore for server certificate verification.\n有时候，设置useSSL=true又会遇到这样的错误:\nCaused by: javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target at sun.security.ssl.Alerts.getSSLException(Alerts.java:192) at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1946) at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:316) at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:310) ... 67 more 上述错误的大意是没找到ssl证书， 那么问题出在了mysql配置服务端或者客户端的配置上\n由于mysql 5.7以上默认开启了ssl，验证一下\n查看mysql SSL状态信息 # # 使用root账户登录 mysql -u root -p # 查看ssl信息 # Server version: 5.7.28 MySQL Community Server (GPL) mysql\u0026gt; show global variables like \u0026#39;%ssl%\u0026#39;; +---------------+-----------------+ | Variable_name | Value | +---------------+-----------------+ | have_openssl | YES | | have_ssl | YES | | ssl_ca | ca.pem | | ssl_capath | | | ssl_cert | server-cert.pem | | ssl_cipher | | | ssl_crl | | | ssl_crlpath | | | ssl_key | server-key.pem | +---------------+-----------------+ 9 rows in set (0.00 sec) #have_ssl = YES， 说明ssl已经启用 #查看当前用户的连接信息 mysql\u0026gt; \\s; -------------- mysql Ver 14.14 Distrib 5.7.28， for Linux (x86_64) using EditLine wrapper Connection id:\t157 Current database: Current user:\troot@localhost SSL:\tNot in use Current pager:\tstdout Using outfile:\t\u0026#39;\u0026#39; Using delimiter:\t; Server version:\t5.7.28 MySQL Community Server (GPL) Protocol version:\t10 Connection:\tLocalhost via UNIX socket Server characterset:\tutf8 Db characterset:\tutf8 Client characterset:\tutf8 Conn. characterset:\tutf8 UNIX socket:\t/var/lib/mysql/mysql.sock Uptime:\t23 hours 21 min 57 sec Threads: 5 Questions: 10325 Slow queries: 0 Opens: 5061 Flush tables: 1 Open tables: 1543 Queries per second avg: 0.122 -------------- ERROR: No query specified #SSL=Not in use 说明没有使用ssl连接 结果显示， mysql 5.7.28已经启用了ssl，并且可以不使用ssl登录\n根据上面的错误， jdbc连接错误的原因是由于证书错误， 做个测试:\n[root@iZbp17pma26sz5vqqwb1v3Z ~]# mysql -u root -p --ssl-ca= Enter password: ERROR 2026 (HY000): SSL connection error: SSL_CTX_set_default_verify_paths failed 当使用SSL登录而不指定证书的时候我们无法登录\n如果你的mysql没有开启SSL，当使用mysql -u root -p --ssl登录的时候，会得到如下错误: ERROR 2026(HY000): SSL connection error: SSL is required but the server doesn't support it\n配置SSL安全连接 # 那么， mysql的证书在哪里? 可能根据安装方式不同， 配置文件路径不一样， 使用yum源安装mysql时，实际上可以在var/lib/mysql里找到mysql的证书文件:\n[root@sample ~]# ll /var/lib/mysql/*.pem -rw------- 1 mysql mysql 1676 Oct 15 15:08 /var/lib/mysql/ca-key.pem -rw-r--r-- 1 mysql mysql 1112 Oct 15 15:08 /var/lib/mysql/ca.pem -rw-r--r-- 1 mysql mysql 1112 Oct 15 15:08 /var/lib/mysql/client-cert.pem -rw------- 1 mysql mysql 1680 Oct 15 15:08 /var/lib/mysql/client-key.pem -rw------- 1 mysql mysql 1680 Oct 15 15:08 /var/lib/mysql/private_key.pem -rw-r--r-- 1 mysql mysql 452 Oct 15 15:08 /var/lib/mysql/public_key.pem -rw-r--r-- 1 mysql mysql 1112 Oct 15 15:08 /var/lib/mysql/server-cert.pem -rw------- 1 mysql mysql 1680 Oct 15 15:08 /var/lib/mysql/server-key.pem 我们指定证书试试看:\n[root@sample ~]# mysql -u root -p --ssl-ca=/var/lib/mysql/ca.pem Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 161 Server version: 5.7.28 MySQL Community Server (GPL) mysql\u0026gt; \\s; -------------- mysql Ver 14.14 Distrib 5.7.28， for Linux (x86_64) using EditLine wrapper Connection id:\t161 Current database: Current user:\troot@localhost **SSL:\tCipher in use is ECDHE-RSA-AES128-GCM-SHA256** Current pager:\tstdout Using outfile:\t\u0026#39;\u0026#39; Using delimiter:\t; Server version:\t5.7.28 MySQL Community Server (GPL) Protocol version:\t10 Connection:\tLocalhost via UNIX socket Server characterset:\tutf8 Db characterset:\tutf8 Client characterset:\tutf8 Conn. characterset:\tutf8 UNIX socket:\t/var/lib/mysql/mysql.sock Uptime:\t1 day 14 min 19 sec Threads: 3 Questions: 10335 Slow queries: 0 Opens: 5061 Flush tables: 1 Open tables: 1543 Queries per second avg: 0.118 -------------- ERROR: No query specified 可以看到， 连接信息的SSL信息变成了Cipher in use is ECDHE-RSA-AES128-GCM-SHA256， 说明mysql可以使用SSL登录\n关于mysql ssl证书的生成，参考 creating-ssl-files-using-openssl\n既然可以指定证书使用SSL， jdbc为什么报错?\n/etc/my.cnf里没有ssl配置?\n如何使用SSL连接，参考 Use Encrypted Connections\n在/etc/my.cnf中添加\n[mysqld] ssl-ca=ca.pem ssl-cert=server-cert.pem ssl-key=server-key.pem 使用service mysqld restart重启mysql server， 让后看看服务端ssl配置是否生效:\n[root@sample ~]# service mysqld restart Redirecting to /bin/systemctl restart mysqld.service [root@sample ~]# mysql -u root -p --ssl WARNING: --ssl is deprecated and will be removed in a future version. Use --ssl-mode instead. Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 2 Server version: 5.7.28 MySQL Community Server (GPL) mysql\u0026gt; \\s; -------------- mysql Ver 14.14 Distrib 5.7.28， for Linux (x86_64) using EditLine wrapper Connection id:\t2 Current database: Current user:\troot@localhost SSL:\tCipher in use is ECDHE-RSA-AES128-GCM-SHA256 Current pager:\tstdout Using outfile:\t\u0026#39;\u0026#39; Using delimiter:\t; Server version:\t5.7.28 MySQL Community Server (GPL) Protocol version:\t10 Connection:\tLocalhost via UNIX socket Server characterset:\tutf8 Db characterset:\tutf8 Client characterset:\tutf8 Conn. characterset:\tutf8 UNIX socket:\t/var/lib/mysql/mysql.sock Uptime:\t12 sec Threads: 1 Questions: 5 Slow queries: 0 Opens: 105 Flush tables: 1 Open tables: 98 Queries per second avg: 0.416 \\-------------- 看到，我们使用ssl登录mysql，这一次并没有指定证书，而mysql连接成功，说明mysql服务端ssl配置成功了\n事实上，做到此步后，jdbc里使用\njdbc:mysql://47.110.226.247:3306/hcfuture_bundule?useUnicode=true\u0026amp;characterEncoding=UTF-8\u0026amp;zeroDateTimeBehavior=convertToNull\u0026amp;useSSL=true 这样的数据库url仍然得到同样的错误；个人认为是由于当客户端设置useSSL=true时，同样需要配置客户端的SSL证书信息\n如何在客户端使用SSL，可以参考 connector-j-reference-using-ssl\n以下内容摘自( https://www.sojpt.com/feedback/5723):\n首先mysql服务端要支持ssl，支持ssl需要以下条件：\n创建ssl证书和密钥\u0026ndash;生成ca.pem server-cert.pem client-cert.pem 文件 mysql提供两种方式 一种方式用openssl编译的mysql版本可以在启动时生成（参考链接：https://dev.mysql.com/doc/refman/5.7/en/creating-ssl-rsa-files-using-mysql.html）； 第二种方式用openssl生成（采用的方式），（参考链接：https://dev.mysql.com/doc/refman/5.7/en/creating-ssl-files-using-openssl.html）\n配置服务器支持（参考链接：https://dev.mysql.com/doc/refman/5.7/en/using-encrypted-connections.html） 主要时需要在my.cnf中需要添加以下配置，文件路径自行修改；还可以指定某个用户必须使用ssl链接等，详情参考官方的链接\n[mysqld] ssl-ca=ca.pem ssl-cert=server-cert.pem ssl-key=server-key.pem require_secure_transport=ON 客户端链接需要以下几个步骤\n需要将服务端的pem证书转换成java支持的JKS证书，得到keystore.jks和truststore.jks： 参考链接1：（可用）https://biteeniu.github.io/ssl/convert_pem_to_jks/ 参考链接2：（官方但连不上不知道什么原因）https://dev.mysql.com/doc/connector-j/5.1/en/connector-j-reference-using-ssl.html 修改mysql链接，指定链接方式为ssl jdbc:mysql://127.0.0.1:3306/test?useUnicode=true\u0026amp;characterEncoding=utf-8\u0026amp;verifyServerCertificate=true\u0026amp;useSSL=true\u0026amp;requireSSL=true 加载生成的jks证书和密码到系统属性，要在ActiveRecordPlugin之前 // keystore.jks和truststore.jks所在的路径，及创建时的密码 System.setProperty(\u0026ldquo;javax.net.ssl.keyStore\u0026rdquo;， \u0026ldquo;path/keystore.jks\u0026rdquo;); System.setProperty(\u0026ldquo;javax.net.ssl.keyStorePassword\u0026rdquo;， \u0026ldquo;password\u0026rdquo;); System.setProperty(\u0026ldquo;javax.net.ssl.trustStore\u0026rdquo;，\u0026ldquo;path/truststore.jks\u0026rdquo;); System.setProperty(\u0026ldquo;javax.net.ssl.trustStorePassword\u0026rdquo;， \u0026ldquo;password\u0026rdquo;); 实在是很繁琐，不过我估计此法是可行的，实际上是配置客户端的certificate，我嫌繁琐并没有尝试\n实际上，我在官方文档里看到了此段话:\nBy default， Connector/J establishes secure connections with the MySQL servers. Note that MySQL servers 5.7 and 8.0， when compiled with OpenSSL， can automatically generate missing SSL files at startup and configure the SSL connection accordingly.\nAs long as the server is correctly configured to use SSL， there is no need to configure anything on the Connector/J client to use encrypted connections (the exception is when Connector/J is connecting to very old server versions like 5.6.25 and earlier or 5.7.5 and earlier， in which case the client must set the connection property useSSL=true in order to use encrypted connections). The client can demand SSL to be used by setting the connection property requireSSL=true; the connection then fails if the server is not configured to use SSL. Without requireSSL=true， the connection just falls back to non-encrypted mode if the server is not configured to use SSL.\n实际上，此前我们mysql server的SSL已经成功配置，已经验证通过mysql -u test -p -h your serverip远程登录mysql后，通过status查看连接信息可以看到是通过SSL连接的\n结合此段声明， mysql 5.7以后的连接是加密的(需要服务端开启SSL)，故无需费时在客户端进行ssl配置(特殊需求除外)\n如果想使用jdbc连接配置SSL， 而不使用编码方式，可以参考 connector-j-reference-configuration-properties\n"},{"id":12,"href":"/zh/docs/java/","title":"Java","section":"Docs","content":" Java入门 # 记录了Java相关的知识，包括了面向对象基础，集合框架、并发和JVM等相关内容。\nJava基础 # 1 必知必会 # Java基础知识容易忽视、混淆的点，简单做一些记录。另外还有一些不常用的Java API，试着优雅的使用它们。\n访问权限修饰符 抽象类与接口 内部类 static关键字 \u0026hellip; 2 集合框架 # 集合框架，开发中使用最多的Java工具类，不管是List，还是Hash还是Map，随处可见，然而要用好它们，可能需要更好地了解它们\u0026hellip;\n数组 链表 队列 映射集 HashMap的源码分析 \u0026hellip; 并发 # 并发，是Java的沼泽地，没有路线指引，只会越陷越深然后迷茫地翻过篇去。这里讨论了和并发相关的的重要概念以及Java提供的并发组件。有些部分深入源码，剖析了它们的实现逻辑，深入理解Java对并发的控制。\n本部分内容由浅入深，首先讨论了线程的概念，生命周期以及另一个重要的概念——任务。以及为什么需要并发，并发过程中会遇到的共享资源的问题。接下来，阐述了并发过程中常遇到的问题——死锁(Dead Lock)。\n线程与任务 锁与同步 获取任务的返回值 终结任务 死锁 接下来，开始讨论执行器和线程池。执行器可以看作执行任务的trigger，Java提供了不同类型的执行器和线程池，以应对不同的应用场景，各线程池的线程创建及销毁条件都有所区别，了解线程池中线程的创建、入队、销毁、拒绝机制，对于理解线程池以及Java并发有很大的帮助。此外，Java还提供了其他一些重要的并发组件，比如阻塞队列，倒计时门栅，信号量等等，一并作介绍。\n[执行器和线程池] Ececutors and ExecutorServices ThreadPoolExecutor 计划执行任务 阻塞队列与生产-消费模式 其他重要的并发组件 最后，简单地讨论了Java的内存模型，同时讨论了volatile这个曾经饱受争议的关键字，介绍了Java虚拟机执行程序的指令重排。\nJava内存模型与valatile关键字 JVM # 关于Java JVM的讨论内容相对较少，周志明《深入理解Java虚拟机》尚未完全读完，也只是看了前面几个章节，所掌握的内容是寥寥无几。相信这一部分的内容，会越来越多。目前尚且只简单讨论了JVM的内存分区以及Java-GC。\nJava内存区域 Java GC "},{"id":13,"href":"/zh/docs/note/course/operating_system_peking/","title":"操作系统原理","section":"课程笔记","content":" 操作系统原理（Operating Systems） - Peking University - Coursera # 《操作系统原理》是针对计算机科学技术专业三年级本科生开设的一门专业基础课程。本课程着重学生系统观的培养，通过重点讲述操作系统的内部结构、工作原理及典型技术的实现，使学生建立起对操作系统的整体及各个功能模块的认识，从而系统掌握计算机的专业知识，进一步提升学生的软件开发能力乃至系统软件开发能力。\n任何计算机都必须在加载相应的操作系统之后，才能构成一个可以运转的、完整的计算机系统。操作系统的功能是否强大，决定了计算机系统的综合能力；操作系统的性能高低，决定了整个计算机系统的性能；操作系统本身的安全可靠程度，决定了整个计算机系统的安全性和可靠性。操作系统是软件技术的核心和基础运行平台。因此，计算机科学技术专业的学生需要学习和掌握操作系统的基本原理和专业知识。\n本课程的教学目标是：\n掌握操作系统的基本概念、功能组成、系统结构及运行环境；\n熟悉并运用操作系统工作原理、设计方法和实现技术，理解有代表性、典型的操作系统实例（如UNIX、Linux和Windows）；\n了解操作系统的演化过程、发展研究动向、新技术以及新思想，为后续相关课程的学习打下良好基础，为后续职业发展奠定基石。\n课程目录 # 引论 操作系统运行环境与运行机制 进程线程模型 "},{"id":14,"href":"/zh/docs/note/course/operating_system_peking/2_env_and_logic/","title":"操作系统运行环境与机制","section":"操作系统原理","content":" 📖 回顾：操作系统的主要工作\n程序的执行 启动程序、执行程序以及程序结束的工作 完成与体系结构相关的工作 完成应用程序所需的共性服务（提供各种基本服务，读盘、申请内存等等） 性能、安全、健壮等问题 应用程序\n———————— 虚拟机器界面 \u0026mdash;\u0026gt; 操作系统运行机制（系统调用）\n操作系统\n———————— 物理机器界面 \u0026mdash;\u0026gt; 操作系统运行环境（CPU状态、中断/异常机制）\n1 处理器状态(模式) # 1.1 中央处理器(CPU) # 处理器由运算器、控制器、一系列的寄存器以及高速缓存构成 两类寄存器: 用户可见寄存器：高级语言编译器通过优化算法分配并使用之，以减少程序访问内存次数 控制和状态寄存器：用于控制处理器的操作，通常由操作系统代码使用 1.2 控制和状态寄存器 # 程序计数器(PC: Program Counter)：记录将要取出的指令的地址 指令寄存器(IR: Instruction Register)：记录最近取出的指令 程序状态字寄存器(PSW: Program Status Word)：记录处理器的运行状态如条件码、 模式、控制位等信息。PSW一般包含以下内容： 程序基本状态：\n等待/计算：当前处理器状态； 目态/管态：当前处理器状态； 条件码：体现当前指令执行结果的各种状态信息（如算术运算产生的正、负、零或溢出等）； 指令地址：下一条指令的存放地址 中断码：保存程序执行时当前发生的中断事件；\n中断屏蔽位：指出程序执行中，是否要响应出现的中断事件。\nReference: 程序状态字\n控制和状态寄存器的作用：\n用于控制处理器的操作 在某种特权级别下可以〔被〕访问、修改 1.3 操作系统的需求——保护 # 从操作系统的特征考虑 并发、共享的数据安全 对操作系统提出要求 ——\u0026gt; 实现保护与控制 需要硬件提供基本运行机制: 处理器具有特权级别，能在不同的特权级运行的不同指令集合 硬件机制可将OS与用户程序隔离 1.4 处理器模式/状态(MODE) # 现代处理器通常将CPU状态设计划分为两种、三种或四种 操作系统〔至少〕需要两种CPU状态 内核态（Kernel Mode）：运行操作系统程序 用户态（User Mode）：运行用户程序 在 程序状态字寄存器PSW中专门设置一位，根据运行程序对资源和指令的使用权限而设置不同的CPU状态 Program Status Word - OSDev Wiki\n例：x86架构中的EFLAGS寄存器中使用2位来保存IO的权限级别（IOPL）\nx86—EFLAGS寄存器详解_随心随意随缘的博客-CSDN博客\n1.5 特权指令和非特权指令 # 特权(privilege)指令：只能由操作系统使用、用户程序不能使用的指令 非特权指令：用户程序可以使用的指令 📖 下列哪些是特权指令? 哪些是非特权指令?\n特权指令：启动I/0 内存清零 修改程序状态字 设置时钟 允许/禁止中断 停机\n非特权指令：控制转移 算术运算 取数指令 访管指令（可以使用户程序从用户态陷入操作系统内核态。）\n1.6 实例：x86系列处理器 # x86支持4个处理器特权级别\n特权环：R0、R1、R2和R3\nR0 是希望能运行操作系统的一些关键代码 所以 R0 相当于内核态。 R1是运行设备驱动程序和一些 I/O 处理的历程。 R2是运行一些受保护共享的代码，比如说一些语言编译环境。 R3是给用户程序使用。\n从R0到R3，特权能力由高到低 R0相当于内核态；R3相当于用户态；R1和R2则介于两者之间 不同级别能够运行的指令集合不同 目前(?2015?)大多数基于x86处理器的操作系统只使用了R0和R3两个特权级别\n1.7 CPU状态之间的转换 # 用户态 —\u0026gt; 内核态 ：唯一途径：中断/异常/陷入机制 内核态 —\u0026gt; 用户态：设置程序状态字 PSW 📖 访管指令（陷入指令）：\n提供给用户程序的接口，用于调用操作系统的功能（服务）。 如：int， trap，syscall，sysenter/sysexit\n2 中断与异常机制 # 中断/异常对于操作系统的重要性就好比：汽车的发动机、飞机的引擎。操作系统是由“中断驱动”或者“事件驱动”的。中断与异常机制主要用来：1）及时处理设备发来的中断请求，2）可使OS捕获用户程序提出的服务请求防止用户程序执行过程中的破坏性活动。3）\u0026hellip;\n中断与异常可以概括为：1）CPU对系统发生的某个事件作出的一种反应，2）CPU暂停正在执行的程序，保留现场后自动转去执行相应事件的处理程序，处理完成后返回断点继续执行被打断的程序。\n中断与异常的特点：\n随机发生 自动处理— 硬件自动完成这一过程 可恢复 中断（外中断）：外部事件，正在运行的程序所不期望发生的\nI/O中断：等待输入、扫描、接收到网络包等等 时钟中断：CPU时间片结束、定时器到时等等 硬件故障：电池即将耗尽等等 异常（内中断）：由正在运行的指令引发\n系统调用 页故障/页错误 （缺页异常—文件未读入内存） 保护性异常（磁盘不可写等等） 断点指令（程序调试等等） 其他程序性异常（算术溢出，内存溢出等等） 类别 原因 异步/同步 返回行为 中断 Interrupt 来自I/O设备、其他硬件部件 异步 总是返回到下一条指令 陷入 Trap 有意安排 同步 返回到下一条指令 故障 Falut 可恢复的错误 同步 返回到当前指令 终止 Abort 不可恢复的错误 同步 不会返回 2.1 为什么引入中断与异常 # 中断的引入：为了支持CPU和设备之间的并行操作。\n当CPU启动设备进行输入/输出后，设备便可以独立工作，CPU转去处理与此次输入/输出不相关的事情；当设备完成输入/输出后，通过向CPU发中断报此次输入/输出的结果，让CPU决定如何处理以后的事情。\n异常的引入：表示CPU执行指令时本身出现的问题。\n如算术溢出、除零、取数时的奇偶错，访存地址时越界或执行了“陷入指令”等，这时硬件改变了CPU当前的执行流程，转到相应的错误处理程序或异常处理程序或执行系统调用。\n2.2 原理 # 中断/异常机制是现代计算机系统的核心机制之一。\n硬件和软件相互配合而使计算机系统得以充分发挥能力。\n硬件该做什么事?\u0026ndash;中断/异常响应\n捕获中断源发出的中断/异常请求，以一定方式响应，将处理器控制权交给特定的处理程序。\n软件要做什么事?\u0026ndash;中断/异常处理程序\n识别中断/异常类型并完成相应的处理。\n2.2.1 中断响应 # 发现中断，接收中断的过程。由中断硬件部件完成。\n处理控制器部件中设有中断寄存器。\n处理控制器是计算机系统中的一个重要组成部分，它由硬件和软件两部分组成。硬件部分包括处理器、寄存器、高速缓存等，软件部分包括操作系统和应用程序。处理控制器的主要功能是处理和控制计算机系统中的数据流和输入输出，以及解决性能、安全、健壮等问题。在计算机系统中，处理控制器是负责管理和协调各个硬件设备和软件应用程序之间通信和数据传输的关键部件。它可以通过操作系统运行机制（系统调用）和物理机器界面来与操作系统和硬件进行交互。\n中断寄存器是计算机中一种特殊的寄存器，用于存储中断处理程序的返回地址和处理状态。\n当计算机遇到中断事件时，处理器会自动将当前程序的执行状态保存到堆栈中，并将处理器的控制权转移给中断处理程序。当中断处理程序完成后，处理器会从堆栈中恢复原程序的执行状态，并将控制权返回给原程序继续执行。\n在x86架构中，中断寄存器被称为EFLAGS寄存器，它包含了处理器的一些状态信息，如进位标志、零标志和符号标志等。此外，EFLAGS寄存器还包含了中断标志位(IF)。当IF标志位被设置为1时，处理器允许中断事件的发生，否则处理器会忽略所有中断事件。这个标志位可以被操作系统用来控制中断的开关。\n总之，中断寄存器是计算机中非常重要的一个硬件寄存器，它是中断处理机制的核心。中断处理机制可以使计算机在运行过程中能够及时响应外部事件，提高计算机的效率和稳定性。\n中断响应的简单过程 2.2.2 中断向量表 # 中断向量\n一个内存单元，存放 中断处理程序入口地址和程序运行时所需的处理机状态字。\n中断向量 执行流程：按中断号/异常类型的不同，通过中断向量表转移控制权给中断处理程序。\n📖 Linux中的中断向量表\n向量范围 用途 0~19 不可屏蔽中断和异常 0 除0 1 单步调试 4 算术溢出 6 非法操作数 12 栈异常 13 保护性错误 14 缺页异常 20~31 Intel保留 32~127 外部中断(IRQ) 128(0x80) 用于系统调用的可编程异常 129~238 外部中断 239 本地APIC时钟中断 240 本地APIC高温中断 241~250 Linux保留 251~253 处理器间中断 254 本地APIC错误中断 255 本地APIC伪中断 2.2.3 中断处理程序 # 设计操作系统时，为每一类中断/异常事件编好相应的处理程序，并设置好 中断向量表。\n系统运行时若响应中断，中断硬件部件将CPU控制权转给中断处理程序:\n保存相关寄存器信息 分析中断/异常的具体原因 执行对应的处理功能 恢复现场，返回被事件打断的程序 2.2.4 中断/异常处理流程 # 中断处理流程 中断/异常机制小结：以设备输入输出中断为例：\n打印机给CPU发中断信号 CPU处理完当前指令后检测到中断，判断出中断来源并向相关设备发确认信号 CPU开始为软件处理中断做准备: 处理器状态被切换到内核态 在系统栈中保存被中断程序的重要上下文环境，主要是程序计数器PC、程序状态字PSW CPU根据中断码查中断向量表，获得与该中断相关的处理程序的入口地址，并将PC设置成该地址，新的指令周期开始时，CPU控制转移到中断处理程序 中断处理程序开始工作 在系统栈中保存现场信息 检查I/0设备的状态信息，操纵I/O设备或者在设备和内存之间传送数据等等 📖 中断处理程序的处理，通常分为两类:\nI/O操作正常结束 若有程序正等待此次I/O的结果，则应将其唤醒 若要继续I/O操作，需要准备好数据重新启动I/O I/O操作出现错误 需要重新执行失败的I/O操作 重试次数有上限，达到时系统将判定硬件故障 中断处理结束时，CPU检测到中断返回指令，从系统栈中恢复被中断程序的上下文环境，CPU状态恢复成原来的状态，PSW和PC恢复成中断前的值，CPU开始一个新的指令周期 2.3 x86中的中断与异常机制 # 中断\n由硬件信号引发的，分为可屏蔽和不可屏蔽中断\n异常\n由指令执行引发的，比如除零异常 80x86处理器发布了大约20种不同的异常 对于某些异常，CPU会在执行异常处理程序之前产生硬件出错码，并压入内核态堆栈 系统调用\n异常的一种，用户态到内核态的唯一入口\n中断控制器(PIC或APIC)\n负责将硬件的中断信号转换为中断向量，并引发CPU中断\n实模式：中断向量表(Interrupt Vector)\n存放中断服务程序的入口地址 入口地址 = 段地址左移4位 + 偏移地址 不支持CPU运行状态切换 中断处理与一般的过程调用相似 保护模式：中断描述符表(IDTInterrupt Descriptor Table)\n采用门(gate)描述符数据结构表示中断向量\n2.3.1 中断门描述符表 # 四种类型门描述符：\n任务门(Task Gate) 中断门(Interrupt Gate) 给出段选择符(Segment Selector)、中断/异常程序的段内偏移量(Offset) 通过中断门后系统会自动禁止中断（通过设置寄存器的中断标识位IF完成） 陷阱门(Trap Gate) 与中断门类似，但通过陷阱门后系统不会自动禁止中断 调用门（Call Gate） 2.3.2 中断/异常的硬件处理过程 # 确定与中断或异常关联的向量i\n通过IDTR寄存器找到IDT表，获得中断描述符(表中的第i项)\n从GDTR寄存器获得GDT的地址；结合中断描述符中的段选择符，在GDT表获取对应的段描述符；从该段描述符中得到中断或异常处理程序所在的段基址\nIDT段选择符→ GDT段描述符→ GDT段基址\n特权级检查（2、3步中包含特权级检查）\n检查是否发生了特权级的变化，如果是，则进行堆栈切换(必须使用与新的特权级相关的栈)\n硬件压栈，保存上下文环境；如果异常产生了硬件出错码，也将它保存在栈中\n如果是中断门，清IF位（中断标识位），陷进门不必如此做\n通过中断描述符中的段内偏移量和段描述符中的基地址，找到中断/异常处理程序的入口地址，执行其第一条指令\nx86的中断/异常的硬件处理过程 3 系统调用机制 # 应用程序通过访管指令(或中断/异常机制)来实现系统调用。\n3.1 系统调用的概念 # 用户在编程时可以调用的操作系统功能。\n系统调用（System Call）是操作系统提供给编程人员的唯一接口 使CPU状态从用户态陷入到内核态 每个操作系统都提供了几百种系统调用（进程控制、进程通信、文件使用、目录操作、设备管理、信息维护等等） 系统调用与库函数、API、内核函数的区别与联系 用户程序往往通过调用函数来进行系统调用，进入内核。\n3.2 系统调用的设计 # 3.2.1 系统调用的要素 # 中断/异常机制\n支持系统调用服务的实现。\n选择一条特殊指令：陷入指令（亦称访管指令）\n引发异常，完成用户态到内核态的切换 。\n所有的系统调用都使用这条指令。\n系统调用号和 参数\n每个系统调用都事先给定一个编号（功能号） 。\n通过编号（功能号）来区分不同的系统调用\n系统调用表\n存放系统调用服务例程的入口地址。\n3.2.2 参数的传递 # ❓ 怎样实现用户程序的参数传递给内核？\n常用的3种实现方法：\n由陷入指令自带参数： 陷入指令的长度有限，且还要携带系统调用功能号，只能自带有限的参数。 通过通用寄存器传递参数（常用）： 这些寄存器是操作系统和用户程序都能访问的，但寄存器的个数会限制传递参数的数量。 在内存中开辟专用堆栈区来传递参数 3.2.3 系统调用示例分析 # #include \u0026lt;unistd.h\u0026gt; int main(){ char string[5] = {\u0026#39;H\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;!\u0026#39;, \u0026#39;\\n\u0026#39;}; write(1, string, 7); // 系统调用1 return 0； // 系统调用2 } // 汇编语言编译后的代码（示例） .section .data output: ascii \u0026#34;Hello!\\n\u0026#34; output_end: .equ len, output_end-output .section .text .globl_start _start: movl $4, %eax # eax寄存器存放系统调用编号 movl $1, %ebx # 通用寄存器传递参数 movl $output, %ecx # 参数 movl $len,%edx # 参数 int $0x80 # 陷入指令，引发一次系统调用 end: movl $1, %eax # 以下是return 0 movl $4, %ebx int $0x80 3.3 系统调用的执行过程 # 当CPU执行到特殊的陷入指令时：\n中断/异常机制 硬件保护现场，通过查询中断向量表（描述符表），把CPU的控制权转交给中断处理程序，或者叫系统调用总入口程序。 系统调用总入口程序 保存现场，将系统调用参数保存在内核的堆栈中，查找系统调用表，把控制权交给对应的系统调用的处理程序或者内核函数 执行系统调用例程 恢复现场，返回用户程序 4 基于x86的Linux系统调用机制简介 # 陷入指令选择128号 int $0x80 门描述符 系统初始化时：对IDT表中的128号门初始化 门描述符的2、3两个字节：内核代码段选择符 0、1、6、7四个字节：偏移量（指向system_call()） 门类型：15 陷井门 DPL：3 与用户级别相同，允许用户使用该门描述符 📖 系统调用号示例\n#define_NR_exit 1 #define_NR_fork 2 #define_NR_read 3 #define_NR_write 4 #define_NR_open 5 #define_NR_close 6 #define_NR_waitpid 7 #define_NR_create 8 #define_NR_link 9 #define_NR_unlink 10 #define_NR_execve 11 #define_NR_chdir 12 #define_NR_time 13 系统执行INT $0x80指令后：\n由于特权级的改变，要切换栈 用户栈→内核栈 CPU从任务状态段TSS中装入新的栈指针(SS:ESP)，指向内核栈。 用户栈的信息(SS:ESP)、EFLAGS、用户态CS、EIP寄存器的内容压栈(返回用) 将EFLAGS压栈后，复位TF，IF位保持不变 用128在IDT中找到该门描述符，从中找出段选择符装入代码段寄存器CS 代码段描述符中的基地址+陷阱门描述符中的偏移量 →定位 system_call()的入口地址 x86的Linux系统调用机制 用户态下调用C库的库函数，如write() 封装后的write()先做好参数传递工作，然后使用int 0x80产生一次异常 CPU通过0x80号在IDT中找到对应的服务例程system_call()，调用之 陷入内核态 压栈 查询系统调用表，调用内核函数 执行完成后，通过ret_from_sys_call返回用户例程 中断发生后linux硬件底层的压栈顺序 中断发生后，OS底层的工作步骤：\n硬件压栈:程序计数器等 硬件从中断向量装入新的程序计数器等 汇编语言过程保存寄存器值 汇编语言过程设置新的堆栈 C语言中断服务程序运行(例:读并缓冲输入) 进程调度程序决定下一个将运行的进程 C语言过程返回至汇编代码 汇编语言过程开始运行新的 当前进程 5 本章重点 # 理解计算机系统的保护机制 掌握处理器状态 掌握特权指令与非特权指令 掌握中断/异常机制 掌握中断/异常的基本概念 理解中断/异常机制的工作原理 掌握系统调用机制 掌握系统调用设计原理 掌握系统调用执行过程 重点阅读教材 第1章相关内容:1.3、1.6 第2章第52页图2-5及说明该图思路的段落 重点概念 CPU状态 内核态/用户态 特权指令/非特权指令 中断异常 中断响应 中断向量 中断处理程序 系统调用 陷入指令 系统调用号 系统调用表 "},{"id":15,"href":"/zh/docs/note/pys/2_data_list/","title":"列表（list）","section":"Python","content":" "},{"id":16,"href":"/zh/docs/craft/design_pattern/creation/2_factory/","title":"工厂模式","section":"创建型","content":" 工厂模式 # by Head First 设计模式\n工厂方法模式定义了一个创建对象的接口，但是由子类决定要创建的对象是哪一个。工厂方法把类的实例化推迟到 子类。\nby Dive into Design Patterns\nFactory Method is a creational design pattern that provides an interface for creating objects in a superclass, but allows subclasses to alter the type of objects that will be created.\n工厂模式指定工厂仅仅能创建特定类型的产品。\n设计原则 # 工厂方法很简单，实际上就是抽取客户中实例化对象的代码，利用\u0026quot;对象工厂\u0026quot;来进行实例化。这样做有几个明显的好处：\n降低耦合：创建对象的过程和具体的业务解耦。 基本上满足开-闭原则：如果使用工厂，创建对象的逻辑变动或者所需要创建对象变动对客户的代码影响不大。 满足依赖倒置原则： 依赖抽象而不是依赖具体实现类。不管是高层组件（接口）还是低层组件（对象），都应该依赖抽象。 高层组件不应该直接依赖具体的对象。 依赖倒置原则-维基百科 UML简图 # classDiagram class Product { \u003c\u003c Interface \u003e\u003e +method1() +method2() } Product ..\u003e ProductCreater class ProductCreater { \u003c\u003c Abstract \u003e\u003e +factoryMethod() Product +otherMethod() } ConcreateProductA ..|\u003e Product class ConcreateProductA { +methodA() +methodB() } ConcreateProductB ..|\u003e Product class ConcreateProductB { +methodA() +methodB() } ProductACreater --|\u003e ProductCreater class ProductACreater { +factoryMethod() Product +otherMethod() } ProductBCreater --|\u003e ProductCreater class ProductBCreater { +factoryMethod() Product +otherMethod() } classDiagram class Product { \u0026lt;\u0026lt;Interface\u0026gt;\u0026gt; +method1() +method2() } Product ..\u0026gt; ProductCreater class ProductCreater { \u0026lt;\u0026lt;Abstract\u0026gt;\u0026gt; +factoryMethod() Product +otherMethod() } ConcreateProductA ..|\u0026gt; Product class ConcreateProductA { +methodA() +methodB() } ConcreateProductB ..|\u0026gt; Product class ConcreateProductB { +methodA() +methodB() } ProductACreater --|\u0026gt; ProductCreater class ProductACreater { +factoryMethod() Product +otherMethod() } ProductBCreater --|\u0026gt; ProductCreater class ProductBCreater { +factoryMethod() Product +otherMethod() } 示例代码 # Generated by gpt4o\n// 产品接口 interface Shape { void draw(); } // 具体产品类 class Circle implements Shape { @Override public void draw() { System.out.println(\u0026#34;Drawing a Circle\u0026#34;); } } class Square implements Shape { @Override public void draw() { System.out.println(\u0026#34;Drawing a Square\u0026#34;); } } class Rectangle implements Shape { @Override public void draw() { System.out.println(\u0026#34;Drawing a Rectangle\u0026#34;); } } // 工厂类 class ShapeFactory { // 使用 getShape 方法获取形状类型的对象 public Shape getShape(String shapeType) { if (shapeType == null) { return null; } if (shapeType.equalsIgnoreCase(\u0026#34;CIRCLE\u0026#34;)) { return new Circle(); } else if (shapeType.equalsIgnoreCase(\u0026#34;SQUARE\u0026#34;)) { return new Square(); } else if (shapeType.equalsIgnoreCase(\u0026#34;RECTANGLE\u0026#34;)) { return new Rectangle(); } return null; } } // 测试工厂模式 public class FactoryPatternDemo { public static void main(String[] args) { ShapeFactory shapeFactory = new ShapeFactory(); // 获取 Circle 对象并调用其 draw 方法 Shape shape1 = shapeFactory.getShape(\u0026#34;CIRCLE\u0026#34;); shape1.draw(); // 获取 Square 对象并调用其 draw 方法 Shape shape2 = shapeFactory.getShape(\u0026#34;SQUARE\u0026#34;); shape2.draw(); // 获取 Rectangle 对象并调用其 draw 方法 Shape shape3 = shapeFactory.getShape(\u0026#34;RECTANGLE\u0026#34;); shape3.draw(); } } 工厂模式的工厂职责相对单一，仅能创建指定对象。\n更多示例代码\n开发建议 # 《深入设计模式》中关于工厂模式的介绍\n"},{"id":17,"href":"/zh/docs/craft/design_pattern/structure/3_decorator/","title":"装饰者模式","section":"结构型","content":" 装饰者模式 # by Head First 设计模式:\n动态地将责任附加到对象上。若要拓展功能，装饰者模式提供了比继承更有弹性的替代方案。\nby Dive into Design Patterns:\nAlso known as Wrapper\nDecorator is a structural design pattern that lets you attach new behaviors to objects by placing these objects inside special wrapper objects that contain the behaviors.\n设计原则 # 找出应用之中可以变化之处，把它们独立出来，不要和那些不需要变化的代码混在一起 针对接口编程，而不是针对实现编程 多用组合，少用继承 为交互对象的松耦合设计而努力 对象应对拓展开放，而对修改关闭（开闭原则） 听起来很矛盾，但是确实有一些OO技巧，允许系统在不修改代码的情况下，进行功能拓展（想想观察者模式）。 装饰者模式也是一个好例子，完全遵循开放-关闭原则 通常，设计无法完全遵循开放-关闭原则。也没有必要让所有的代码都强行按照这个原则去设计，强行如此做 只会增加工作量，并且让代码更加复杂。 UML简图 # classDiagram class Component { \u003c\u003c Abstract \u003e\u003e +methodA() +methodB() } Component \u003c|-- ConcreteComponent class ConcreteComponent { +methodA() +methodB() } Component \u003c|..* Decorator class Decorator { \u003c\u003c Abastract \u003e\u003e #Component component +methodA() +methodB() } Decorator \u003c|-- DecoratorA class DecoratorA { #Component component +methodA() +methodB() } Decorator \u003c|-- DecoratorB class DecoratorB { #Component component +methodA() +methodB() } Decorator \u003c|-- DecoratorC class DecoratorC { #Component component -Object newStats +methodA() +methodB() } classDiagram class Component { \u0026lt;\u0026lt;Abstract\u0026gt;\u0026gt; +methodA() +methodB() } Component \u0026lt;|-- ConcreteComponent class ConcreteComponent { +methodA() +methodB() } Component \u0026lt;|..* Decorator class Decorator { \u0026lt;\u0026lt;Abastract\u0026gt;\u0026gt; #Component component +methodA() +methodB() } Decorator \u0026lt;|-- DecoratorA class DecoratorA { #Component component +methodA() +methodB() } Decorator \u0026lt;|-- DecoratorB class DecoratorB { #Component component +methodA() +methodB() } Decorator \u0026lt;|-- DecoratorC class DecoratorC { #Component component -Object newStats +methodA() +methodB() } 示例代码 # Generated by chatgpt.\n装饰者模式（Decorator Pattern）是一种结构型设计模式，它允许向一个现有的对象添加新的功能，同时又不改变其结构。这种类型的设计模式属于结构型模式，它是作为现有类的一个包装。\n这个模式创建了一个装饰类，用来包装原有的类，并在保持原有类方法签名完整性的前提下，提供了额外的功能。\n下面是一个简单的装饰者模式的示例代码，展示了如何为简单的饮料添加不同的调料装饰。\n首先，创建一个Beverage接口和几个实现了Beverage接口的具体饮料类：\n// 饮料接口 public interface Beverage { String getDescription(); double cost(); } // 具体饮料类：咖啡 class Coffee implements Beverage { @Override public String getDescription() { return \u0026#34;Coffee\u0026#34;; } @Override public double cost() { return 1.99; } } // 具体饮料类：茶 class Tea implements Beverage { @Override public String getDescription() { return \u0026#34;Tea\u0026#34;; } @Override public double cost() { return 1.49; } } 接下来，创建一个装饰者抽象类，它实现了Beverage接口：\n// 装饰者抽象类 abstract class CondimentDecorator implements Beverage { protected Beverage beverage; } 然后，实现具体的装饰者类，为饮料添加不同的调料：\n// 具体装饰者：牛奶 class Milk extends CondimentDecorator { public Milk(Beverage beverage) { this.beverage = beverage; } @Override public String getDescription() { return beverage.getDescription() + \u0026#34;, Milk\u0026#34;; } @Override public double cost() { return beverage.cost() + 0.50; } } // 具体装饰者：糖 class Sugar extends CondimentDecorator { public Sugar(Beverage beverage) { this.beverage = beverage; } @Override public String getDescription() { return beverage.getDescription() + \u0026#34;, Sugar\u0026#34;; } @Override public double cost() { return beverage.cost() + 0.20; } } 最后，使用装饰者模式来装饰饮料：\npublic class DecoratorPatternDemo { public static void main(String[] args) { Beverage coffee = new Coffee(); System.out.println(coffee.getDescription() + \u0026#34; $\u0026#34; + coffee.cost()); Beverage tea = new Tea(); tea = new Milk(tea); tea = new Sugar(tea); System.out.println(tea.getDescription() + \u0026#34; $\u0026#34; + tea.cost()); } } 在这个示例中，Coffee和Tea是两种饮料，我们通过Milk和Sugar装饰者来为它们添加额外的调料。这样，我们可以动态地为饮料添加任意数量的调料，而不需要修改原有的饮料类。\n笔记 # 继承属于拓展的形式之一，但是不见得是达到弹性拓展的最佳方式。 在我们的设计中，应该允许行为可以被拓展，而无需修改现有的代码。 组合和委托可用于运行时动态地加上新行为。 除了继承，装饰者也可以让我们拓展行为。 装饰者模式意味着一群装饰者类，用来包装具体的组件 装饰者可以在被装饰者前面/后面加上自己的行为，或者替代被装饰者的行为，以达到目的。 如有必要，装饰者可以无限制地使用。 装饰者一般对组件的客户是透明的，除非客户程序依赖组件的具体类型。 装饰者模式会导致设计中多出许多小类，如果过度使用，会让程序变得复杂。 装饰器模式示例代码 "},{"id":18,"href":"/zh/docs/craft/design_pattern/behaviour/2_observer/","title":"观察者模式","section":"行为型","content":" 观察者模式 # by Head First 设计模式 在对象之间建立一对多的依赖，这样一来，当一个对象的状态改变，依赖它的对象都会收到通知，并且自动更新。\nby Dive into Design Patterns: Also Known as: Event-Subscriber, Listener\nObserver is a behavioral design pattern that lets you define a subscription mechanism to notify multiple objects about any events that happen to the object they’re observing.\n设计原则 # 找出应用之中可以变化之处，把它们独立出来，不要和那些不需要变化的代码混在一起 针对接口编程，而不是针对实现编程 多用组合，少用继承 为交互对象的松耦合设计而努力 事实上，不用设计模式也可以硬编码出发布者-订阅者工作模式的代码，只不过发布者与订阅者呆在一起，会比较臃肿😮， 也不利于扩展。 在观察者模式中，被观察者（发布者）与观察者（订阅者）是松耦合的，发布者并不关心订阅者的具体细节，只需要知道 其订阅与否，就知道状态变化后是否对其发送通知；同样地，订阅者也不关心发布者如何通知它，只需要处理好自己收到 通知的业务就行了😊 松耦合的设计优势得以体现：代码有层次感，易于拓展和维护。 想想看MVC开发模式，这是不是松耦合的设计呢？控制层、模型层、视图层分别有自己的业务范围\nUML简图 # classDiagram direction LR class Publisher { \u003c\u003c interface \u003e\u003e + registSubscriber(Subscriber s) + unregistSubscriber(Subscriber s) + notifySubscribers() } Publisher \u003c|.. Client Client *..\u003e Subscriber class Client { - List~Subscriber~ subscribers - Boolean state + registSubscriber(Subscriber s) + unregistSubscriber(Subscriber s) + notifySubscribers() } class Subscriber { \u003c\u003c interface \u003e\u003e +update() } Subscriber \u003c|.. ConcreteSubscriber : impl class ConcreteSubscriber { ... + update() } classDiagram direction LR class Publisher { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; + registSubscriber(Subscriber s) + unregistSubscriber(Subscriber s) + notifySubscribers() } Publisher \u0026lt;|.. Client Client *..\u0026gt; Subscriber class Client { - List~Subscriber~ subscribers - Boolean state + registSubscriber(Subscriber s) + unregistSubscriber(Subscriber s) + notifySubscribers() } class Subscriber { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; +update() } Subscriber \u0026lt;|.. ConcreteSubscriber : impl class ConcreteSubscriber { ... + update() } 笔记 # 观察者模式定义了对象之间一对多的关系。 发布者（被观察者）用一个统一的接口来更新观察者。 发布者和订阅者之间使用松耦合（loosecoupling）的方式结合，订阅者不知道观察者的细节，只知道观察者实现观察者接口。 使用此模式时，订阅者可以从发布者处\u0026quot;推\u0026quot;或者\u0026quot;拉\u0026quot;数据， 不过\u0026quot;推\u0026quot;一般被认为是正确的方式。 有多个订阅者时，可以不依赖特性的通知顺序。 Java提供了此模式的包，包括java.util.Observable（Deprecated since Java 9）。 此模式被用在其他地方，如JavaBeans，RMI。 示例代码 # 发布者 # public interface Subject { void registerBoard(Board board); void unregisterBoard(Board board); void notifyBoard(); // other businesses } public class WeatherStation implements Subject { // 并发风险 private List\u0026lt;Board\u0026gt; boards; private boolean status; public WeatherStation() { this.boards = new LinkedList\u0026lt;\u0026gt;(); this.status = false; } @Override public void registerBoard(Board board) { if (!boards.contains(board)){ boards.add(board); } } @Override public void unregisterBoard(Board board) { boards.remove(board); } @Override public void notifyBoard() { if (status){ for (Board board : boards) { board.update(this); } status = false; } } public void setStatus(boolean status) { this.status = status; } private float temperature; private float humidity; private float pressure; public void setData(float temperature, float humidity, float pressure){ this.temperature = temperature; this.humidity = humidity; this.pressure = pressure; this.status = true; notifyBoard(); // set and notify subscriber } // getters // other business } 订阅者 # public interface Board { // 观察者收到通知之后的更新，方法参数可以是指定字段或者实体 void update(WeatherStation client); } public class StatisticsBoard implements Board { @Override public void update(WeatherStation client) { System.out.printf(\u0026#34;Average weather of this month:\u0026#34; + \u0026#34;\\n Average Temperature %.2f celsius\u0026#34; + \u0026#34;\\n Average Humidity %.2f\u0026#34; + \u0026#34;\\n Average Pressure %.2f\\n\u0026#34;, client.getTemperature(), client.getHumidity(), client.getPressure()); } } 客户端 # public class WeatherStationClient { public static void main(String[] args) { WeatherStation client = new WeatherStation(); // register a new listener StatisticsBoard statisticsBoard = new StatisticsBoard(); client.registerBoard(statisticsBoard); client.setData(23.2f, 10.91f, 1.01f); } } 更加详细的代码\n"},{"id":19,"href":"/zh/docs/craft/design_pattern/behaviour/3_strategy/","title":"策略模式","section":"行为型","content":" 策略模式 # by Head First 设计模式:\n策略模式定义了算法族，分别封装起来，让他们之间可以互相替换。此模式让算法的变化独立于使用算法的\u0026quot;客户\u0026quot;。\nby Dive into Design Patterns:\nStrategy is a behavioral design pattern that lets you define a family of algorithms, put each of them into a separate class, and make their objects interchangeable.\n设计原则 # 找出应用之中可以变化之处，把它们独立出来，不要和那些不需要变化的代码混在一起 针对接口编程，而不是针对实现编程 客户的行为可以抽象为接口的，不必让客户去实现接口。如果这样做，客户想改变行为需要不断地去编写 实现。这样的行为，可以理解为针对实现编程。 鉴于此，可以在别处实现接口，客户只需要根据接口来选择合适的行为，这样做客户的代码更简洁且便于 维护。 多用组合，少用继承 将两（多）个类组合起来使用，就是组合（composition），这样比使用继承好的一点是：系统的弹性 更大，并且可以避免使用继承不得不出现的无意义重写（override）一些需要规避掉的方法。 UML简图 # classDiagram direction UD class Charactor{ \u003c\u003c Abstract \u003e\u003e +WeaponBehavior weaponBehavior +fight()* +setWeapon(WeaponBeahvior) } Charactor \u003c|-- King: Is A class King King: +fight() class Queen Queen: +fight() Charactor \u003c|-- Queen: Is A class Knight Knight: +fight() Charactor \u003c|-- Knight: Is A class WeaponBehavior Charactor *--\u003e WeaponBehavior : Has A \u003c\u003c Interface \u003e\u003e WeaponBehavior WeaponBehavior: +useWeapon()* calss SwordBehavior WeaponBehavior \u003c|.. SwordBehavior : Implement SwordBehavior: +useWeapon() calss AxeBehavior WeaponBehavior \u003c|.. AxeBehavior : Implement AxeBehavior: +useWeapon() class KnifeBehavior WeaponBehavior \u003c|.. KnifeBehavior: Implement KnifeBehavior: +useWeapon() classDiagram direction UD class Charactor{ \u0026lt;\u0026lt;Abstract\u0026gt;\u0026gt; +WeaponBehavior weaponBehavior +fight()* +setWeapon(WeaponBeahvior) } Charactor \u0026lt;|-- King: Is A class King King: +fight() class Queen Queen: +fight() Charactor \u0026lt;|-- Queen: Is A class Knight Knight: +fight() Charactor \u0026lt;|-- Knight: Is A class WeaponBehavior Charactor *--\u0026gt; WeaponBehavior : Has A \u0026lt;\u0026lt;Interface\u0026gt;\u0026gt; WeaponBehavior WeaponBehavior: +useWeapon()* calss SwordBehavior WeaponBehavior \u0026lt;|.. SwordBehavior : Implement SwordBehavior: +useWeapon() calss AxeBehavior WeaponBehavior \u0026lt;|.. AxeBehavior : Implement AxeBehavior: +useWeapon() class KnifeBehavior WeaponBehavior \u0026lt;|.. KnifeBehavior: Implement KnifeBehavior: +useWeapon() 示例代码 # 抽象角色 # public abstract class Duck { // 定义角色的可变行为 protected FlyBehavior flyBehavior; protected QuarkBehavior quarkBehavior; // 不变的部分 public abstract void swim(); public abstract void display(); // fly and quark // 由于并不是所有的\u0026#34;鸭子\u0026#34;实现不能都会飞或者叫 // 实际开发中经常遇到实现并不需要全部的功能这种情况 // 于是把\u0026#34;变化的部分\u0026#34;独立出去，鸭子类更易于拓展，否则可能需要处理很多无用的覆写啦😄 // 实际上变化的功能，交给具体的实现去做啦 /* * PS: 让鸭子实现直接实现FlyBehavior接口的话，也相当于只做了一半的工作。改变鸭子的行为， * 依然需要改变实现，这就是所谓\u0026#34;面对实现编程\u0026#34; */ public void performFly() { flyBehavior.fly(); } public void performQuark() { quarkBehavior.quark(); } // 通过使用策略模式，不局限于规范行为的接口，可以动态改变实现的行为 public void setFlyBehavior(FlyBehavior fb) { this.flyBehavior = fb; } public void setQuarkBehavior(QuarkBehavior qb) { this.quarkBehavior = qb; } } 具体角色 # public class MallardDuck extends Duck { public MallardDuck() { this.quarkBehavior = new Quark(); this.flyBehavior = new FlyWithWings(); } @Override public void swim() { //... } @Override public void display() { //... } } 可变行为 # 可变行为一般有多个实现，这样才能实现策略嘛。比如支付通道什么的😄️。这里只简单贴点代码。\n// 要实现策略，它肯定有多个实现啦 public interface FlyBehavior { void fly(); } public class FlyWithWings implements FlyBehavior{ @Override public void fly() { System.out.println(\u0026#34;Yes! I can fly with wings!\u0026#34;); } } // 另一个行为 public interface QuarkBehavior { void quark(); } public class Quark implements QuarkBehavior{ @Override public void quark() { System.out.println(\u0026#34;Quark!\u0026#34;); } } 客户端代码 # public class DuckTest { public static void main(String[] args) { // 这种🦆的飞/叫行为已经在策略里定义了 MallardDuck mock = new MallardDuck(); mock.performFly(); mock.performQuark(); // 改变行为（策略）试试 mock.setFlyBehavior(new FlyWithRocket()); mock.performFly(); } } 更加详细的代码\n"},{"id":20,"href":"/zh/docs/craft/algo/%E7%A7%BB%E4%BD%8D%E8%BF%90%E7%AE%97/","title":"移位运算","section":"算法讨论","content":"位运算是直接操作内存中的二进制数据。因此运算效率比常规的四则运算高出不少。\n1.左移运算 # 左移运算用\u0026lt;\u0026lt;表示，按照高位舍弃，低位补0的方式将所有数据位向左移动。\n直观来讲，向左移1位等同于将数值乘以2。大多数情形下也确实如此。如：\nval a = 3 println(\u0026#34;a \u0026lt;\u0026lt; 1 = ${a shl 1}\u0026#34;) // 6 val b = -1 println(\u0026#34;b \u0026lt;\u0026lt; 1 = ${b shl 1}\u0026#34;) // -2 val c = -0xff println(\u0026#34;c \u0026lt;\u0026lt; 1 = ${c shl 1}\u0026#34;) // -510 val d = 0xff println(\u0026#34;d \u0026lt;\u0026lt; 1 = ${d shl 1}\u0026#34;) // 510 Kotlin 中使用特定的移位操作符。\n但是，这是数据没有溢出的情形。如果一个数足够大，移位时可能会发生数据溢出：\nval a = 0x5FFFFFFF // 1610612736 println(\u0026#34;a \u0026lt;\u0026lt; 1 = ${a shl 1}\u0026#34;) // -1073741826 val b = -0x60000000 // -1610612736 println(\u0026#34;b \u0026lt;\u0026lt; 1 = ${b shl 1}\u0026#34;) // 1073741824 上面的2种情形则有不同，当它们向左移位时，按照之前的逻辑，各自的值会翻倍。得到的结果超出了32位整数（int）的取值范围（-232 ~232-1），超出的数位被舍弃。以0x5FFFFFFF为例，其2进制表示为：\n0101 1111 1111 1111 1111 1111 1111 1111 \u0026lt;\u0026lt; 1 --------------------------------------------- 0 1011 1111 1111 1111 1111 1111 1111 1110 最高位的0被舍弃，得到的结果高位为1，结果为负数。\n左移运算为什么不需要区分逻辑左移和算术左移呢？\n左移位数与符号位后位数对应的数只要是1，左移就会溢出，符号发生改变；反之，如果是0，则符号不会发生改变。\n因为左移运算存在溢出。以上述-0x60000000为例，其原码的最高位为1（符号位后一位），由此可知，其左移1位，就会溢出，下图展示了其运算过程：\n原码：0110 0000 0000 0000 0000 0000 0000 0000 反码：1001 1111 1111 1111 1111 1111 1111 1111 补码：1010 0000 0000 0000 0000 0000 0000 0000 \u0026lt;\u0026lt; 1: --------------------------------------------------- 1 0100 0000 0000 0000 0000 0000 0000 0000 2. 右移运算 # 和左移运算一样，右移运算将所有的数据位向右移动，低位舍弃，高位补0/1。需要注意的是，对于有符号数，由于计算机用最高位表示符号位，因此根据符号位是否移动，可以将右移运算分为逻辑右移和算术右移。\n对于正数来讲，逻辑右移和算术右移是相等的，正数的最高位为0，向右移动时，高位补充的也是0，对结果没有影响。\n2.1 逻辑右移 # 逻辑右移又叫“无符号右移”，使用\u0026gt;\u0026gt;\u0026gt;表示，“逻辑”的意思是，不考虑符号位，所有数位全部右移。在这种情况下，负数右移就会发生符号变化。就像下面这样：\nval a = -0xf println(\u0026#34;$a \u0026gt;\u0026gt;\u0026gt; 1 = ${a ushr 1}\u0026#34;) // -15 \u0026gt;\u0026gt;\u0026gt; 1 = 2147483640 val b = 0xf println(\u0026#34;$b \u0026gt;\u0026gt;\u0026gt; 1 = ${b ushr 1}\u0026#34;) // 15 \u0026gt;\u0026gt;\u0026gt; 1 = 7 val c = -0x80000000 println(\u0026#34;$c \u0026gt;\u0026gt;\u0026gt; 1 = ${c ushr 1}\u0026#34;) // -2147483648 \u0026gt;\u0026gt;\u0026gt; 1 = 1073741824 可见，逻辑右移运算在操作负数的情况下，直接移动了符号位，最高位补0，负数也变成了正数。\n下图简单地以-0xf为例，解释运算过程：\n正数原码：0000 0000 0000 0000 0000 0000 0000 1111 反码：1111 1111 1111 1111 1111 1111 1111 0000 补码：1111 1111 1111 1111 1111 1111 1111 0001 ---------------------------------------------------- \u0026gt;\u0026gt;\u0026gt; 1 : 0111 1111 1111 1111 1111 1111 1111 1000 1 2.2 算术右移 # 算术右移使用\u0026gt;\u0026gt;表示，相较于逻辑右移，算术右移考虑符号位：\n若移动的是正数，符号位是0，移动时，符号位保持0不变，移动多少位，就在符号位后补多少0。从这个描述来看，正数的算术右移和逻辑右移结果是相等的； 若移动的是负数，符号位是1，，移动时，符号位保持1不变，移动多少位，就在符号位后补多少1。 简而言之，算术右移正数补0，负数补1。算术右移的结果就是，值变为原来的1/2。\nval a = -0xf println(\u0026#34;$a \u0026gt;\u0026gt; 1 = ${a shr 1}\u0026#34;) // -15 \u0026gt;\u0026gt; 1 = -8 val b = 0xf println(\u0026#34;$b \u0026gt;\u0026gt; 1 = ${b shr 1}\u0026#34;) // 15 \u0026gt;\u0026gt; 1 = 7 val c = -0x80000000 println(\u0026#34;$c \u0026gt;\u0026gt; 1 = ${c shr 1}\u0026#34;) // -2147483648 \u0026gt;\u0026gt; 1 = -1073741824 右移运算不会出现溢出。\n"},{"id":21,"href":"/zh/docs/note/translations/use-springboot-messagesource/","title":"在SpringBoot中使用MessageSource","section":"翻译文章","content":" 几个说明：\nproperties配置文件中，spring.messages.basename必须要加classpath前缀。如 spring.messages.basename=classpath:i18n/messages； 必须要手动配置MessageSource，springboot不会自动配置之； 如果使用MessageSource.getMessage()方法，第一个参数的引用形式为\u0026quot;code\u0026quot;，而不是\u0026quot;{code}\u0026quot;或者\u0026quot;${code}\u0026quot;。如messageSource.getMessage(\u0026ldquo;test.msg\u0026rdquo;, null, Locale.getDefault())； 在配置LocalValidatorFactoryBean之后，才可以在javax.validation.constraints包下的注解（@Size，@NotNull\u0026hellip;）下的message属性中使用\u0026quot;{code}\u0026quot;的形式声明校验提示信息。如 @NotNull(message = \u0026quot;{leftTime.not.null}\u0026quot;)； springMVC的locale配置和JVM的locale配置不一样，在application.properties中配置的spring.mvc.locale=zh_CN实际上配置的是WebMvcProperties，在获取消息时，locale信息应该使用webMvcProperties.getLocale()1获取而不是使用Locale.getDefault()获取。 MessageSource is a powerful feature available in Spring applications. This helps application developers handle various complex scenarios with writing much extra code, such as environment-specific configuration, internationalization or configurable values.\nOne more scenario could be modifying the default validation messages to more user-friendly/custom messages.\nIn this tutorial, we\u0026rsquo;ll see how to configure and manage custom validation MessageSource in the application using Spring Boot.\n2 引入Maven依赖 # Let\u0026rsquo;s start with adding the necessary Maven dependencies:\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-validation\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; You can find the latest versions of these libraries over on Maven Central.\n3 自定义校验信息示例 # Let\u0026rsquo;s consider a scenario where we have to develop an application that supports multiple languages. If the user doesn\u0026rsquo;t provide the correct details as input, we\u0026rsquo;d like to show error messages according to the user\u0026rsquo;s locale.\nLet\u0026rsquo;s take an example of a Login form bean:\npublic class LoginForm { // 注意此处的语法，为\u0026#34;{}\u0026#34;形式，在spring项目中，是无法通过ctrl+鼠标左键定位到配置文件的 // 若去除大括号，则可以通过ctrl+鼠标左键定位到配置的值 @NotEmpty(message = \u0026#34;{email.notempty}\u0026#34;) @Email private String email; @NotNull private String password; // standard getter and setters } Here we\u0026rsquo;ve added validation constraints that verify if an email is not provided at all, or provided, but not following the standard email address style.\nTo show custom and locale-specific message, we can provide a placeholder as mentioned for the @NotEmpty annotation.\nThe email.notemptyproperty will be resolved from a properties files by the MessageSource configuration.\n4 配置MessageSource # An application context delegates the message resolution to a bean with the exact name messageSource.\nReloadableResourceBundleMessageSource is the most common MessageSource implementation that resolves messages from resource bundles for different locales:\n@Bean public MessageSource messageSource() { ReloadableResourceBundleMessageSource messageSource = new ReloadableResourceBundleMessageSource(); // 如果使用ReloadableResourceBundleMessageSource，classpath前缀必不可少 // classpath前缀告诉ReloadableResourceBundleMessageSource从classpath中获取配置 messageSource.setBasename(\u0026#34;classpath:messages\u0026#34;); messageSource.setDefaultEncoding(\u0026#34;UTF-8\u0026#34;); return messageSource; } Here, it\u0026rsquo;s important to provide the basename as locale-specific file names will be resolved based on the name provided.\n4.1 关于MessageSource的自动配置 # 实际上，Spring Boot可以自动配置MessageSourece，不过，想要成功配置，有2个条件：\nSpring Boot自动配置实际上使用的是ResourceBundleMessageSourece，不同于ReloadableResourceBundleMessageSource 你无需再配置别名为\u0026quot;messageSource\u0026quot;的Bean，也就是说上述的配置必须忽略掉 不妨看看MessageSource自动配置相关的类，具体内容在org.springframework.boot.autoconfig.context.MessageSourceAutoConfiguration.java类中：\n@Configuration(proxyBeanMethods = false) @ConditionalOnMissingBean(name = AbstractApplicationContext.MESSAGE_SOURCE_BEAN_NAME, search = SearchStrategy.CURRENT) @AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE) @Conditional(ResourceBundleCondition.class) @EnableConfigurationProperties public class MessageSourceAutoConfiguration { //... } 注意该自动配置类上的2个注解：\n@ConditionalOnMissingBean(name = AbstractApplicationContext.MESSAGE_SOURCE_BEAN_NAME, search = SearchStrategy.CURRENT)\n这个注解说明的就是，如果你没有配置messageSource，那么SpringBoot（可能）会自动为你配置\n@Conditional(ResourceBundleCondition.class)\n这是一个条件化注入，条件在ResourceBundleCondition.class中定义。通过名字就知道，Spring Boot自动配置使用的是ResourceBundleMessageSourece\nResourceBundleCondition.class是MessageSourceAutoConfiguration.class的内部类，以下是其内容：\n@Override public ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) { String basename = context.getEnvironment().getProperty(\u0026#34;spring.messages.basename\u0026#34;, \u0026#34;messages\u0026#34;); ConditionOutcome outcome = cache.get(basename); if (outcome == null) { outcome = getMatchOutcomeForBasename(context, basename); cache.put(basename, outcome); } return outcome; } private ConditionOutcome getMatchOutcomeForBasename(ConditionContext context, String basename) { ConditionMessage.Builder message = ConditionMessage.forCondition(\u0026#34;ResourceBundle\u0026#34;); for (String name : StringUtils.commaDelimitedListToStringArray(StringUtils.trimAllWhitespace(basename))) { for (Resource resource : getResources(context.getClassLoader(), name)) { if (resource.exists()) { return ConditionOutcome.match(message.found(\u0026#34;bundle\u0026#34;).items(resource)); } } } return ConditionOutcome.noMatch(message.didNotFind(\u0026#34;bundle with basename \u0026#34; + basename).atAll()); } // basename不需要classpath前缀，它总是从classpath中获取资源 private Resource[] getResources(ClassLoader classLoader, String name) { String target = name.replace(\u0026#39;.\u0026#39;, \u0026#39;/\u0026#39;); try { return new PathMatchingResourcePatternResolver(classLoader) .getResources(\u0026#34;classpath*:\u0026#34; + target + \u0026#34;.properties\u0026#34;); } catch (Exception ex) { return NO_RESOURCES; } } 我们只需要关注getResources方法，可以看到，其自动补全了classpath前缀，因此，ResourceBundleMessageSourece总是从classpath中获取资源的。\n如果这两个条件都满足，那么SpringBoot会自动使用ResourceBundleMessageSourece配置MessageSource。\n4.2 RBMS和RRBMS # RBMS: ResourceBundleMessageSource RRBMS: ReloadableResourceBundleMessageSource 在本文的 文首，标注了几个实践时需要注意的点，现在看来，前2点都是错误的表述，因为当时实践时使用的是ReloadableResourceBundleMessageSourece，并且没有搞清楚Spring Boot自动配置MessageSource的条件。\n关于这2个“MessageSource”的区别，github上有一个经典的 issue，描述的问题是如果不使用classpath前缀，前者可以读取消息，后者不能读取消息。spring开发人员的回复一针见血：\nI assume your resource bundle files live in the classpath? There is an important difference between ResourceBundleMessageSource and ReloadableResourceBundleMessageSource: The former always loads resource bundles from the classpath (since that is all that standard java.util.ResourceBundle is capable of), whereas the latter loads resource bundle files through the ApplicationContext\u0026rsquo;s ResourceLoader. If your context is a ClassPathXmlApplicationContext, you won\u0026rsquo;t notice a difference - but if it is a WebApplicationContext, it will try to find the files in the WAR directory structure when not using a prefix. So it would simply not find your files because it is looking in the wrong location.\nIf my assumption is correct, the following quick fix will allow your messages to be found in their existing location when switching to ReloadableResourceBundleMessageSource:\n\u0026lt;property name=\u0026quot;basename\u0026quot; value=\u0026quot;classpath:messages\u0026quot;\u0026gt;\nHowever, since classpath resources will be cached by the ClassLoader, ReloadableResourceBundleMessageSource\u0026rsquo;s refreshing is likely to not actually work in that case. So I\u0026rsquo;d rather recommend specifying something like the following, operating against an expanded WAR directory structure where WEB-INF resources can be refreshed from the file system:\n\u0026lt;property name=\u0026quot;basename\u0026quot; value=\u0026quot;WEB-INF/messages\u0026quot;/\u0026gt;\n回复指出了ResourceBundleMessageSourece和ReloadableResourceBundleMessageSourece最重要的区别：\nResourceBundleMessageSourece总是从classpath中加载资源 ReloadableResourceBundleMessageSourece 则从ApplicationContext\u0026rsquo;s ResourceLoader中加载资源 除此之外，二者还有一些其他的区别：\nResourceBundleMessageSourece只能读取properties配置文件，而ReloadableResourceBundleMessageSourece还可以读取xml配置文件 ReloadableResourceBundleMessageSourece可以从任意位置2读取配置文件 从名字来看，Reloadable是可以动态加载配置文件的，事实上也确实如此，它有一个属性cacheSeconds，用来设置缓存配置文件的时间间隔： 默认值是 -1，意味着不动态加载配置文件 如果配置值为0，那么每次获取消息时就会检查配置文件的改动，这个配置值要慎用 如果配置为其他正整数，则会在固定间隔后检查配置文件改动 5 配置LocalValidatorFactoryBean # 为了在javax.validation.constraints包下注解（@NotEmpty、@NotNull等）的校验中使用messageResource，还需要配置LocalValidatorFactoryBean\nTo use custom name messages in a properties file like we need to define a LocalValidatorFactoryBean and register the messageSource:\n@Bean public LocalValidatorFactoryBean getValidator() { LocalValidatorFactoryBean bean = new LocalValidatorFactoryBean(); bean.setValidationMessageSource(messageSource()); return bean; } However, note that if we had already extended the WebMvcConfigurerAdapter, to avoid having the custom validator ignored, we\u0026rsquo;d have to set the validator by overriding the getValidator() method from the parent class.\nNow we can define a property message like:\n“email.notempty=\u0026lt;Custom_Message\u0026gt;” instead of\n“javax.validation.constraints.NotEmpty.message=\u0026lt;Custom_message\u0026gt;” 6 国际化properties文件 # The final step is to create a properties file in the src/main/resources directory with the name provided in the basename in step 4:\n6.1 messages.properties # email.notempty=Please provide valid email id. Here we can take advantage of internationalization along with this. Let\u0026rsquo;s say we want to show messages for a French user in their language.\nIn this case, we have to add one more property file with the name the messages_fr.properties in the same location (No code changes required at all):\n6.2 messages_fr.properties # email.notempty=Veuillez fournir un identifiant de messagerie valide. 7 结论 # In this article, we covered how the default validation messages can be changed without modifying the code if the configuration is done properly beforehand.\nWe can also leverage the support of internationalization along with this to make the application more user-friendly.\n8 使用并解析message # 前文介绍了如何使用MessageResource进行参数校验时的国际化信息展现，最后补充如何在其他部分展现国际化的信息，最显著的一个使用场景就是错误消息的展现。\n配置好messages.properties文件之后，我们可以定义一个错误信息的枚举类：\n# messages.properties satisfied.resource.not.found=要处理的资源不存在 unknown.error=未知错误 # other promote messages no.specific.id.resource=对应id的资源不存在 @Getter public enum ReqState { RESPONSE_ADVICE_ERROR(500_08, \u0026#34;response.advice.error\u0026#34;), SATISFIED_RESOURCE_NOT_FOUND(500_09,\u0026#34;satisfied.resource.not.found\u0026#34;), UNKNOWN_ERROR(600_00, \u0026#34;unknown.error\u0026#34;); private int code; private String message; ReqState(int code, String message) { this.code = code; this.message = message; } } 和在@NotEmpty注解中使用方式不一样，这里只需要以字符串的形式直接引用即可。当然，这个消息还需要解析（实际上消息是以key-value的形式配置的，以key的形式引用，而要以value的形式呈现，在多语言的环境，可以实现\u0026quot;一次引用，多种呈现”的目的），解析的方式也很简单：\n@Autowired MessageResource messageSource; messageSource.getMessage(\u0026#34;unknown.error\u0026#34;, null, LocaleContextHolder.getLocale())) 如果此处像文章开头说的那样，使用webMvcProperties.getLocale()的话，在获取HTTP Header设置的Loacle时有些问题。此处使用了LocaleContextHolder.getLocale()，LocaleContextHolder可以灵活地获取每一次Servlet请求的Locale信息。\n我们不妨看看WebMvcProperties类的Locale域：\n/** * Locale to use. By default, this locale is overridden by the \u0026#34;Accept-Language\u0026#34; header. */ private Locale locale; 注意到，可以通过设置HTTP请求头的方式来设置Locale信息。\n实际上，测试发现，通过设置Accept-Language请求头，配合使用LocaleContextHolder.getLocale()获取Locale信息，可以实现国际化效果，而使用webMvcProperties.getLocale()无法总是正确获取请求头设置的Locale信息。\n还有一点就是，LocaleContextHolder是通过静态方法获取的Locale信息，相较于webMvcProperties的实例方法，免去了注入WebMvcProperties的麻烦。\n8.1 LocaleContextHolder和Accept-Language # 现在我们知道，可以通过LocaleContextHolder和设置Accept-Language头动态获取请求的Locale信息，那么我们可以在控制器中 这样使用Locale信息：\n@Controller public class WifeController { @Autowired private MessageSource msgSrc; @RequestMapping(value = \u0026#34;/wife/mood\u0026#34;) public String readWife(Model model, @RequestParam(\u0026#34;whatImDoing\u0026#34;) String iAm) { // 获取Locale信息 Locale loc = LocaleContextHolder.getLocale(); if(iAm.equals(\u0026#34;playingXbox\u0026#34;)) { model.addAttribute( \u0026#34;statusTitle\u0026#34;, msgSrc.getMessage(\u0026#34;mood.angry\u0026#34;, null, loc) ); model.addAttribute( \u0026#34;statusDetail\u0026#34;, msgSrc.getMessage(\u0026#34;mood.angry.xboxdiatribe\u0026#34;, null, loc) ); } return \u0026#34;moodResult\u0026#34;; } } 不过，在每个控制器里都需要获取一次Loacle信息，这样的方式似乎有点繁琐。那么是否可以简单一点呢？显然是可以的。\nspringMvc v3.2.x doc 17.3.3中定义了控制器方法支持的参数：\n\u0026hellip;\njava.util.Locale for the current request locale, determined by the most specific locale resolver available, in effect, the configured LocaleResolver in a Servlet environment.\n\u0026hellip;\n也就是说，Locale可以直接作为参数被HTTP请求传递进来。因此，可以这样改造上述控制器：\n@RequestMapping(value = \u0026#34;/wife/mood\u0026#34;) public String readWife(Model model, @RequestParam(\u0026#34;whatImDoing\u0026#34;) String iAm, Locale loc) { if(iAm.equals(\u0026#34;playingXbox\u0026#34;)) { model.addAttribute( \u0026#34;statusTitle\u0026#34;, msgSrc.getMessage(\u0026#34;mood.angry\u0026#34;, null, loc) ); model.addAttribute( \u0026#34;statusDetail\u0026#34;, msgSrc.getMessage(\u0026#34;mood.angry.xboxdiatribe\u0026#34;, null, loc) ); } return \u0026#34;moodResult\u0026#34;; } 这样简洁多了，SpringMvc简直太聪明了！等等，通过spring.mvc.locale=zh_CN或通过Accept-Language: en;q=0.7,zh-TW;q=0.8,zh-CN;q=0.7这样的形式配置MVC context的Locale信息还是有点麻烦，并且这样的话，前端每次请求都需要手动设置（校验）请求头，麻烦！\n默认情况下，浏览器发起请求的Accept-Language是根据用户语言设置的。\n文章到此，我们已经可以通过配置WebMvcProperties和设置Accept-Language请求头来设置Spring MVC Context的Locale信息；并且通过LocaleContextHolder.getLocale()方法或者直接在控制器中传递Locale参数的形式获取Locale信息。\n8.2 Locale Resolver # 这样看来，国际化的配置还是不够灵活，配置文件的加载以及请求头的设置这两种方法都略显笨重。\n去找找文档看看其他的思路吧：\n(旧版本)springMvc-3.2.x-17.8 spring webMvc doc 当请求进入到控制器时，DispatcherServlet会寻找locale resolver，并使用其设置Locale。使用RequestContext.getLocale()方法总是可以获取到Locale信息：\n@GetMapping(\u0026#34;/resolver/locale\u0026#34;) public ReqResult\u0026lt;?\u0026gt; locale(HttpServletRequest request) { // 构建RequestContext RequestContext rc = new RequestContext(request); log.info(\u0026#34;locale: {}\u0026#34;, rc.getLocale()); return ReqResult.ok(rc.getMessage(\u0026#34;http.ok\u0026#34;), rc.getLocale()); } 这个控制器可能的返回结果为：\n{ \u0026#34;code\u0026#34;: 20000, \u0026#34;msg\u0026#34;: \u0026#34;success\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;en\u0026#34; } { \u0026#34;code\u0026#34;: 20000, \u0026#34;msg\u0026#34;: \u0026#34;成功\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;zh_CN\u0026#34; } RequestContext可以很方便的获取请求中包含的信息，可能的参数绑定（校验）错误等，还能直接获取Spring Message，很强大。\n注意到，ServletRequest也有一个getLocale()方法，那么，我们直接从Request中获取Locale不是很方便么？就像这样：\n@GetMapping(\u0026#34;/request/locale\u0026#34;) public ReqResult\u0026lt;?\u0026gt; locale(HttpServletRequest request, HttpServletResponse response){ // TODO why this method always return client default locale? return ReqResult.ok(request.getLocale()); } 哈哈。似乎一切都完美。不过，注意看ServletRequest.getLocale()的 文档你就会发现问题:\nReturns the preferred Locale that the client will accept content in, based on the Accept-Language header. If the client request doesn\u0026rsquo;t provide an Accept-Language header, this method returns the default locale for the server.\n也就是说，从request中获取的并不是获取的Spring MVC Context当前使用的Locale信息。这一点在使用了LocaleChangeInterceptor之后，更能够得到 证明。\n除了RequestContext的方式之外，还可以通过配置拦截器、通过特定的条件（比如请求参数）来更改Locale。\n文档提到了几种不同的LocaleResolver：\nAcceptHeaderLocaleResolver\n这个locale resolver已经在前文讨论过了，通过设置HTTP Header的Accept-Language请求头可以设置SpringMvc Context的Locale信息。这个resolver在前文就已经试验过了。\nCookieLocaleResolver\n这个locale resolver检查cookie中是否声明了Locale信息，如果有，则使用之。\nSessionLocaleResolver\n这个locale resolver可以从当前请求的HttpSession中获取Locale和TimeZone信息。由于和Session相关，故在切换Locale时没有cookie灵活，只有session关闭之后Locale配置才能重新设置。\nLocaleChangeInterceptor\n这是推荐使用的方式，通过拦截器+请求参数实现国际化。\n8.3 通过LocaleChangeInterceptor实现国际化 # 以下两篇文章分别使用xml和java Bean的方式配置了LocaleChangeInterceptor，通过地址栏参数展现国际化信息：\n[基于xml的配置]Spring MVC Internationalization (i18n) and Localization (i10n) Example [基于java bean的配置]LOCALE AND INTERNATIONALIZATION IN SPRING MVC 参考配置地址：\nhttps://github.com/wangy325/mybatis-plus-starter/blob/master/web-security-demo/src/main/java/com/wangy/config/MessageSourceConfig.java https://github.com/wangy325/mybatis-plus-starter/blob/master/web-security-demo/src/main/java/com/wangy/config/WebConfig.java 不妨看看LocaleChangeInterceptor是如何工作的：\n@Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws ServletException { // 从请求路径中获取Locale参数 String newLocale = request.getParameter(getParamName()); if (newLocale != null) { if (checkHttpMethod(request.getMethod())) { // locale resovler LocaleResolver localeResolver = RequestContextUtils.getLocaleResolver(request); if (localeResolver == null) { throw new IllegalStateException( \u0026#34;No LocaleResolver found: not in a DispatcherServlet request?\u0026#34;); } try { // 设置Locale信息 localeResolver.setLocale(request, response, parseLocaleValue(newLocale)); } catch (IllegalArgumentException ex) { if (isIgnoreInvalidLocale()) { if (logger.isDebugEnabled()) { logger.debug(\u0026#34;Ignoring invalid locale value [\u0026#34; + newLocale + \u0026#34;]: \u0026#34; + ex.getMessage()); } } else { throw ex; } } } } // Proceed in any case. return true; } 可以看到，LocaleChangeInterceptor的工作方式比较简单：\n从路径参数中获取Locale参数配置 获取LocaleResolver 利用LocaleResolver重新设置步骤1中获取的Locale配置 这里有一个重点：LocaleResolver。如果不在项目中显示的配置LocaleResolver，那么此拦截器获取到的实例是AcceptHeaderLocaleResolver，这很致命：\n// AcceptHeaderLocaleResolver.java @Override public void setLocale(HttpServletRequest request, @Nullable HttpServletResponse response, @Nullable Locale locale) { throw new UnsupportedOperationException( \u0026#34;Cannot change HTTP accept header - use a different locale resolution strategy\u0026#34;); } 因为AcceptHeaderLocaleResolver的setLocale()方法直接抛出异常，导致Locale信息无法被设置。\n所以，如果使用LocaleChangeInterceptor，那么必须要显式配置一个LocalResolver，可以是SessionLocaleResolver或者CookieLocaleResolver：\n@Bean public SessionLocaleResolver localeResolver() { SessionLocaleResolver sessionLocaleResolver = new SessionLocaleResolver(); // 配置默认Locale sessionLocaleResolver.setDefaultLocale(locale); return sessionLocaleResolver; } 这样，保证即使不传递路径国际化参数，也能使用默认的Locale配置。\n现在，我们再回头看看从HttpServletRequest中获取当前MVC Context 的Locale信息失败的原因：\nLocaleChangeInterceptor不与AcceptHeaderLocaleResolver兼容 HttpServletRequest从Accept-Language中获取Locale配置，否则返回服务器默认Locale信息 这应该比较好理解了，即使设置了Accept-language，这个设置也不能被配置了LocaleChangeInterceptor的mvc容器采纳。\n9 参考 # 原文地址： https://www.baeldung.com/spring-custom-validation-message-source 简单使用MessageSource [stackoverflow] MessageSource配置异常 [stackoverflow] 2个MessageSource的区别1 [github issue] 2个MessageSource的区别2 如何设置HTTP请求头Accept-Language 官方文档：使用messageSource进行国际化 官方文档：Spring MVC locale resovler HttpServletRequest并不能直接获取spring MVC Context当前的Locale信息 LocaleContextHolder是它的完美替代。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n从文档和一些其他的资料来看，RRBMS是可以从任意位置读取配置文件的，不过笔者并没有实践这一说法。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":22,"href":"/zh/docs/java/jvm/java-gc/","title":"JVM垃圾回收概要(转)","section":"JVM","content":" 本节常见面试题 # 问题答案在文中都有提到\n如何判断对象是否死亡（两种方法）。 简单的介绍一下强引用、软引用、弱引用、虚引用（虚引用与软引用和弱引用的区别、使用软引用能带来的好处）。 如何判断一个常量是废弃常量 如何判断一个类是无用的类 垃圾收集有哪些算法，各自的特点？ HotSpot 为什么要分为新生代和老年代？ 常见的垃圾回收器有哪些？ 介绍一下 CMS,G1 收集器。 Minor Gc 和 Full GC 有什么不同呢？ 本文概览 # graph LR A[Java内存分配规则] --\u003e B[找出垃圾] --\u003eC[触发GC] --\u003eD[如何回收垃圾] 当需要排查各种内存溢出问题、当垃圾收集成为系统达到更高并发的瓶颈时，我们就需要对这些“自动化”的技术实施必要的监控和调节。\n1 揭开 JVM 内存分配与回收的神秘面纱 # Java 的自动内存管理主要是针对对象内存的回收和对象内存的分配。同时，Java 自动内存管理最核心的功能是 堆 内存中对象的分配与回收。\nJava 堆是垃圾收集器管理的主要区域，因此也被称作GC 堆（Garbage Collected Heap）.从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代：再细致一点有：Eden 空间、From Survivor、To Survivor 空间等。进一步划分的目的是更好地回收内存，或者更快地分配内存。\n堆空间的基本结构：\n上图所示的 Eden 区、From Survivor0(\u0026ldquo;From\u0026rdquo;) 区、To Survivor1(\u0026ldquo;To\u0026rdquo;) 区都属于新生代，Old Memory 区属于老年代。\n大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 s0 或者 s1，并且对象的年龄还会加 1(Eden 区-\u0026gt;Survivor 区后对象的初始年龄变为 1)，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。\n修正（ issue552）：“Hotspot遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了survivor区的一半时，取这个年龄和MaxTenuringThreshold中更小的一个值，作为新的晋升年龄阈值”。\n动态年龄计算的代码如下\nuint ageTable::compute_tenuring_threshold(size_t survivor_capacity) { //survivor_capacity是survivor空间的大小 size_t desired_survivor_size = (size_t)((((double) survivor_capacity) *TargetSurvivorRatio)/100); size_t total = 0; uint age = 1; while (age \u0026lt; table_size) { total += sizes[age];//sizes数组是每个年龄段对象大小 if (total \u0026gt; desired_survivor_size) break; age++; } uint result = age \u0026lt; MaxTenuringThreshold ? age : MaxTenuringThreshold; ... } 经过这次GC后，Eden区和\u0026quot;From\u0026quot;区已经被清空。这个时候，\u0026ldquo;From\u0026quot;和\u0026quot;To\u0026quot;会交换他们的角色，也就是新的\u0026quot;To\u0026quot;就是上次GC前的“From”，新的\u0026quot;From\u0026quot;就是上次GC前的\u0026quot;To\u0026rdquo;。不管怎样，都会保证名为To的Survivor区域是空的。Minor GC会一直重复这样的过程，直到“To”区被填满，\u0026ldquo;To\u0026quot;区被填满之后，会将所有对象移动到老年代中。\ngraph LR A[堆内存常见分配策略]-- 1 --\u003eB[对象优先在eden区分配] A -- 2 --\u003e C[大对象直接进入老年代] A -- 3 --\u003e D[长期存活的对象将进入老年代] 1.1 对象优先在 eden 区分配 # 目前主流的垃圾收集器都会采用分代回收算法，因此需要将堆内存分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。\n大多数情况下，对象在新生代中 eden 区分配。当 eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC.下面我们来进行实际测试以下。\n测试：\npublic class GCTest { public static void main(String[] args) { byte[] allocation1, allocation2; allocation1 = new byte[30900*1024]; //allocation2 = new byte[900*1024]; } } 通过以下方式运行： 添加的参数：-XX:+PrintGCDetails 运行结果 (红色字体描述有误，应该是对应于 JDK1.7 的永久代)：\n从上图我们可以看出 eden 区内存几乎已经被分配完全（即使程序什么也不做，新生代也会使用 2000 多 k 内存）。假如我们再为 allocation2 分配内存会出现什么情况呢？\nallocation2 = new byte[900*1024]; 简单解释一下为什么会出现这种情况： 因为给 allocation2 分配内存的时候 eden 区内存几乎已经被分配完了，我们刚刚讲了当 Eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC.GC 期间虚拟机又发现 allocation1 无法存入 Survivor 空间，所以只好通过 分配担保机制 把新生代的对象提前转移到老年代中去，老年代上的空间足够存放 allocation1，所以不会出现 Full GC。执行 Minor GC 后，后面分配的对象如果能够存在 eden 区的话，还是会在 eden 区分配内存。可以执行如下代码验证：\npublic class GCTest { public static void main(String[] args) { byte[] allocation1, allocation2,allocation3,allocation4,allocation5; allocation1 = new byte[32000*1024]; allocation2 = new byte[1000*1024]; allocation3 = new byte[1000*1024]; allocation4 = new byte[1000*1024]; allocation5 = new byte[1000*1024]; } } 1.2 大对象直接进入老年代 # 大对象就是需要大量连续内存空间的对象（比如：字符串、数组）。\n为什么要这样呢？\n为了避免为大对象分配内存时由于分配担保机制带来的复制而降低效率。\n1.3 长期存活的对象将进入老年代 # 既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别哪些对象应放在新生代，哪些对象应放在老年代中。为了做到这一点，虚拟机给每个对象一个对象年龄（Age）计数器。\n如果对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为 1.对象在 Survivor 中每熬过一次 MinorGC,年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。\n1.4 动态对象年龄判定 # 大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 s0 或者 s1，并且对象的年龄还会加 1(Eden 区-\u0026gt;Survivor 区后对象的初始年龄变为 1)，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。\n修正（ issue552）：“Hotspot遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了survivor区的一半时，取这个年龄和MaxTenuringThreshold中更小的一个值，作为新的晋升年龄阈值”。\n动态年龄计算的代码如下\nuint ageTable::compute_tenuring_threshold(size_t survivor_capacity) { //survivor_capacity是survivor空间的大小 size_t desired_survivor_size = (size_t)((((double) survivor_capacity)*TargetSurvivorRatio)/100); size_t total = 0; uint age = 1; while (age \u0026lt; table_size) { total += sizes[age];//sizes数组是每个年龄段对象大小 if (total \u0026gt; desired_survivor_size) break; age++; } uint result = age \u0026lt; MaxTenuringThreshold ? age : MaxTenuringThreshold; ... } 额外补充说明( issue672)：关于默认的晋升年龄是15，这个说法的来源大部分都是《深入理解Java虚拟机》这本书。 如果你去Oracle的官网阅读 相关的虚拟机参数，你会发现-XX:MaxTenuringThreshold=threshold这里有个说明\nSets the maximum tenuring threshold for use in adaptive GC sizing. The largest value is 15. The default value is 15 for the parallel (throughput) collector, and 6 for the CMS collector.默认晋升年龄并不都是15，这个是要区分垃圾收集器的，CMS就是6.\n1.5主要进行 gc 的区域 # 周志明先生在《深入理解Java虚拟机》第二版中P92如是写道：\n“老年代GC（Major GC/Full GC），指发生在老年代的GC……”\n上面的说法已经在《深入理解Java虚拟机》第三版中被改正过来了。感谢R大的回答：\n总结：\n针对HotSpot VM的实现，它里面的GC其实准确分类只有两大种：\n部分收集 (Partial GC)：\n新生代收集（Minor GC / Young GC）：只对新生代进行垃圾收集； 老年代收集（Major GC / Old GC）：只对老年代进行垃圾收集。需要注意的是 Major GC 在有的语境中也用于指代整堆收集； 混合收集（Mixed GC）：对整个新生代和部分老年代进行垃圾收集。 整堆收集 (Full GC)：收集整个 Java 堆和方法区。\n2 对象已经死亡？ # 堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断那些对象已经死亡（即不能再被任何途径使用的对象）。\n2.1 引用计数法 # 给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加 1；当引用失效，计数器就减 1；任何时候计数器为 0 的对象就是不可能再被使用的。\n这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。 所谓对象之间的相互引用问题，如下面代码所示：除了对象 objA 和 objB 相互引用着对方之外，这两个对象之间再无任何引用。但是他们因为互相引用对方，导致它们的引用计数器都不为 0，于是引用计数算法无法通知 GC 回收器回收他们。\npublic class ReferenceCountingGc { Object instance = null; public static void main(String[] args) { ReferenceCountingGc objA = new ReferenceCountingGc(); ReferenceCountingGc objB = new ReferenceCountingGc(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; } } 2.2 可达性分析算法 # 这个算法的基本思想就是通过一系列的称为 “GC Roots” 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。\n![可达性分析算法 ](/img/jvm/jvm-gc-object-death-2.png) 可作为GC Roots的对象包括下面几种:\n虚拟机栈(栈帧中的本地变量表)中引用的对象 本地方法栈(Native方法)中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 2.3 再谈引用 # 无论是通过引用计数法判断对象引用数量，还是通过可达性分析法判断对象的引用链是否可达，判定对象的存活都与“引用”有关。\nJDK1.2 之前，Java 中引用的定义很传统：如果 reference 类型的数据存储的数值代表的是另一块内存的起始地址，就称这块内存代表一个引用。\nJDK1.2 以后，Java 对引用的概念进行了扩充，将引用分为强引用、软引用、弱引用、虚引用四种（引用强度逐渐减弱）\n1．强引用（StrongReference）\n以前我们使用的大部分引用实际上都是强引用，这是使用最普遍的引用。如果一个对象具有强引用，那就类似于必不可少的生活用品，垃圾回收器绝不会回收它。当内存空间不足，Java 虚拟机宁愿抛出 OutOfMemoryError 错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。\n2．软引用（SoftReference）\n如果一个对象只具有软引用，那就类似于可有可无的生活用品。如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。\n软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收，JAVA 虚拟机就会把这个软引用加入到与之关联的引用队列中。\n3．弱引用（WeakReference）\n如果一个对象只具有弱引用，那就类似于可有可无的生活用品。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。\n弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java 虚拟机就会把这个弱引用加入到与之关联的引用队列中。\n4．虚引用（PhantomReference）\n\u0026ldquo;虚引用\u0026quot;顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。\n虚引用主要用来跟踪对象被垃圾回收的活动。\n虚引用与软引用和弱引用的一个区别在于： 虚引用必须和引用队列（ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。\n特别注意，在程序设计中一般很少使用弱引用与虚引用，使用软引用的情况较多，这是因为软引用可以加速 JVM 对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生。\n2.4 不可达的对象并非“非死不可” # 即使在可达性分析法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑阶段”，要真正宣告一个对象死亡，至少要经历两次标记过程；可达性分析法中不可达的对象被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行 finalize 方法。当对象没有覆盖 finalize 方法，或 finalize 方法已经被虚拟机调用过时，虚拟机将这两种情况视为没有必要执行。\n被判定为需要执行的对象将会被放在一个队列中进行第二次标记，除非这个对象与引用链上的任何一个对象建立关联，否则就会被真的回收。\n2.5 如何判断一个常量是废弃常量？ # 运行时常量池主要回收的是废弃的常量。那么，我们如何判断一个常量是废弃常量呢？\nJDK1.7 及之后版本的 JVM 已经将运行时常量池从方法区中移了出来，在 Java 堆（Heap）中开辟了一块区域存放运行时常量池。\n修正( issue747， reference)：\nJDK1.7之前运行时常量池逻辑包含字符串常量池存放在方法区, 此时hotspot虚拟机对方法区的实现为永久代 JDK1.7 字符串常量池被从方法区拿到了堆中, 这里没有提到运行时常量池,也就是说字符串常量池被单独拿到堆,运行时常量池剩下的东西还在方法区, 也就是hotspot中的永久代 。 JDK1.8 hotspot移除了永久代用元空间(Metaspace)取而代之, 这时候字符串常量池还在堆, 运行时常量池还在方法区, 只不过方法区的实现从永久代变成了元空间(Metaspace) 假如在字符串常量池中存在字符串 \u0026ldquo;abc\u0026rdquo;，如果当前没有任何 String 对象引用该字符串常量的话，就说明常量 \u0026ldquo;abc\u0026rdquo; 就是废弃常量，如果这时发生内存回收的话而且有必要的话，\u0026ldquo;abc\u0026rdquo; 就会被系统清理出常量池了。\n2.6 如何判断一个类是无用的类 # 方法区主要回收的是无用的类，那么如何判断一个类是无用的类的呢？\n判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面 3 个条件才能算是 “无用的类” ：\n该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 虚拟机可以对满足上述 3 个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。\n3 垃圾收集算法 # graph TD A[垃圾收集算法]--\u003e B[标记-清除算法] A --\u003eC[复制算法] \u0026 D[标记-整理算法] \u0026 E[分代收集算法] 3.1 标记-清除算法 # 该算法分为“标记”和“清除”阶段：首先标记出所有不需要回收的对象，在标记完成后统一回收掉所有没有被标记的对象。它是最基础的收集算法，后续的算法都是对其不足进行改进得到。这种垃圾收集算法会带来两个明显的问题：\n效率问题 空间问题（标记清除后会产生大量不连续的碎片） 3.2 复制算法 # 为了解决效率问题，“复制”收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。\n3.3 标记-整理算法 # 根据老年代的特点提出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。\n3.4 分代收集算法 # 当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将 java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。\n比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。\n延伸面试问题： HotSpot 为什么要分为新生代和老年代？\n根据上面的对分代收集算法的介绍回答。\n4 垃圾收集器 # graph TD A[垃圾收集器分类]--\u003e B[serial收集器] A --\u003eC[ParNew收集器] \u0026 D[Parallel Scavenge收集器] \u0026 E[CMS收集器] \u0026 F[G1收集器] 如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。\n虽然我们对各个收集器进行比较，但并非要挑选出一个最好的收集器。因为直到现在为止还没有最好的垃圾收集器出现，更加没有万能的垃圾收集器，我们能做的就是根据具体应用场景选择适合自己的垃圾收集器。试想一下：如果有一种四海之内、任何场景下都适用的完美收集器存在，那么我们的 HotSpot 虚拟机就不会实现那么多不同的垃圾收集器了。\n4.1 Serial 收集器 # Serial（串行）收集器收集器是最基本、历史最悠久的垃圾收集器了。大家看名字就知道这个收集器是一个单线程收集器了。它的 “单线程” 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ \u0026ldquo;Stop The World\u0026rdquo; ），直到它收集结束。\n虚拟机的设计者们当然知道 Stop The World 带来的不良用户体验，所以在后续的垃圾收集器设计中停顿时间在不断缩短（仍然还有停顿，寻找最优秀的垃圾收集器的过程仍然在继续）。\n但是 Serial 收集器有没有优于其他垃圾收集器的地方呢？当然有，它简单而高效（与其他收集器的单线程相比）。Serial 收集器由于没有线程交互的开销，自然可以获得很高的单线程收集效率。Serial 收集器对于运行在 Client 模式下的虚拟机来说是个不错的选择。\n4.2 ParNew 收集器 # ParNew 收集器其实就是 Serial 收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和 Serial 收集器完全一样。\n它是许多运行在 Server 模式下的虚拟机的首要选择，除了 Serial 收集器外，只有它能与 CMS 收集器（真正意义上的并发收集器，后面会介绍到）配合工作。\n并行和并发概念补充：\n并行（Parallel） ：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。\n并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个 CPU 上。\n4.3 Parallel Scavenge 收集器 # Parallel Scavenge 收集器也是使用复制算法的多线程收集器，它看上去几乎和ParNew都一样。 那么它有什么特别之处呢？\n-XX:+UseParallelGC 使用 Parallel 收集器+ 老年代串行 -XX:+UseParallelOldGC 使用 Parallel 收集器+ 老年代并行 Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。 Parallel Scavenge 收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解，手工优化存在困难的时候，使用Parallel Scavenge收集器配合自适应调节策略，把内存管理优化交给虚拟机去完成也是一个不错的选择。\n是JDK1.8默认收集器\n使用java -XX:+PrintCommandLineFlags -version命令查看\n-XX:InitialHeapSize=262921408 -XX:MaxHeapSize=4206742528 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC java version \u0026#34;1.8.0_211\u0026#34; Java(TM) SE Runtime Environment (build 1.8.0_211-b12) Java HotSpot(TM) 64-Bit Server VM (build 25.211-b12, mixed mode) JDK1.8默认使用的是Parallel Scavenge + Parallel Old，如果指定了-XX:+UseParallelGC参数，则默认指定了-XX:+UseParallelOldGC，可以使用-XX:-UseParallelOldGC来禁用该功能\n4.4.Serial Old 收集器 # Serial 收集器的老年代版本，它同样是一个单线程收集器。它主要有两大用途：一种用途是在 JDK1.5 以及以前的版本中与 Parallel Scavenge 收集器搭配使用，另一种用途是作为 CMS 收集器的后备方案。\n4.5 Parallel Old 收集器 # Parallel Scavenge 收集器的老年代版本。使用多线程和“标记-整理”算法。在注重吞吐量以及 CPU 资源的场合，都可以优先考虑 Parallel Scavenge 收集器和 Parallel Old 收集器。\n4.6 CMS 收集器 # CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。\nCMS（Concurrent Mark Sweep）收集器是 HotSpot 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。\n从名字中的Mark Sweep这两个词可以看出，CMS 收集器是一种 “标记-清除”算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤：\n初始标记： 暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ； 并发标记： 同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。 重新标记： 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短 并发清除： 开启用户线程，同时 GC 线程开始对未标记的区域做清扫。 从它的名字就可以看出它是一款优秀的垃圾收集器，主要优点：并发收集、低停顿。但是它有下面三个明显的缺点：\n对 CPU 资源敏感； 无法处理浮动垃圾； 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。 4.7 G1 收集器 # G1 (Garbage-First) 是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征.\n被视为 JDK1.7 中 HotSpot 虚拟机的一个重要进化特征。它具备一下特点：\n并行与并发：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。 分代收集：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。 空间整合：与 CMS 的“标记\u0026ndash;清理”算法不同，G1 从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。 可预测的停顿：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。 G1 收集器的运作大致分为以下几个步骤：\n初始标记 并发标记 最终标记 筛选回收 G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来)。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）。\n5 JVM 配置常用参数 # 5.1 Java内存区域常见配置概览 # 5.2 堆参数 # \u0026lt;/img/jvm src=\u0026quot;/img/jvm/jvm-heap-param.jpg\u0026rdquo; alt=\u0026ldquo;堆参数\u0026rdquo; width=\u0026ldquo;500px\u0026rdquo; position=\u0026ldquo;center\u0026rdquo;/\u0026gt;\n5.3 回收器参数 # 如上表所示，目前主要有串行、并行和并发三种，对于大内存的应用而言，串行的性能太低，因此使用到的主要是并行和并发两种。并行和并发 GC 的策略通过 UseParallelGC 和 UseConcMarkSweepGC 来指定，还有一些细节的配置参数用来配置策略的执行方式。例如：XX:ParallelGCThreads， XX:CMSInitiatingOccupancyFraction 等。 通常：Young 区对象回收只可选择并行（耗时间），Old 区选择并发（耗 CPU）。\n5.4 推荐配置 # 在Java8中永久代的参数-XX:PermSize 和-XX：MaxPermSize已经失效。\n按需求弹性配置各项参数，请勿死记硬背\n5.5 常用的垃圾回收器组合 # 6 不要急着GC调优 # 在调优之前，我们需要记住下面的原则：\n多数的 Java 应用不需要在服务器上进行 GC 优化； 多数导致 GC 问题的 Java 应用，都不是因为我们参数设置错误，而是代码问题； 在应用上线之前，先考虑将机器的 JVM 参数设置到最优（最适合）； 减少创建对象的数量； 减少使用全局变量和大对象； GC 优化是到最后不得已才采用的手段； 在实际使用中，分析 GC 情况优化代码比优化 GC 参数要多得多。 总结一句话，养成良好的编码习惯，是避免GC调优的好办法，GC调优应该是最后的选择。\n要始终相信Java虚拟机自身的性能，如果项目的负荷重、体量大，并发高，代码层面优化的余地小，再尝试做GC优化方面的工作。\n6.1 GC调优目的 # 将转移到老年代的对象数量降低到最小； 减少GC的执行时间。\n6.2 GC调优策略 # 策略1： 将新对象预留在新生代，由于 Full GC 的成本远高于 Minor GC，因此尽可能将对象分配在新生代是明智的做法，实际项目中根据 GC 日志分析新生代空间大小分配是否合理，适当通过“-Xmn”命令调节新生代大小，最大限度降低新对象直接进入老年代的情况。 策略2： 大对象进入老年代，虽然大部分情况下，将对象分配在新生代是合理的。但是对于大对象这种做法却值得商榷，大对象如果首次在新生代分配可能会出现空间不足导致很多年龄不够的小对象被分配的老年代，破坏新生代的对象结构，可能会出现频繁的 full gc。因此，对于大对象，可以设置直接进入老年代（当然短命的大对象对于垃圾回收来说简直就是噩梦）。-XX:PretenureSizeThreshold 可以设置直接进入老年代的对象大小。 策略3： 合理设置进入老年代对象的年龄，-XX:MaxTenuringThreshold 设置对象进入老年代的年龄大小，减少老年代的内存占用，降低 full gc 发生的频率。 策略4： 设置稳定的堆大小，堆大小设置有两个参数：-Xms 初始化堆大小，-Xmx 最大堆大小。 策略5： 注意： 如果满足下面的指标，则一般不需要进行 GC 优化： MinorGC 执行时间不到50ms； Minor GC 执行不频繁，约10秒一次； Full GC 执行时间不到1s； Full GC 执行频率不算频繁，不低于10分钟1次。\n参考 # 《深入理解 Java 虚拟机：JVM 高级特性与最佳实践（第二版》 https://my.oschina.net/hosee/blog/644618 https://docs.oracle.com/javase/specs/jvms/se8/html/index.html 点我查看原文\n"},{"id":23,"href":"/zh/docs/java/concurrency/1%E7%BA%BF%E7%A8%8B%E4%B8%8E%E4%BB%BB%E5%8A%A1_2/","title":"线程与任务(二)","section":"并发编程","content":" 第一篇文章中，讨论了线程与任务的概念，以及利用任务（Runnable接口）来创建线程。\n同时，讨论了线程的生命周期。此外，介绍了线程的优先级以及守护线程这两个实用性不高的概念。\n最后，讨论了线程的中断状态这个概念。线程的中断状态以及如何响应中断，对于理解线程的运行机制很重要。\n这一篇，继续讨论几个线程相关的概念，包括：\n线程的让步 等待线程加入 自管理线程 处理线程的异常 线程让步 # Thread.yield()是一个静态方法，可以给线程调度器一个暗示：当前线程的run()方法已经完成的差不多了，可以让别的线程（相同优先级）使用CPU了。注意，没有任何机制保证这个暗示一定会采纳。\n这个方法并不能控制线程的运行，不要误用此方法！\n线程休眠 # 通常调用sleep()可以使线程中止一段时间，此时线程让出CPU时间给其他线程使用。\nJava SE 5 之后，可以使用 TimeUnit来执行这个行为1。\n调用sleep()可能引发 中断异常（ Interrupted Exception ）。\n需要说明的是，不同于Object.wait()，在使用同步时，线程的休眠并不会释放锁。\n加入线程(join) # 可以在一个线程（ A ）中调用另一个线程（ B ）的join()方法，其效果是A线程会进入等待（挂起），等待B线程执行完毕后再继续执行，join()方法可以接受一个时间参数，表示最长等待时间，若超时仍未返回，A线程继续执行。\njoin()方法可以被中断，中断发生的情况和休眠一致。\n下面的代码演示了 interrupt，sleep和join方法所执行的操作：\npublic class JoinAndSleep { public static void main(String[] args) { Slepper sa = new Slepper(\u0026#34;sa\u0026#34;,100); Slepper sb = new Slepper(\u0026#34;sb\u0026#34;,100); Joiner ja = new Joiner(\u0026#34;ja\u0026#34;,sa); Joiner jb = new Joiner(\u0026#34;jb\u0026#34;,sb); sa.interrupt(); } } // 继承Thread来创建线程 class Slepper extends Thread{ private int duration; public Slepper(String name, int duration) { super(name); this.duration = duration; start(); } @Override public void run() { try{ sleep(duration); }catch (InterruptedException e){ System.out.println(currentThread() + \u0026#34;is interrupted ? \u0026#34; + isInterrupted()); return; } System.out.println(currentThread() + \u0026#34; has awakened.\u0026#34;); } } class Joiner extends Thread{ private Slepper slepper; public Joiner(String name, Slepper slepper) { super(name); this.slepper = slepper; start(); } @Override public void run() { try { slepper.join(); } catch (InterruptedException e) { System.out.println(currentThread() + \u0026#34; interrupted()\u0026#34;); return; } System.out.println(currentThread() + \u0026#34;join completed.\u0026#34;); } } /* output: Thread[sa,5,main]is interrupted ? false Thread[ja,5,main]join completed. Thread[sb,5,main] has awakened. Thread[jb,5,main]join completed. *///:~ 上例中，ja和jb总是会等待sa和sb完成，sa在main()中被设置中断状态，因此在sa的run()方法执行sleep()会抛出异常，同时清除中断状态，因此中断状态为false。\n可以使不同的线程中断查看程序的状态\n若上例在main()方法中使ja中断，那么可能的输出结果是：\n/* Thread[ja,5,main] interrupted() Thread[sa,5,main] has awakened. Thread[sb,5,main] has awakened. Thread[jb,5,main]join completed. */ 此时的情况是ja的run()方法中执行join()抛出异常，此时ja直接结束而不等待sa运行结束。\n上例中，还有一个关注点：在构造器中直接调用了start()方法，这种方式称为自管理线程。\n简单的无锁同步 # 不难理解，“加入一个线程”含有让线程有序执行的语义，利用这个性质，可以实现简单的无锁同步。\npublic class SyncWithoutSynchronized { private int sum; void increase() { sum+=; System.out.println(Thread.currentThread() + \u0026#34;: \u0026#34; + sum); } /** 单线程模式 */ void singleThread() throws InterruptedException { Thread task = new Thread(() -\u0026gt; { for (int i = 0; i \u0026lt; 10; i++) { increase(); } }); task.start(); // 等待task执行完成 task.join(); System.out.println(sum); } void multiThread() throws InterruptedException { for (int i = 0; i \u0026lt; 10; i++) { Thread thread = new Thread(() -\u0026gt; { for (int j = 0; j \u0026lt; 1; j++) { increase(); } }); thread.start(); // 使用join()保证有序性，此时可以不需要同步 // join() 保证了happens-before原则 thread.join(); } // 主线程等待所有的子线程结束 System.out.println(sum); } public static void main(String[] args) throws InterruptedException { SyncWithoutSynchronized va = new SyncWithoutSynchronized(); // va.singleThread(); va.multiThread(); } } /* output: Thread[Thread-0,5,main]: 1 Thread[Thread-1,5,main]: 2 Thread[Thread-2,5,main]: 3 Thread[Thread-3,5,main]: 4 Thread[Thread-4,5,main]: 5 Thread[Thread-5,5,main]: 6 Thread[Thread-6,5,main]: 7 Thread[Thread-7,5,main]: 8 Thread[Thread-8,5,main]: 9 Thread[Thread-9,5,main]: 10 10 *///:~ 上例使用后台任务自增共享变量sum的值，主线程总是等待后台任务执行完成之后再返回。在multiThread()方法中，额外开启了10个线程，每一个线程都在主线程上调用join()方法，从输出来看，线程0-9是顺序执行的，最终的结果不会出现讹误，这种情况下，实现了无锁同步，而共享变量sum不需要额外处理。\n自管理线程 # 除了实现Runnable接口之外，还可以通过继承Thread类来创建线程：\npublic class SelfManageThread { public static void main(String[] args) { for (int i = 0; i \u0026lt;5 ; i++) { new SelfManaged(); // new SlefRunnable(); } } static class SelfManaged extends Thread { private static int count = 0; private final int id = count; public SelfManaged() { super(String.valueOf(++count)); // 在构造器中调用start() start(); } @Override public String toString() { return \u0026#34;#\u0026#34; + getName() + \u0026#34;(\u0026#34; + id + \u0026#34;), \u0026#34;; } @Override public void run() { System.out.print(this); Thread.yield(); } } } /* output: (sample) * #1(1), #4(4), #5(5), #3(3), #2(2), *///:~ 上面的示例中，对象创建时顺便创建并启动线程。\n一般地，任务都实现自Runnable接口，同样可以利用Runnable实现自管理线程：\nstatic class SlefRunnable implements Runnable{ private static int count = 0; private final int id = ++count; private Thread t = new Thread(this, String.valueOf(id)); public SlefRunnable() { t.start(); } @Override public String toString() { return \u0026#34;#\u0026#34; + t.getName() + \u0026#34;(\u0026#34; + id + \u0026#34;), \u0026#34;; } @Override public void run() { System.out.print(this); Thread.yield(); } } 实现Runnable的好处是其可以再继承自某个类（如果需要的话）。\n由于示例比较简单，因此在构造器中启动线程可能是安全的。但是，并不建议在构造器中启动线程，这样可能会存在风险：另一个任务可能在实例初始化完成之前开始执行，这意味着访问处于不稳定的状态。\n自管理线程的惯用法 # 有时候，把线程以内部类的形式实现可能会很有用，就像上面的示例那样，甚至可以使用匿名内部类：\n// form1 比较常用 //... Thread thread = new Thread(new Runnable() { private int count = 5; @Override public String toString() { return \u0026#34;#\u0026#34; + Thread.currentThread().getName() + \u0026#34;(\u0026#34; + count + \u0026#34;), \u0026#34;; } @Override public void run() { while (--count \u0026gt; 0) { System.out.print(this); Thread.yield(); } } }); thread.start(); //... // form2 public class SelfManageThread { Thread thread; public SelfManageThread() { thread= new Thread(new Runnable() { private int count = 5; @Override public String toString() { return \u0026#34;#\u0026#34; + Thread.currentThread().getName() + \u0026#34;(\u0026#34; + count + \u0026#34;), \u0026#34;; } @Override public void run() { while (--count \u0026gt; 0) { System.out.print(this); Thread.yield(); } } }); thread.start(); } } 需要说明的是，本节讨论的都是显式创建线程的方式，这种方式在部分编程规范2里已经不再推荐了，尤其在很多线程协同的场景下，创建并维护线程的成本以及上下文切换的成本会非常高，此时，线程池将是更好的选择。\n捕获线程的异常 # 从线程中逃逸的异常不能被捕获，一旦线程中的异常逃逸到run()方法外部，那么它将会传播到控制台，这种情况下，线程就终止了。\npublic class ExceptionThread { public static void main(String[] args) { Thread t = new Thread(new ExceptionT()); try { t.start(); } catch (Exception x) { System.out.println(x.toString()); } } static class ExceptionT implements Runnable { @Override public void run() { throw new RuntimeException(); } } } /* Exception in thread \u0026#34;Thread-0\u0026#34; java.lang.RuntimeException at com.access.concurrency.basic.ExceptionThread$ExceptionT .run(ExceptionThread.java:22) at java.lang.Thread.run(Thread.java:748) *///:~ 可以看到，线程抛出的异常无法在线程外部被捕获。\n在Java SE 5之后，为Thread类添加了一个接口Thread.UncaughtExceptionHandler，该接口允许在每个Thread对象上分配一个异常处理器，用来应对线程出现未捕获的异常而濒临死亡的情况。\npublic class ExceptionThread2 { public static void main(String[] args) { // 静态方法，为线程分配默认异常处理器 Thread.setDefaultUncaughtExceptionHandler( new MyUncaughtExceptionHandler(true)); Thread t = new Thread(new ExceptionT()); // 分配异常处理器 t.setUncaughtExceptionHandler(new MyUncaughtExceptionHandler()); t.start(); } static class ExceptionT implements Runnable { @Override public void run() { throw new RuntimeException(); } } // 自定义异常处理器 static class MyUncaughtExceptionHandler implements Thread.UncaughtExceptionHandler { private boolean isDeafult; public MyUncaughtExceptionHandler() { } public MyUncaughtExceptionHandler(boolean isDeafult) { this.isDeafult = isDeafult; } @Override public void uncaughtException(Thread t, Throwable e) { System.out.println(\u0026#34;default ?(\u0026#34; + isDeafult+ \u0026#34;) \u0026#34; + \u0026#34;caught \u0026#34; + e); } } } /* output: default ?(true) caught java.lang.RuntimeException *///:~ 给线程分配异常处理器的的方法有2个：\n- static setDefaultUncaughtExceptionHandler(UncaughtExceptionHandler eh) - setUncaughtExceptionHandler(UncaughtExceptionHandler eh) 其中给线程分配默认异常处理器是静态方法，调用之后，在此线程内创建的所有线程都使用此异常处理器。\n上文已多处使用此方法。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n阿里编码规范不推荐显式创建线程。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":24,"href":"/zh/docs/java/collections/1_List_linkedlist/","title":"LinkedList","section":"集合框架","content":"LinkedList是基于双向链表实现的有序集合，其不能像ArrayList一样通过索引(index)访问元素，同时LinkedList还实现了Deque接口，意味着LinkedList可以实现双端队列的操作。\nLinkedList继承关系图\n链表将每个对象存放在独立的节点(Node)中，节点中还保存对序列中前、后节点的引用。理论上，LinkedList没有容量限制（取决于你的物理内存大小）。\nLinkedList的基本数据结构 from Core Java\nNode（节点） # Node（节点）是LinkedList的存储载体，每向LinkedList中增加/删除一个元素，就会增加/减少一个Node，Node定义了3个字段，其含义分别是：\nE item：存入LinkedList的内容\nNode\u0026lt;E\u0026gt; prev：前一个节点的引用\nNode\u0026lt;E\u0026gt; next：后一个节点的引用\n结合LinkedList的字段来看，LinkedList定义了两个个Node相关的引用：\ntransient Node\u0026lt;E\u0026gt; first：总是指向LinkedList的第一个节点\ntransient Node\u0026lt;E\u0026gt; last：总是指向LinkedList的最后一个节点\nLinkedList有如下规律：\nfirst.prev总是为null last.next总是为null 当LinkedList只有一个元素时，first == last 下面的代码验证了上述推论：\nstatic void initializeTest() throws Exception { List\u0026lt;String\u0026gt; a = new LinkedList\u0026lt;\u0026gt;(); a.add(\u0026#34;google\u0026#34;); // a.add(\u0026#34;chrome\u0026#34;); // a.add(\u0026#34;photos\u0026#34;); Class\u0026lt;?\u0026gt; cls = LinkedList.class; // LinkedList field Field ff = cls.getDeclaredField(\u0026#34;first\u0026#34;); Field lf = cls.getDeclaredField(\u0026#34;last\u0026#34;); ff.setAccessible(true); lf.setAccessible(true); Object first = ff.get(a); Object last = lf.get(a); Class\u0026lt;?\u0026gt; node = Class.forName(\u0026#34;java.util.LinkedList$Node\u0026#34;); // LinkedList$Node field Field item = node.getDeclaredField(\u0026#34;item\u0026#34;); Field next = node.getDeclaredField(\u0026#34;next\u0026#34;); Field prev = node.getDeclaredField(\u0026#34;prev\u0026#34;); item.setAccessible(true); next.setAccessible(true); prev.setAccessible(true); // first System.out.println(\u0026#34;first: \u0026#34; + first); Object firstItem = item.get(first); Object firstPrev = prev.get(first); // Node Object firstNext = next.get(first); // Node System.out.println(\u0026#34;\\t\u0026#34; + \u0026#34;item: \u0026#34; + firstItem +\u0026#34;\\n\\t\u0026#34; + \u0026#34;prev: \u0026#34; + firstPrev + \u0026#34;\\n\\t\u0026#34; + \u0026#34;next: \u0026#34; + firstNext + \u0026#34;\\n\u0026#34;); // last System.out.println(\u0026#34;last: \u0026#34; + last); Object lastItem = item.get(last); Object lastPrev = prev.get(last); Object lastNext = next.get(last); System.out.println(\u0026#34;\\t\u0026#34; + \u0026#34;item: \u0026#34; + lastItem +\u0026#34;\\n\\t\u0026#34; + \u0026#34;prev: \u0026#34; + lastPrev + \u0026#34;\\n\\t\u0026#34; + \u0026#34;next: \u0026#34; + lastNext); } /* output: first: java.util.LinkedList$Node@512ddf17 item: google prev: null next: null last: java.util.LinkedList$Node@512ddf17 item: google prev: null next: null // 当有3个元素时，first的next == last的prev first: java.util.LinkedList$Node@512ddf17 item: google prev: null next: java.util.LinkedList$Node@2c13da15 last: java.util.LinkedList$Node@77556fd item: photos prev: java.util.LinkedList$Node@2c13da15 next: null *///:~ 利用Node，对链表中的元素的删除和插入操作将变得便利，只需要同时修改自身及前后节点的引用即可将元素置入链中。\n参考如下源码：\n/** * Inserts element e before non-null Node succ. */ void linkBefore(E e, Node\u0026lt;E\u0026gt; succ) { // assert succ != null; final Node\u0026lt;E\u0026gt; pred = succ.prev; final Node\u0026lt;E\u0026gt; newNode = new Node\u0026lt;\u0026gt;(pred, e, succ); succ.prev = newNode; if (pred == null) first = newNode; else pred.next = newNode; size++; modCount++; } 上述源码解释了如何将一个新的元素插入到链表中。\n迭代器 # LinkedList没有 Iterator 的实现，只有 ListIterator 的实现，里面定义了相当充分的操作元素的方法，由于LinkedList也是List的实现类，故也可调用接口定义的iterator()方法1，不过其实际上返回的是 LinkedList.ListIterator 实例。\nLinkedList调用iterator()的时序图\n尽管如此，由于使用LinkedList.iterator()方法返回的是Iterator，其对集合的操作性降低到只有4个方法。由于我们知道其实际返回的是Listiterator，我们可以将该返回值向下转型：\nListIterator\u0026lt;String\u0026gt; i = (ListIterator\u0026lt;String\u0026gt;) list.iterator(); // 等价于 ListIterator\u0026lt;String\u0026gt; listIterator = list.listIterator(); // 等价于 ListIterator\u0026lt;String\u0026gt; listIterator1 = list.listIterator(0); 参考如下示例：\nstatic void iteratorTest(){ List\u0026lt;String\u0026gt; list = new LinkedList\u0026lt;String\u0026gt;(){{ add(\u0026#34;Java\u0026#34;); add(\u0026#34;Python\u0026#34;); add(\u0026#34;JavaScript\u0026#34;); add(\u0026#34;C\u0026#34;); }}; ListIterator\u0026lt;String\u0026gt; i = (ListIterator\u0026lt;String\u0026gt;) list.iterator(); while (i.hasNext()){ if (i.next().equals(\u0026#34;JavaScript\u0026#34;)){ i.set(\u0026#34;JS\u0026#34;); } } i.remove(); i.add(\u0026#34;C++\u0026#34;); // 反向迭代 while (i.hasPrevious()){ System.out.println(i.previous()); } System.out.println(\u0026#34;-------\u0026#34;); ListIterator\u0026lt;String\u0026gt; iterator = list.listIterator(2); iterator.forEachRemaining(System.out::println); } /* output: C++ JS Python Java ------- JS C++ *///:~ ListIterator\u0026lt;E\u0026gt; listIterator(int index);\n此方法用于获取 index （含）之后的元素的迭代器\n与ArrayList对比 # ArrayList的优势在于可以利用 index 快速访问集合中的元素，劣势在于对于容量大的集合，插入和删除的效率稍低。\nLinkedList基于链表，插入和删除操作效率高并不总这样；但由于没有元素索引( index )，使用get(int index)和set(int index , E e)的效率稍低2\n在LinkedList中，和索引相关的操作有：\npublic E get(int index) public E set(int index, E element) public void add(int index, E element) public E remove(int index) public int indexOf(Object o) 获取对象首次出现的位置 public int lastIndexOf(Object o)\t获取对象最后出现的位置 除了indexOf和lastIndexOf方法之外，其他的四个方法的实现都和这个方法有关：\npublic void add(int index, E element) { checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index)); } /** * Returns the (non-null) Node at the specified element index. */ Node\u0026lt;E\u0026gt; node(int index) { // assert isElementIndex(index); if (index \u0026lt; (size \u0026gt;\u0026gt; 1)) { Node\u0026lt;E\u0026gt; x = first; for (int i = 0; i \u0026lt; index; i++) x = x.next; return x; } else { Node\u0026lt;E\u0026gt; x = last; for (int i = size - 1; i \u0026gt; index; i--) x = x.prev; return x; } } 可以看到，node(int index)总是从头/尾开始逐一遍历，当集合较大时，这种操作的效率是很低的。\n既然如此，LinkedList插入和删除的效率如何高呢？答案就是使用迭代器，由于迭代器持有指针(cursor)，免去了遍历集合获取节点的时间消耗，因而插入和删除只需要修改前后节点的引用即可：\n从LinkedList删除一个元素 from Core Java\n所以，不要在LinkedList中使用带有索引(index)参数的操作，这会大大降低程序的运行效率，若要使用索引，请使用ArrayList。\n作为双端队列 # LinkedList除了实现了List接口之外，还实现了Deque接口，也就是说，LinkedList还是一个双端队列，具体请参照 Queue\n这和ArrayList的ListIterator没有实现hasNext()一样，实际上也是可以使用的(接口动态绑定超类方法)，这种情况在集合框架中很常见\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLinkedList使用和索引相关的操作get()/set()/add()/remove()的效率是一致的\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":25,"href":"/zh/docs/java/basic/2_static%E5%85%B3%E9%94%AE%E5%AD%97/","title":"static关键字","section":"面向对象","content":" static关键字 # static关键字意为“静态的”，其语义可以理解为“类的对象”(不要理解为Class对象)，即不需要对象实例，可以直接通过类名.字段名的形式直接访问。\n静态域 # 如果将一个域定义为static，那么每个类中都只有一个这样的域。参考如下例子：\nclass Employee{ private static int nextId = 1; private int id; ... } 每一个Employee都有自己的一个id域，但是这个类的所有实例都共享一个nextId域。记住，即使没有Employee实例，静态域nextId也存在，它属于类而不属于任何对象。static域只在类加载的时候初始化一次，并且是先于非static域初始化的。\n以下是一个简单的static关键字使用示例：\nclass Employee { static int nextId = 0; private int id; private String name; private int salary; public Employee(String name, int salary) { this.name = name; this.salary = salary; } public void setId() { this.id = nextId; nextId++; } public static int getNextId() { return nextId; } // ...get() } public class TestStatic { public static void main(String[] args) { Employee[] x = new Employee[3]; x[0] = new Employee(\u0026#34;alex\u0026#34;, 5000); x[1] = new Employee(\u0026#34;bob\u0026#34;, 6000); x[2] = new Employee(\u0026#34;cup\u0026#34;, 7000); for (Employee e : x) { e.setId(); System.out.println(\u0026#34;id = \u0026#34; + e.getId() + \u0026#34; name = \u0026#34; + e.getName() + \u0026#34; salary = \u0026#34; + e.getSalary()); } System.out.println(\u0026#34;the nextId is: \u0026#34; + Employee.getNextId()); } } /* output: id = 0 name = alex salary = 5000 id = 1 name = bob salary = 6000 id = 2 name = cup salary = 7000 the nextId is: 3 *///:~ 静态常量 # 使用static final修饰的域可以作为静态常量，静态常量一般被声明为public,通常作为工具包的常量被其他类使用，如Math.PI。\n静态方法 # 使用static修饰的方法被称为静态方法，和静态常量一样，通常被声明为public，供其他类通过类名直接调用，如Math.pow(x,a)用于计算xa。静态方法不能访问对象域，因为其不能操作对象，但是其可以访问类的静态域。\n尽管可以通过对象实例来调用类的静态方法，但是不推荐如此做，编译器也会提示应该使用类调用静态方法，因为对象尽管可以调用静态方法，但是往往静态方法的返回与对象无关（静态方法只能操作静态域，而不能操作对象属性），反而会造成混淆。\nJava对于static的语义可以理解为：\n属于类但是不属于对象的字段和方法\n工厂方法 # 也是一种静态方法，不过其用来构造对象，因此被称为静态工厂方法，例如NumberFormat.getCurrencyInstance()就是一个利用工厂方法获取对象的例子。\n参考 接口与工厂\n"},{"id":26,"href":"/zh/docs/craft/db/redis/build-redis-sentinel/","title":"Redis Sentinel高可用实现","section":"redis","content":"Redis v2.8 之后提供了高可用实现Redis Sentinel，实现了主从复制以及被动主备切换。 v3.0 之后提供了分布式实现Redis Cluster。\n本文讨论的是使用Sentinel搭建Redis高可用服务。\nIf all redis and sentinel instances were deployed in same host, you just build a fake redis-sentinel High-Availability environment1.\n1 准备 # 1.1 linux主机 # 本文使用centOS7，需安装gcc：\nyum install gcc # or on ubuntu apt-get install gcc 1.2 Redis 源码 # 本文使用 v4.0.0.11，版本号应大于2.8.0。\n可以使用如下命令来获取指定版本的redis：\nwget http://download.redis.io/releases/redis-4.0.11.tar.gz 1.3 了解linux防火墙的基本知识 # centOS7和centOS6使用不同的防火墙机制，前者使用firewall，后者使用iptables。\n1.4 master，slave和sentinel # 如果只想搭建一个单机(standalone)实例2来学习redis的数据结构，只需要阅读安装redis实例就好。\n多个standalone加之合适的配置便组成了master-slave结构，一般而言，此时已经具备了「主从复制」的能力。\n所谓Sentinel，并不是所谓「新技术」名词，只是一个用来做特定事情3的redis实例而已，故此我们也可以将其称作「服务」。如果需要搭建Sentinel服务，你需要先具备master-slave结构，也就是说，你至少需要搭建2个redis实例，并且将其中一台配置为另一台的slave。\n了解更多关于redis-sentinel的相关内容，请参考 redis哨兵与高可用架构。\n2 安装配置Redis # 接下来会依次安装Redis并且配置多个Redis实例\n2.1 编译源码 # tar -zxf redis-4.0.11.tar.gz # compile source code cd redis-4.0.11 # redis was recommended to install in /usr/local/redis mkdir /usr/local/redis make install PREFIX=/usr/local/redis # --- # if all operations are right, you will see the output below: [root@shell ~]# cd /usr/local/redis ; ll total 68 #the redis executable binary file folder drwxr-xr-x 2 root root 4096 Aug 4 15:19 bin # the (RDB)dump file of redis database, You can config where to save it later -rw-r--r-- 1 root root 93 Aug 4 16:54 dump.rdb # the config file of a particular redis instance -rw-r--r-- 1 root root 58905 Aug 7 13:56 redis.conf [root@shell redis]# cd /usr/local/redis/bin ; ll total 21876 # redis test tool -rwxr-xr-x 1 root root 2452168 Aug 4 15:19 redis-benchmark # redis AOF persistent check tool -rwxr-xr-x 1 root root 5775312 Aug 4 15:19 redis-check-aof # redis RBD persistent check tool -rwxr-xr-x 1 root root 5775312 Aug 4 15:19 redis-check-rdb # launch a redis client -rwxr-xr-x 2 root root 2618192 Aug 4 15:19 redis-cli # link to redis-server, launch a redis sentinel lrwxrwxrwx 1 root root 12 Aug 4 15:19 redis-sentinel -\u0026gt; redis-server server #launch a redis server(instance) -rwxr-xr-x 3 root root 5775312 Aug 4 15:19 redis-server 两个ll命令显示了一个redis的全部内容。本文用到的几个文件分别是：\nredis.conf： 配置文件，绝对的主角，它的戏谁都抢不走 redis-server： 用于启动redis缓存服务 redis-client：command-line client tool 2.2 其他配置项 # 如果上述操作没有问题这么简单也不会有问题，理论上，一个standalone实例已经安装完成了，可以通过「命令 配置文件」的方式启动redis服务：\n/usr/local/redis/bin/redis-server /usr/local/redis/redis.conf 但是为了方便启动服务，还需要做一些额外的操作：\n1. 复制redis二进制程序到系统环境变量 # cd /usr/local/redis/bin/ cp redis-server redis-cli redis-sentinel /usr/local/bin 如此，启动redis的时候便不需要指定程序路径; 此时，已经可以直接在终端运行redis-server了\n2. 将redis设置为开机启动： # # 安装完成后可以添加多个命令启动redis主从-哨兵系统 echo \u0026#34;redis-server /usr/local/redis.conf\u0026#34; \u0026gt;\u0026gt; /etc/rc.local 3. 开放防火墙端口 # 若主机未开启防火墙，则无需操作\n如果你的主机开启了防火墙，其他主机是无法连接上你的redis-server的，此时需要为其开放端口。\n前面说到，centOS7和centOS6的防火墙机制不一样，需要分别处理。\n若需知晓防火墙状态，请运行4\nsystemctl status serviceName centOS7 和centOS6的防火墙服务名分别为 firewalld和iptables\n对于centOS 7： # # 查看开放端口 [root@shell ~]# firewall-cmd --list-all public target: default icmp-block-inversion: no interfaces: sources: services: ssh dhcpv6-client http ports: 6379/tcp protocols: masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: # 如果6379端口不在返回结果中，那么将6379添加到开放端口列表中 [root@shell ~]# firewall-cmd --permanent --add-port=6379/tcp [root@shell ~]# firewall-cmd --reload centOS 6 # # 添加规则 iptables -I INPUT -p tcp -m tcp --dport 6379 -j ACCEPT # 保存规则 service iptables save # 重启iptables service iptables restart 2.3 配置文件redis.conf # 在redis的 安装文件夹内，有一个系统预配置文件redis.conf，我们需要修改此配置文件以满足需求。\n以下列出了(redis-standalone)常见配置列表4：\n# redis进程是否以守护进程的方式(后台)运行(不以守护进程的方式运行会占用一个终端) daemonize yes # 指定redis进程的PID文件存放位置 pidfile /var/run/redis.pid # redis进程的端口号 port 6379 # 允许任何ipv4的主机连接； bind 0.0.0.0 # 客户端闲置多长时间(s)后关闭连接，默认此参数为0即关闭此功能 timeout 300 # redis日志级别，可用的级别有debug.verbose.notice.warning loglevel verbose # log文件输出位置，如果进程以守护进程的方式运行，此处又将输出文件设置为stdout的话， # 就会将日志信息输出到/dev/null里面去了 logfile /var/log/redis/redis_6379.log # 设置数据库的数量，默认为0可以使用select \u0026lt;dbid\u0026gt;命令在连接上指定数据库id databases 16 # 保存db到磁盘，可配置多条，表示不同级别的数据改动 # 如下配置表示至少有一个key-value发生改动时，900s之后将其保存到磁盘； # 如果至少有10个key-value发生改动，那么300s后将其保存到磁盘； save 900 1 save 300 10 # 指定存储至本地数据库时是否压缩文件，默认为yes即启用存储 rdbcompression yes # 指定本地数据库文件名 dbfilename dump.db # 指定本地数据文件存放位置，以下配置表示保存在redis安装目录 dir ./ # 指定当本机为slave服务，配置为master的IP及端口，在redis启动的时候他会自动跟master进行数据同步 slaveof \u0026lt;masterip\u0026gt; \u0026lt;masterport\u0026gt; # 当master设置了密码保护时，slave服务连接master的密码 masterauth \u0026lt;master-password\u0026gt; # 设置redis连接密码，如果配置了连接密码，客户端在连接redis是需要通过AUTH\u0026lt;password\u0026gt;命令 # 提供密码，默认关闭 requirepass password # 设置同一时间最大客户连接数，默认无限制。redis可以同时连接的客户端数为redis程序可以打开的最大 # 文件描述符，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的 # 连接并向客户端返回 max number of clients reached 错误信息 maxclients 128 # 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除 # 已到期或即将到期的Key。当此方法处理后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以 # 进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区 maxmemory \u0026lt;bytes\u0026gt; # 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可 # 能会在断电时导致一段时间内的数据丢失。因为redis本身同步数据文件是按上面save条件来同步的，所以 # 有的数据会在一段时间内只存在于内存中。默认为no。 appendonly no # 指定跟新日志文件名默认为appendonly.aof appendfilename appendonly.aof # 指定更新日志的条件，有三个可选参数 - no：表示等操作系统进行数据缓存同步到磁盘(快)，always：表示每次 # 更新操作后手动调用fsync()将数据写到磁盘(慢，安全)， everysec：表示每秒同步一次(折衷，默认值)； appendfsync everysec ⚠️注意：关于bind指令的描述可以配置指定ip来允许指定连接，多个ip使用空格分隔，关于bind的意义，参考 redis配置外网访问\n3 启动redis # redis.conf文件配置无差的话，即可指定配置文件启动redis服务：\nredis-server /usr/local/redis/redis.conf 启动日志：\n27552:C 04 Aug 16:12:58.912 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 27552:C 04 Aug 16:12:58.912 # Redis version=4.0.11, bits=64, commit=00000000, modified=0, pid=27552, just started 27552:C 04 Aug 16:12:58.912 # Configuration loaded _._ _.-``__ \u0026#39;\u0026#39;-._ _.-`` `. `_. \u0026#39;\u0026#39;-._ Redis 4.0.11 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ \u0026#39;\u0026#39;-._ ( \u0026#39; , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|\u0026#39;` _.-\u0026#39;| Port: 6379 | `-._ `._ / _.-\u0026#39; | PID: 27553 `-._ `-._ `-./ _.-\u0026#39; _.-\u0026#39; |`-._`-._ `-.__.-\u0026#39; _.-\u0026#39;_.-\u0026#39;| | `-._`-._ _.-\u0026#39;_.-\u0026#39; | http://redis.io `-._ `-._`-.__.-\u0026#39;_.-\u0026#39; _.-\u0026#39; |`-._`-._ `-.__.-\u0026#39; _.-\u0026#39;_.-\u0026#39;| | `-._`-._ _.-\u0026#39;_.-\u0026#39; | `-._ `-._`-.__.-\u0026#39;_.-\u0026#39; _.-\u0026#39; `-._ `-.__.-\u0026#39; _.-\u0026#39; `-._ _.-\u0026#39; `-.__.-\u0026#39; 27553:M 04 Aug 16:12:58.915 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128. 27553:M 04 Aug 16:12:58.916 # Server initialized 27553:M 04 Aug 16:12:58.916 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add \u0026#39;vm.overcommit_memory = 1\u0026#39; to /etc/sysctl.conf and then reboot or run the command \u0026#39;sysctl vm.overcommit_memory=1\u0026#39; for this to take effect. 27553:M 04 Aug 16:12:58.916 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command \u0026#39;echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled\u0026#39; as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled. 27553:M 04 Aug 16:12:58.916 * Ready to accept connections 可以看到，一个standalon已经运行成功，但是有3个WARNING[^V5]:\nWARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128. # solution [root@shell ~]# echo 511 \u0026gt;/proc/sys/net/core/somaxconn [root@shell ~]# echo \u0026#34;net.core.somaxconn = 551\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add \u0026#39;vm.overcommit_memory = 1\u0026#39; to /etc/sysctl.conf and then reboot or run the command \u0026#39;sysctl vm.overcommit_memory=1\u0026#39; for this to take effect. #solution [root@shell ~]# echo 1 \u0026gt; /proc/sys/vm/overcommit_memory [root@shell ~]# echo \u0026#34;vm.overcommit_memory=1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command \u0026#39;echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled\u0026#39; as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled. #solution [root@shell ~]# echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled [root@shell ~]# vi /etc/rc.local if test -f /sys/kernel/mm/transparent_hugepage/enabled; then echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled fi if test -f /sys/kernel/mm/transparent_hugepage/defrag; then echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/defrag fi 4 使用redis-cli # redis服务启动成功之后，便可以通过redis-cli与服务进行交互。\n# 连接redis-server，若-h和-p参数缺省，则默认连接localhost:6379 redis-cli -h 127.0.0.1 -p 6379 127.0.0.1:6379\u0026gt; # 若redis-server requirepass设置了密码，那么需要认证 127.0.0.1:6379\u0026gt; auth yourpassword OK # ping-PONG说明redis服务正常 127.0.0.1:6379\u0026gt; ping 127.0.0.1:6379\u0026gt; PONG # 获取帮助 127.0.0.1:6379\u0026gt; help redis-cli 4.0.11 To get help about Redis commands type: \u0026#34;help @\u0026lt;group\u0026gt;\u0026#34; to get a list of commands in \u0026lt;group\u0026gt; \u0026#34;help \u0026lt;command\u0026gt;\u0026#34; for help on \u0026lt;command\u0026gt; \u0026#34;help \u0026lt;tab\u0026gt;\u0026#34; to get a list of possible help topics \u0026#34;quit\u0026#34; to exit To set redis-cli preferences: \u0026#34;:set hints\u0026#34; enable online hints \u0026#34;:set nohints\u0026#34; disable online hints Set your preferences in ~/.redisclirc 127.0.0.1:6379\u0026gt; help shutdown SHUTDOWN [NOSAVE|SAVE] summary: Synchronously save the dataset to disk and then shut down the server since: 1.0.0 group: server 127.0.0.1:6379\u0026gt; # 退出客户端 127.0.0.1:6379\u0026gt; exit 5 关闭redis-server # ⚠️不要使用kill -9 pid关闭redis server，这样会可能会丢失数据完整性\n#关闭redis-server 可选参数nosave|save意为关闭服务之前是否保存数据到磁盘 127.0.0.1:6379\u0026gt; shutdown [nosave|save] 6 艺术就是复制 # 以下配置是基于一台服务器的演示，如果要部署高可用环境，需要在不同的服务器上安装redis并作如下配置\n经过上述操作，一个redis-standalone服务就配置好了，如果要将redis系统高可用，只需要「复制」就好了。\n前面说过，redis-server是通过可执行文件 + 配置文件的方式启动，可执行文件已经解压得到，那么只需要复制配置文件就可以了。\n以下是本次slave和sentinel的配置：\nRole Address Port Master localhost 6379 Slave localhost 16379, 26379 Sentinel localhost 6380, 16380, 26380 # current workDir cd /usr/local # 创建文件夹存放slave和sentinel配置文件 mkdir redis-slave redis-sentinel cp -r redis/redis.conf redis-slave cp -r redis/redis.conf redis-sentinel # slave配置文件 mv redis-slave/redis.conf redis-slave/slave-16379.conf 6.1 配置redis-salve # slave的配置大抵和standalone一致，需要注意配置几个地方：\nlogfile的保存地址配置自行配置 masterauth和requirepass配置master的密码 slaveof指明了其是哪个「主」的「从」 slave-read-only指明从服务器只读 vim redis-slave/slave-16379.conf \u0026lt;\u0026lt;\u0026lt; daemonize yes pidfile /var/run/redis-16379.pid logfile /var/log/redis/redis-16379.log port 16379 bind 0.0.0.0 timeout 300 databases 16 dbfilename dump-16379.db dir ./ masterauth yourpassword requirepass yourpassword slave-read-only yes slaveof 127.0.0.1 6379 # 再多配一个slave cp redis-slave/slave-16379.conf redis-slave/slave-26379.conf 同样地，只需要更改部分配置内容（端口，文件名）就可以了。\n6.1.1 salve启动日志 # 以下是配置成功的slave启动日志：\n30463:C 05 Aug 11:33:34.536 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 30463:C 05 Aug 11:33:34.537 # Redis version=4.0.11, bits=64, commit=00000000, modified=0, pid=30463, just started 30463:C 05 Aug 11:33:34.537 # Configuration loaded _._ _.-``__ \u0026#39;\u0026#39;-._ _.-`` `. `_. \u0026#39;\u0026#39;-._ Redis 4.0.11 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ \u0026#39;\u0026#39;-._ ( \u0026#39; , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|\u0026#39;` _.-\u0026#39;| Port: 26379 | `-._ `._ / _.-\u0026#39; | PID: 30464 `-._ `-._ `-./ _.-\u0026#39; _.-\u0026#39; |`-._`-._ `-.__.-\u0026#39; _.-\u0026#39;_.-\u0026#39;| | `-._`-._ _.-\u0026#39;_.-\u0026#39; | http://redis.io `-._ `-._`-.__.-\u0026#39;_.-\u0026#39; _.-\u0026#39; |`-._`-._ `-.__.-\u0026#39; _.-\u0026#39;_.-\u0026#39;| | `-._`-._ _.-\u0026#39;_.-\u0026#39; | `-._ `-._`-.__.-\u0026#39;_.-\u0026#39; _.-\u0026#39; `-._ `-.__.-\u0026#39; _.-\u0026#39; `-._ _.-\u0026#39; `-.__.-\u0026#39; 30464:S 05 Aug 11:33:34.539 # Server initialized 30464:S 05 Aug 11:33:34.539 * Ready to accept connections # 注意以下输出： 30464:S 05 Aug 11:33:34.539 * Connecting to MASTER 127.0.0.1:6379 30464:S 05 Aug 11:33:34.539 * MASTER \u0026lt;-\u0026gt; SLAVE sync started 30464:S 05 Aug 11:33:34.539 * Non blocking connect for SYNC fired the event. 30464:S 05 Aug 11:33:34.539 * Master replied to PING, replication can continue... 30464:S 05 Aug 11:33:34.539 * Partial resynchronization not possible (no cached master) 30464:S 05 Aug 11:33:34.540 * Full resync from master: 4e99dfc708f2035b3b39f34796434de5889f667b:308 30464:S 05 Aug 11:33:34.543 * MASTER \u0026lt;-\u0026gt; SLAVE sync: receiving 177 bytes from master 30464:S 05 Aug 11:33:34.543 * MASTER \u0026lt;-\u0026gt; SLAVE sync: Flushing old data 30464:S 05 Aug 11:33:34.543 * MASTER \u0026lt;-\u0026gt; SLAVE sync: Loading DB in memory 30464:S 05 Aug 11:33:34.543 * MASTER \u0026lt;-\u0026gt; SLAVE sync: Finished with success slave的启动日志有几个信息值得关注：\nredis启动警告信息消除，说明我们之前的配置生效了； slave server 初始化成功之后，便开始连接master； master 连接成功之后，便开始从主数据库同步数据； 之后，从数据库一直监听机制主数据库的改动并同步数据 6.1.2 验证主从数据同步 # 可以通过在主数据库写入数据，通过从服务器读取数据来验证主从关系是否正常。\n[root@shell ~]# redis-cli -h localhost -p 6379 localhost:6379\u0026gt; auth yourpassword OK localhost:16379\u0026gt; get count \u0026#34;6\u0026#34; localhost:16379\u0026gt; decr count (integer) 5 localhost:16379\u0026gt; exit [root@ ~]# redis-cli -h localhost -p 16379 localhost:6379\u0026gt; auth yourpassword OK localhost:6379\u0026gt; get count \u0026#34;5\u0026#34; localhost:6379\u0026gt; incr count (error) READONLY You can\\\u0026#39;t write against a read only slave. 可以看到，主服务器将count值自减1之后，从服务器获取的count值也是自减后的值；同时，如果在从服务器上对count进行自增操作，会得到一条\n(error) READONLY You can\u0026#39;t write against a read only slave. 的错误消息，说明\n端口16379的redis服务是slave；\n我们配置的从服务器只读生效了\n以上，即可完成配置经典的一主多备的redis服务部署。\n6.2 配置redis-sentinel # 同slave的配置一样，复制配置文件，少许改动即可，以下列出了sentinel的异于slave的配置项5：\n# 哨兵sentinel监控的redis主节点的 ## quorum：当这些quorum个数sentinel哨兵认为master主节点失联 那么这时 客观上认为主节点失联了 # sentinel monitor \u0026lt;master-name\u0026gt; \u0026lt;ip\u0026gt; \u0026lt;port\u0026gt; \u0026lt;quorum\u0026gt; sentinel monitor master 127.0.0.1 6379 2 # 当在Redis实例中开启了requirepass \u0026lt;foobared\u0026gt;，所有连接Redis实例的客户端都要提供密码 # sentinel auth-pass \u0026lt;master-name\u0026gt; \u0026lt;password\u0026gt; sentinel auth-pass master yourpassword # 指定主节点应答哨兵sentinel的最大时间间隔，超过这个时间，哨兵主观上认为主节点下线，默认30秒 # sentinel down-after-milliseconds \u0026lt;master-name\u0026gt; \u0026lt;milliseconds\u0026gt; sentinel down-after-milliseconds master 30000 # 指定了在发生failover主备切换时，最多可以有多少个slave同时对新的master进行同步。 # 这个数字越小，完成failover所需的时间就越长；反之，但是如果这个数字越大，就意味着越多的 # slave因为replication而不可用。可以通过将这个值设为1，来保证每次只有一个slave，处于不能 # 处理命令请求的状态。 # sentinel parallel-syncs \u0026lt;master-name\u0026gt; \u0026lt;numslaves\u0026gt; sentinel parallel-syncs master 1 # 故障转移的超时时间failover-timeout，默认三分钟，可以用在以下这些方面： ## 1. 同一个sentinel对同一个master两次failover之间的间隔时间。 ## 2. 当一个slave从一个错误的master那里同步数据时开始，直到slave被纠正为从正确的master # 那里同步数据时结束。 ## 3. 当想要取消一个正在进行的failover时所需要的时间。 ## 4.当进行failover时，配置所有slaves指向新的master所需的最大时间。不过，即使过了这个超时， # slaves依然会被正确配置为指向master，但是就不按parallel-syncs所配置的规则来同步数据了 # sentinel failover-timeout \u0026lt;master-name\u0026gt; \u0026lt;milliseconds\u0026gt; sentinel failover-timeout master 180000 # sentinel配置文件 mv redis-sentinel/redis.conf redis-sentinel/sentinel-6380.conf vim redis-sentinel/sentinel-6380.conf \u0026lt;\u0026lt;\u0026lt; protected-mode no bind 0.0.0.0 port 16380 daemonize yes sentinel monitor master 127.0.0.1 6379 2 sentinel down-after-milliseconds master 5000 sentinel failover-timeout master 180000 sentinel parallel-syncs master 1 sentinel auth-pass master yourpassword logfile /var/log/redis/sentinel-16380.log 同理，可以再配置其他2个sentinel服务。\n6.2.1 sentinel启动日志 # 启动sentinel6\nredis-sentinel /usr/local/redis-sentinel/sentinel-6380.conf # 或者 redis-server /usr/local/redis-sentinel/sentinel-6380.conf --sentinel 以下是配置成功的sentinel启动日志其一\n8550:X 05 Aug 14:29:38.696 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 8550:X 05 Aug 14:29:38.696 # Redis version=4.0.11, bits=64, commit=00000000, modified=0, pid=8550, just started 8550:X 05 Aug 14:29:38.696 # Configuration loaded _._ _.-``__ \u0026#39;\u0026#39;-._ _.-`` `. `_. \u0026#39;\u0026#39;-._ Redis 4.0.11 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ \u0026#39;\u0026#39;-._ ( \u0026#39; , .-` | `, ) Running in sentinel mode |`-._`-...-` __...-.``-._|\u0026#39;` _.-\u0026#39;| Port: 6380 | `-._ `._ / _.-\u0026#39; | PID: 8551 `-._ `-._ `-./ _.-\u0026#39; _.-\u0026#39; |`-._`-._ `-.__.-\u0026#39; _.-\u0026#39;_.-\u0026#39;| | `-._`-._ _.-\u0026#39;_.-\u0026#39; | http://redis.io `-._ `-._`-.__.-\u0026#39;_.-\u0026#39; _.-\u0026#39; |`-._`-._ `-.__.-\u0026#39; _.-\u0026#39;_.-\u0026#39;| | `-._`-._ _.-\u0026#39;_.-\u0026#39; | `-._ `-._`-.__.-\u0026#39;_.-\u0026#39; _.-\u0026#39; `-._ `-.__.-\u0026#39; _.-\u0026#39; `-._ _.-\u0026#39; `-.__.-\u0026#39; 8551:X 05 Aug 14:29:38.702 # Sentinel ID is c3776869c9bc3998e45158d3933d8e7b7c60ea84 8551:X 05 Aug 14:29:38.702 # +monitor master master 127.0.0.1 6379 quorum 2 通过观查启动日志，我们可以看到：\n此实例的启动模式为sentinel mode，端口为6380 sentinel已经成功监控master端口6379了 全部哨兵系统搭建起来并运行之后，再去查看sentinel的配置文件，会有如下自动配置的内容：\n# Generated by CONFIG REWRITE sentinel auth-pass master yourpassword sentinel config-epoch master 1 sentinel leader-epoch master 1 sentinel known-slave master 127.0.0.1 16379 sentinel known-slave master 127.0.0.1 26379 sentinel known-sentinel master 127.0.0.1 26380 e615ce sentinel known-sentinel master 127.0.0.1 6380 dcc9d7 sentinel current-epoch 1 上面的配置列出了\n主服务器的密码 以及当前世代（每发生一次主备切换称为一次世代，epoch加1） 当前所有从服务器的地址和端口信息 当前所以其他已知哨兵的端口和id信息 6.2.2 使用redis-cli查看系统信息 # sentinel哨兵系统搭建起来之后，可以任一通过客户端查看系统内的实例信息。\n127.0.0.1:16380\u0026gt; sentinel master master 1) \u0026#34;name\u0026#34; 2) \u0026#34;master\u0026#34; 3) \u0026#34;ip\u0026#34; 4) \u0026#34;127.0.0.1\u0026#34; 5) \u0026#34;port\u0026#34; 6) \u0026#34;6379\u0026#34; 7) \u0026#34;runid\u0026#34; 8) \u0026#34;dfefe0ba7435f7c2c193698f17b7e46f7450d5ce\u0026#34; 9) \u0026#34;flags\u0026#34; 10) \u0026#34;master\u0026#34; ... 127.0.0.1:16380\u0026gt; sentinel slaves master 1) 1) \u0026#34;name\u0026#34; 2) \u0026#34;127.0.0.1:16379\u0026#34; 3) \u0026#34;ip\u0026#34; 4) \u0026#34;127.0.0.1\u0026#34; 5) \u0026#34;port\u0026#34; 6) \u0026#34;16379\u0026#34; 7) \u0026#34;runid\u0026#34; 8) \u0026#34;fdda882f98724c46359a4deb9390b6ae4de13320\u0026#34; 9) \u0026#34;flags\u0026#34; 10) \u0026#34;slave\u0026#34; ... 2) 1) \u0026#34;name\u0026#34; 2) \u0026#34;127.0.0.1:26379\u0026#34; 3) \u0026#34;ip\u0026#34; 4) \u0026#34;127.0.0.1\u0026#34; 5) \u0026#34;port\u0026#34; 6) \u0026#34;26379\u0026#34; 7) \u0026#34;runid\u0026#34; 8) \u0026#34;4a2c286c0c99c3a1202eec142599193a85671f6c\u0026#34; 9) \u0026#34;flags\u0026#34; 10) \u0026#34;slave\u0026#34; ... 6.2.3 模拟主备切换 # 哨兵的存在就是为了解决master-slave系统中由于master宕机引起的系统瘫痪问题。\n在哨兵系统中，一旦哨兵发现当前master宕机，哨兵会在余下的slaves中选举一个「继任」为新一代的master，从而保证系统的高可用。\n现在我们通过主动关闭当前master服务的方式来模拟master宕机，看看哨兵会做什么：\n# 关闭master服务 redis-cli -p 6379 127.0.0.1:6379\u0026gt; auth yourpassword OK 127.0.0.1:6379\u0026gt; shutdown save 127.0.0.1:6379\u0026gt; exit # 查看sentinel日志 less /var/log/redis/sentinel-6380.log \u0026lt;\u0026lt;\u0026lt; 29649:X 23 Aug 17:14:02.326 # +sdown master master 127.0.0.1 6379 29649:X 23 Aug 17:14:02.389 # +new-epoch 1 29649:X 23 Aug 17:14:02.391 # +vote-for-leader 503d5371452f8e110df0f12c236da3e51b55b03a 1 29649:X 23 Aug 17:14:03.444 # +odown master master 127.0.0.1 6379 #quorum 3/2 29649:X 23 Aug 17:14:03.444 # Next failover delay: I will not start a failover before Fri Aug 23 17:14:38 2019 29649:X 23 Aug 17:14:03.488 # +config-update-from sentinel 503d5371452f8e110df0f12c236da3e51b55b03a 172.16.16.203 16380 @ master 127.0.0.1 6379 29649:X 23 Aug 17:14:03.488 # +switch-master master 127.0.0.1 6379 127.0.0.1 26379 29649:X 23 Aug 17:14:03.488 * +slave slave 127.0.0.1:16379 127.0.0.1 16379 @ master 127.0.0.1 26379 29649:X 23 Aug 17:14:03.488 * +slave slave 127.0.0.1:6379 127.0.0.1 6379 @ master 127.0.0.1 26379 29649:X 23 Aug 17:14:08.536 # +sdown slave 127.0.0.1:6379 127.0.0.1 6379 @ master 127.0.0.1 26379 29649:X 23 Aug 17:15:42.868 # -sdown slave 127.0.0.1:6379 127.0.0.1 6379 @ master 127.0.0.1 26379 29649:X 23 Aug 17:15:52.888 * +convert-to-slave slave 127.0.0.1:6379 127.0.0.1 6379 @ master 127.0.0.1 26379 通过24行sentinel日志，我们可以看到的信息有哪些呢？\nmaster主观下线7； 系统进入新世代； 3/2投票认为master下线，master客观下线8； 切换主服务器：从6379切换为26379； 同时6379和16379切换为26379的从节点 此时，我们如果查看redis的配置文件，会发现原6379的主服务器配置文件多了一行\nslaveof 127.0.0.1 26379 同时，16379和26379端口的服务的slaveof配置项也作了相应修改。\n7 结束语 # 至此，基于sentinel的redis高可用集群就搭建完成了。虽然篇幅较长，实际上搭建一个这样的系统的逻辑是比较简单的。\n主要易于混淆的是6不个redis实例的配置，细心点就好了。\n想用好这个高可用系统，你可能还需要了解更多关于sentinel的内容。\n本文是在所有服务均配置完成之后所作的记录，并非同步记录，部分操作可能存在错误\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n下文会多次提到实例这个概念，它在本文中指一个运行的Redis数据库服务\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n监控master状态，如果宕机，则执行主备切换\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n搭建redis单机服务\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nredis哨兵与高可用\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nredis-server man page\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n仅当前哨兵接收不到master的心跳，称为主观下线\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n经过投票之后，满足配置个数的哨兵认为master下线，则master被认为客观下线，触发主备切换\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":27,"href":"/zh/docs/craft/db/sql/2_MySQL%E7%9A%84%E5%87%A0%E4%B8%AA%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86%E5%87%BD%E6%95%B0/","title":"MySQL字符串处理函数","section":"mysql","content":"本文介绍了mysql的几个方便的字符串处理函数，通常用于简单的查询结果处理。适用在mapper.xml的语句标签中对数据库字段数据进行简单的处理。\nSUBSTRING_INDEX(str,delim,count) # 根据索引获取子字符串 @param str 待处理字符串 @delim 关键字 @count 关键字出现的次数\nSELECT SUBSTRING_INDEX(\u0026#39;www.google.com/welcome\u0026#39;,\u0026#39;/\u0026#39;,1); -- www.google.com SELECT SUBSTRING_INDEX(SUBSTRING_INDEX(\u0026#39;www.google.com/welcome\u0026#39;,\u0026#39;/\u0026#39;,1),\u0026#39;.\u0026#39;,-2); -- google.com -- 当count为负数的时候,从尾部开始计算 SUBSTRING(str,pos,len) # 获取指定长度的字串 @str 原字符串 @pos 开始截取的位置(包含) @len 子串长度\nSELECT SUBSTRING(\u0026#34;www.google.com\u0026#34;, 5, 6); SELECT SUBSTRING(\u0026#34;www.google.com\u0026#34; FROM 5 FOR 6); -- google 此方法还有一些重载方法\nREPLACE(str,from_str,to_str) # 替换字符串的内容 @str 原字符串 @from_str 目标字符串(子串) @to_str 替换的字符串\nSELECT REPLACE(\u0026#39;www.google.com\u0026#39;,\u0026#39;google\u0026#39;,\u0026#39;baidu\u0026#39;); -- www.baidu.com ALTER # 新增字段 (ADD) # 在某张表中添加字段使用ADD关键字 支持批量添加 如果要在某个字段之后添加字段,可使用 AFTER 关键字\nALTER TABLE TABLE_NAME ADD (COL_NAME DATATYPE [UNSIGNED DEFAULT NOT NULL COMMENT],COLNAME2 DATATYPE,...); ALTER TABLE TABLE_NAME ADD COL_NAME DATATYPE AFTER `col_name`; 修改字段 (MODIFY CHANGE) # 修改字段属性(数据类型,默认值,非空约束等)使用 MODIFY 修改字段名字以及数据类型,默认值,非空约束等使用 CHANGE\n-- 修改字段属性 ALTER TABLE t1 MODIFY col1 BIGINT UNSIGNED DEFAULT 1 COMMENT \u0026#39;my column\u0026#39;; -- 修改字段名字和属性 ALTER TABLE t1 CHANGE a b INT(11) DEFAULT 0 NOT NULL COMMENT \u0026#39;comment\u0026#39;; "},{"id":28,"href":"/zh/docs/java/collections/","title":"集合框架","section":"Java","content":" Java集合框架结构简图\n未列出枚举集（EnumSet/EnumMap） 未列出IdentityHashMap 未列出java.util.concurrent包下的实现 上图列出了集合框架的常见实现，Java集合框架系列文章介绍了图中列出的大部分内容。\n主要讨论三大接口：\nList\nList是有序集合，或称之为序列。List的实现可以准确地控制插入元素的位置，也可以通过元素的索引(index)访问之，还可以在集合中搜索元素\n和 Set不同，List允许元素重复出现，甚至允许多个null元素出现\nList定义了4个由索引执行的操作\nE get(int index);\nE set(int index, E element);\nvoid add(int index, E element);\nE remove(int index);\nArrayList由于实现了RandomAccess接口，其在使用索引随机访问时性能不会受影响，但是LinkedList执行索引操作的耗时是与集合大小正相关的。\n因此，在不清楚List的实现类型的时候1，通过迭代器遍历集合中的元素进行操作比直接使用索引更可取。\nList提供了一个独有的迭代器ListIterator，其提供了插入/替换元素的操作，并且支持双向迭代。\n关于List，分2文讨论：\nArrayList LinkedList Set\nSet是不含重复元素的集，严格来讲，Set不允许当e1.equals(e2)为真时， e1 和 e2 同时出现在集合中。Set最多允许一个null元素。\n将可变对象置入Set时需要特别小心，当对象的改动影响到了元素之间的equals()比较的结果，那么Set的行为就变得不确定了。因此，不能将Set本身作为Set的元素。\n集的部分，主要讨论了HashSet和TreeSet：\nHashSet TreeSet Map\nMap即映射，即键-值对，键不允许重复，并且一个键最多映射一个值。Map不在Java集合框架的范畴，但是其由集合框架的内容实现。自然也在集合框架的讨论之内。\n映射提供3种集合视图\n键集 （Set实现） 值集 （Collection实现） Map.Entry集（Set实现） 关于Map的内容，主要讨论了3个：\nHashMap TreeMap LinkedHashMap 有关线程安全的集合将在并发编程部分讨论。\n这种情况在获取集合视图(Collection view)时经常出现。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":29,"href":"/zh/docs/note/course/algorithms_part1/","title":"算法-第一部分","section":"课程笔记","content":" Algorithms, Part I - Princeton University - Coursera # This course covers the essential information that every serious programmer needs to know about algorithms and data structures, with emphasis on applications and scientific performance analysis of Java implementations.\nPart I covers elementary data structures, sorting, and searching algorithms.\nPart II focuses on graph- and string-processing algorithms.\nP1: 6 weeks of study, 6–10 hours per week. 1 hour\u0026ndash;1 and a half per day.\n本部分的内容包括：\n基础数据结构（一维） 排序算法 搜索算法 "},{"id":30,"href":"/zh/docs/note/course/operating_system_peking/3_processes_and_threads/","title":"进程和线程模型","section":"操作系统原理","content":" 进程模型 # 多道程序设计 # MultiProgramming：多个程序同时进入内存并运行，提高操作系统效率。并发环境。\n多个虚拟（逻辑）程序计数器 \u0026mdash;\u0026gt; 物理计数器\n进程的概念以及进程控制块 # 进程 # Process：进程是具有独立功能的程序关于某个数据集合上的一次运行活动，是系统进行资源分配和调度的独立单位。\n是程序的一次执行过程 是正在运行的程序的抽象 将一个CPU变幻成多个虚拟的CPU （是CPU的抽象） 系统资源以进程为单位分配，如内存、文件、独立的地址空间\u0026hellip;\u0026hellip; 进程控制块(PCB) # PCB: Process Control Block\n又称进程描述符、进程属性 操作系统用于管理控制进程的一一个专门数据结构 不同操作系统，对PCB的实现可能不同，但是其功能相同。\nLinux中叫task_sturct\nWindows中叫EPROCESS，KPROCESS，PEB\n记录进程的各种属性，描述进程的动态变化过程 PCB是系统感知进程存在的唯一标志 \u0026gt;进程与PCB是一一 对应\n进程表: 所有进程的PCB集合。在内存的固定区域，大小固定，所以存储的PCB信息也是有限的，这就是操作系统的并发度。\nPCB存储了哪些信息？\n1） 进程描述信息\n进程标识符(process ID)，唯一，通常是一个整数 进程名，通常基于可执行文件名，不唯一 用户标识符(user ID) 进程组关系 2）进程控制信息\n当前状态 优先级(priority) 代码执行入口地址 程序的磁盘地址 运行统计信息(执行时间、页面调度)进程间同步和通信 进程的队列指针 进程的消息队列指针 3）所拥有的资源和使用情况\n虚拟地址空间的状况 打开文件列表 4）CPU现场信息\n寄存器值（通用寄存器、程序计数器PC、程序状态字PSW、栈指针） 指向该进程页表的指针 还可以从下面三个维度来看看PCB存储的信息\n进程管理 存储管理 文件管理 进程的状态及转换、进程队列 # 进程的三种基本状态 # 运行态（Running）：占有CPU，并在CPU上运行 就绪态（Ready）：已经具备运行的条件，但没有空闲CPU，故暂时不能运行 等待态（Waiting/Blocked）：因等待某一事件而暂时不能运行（如等待磁盘结果）。也叫做阻塞态、封锁态或睡眠态 进程的状态转换 # 进程3状态转换示意图 其他线程状态 # 1）创建（New）：\n已完成创建一进程所必要的工作 - PID、PCB 但尚未同意执行该进程 -因为资源有限 2）结束（Terminated）：\n终止执行后，进程进入该状态 可完成一些数据统计工作 资源回收 3）挂起（Suspend）： 用于调节负载\n进程不占用内存空间，其进程映像交换到磁盘上 进程5状态转换示意图 进程队列 # PCB组成的队列，不同状态的进程，分别进入不同的队列。进程状态变化时，进程程PCB也会从A队列出队而进入B队列。\n进程控制 # 进程控制操作完成进程各状态之间的转换，由具有特定功能的原语完成。\n原语 (primitive)\n完成某种特定功能的一段程序，具有不可分割性或不可中断性\n即原语的执行必须是连续的，在执行过程中不允许被中断[原子操作 (atomic)]\n进程创建原语 进程撤消原语 阻塞原语 唤醒原语 挂起原语 激活原语 改变进程优先级 \u0026hellip;.. 创建进程 # 1）给新进程分配一个唯一标识以及进程控制块\n2）为进程分配地址空间\n3）初始化进程控制块 - 设置默认值(如:状态为New, \u0026hellip;)\n4）设置相应的队列指针 - 如:把新进程加到就绪队列链表中\n不同操作系统创建进程的方法：\nUNIX: fork/exec\nWindows: CreateProcess\n结束（撤消）进程 # 1）收回进程所占有的资源 - 关闭打开的文件、断开网络连接、回收分配的内存\u0026hellip;\n2）撤消该进程的PCB\n不同操作系统创建进程的方法：\nUNIX: exit\nWindows: TerminateProcess\n线程的阻塞 # 处于运行状态的进程，在其运行过程中期待某一事件发生，如等待键盘输入、等待磁盘数据传输完成、等待其它进程发送消息当被等待的事件未发生时，由进程自己执行阻塞原语，使自己由运行态变为阻塞态。\n不同操作系统创建进程的方法：\nUNIX: wait\nWindows: WaitForSingleObject\nUnix的几个进程控制操作 # 它们都是系统调用\n1）fork()：通过复制调用进程来建立新的进程，是最基本的进程建立过程。\n2）exec()：包括一系列系统调用，它们都是通过用一段新的程序代码覆盖原来的地址空间，实现进程执行代码的转换。\n3）wait()：提供初级进程同步操作，能使一个进程等待另外一个进程的结束。\n4）exit()：用来终止一个进程的运行。\nUnix和Linux系统的fork()方法虽然都创建进程，但实现逻辑略有不同。\nUnix在创建进程时，子进程会直接分配一个独立的内存空间，并复制父进程全部文件描述符。\nLinux则不同，子进程共享父进程的物理内存页，只有在子进程尝试修改页内容时，才会复制父进程的页内容。这个技术叫COW（copy on write）。\n得益于Linux的COW技术，fork()的效率比Unix上更好。\nReferences about fork() and Copy-On-Write:\nDocs:\nUnix fork() documentation Linux fork() man page Copy-on-write, wikipeida Discussions:\nDoes fork() immediately copy the entire process heap in Linux? How does copy-on-write give one optimization for fork-exec? What is copy-on-write? 下面的代码展示了创建子进程并等待子进程执行完成的过程：\n# include \u0026lt;stdio.h\u0026gt; # include \u0026lt;stdlib.h\u0026gt; # include \u0026lt;unistd.h\u0026gt; # include \u0026lt;sys/types.h\u0026gt; int main(){ // 父进程中返回子进程的id // 子进程中返回0 int pid = fork(); if (pid == 0) { printf(\u0026#34;child\u0026#39;s PID is %d. \\n\u0026#34;, getpid()); } else if (pid \u0026gt; 0) { // 父进程等待子进程执行完成，再继续执行 wait(NULL); printf(\u0026#34;parent\u0026#39;s PID is %d. \\n\u0026#34;, getpid()); printf(\u0026#34;child\u0026#39;s PID is %d. \\n\u0026#34;, pid); } else { perror(\u0026#34;fork() failed\u0026#34;); exit(1); } exit(0); } /* output: child\u0026#39;s PID is 70291. parent\u0026#39;s PID is 70290. child\u0026#39;s PID is 70291. */ 进程的讨论 # 分类 # 按用户分： 1） 系统进程 2）用户进程\n按运行方式分： 1）前台进程 2）后台进程\n按资源需求分： 1） CPU密集型进程 2）I/O密集型进程\n和程序的区别：\n进程更能准确刻画并发，而程序不能。\n程序是静态的，进程是动态的。\n进程有生命周期的，有诞生有消亡短暂的;而程序是相对长久的。\n一个程序可对应多个进程。\n进程具有创建其他进程的功能。\n层次结构 # 不同操作系统，进程的层次有所差异。\n⚠️generated by gpt.\nLinux操作系统中的进程层次结构：\n父子关系：在Linux中，每个进程（除了根进程init，进程ID=1）都有一个父进程，创建子进程的进程被称为父进程，而新创建的进程被称为子进程。父进程负责创建、管理和控制子进程，形成了一个层次结构，类似于树状结构。 子进程：除了根进程外，每个进程都可以创建一个或多个子进程。当一个进程创建一个子进程时，子进程会继承父进程的某些属性和资源，如内存空间、文件描述符和环境变量。 进程组：在Linux中，可以将属于同一进程层次结构的进程组织成进程组。进程组是一组相关的进程，可以进行集体管理和控制。进程组允许在多个进程之间进行信号传递和进程控制等操作。 进程树：进程层次结构形成了一种树状结构，通常称为进程树。根进程位于树的顶部，子进程从其父进程分支出来。进程树表示了系统中进程之间的关系和依赖。 Windows操作系统中的进程层次结构：\n父子关系：在Windows中，每个进程（除了系统进程）都有一个父进程，创建子进程的进程被称为父进程，而新创建的进程被称为子进程。父进程负责创建、管理和控制子进程。 子进程继续运行：在Windows中，如果父进程终止，子进程可以继续运行。子进程不会因为父进程的终止而被终止，它可以继续独立运行。 僵尸进程：在Linux中，如果父进程终止，所有与之关联的子进程都会被强制退出。而在Windows中，子进程可以继续运行，即使父进程已经终止。这可能导致僵尸进程的存在，即已经终止但在进程表中仍有条目的进程。 需要注意的是，进程层次结构在Linux和Windows中可能会有一些特定的实现差异，但基本的父子关系和层次结构概念是相似的。\nReferences:\nWhat is the process hierarchy in an operating system? - CompuHoy.com Process Hierarchy in Operating System | by Rahul Ahir | Medium What is a process hierarchy? - Tutorialspoint What are the process states in Windows and Linux? - Tutorialspoint 进程地址空间 # 操作系统给每个进程都分配了一个地址空间。\n进程地址空间 下面的代码示例展示了进程运行时的地址：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; int myval; int main(int argc, char *argv[]) { myval = atoi(argv[1]); while(1){ printf(\u0026#34;myval is %d, loc 0x%lx\\n\u0026#34;, myval, (long)\u0026amp;myval); } } 在不同的终端上运行上述代码，可以看到如下可能的输出：\n~ ./myval 7 myval is 7, loc 0x10d222018 ... ~ ./myval 8 myval is 8, loc 0x102f4a018 ... 可以看到，2个程序的变量所指向的地址是不用的。不过，这个地址并不是物理地址，而是虚拟地址或者叫逻辑地址。\n进程映像（IMAGE） # 指对进程执行活动全过程的静态描述（进程快照）。\n由进程地址空间内容、硬件寄存器内容及与该进程相关的内核数据结构、内核栈组成。\n用户相关:\n进程地址空间(包括代码段、数据段、堆和栈、共享库.....)。 寄存器相关:\n程序计数器、指令寄存器、程序状态寄存器、栈指针、通用寄存器等的值。 内核相关:\n1）静态部分: PCB及各种资源数据结构 2）动态部分: 内核栈(不同进程在进入内核后使用不同的内核栈) 上下文切换（CONTEXT） # 将CPU硬件状态从一个进程换到另一个进程的过程称为上下文切换。\n进程运行时，其硬件状态保存在CPU上的寄存器中。\n寄存器: 程序计数器、程序状态寄存器、栈指针、通用寄存器、其他控制寄存器的值。 进程不运行时，这些寄存器的值保存在进程控制块PCB中;当操作系统要运行一个新的进程时，将PCB中的相关值送到对应的寄存器中\n线程模型 # 为什么引入线程 # 线程的组成 # 线程机制的实现 # 用户级线程 # 核心级线程 # 混合方式 # "},{"id":31,"href":"/zh/docs/note/pys/3_data_str/","title":"字符串，元组和字典","section":"Python","content":" "},{"id":32,"href":"/zh/docs/craft/design_pattern/structure/2_adaptor/","title":"适配器模式","section":"结构型","content":" 适配器模式 # 适配器模式将一个类的接口，转换成客户期望的另一个接口。 适配器模式可以让原本接口不兼容的类可以合作无间。\n设计原则 # 针对接口编程，而不是针对实现编程 多用组合，少用继承 为交互对象之间的松耦合而努力 类应该对拓展开放，而对修改关闭 （开放-关闭原则） 依赖抽象，而不依赖具体类 （依赖倒置原则） UML简图 # classDiagram direction LR class Client{ +Adaptor adaptor +otherOperations() } class Target { \u003c\u003c Interface \u003e\u003e operationA() } Client *--\u003e Adaptor Adaptor ..|\u003e Target Adaptor *..\u003e Adaptee class Adaptor { +Adaptee adaptee operationA() } class Adaptee { \u003c\u003c Interface \u003e\u003e operationB() } classDiagram direction LR class Client{ +Adaptor adaptor +otherOperations() } class Target { \u0026lt;\u0026lt;Interface\u0026gt;\u0026gt; operationA() } Client *--\u0026gt; Adaptor Adaptor ..|\u0026gt; Target Adaptor *..\u0026gt; Adaptee class Adaptor { +Adaptee adaptee operationA() } class Adaptee { \u0026lt;\u0026lt;Interface\u0026gt;\u0026gt; operationB() } 要点 # 适配器模式，通过创建\u0026quot;适配器\u0026quot;进行接口转换，可以让不兼容的接口变得兼容。 适配器模式让客户从接口的实现解耦。 注意适配器和装饰模式的区别，适配器改变接口以让其对不兼容的对象可用， 装饰模式是通过继承，赋予类新的行为和\u0026quot;职责\u0026quot;。 当需要使用一个现有的类而可用的接口并不适配时，考虑使用适配器模式。 对象适配器和类适配器\n在Java中，看不到类适配器。类适配器，只有在支持多继承（C++）的语言中 适用。类似配器，就是被适配的对象为实例类，同时适配器继承之。\n示例代码 # Generated by Gemini 1.5-flash, revised.\n示例代码展示了如何让普通的媒体播放器具备播放vlc和mp4的能力。\nTarget # // 目标接口（Target） // 普通的媒体播放器 interface MediaPlayer { void play(String audioType, String fileName); } Adaptee # // 要适配的接口（Adaptee） interface AdvancedMediaPlayer { void playVlc(String fileName); void playMp4(String fileName); } // 适配者的实现（Adaptee‘s implements） class VlcPlayer implements AdvancedMediaPlayer { @Override public void playVlc(String fileName) { System.out.println(\u0026#34;正在播放 VLC 文件: \u0026#34; + fileName); } @Override public void playMp4(String fileName) { // do nothing } } class Mp4Player implements AdvancedMediaPlayer { @Override public void playVlc(String fileName) { // do nothing } @Override public void playMp4(String fileName) { System.out.println(\u0026#34;正在播放 MP4 文件: \u0026#34; + fileName); } } Adapter # // 适配器类（Adapter） class MediaAdapter implements MediaPlayer { private AdvancedMediaPlayer mediaPlayer; public MediaAdapter(String audioType) { if (audioType.equalsIgnoreCase(\u0026#34;vlc\u0026#34;)) { mediaPlayer = new VlcPlayer(); } else if (audioType.equalsIgnoreCase(\u0026#34;mp4\u0026#34;)) { mediaPlayer = new Mp4Player(); } } @Override public void play(String audioType, String fileName) { if (audioType.equalsIgnoreCase(\u0026#34;vlc\u0026#34;)) { mediaPlayer.playVlc(fileName); } else if (audioType.equalsIgnoreCase(\u0026#34;mp4\u0026#34;)) { mediaPlayer.playMp4(fileName); } } } 客户端 # // 客户端类 class AudioPlayer implements MediaPlayer { private MediaAdapter adapter; public void play(String audioType, String fileName) { if (audioType.equalsIgnoreCase(\u0026#34;mp3\u0026#34;)) { System.out.println(\u0026#34;正在播放 MP3 文件: \u0026#34; + fileName); } else if (audioType.equalsIgnoreCase(\u0026#34;vlc\u0026#34;) || audioType.equalsIgnoreCase(\u0026#34;mp4\u0026#34;)) { adapter = new MediaAdapter(audioType); adapterplay(audioType, fileName); } else { System.out.println(\u0026#34;不支持的文件格式\u0026#34;); } } } public class AdapterPatternDemo { public static void main(String[] args) { AudioPlayer audioPlayer = new AudioPlayer(); audioPlayer.play(\u0026#34;mp3\u0026#34;, \u0026#34;beyond the horizon.mp3\u0026#34;); audioPlayer.play(\u0026#34;vlc\u0026#34;, \u0026#34;far far away.vlc\u0026#34;); audioPlayer.play(\u0026#34;mp4\u0026#34;, \u0026#34;alone.mp4\u0026#34;); } } 话外 # 感觉有点怪，究竟是怎样的场景，需要使用到适配器模式？我想肯定不会是 开发计划期或alpha版本开发期。\n出现需要使用适配器的场景，应该是出现在代码迭代期，可能有更新版本（不兼容） 的API需要适配，又为了避免大量修改已经存在的代码。\n可能，适配器模式是代码系统优化或者重构的时候，需要考虑的模式?\n适配器模式的示例代码 "},{"id":33,"href":"/zh/docs/craft/design_pattern/creation/3_abstract_factory/","title":"抽象工厂模式","section":"创建型","content":" 抽象工厂模式 # by Head First 设计模式\n抽象工厂模式提供了一个接口，用于创建相关或依赖对象的家族，而不需要指定具体类。 简而言之，抽象工厂可以创建一群对象，而不单单只创建一种对象。\nby Dive into Design Patterns\nAbstract Factory is a creational design pattern that lets you produce families of related objects without specifying their concrete classes.\nUML简图 # classDiagram class AbstractFactory { \u003c\u003c Abstract \u003e\u003e createProductA() ProductA createProductB() ProductB otherMethod() } ConcreteFactoryA --|\u003e AbstractFactory class ConcreteFactoryA{ createProductA() ProductA createProductB() ProductB } ConcreteFactoryB --|\u003e AbstractFactory class ConcreteFactoryB { createProductA() ProductA createProductB() ProductB } ConcreteFactoryA \u003c.. ProductA ConcreteFactoryA \u003c.. ProductB class ProductA { \u003c\u003c Interface \u003e\u003e } ProductA \u003c|.. ConcreteProductA class ConcreteProductA ConcreteFactoryB \u003c.. ProductA ConcreteFactoryB \u003c.. ProductB class ProductB { \u003c\u003c Interface \u003e\u003e } ProductB \u003c|.. ConcreteProductB class ConcreteProductB AbstractFactory \u003c..* Client class Client { -AbstractFactory absFactory +Client(AbstractFactory f) Client +otherMethod() } classDiagram class AbstractFactory { \u0026lt;\u0026lt;Abstract\u0026gt;\u0026gt; createProductA() ProductA createProductB() ProductB otherMethod() } ConcreteFactoryA --|\u0026gt; AbstractFactory class ConcreteFactoryA{ createProductA() ProductA createProductB() ProductB } ConcreteFactoryB --|\u0026gt; AbstractFactory class ConcreteFactoryB { createProductA() ProductA createProductB() ProductB } ConcreteFactoryA \u0026lt;.. ProductA ConcreteFactoryA \u0026lt;.. ProductB class ProductA { \u0026lt;\u0026lt;Interface\u0026gt;\u0026gt; } ProductA \u0026lt;|.. ConcreteProductA class ConcreteProductA ConcreteFactoryB \u0026lt;.. ProductA ConcreteFactoryB \u0026lt;.. ProductB class ProductB { \u0026lt;\u0026lt;Interface\u0026gt;\u0026gt; } ProductB \u0026lt;|.. ConcreteProductB class ConcreteProductB AbstractFactory \u0026lt;..* Client class Client { -AbstractFactory absFactory +Client(AbstractFactory f) Client +otherMethod() } 设计原则 # 针对接口编程，而不是针对实现编程 多用组合，少用继承 为交互对象之间的松耦合而努力 类应该对拓展开放，而对修改关闭 （开放-关闭原则） 依赖抽象，而不依赖具体类 （依赖倒置原则） 示例代码 # Generated by gpt-4-tubo\n抽象工厂模式是一种创建型设计模式，它提供了一种方式，可以封装一组具有共同主题的单独的工厂，而不需要指定它们的具体类。这里给出一个简单的抽象工厂模式的示例，使用Java语言实现。\n首先，定义抽象产品类和具体产品类：\n// 抽象产品A interface ProductA { void use(); } // 具体产品A1 class ProductA1 implements ProductA { public void use() { System.out.println(\u0026#34;Using ProductA1\u0026#34;); } } // 具体产品A2 class ProductA2 implements ProductA { public void use() { System.out.println(\u0026#34;Using ProductA2\u0026#34;); } } // 抽象产品B interface ProductB { void use(); } // 具体产品B1 class ProductB1 implements ProductB { public void use() { System.out.println(\u0026#34;Using ProductB1\u0026#34;); } } // 具体产品B2 class ProductB2 implements ProductB { public void use() { System.out.println(\u0026#34;Using ProductB2\u0026#34;); } } 接下来，定义抽象工厂接口和具体工厂类：\n// 抽象工厂 interface AbstractFactory { ProductA createProductA(); ProductB createProductB(); } // 具体工厂1 class ConcreteFactory1 implements AbstractFactory { public ProductA createProductA() { return new ProductA1(); } public ProductB createProductB() { return new ProductB1(); } } // 具体工厂2 class ConcreteFactory2 implements AbstractFactory { public ProductA createProductA() { return new ProductA2(); } public ProductB createProductB() { return new ProductB2(); } } 最后，使用抽象工厂模式：\npublic class AbstractFactoryDemo { public static void main(String[] args) { AbstractFactory factory1 = new ConcreteFactory1(); ProductA productA1 = factory1.createProductA(); ProductB productB1 = factory1.createProductB(); productA1.use(); productB1.use(); AbstractFactory factory2 = new ConcreteFactory2(); ProductA productA2 = factory2.createProductA(); ProductB productB2 = factory2.createProductB(); productA2.use(); productB2.use(); } } 这个示例中，AbstractFactory接口定义了创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。ConcreteFactory1和ConcreteFactory2是具体实现这个接口的工厂类，它们分别生产一套具有不同实现的产品（ProductA1和ProductB1，ProductA2和ProductB2）。通过使用不同的工厂实例，客户端可以创建不同风格的产品，而不需要知道具体的实现细节。\n更加详细的代码\n与工厂模式的区别 # Generated by Gemini 1.5-flash\n工厂 # 核心思想: 提供一个创建对象的接口，但由子类决定实例化哪个类。 特点: 简单直接，适合创建单一类型的对象。 结构: 通常包含一个抽象工厂类（接口）和多个具体工厂类，每个具体工厂类负责创建特定类型对象的实例。 抽象工厂 # 核心思想: 提供一个创建一系列相关或依赖对象的接口，但无需指定具体类。 特点: 更灵活，适合创建多个相关对象，例如，一个工厂创建多个类型的产品。 结构: 包含一个抽象工厂类（接口）、多个具体工厂类和多个抽象产品类以及多个具体产品类。每个具体工厂类负责创建一组特定类型产品对象的实例。 区别总结 # 特性 工厂模式 抽象工厂模式 核心目的 创建单一类型的对象 创建多个相关或依赖对象的系列 复杂程度 相对简单 相对复杂 灵活性 较低 较高 应用场景 创建单一类型的对象时 需要创建多个相关或依赖对象的系列时 实例 创建汽车时，工厂模式可以创建一辆汽车 创建汽车时，抽象工厂模式可以创建一辆汽车和一个发动机 简单来说，工厂模式就像一个简单的工具，只负责生产一种特定类型的产品；而抽象工厂模式就像一个完整的生产线，可以生产多种相关产品的系列。\n一些补充的话\n所有的工厂都是用封装来创建对象。 工厂方法使用继承：把对象的创建委托给子类，子类实现工厂方法来创建对象。 抽象工厂使用对象组合：对象的创建被实现在工厂接口所暴露的方法中。 所有工厂模式通过减少应用程序和具体类之间的依赖，而促进松耦合。 工厂方法允许将类的实例化延迟到子类进行。 抽象工厂创建相关的对象家族，而不需要依赖它的具体类。 "},{"id":34,"href":"/zh/docs/craft/algo/%E5%BC%82%E6%88%96%E8%BF%90%E7%AE%97/","title":"异或运算","section":"算法讨论","content":"异或运算(exclusive or)又记作XOR，一般用插入符号(caret)^表示，其可以看到是更加单纯的或运算(|)。我们知道，或运算的规则是：\na=1，b=1，a|b=1 ① a，b任意一个为1，a|b=1 ② 异或运算则是去除了或运算中的规则①，即只有a、b相异时，结果才为真，其他情形都为假。因此异或运算的真值表为：\n0^0 = 0 0^1 = 1 1^0 = 1 1^1 = 0 与0异或，其值不变；与1异或，相当于取反。\n异或运算有一些特殊的性质，利用这些性质，可以解决特定的问题。这也是本文所要讨论的重点。\n1. 异或运算的性质 # 交换律： A^B = B^A 结合律： (A^B)^C = A^(B^C) 对于任意数A，都有A^A=0，A^0=A 自反性：A^B^B = A 其中，自反性尤其重要。其内涵为，对于任意数A，给定任意运算因子B，做偶数次异或运算后，得到A本身。异或运算的很多应用，都是基于自反性。\n2. 异或运算的典型应用 # 2.1 交换2个数 # 一般地，如果想交换2个数，我们会引入一个中间变量来完成这一操作。但是，利用异或运算，可以在不需要额外空间的情况下完成2个数的交换：\nvar a = 1 var b = 2 // swap a = a^b b = b^a // b^a^b = a a = a^b // a^b^b^a^b = b println(\u0026#34;a=$a, b=$b\u0026#34;) // a = 2, b=1 在kotlin中，交换2个数可以这样实现：\nvar a = 1 var b = 2 a = b.also { b = a} 2.2 经典面试题 # 找出唯一数 # 在一个整数数组中，仅存在唯一一个不重复的数字，其他的数字均出现2次或2次以上（偶数次），找出那个不重复的数字。\n如果熟悉异或运算的自反性，阅读题干就能自然联想到，使用异或运算能够快速求解：\n设唯一元素为N，那么 A^B^C^...N^D^E^F... 由于除了N外，A、B、C、D、E、F都出现偶数次，其异或运算结果为0，故原式即为 N^0 当然，此题还有其他解法，如典型的使用嵌套循环，即可找出唯一数：\nfun solution(arr: IntArray): Int { for (j in arr) { var count = 0 for (k in arr) { if (j == k) count++ } if (count == 1) return j } return -1 } 找出重复数 # 将1-999放在一个容量为1000的集合中，只有1个元素重复，其他的元素均只出现1次，找出这个重复的元素。\n在数据不溢出的情况下，此题可通过所有元素和轻松解出。不过，我们讨论的是使用异或运算的性质来解题。\n记重复数为N， 设 1^2^3^...^(N-1)^N^N^(N+1)^...^997^998^999 = T 则 1^2^3^...^(N-1)^N^(N+1)^...^997^998^999 = T^N 故 N = T^T^N 上述题还有一相关变体：\n一个数组包含 n-1 个成员，这些成员是 1 到 n 之间的整数，且没有重复，请找出缺少的那个数字。\n同样地，对集合中的元素和1-n的有序序列数做异或运算，既可得到缺少的那个值（只出现一次）。\n2.3 加解密 # 若有明文A以及密钥K，那么密文S可以由\nA^K=S\n获得。同理，当需要解密时，可以使用\nS^K=A 获得明文。\n备份文件 # 若有A、B两个文件，只要A、B不同时损坏，即可以通过异或运算的备份T来恢复其中一个损坏的文件：\nA^B=T\n若文件A损坏，则可以通过\nT^B=A\n来恢复损坏的文件A。反之亦然。\n"},{"id":35,"href":"/zh/docs/craft/db/redis/deploy-redis-cluster-with-docker/","title":"使用docker镜像快速搭建redis集群开发环境","section":"redis","content":" 准备镜像 # docker以及docker-compose的安装以及加速镜像的配置不在此处说明。windows系统上直接安装客户端即可完成docker及docker-compose的安装。在centOS 8中安装docker服务以及docker-compose可以参考下面的文章：\n在centOS 8中安装docker 在contOS 8中安装docker-compose 运行如下命令检查docker和docker-compose的安装情况：\n[xx@CentOS8 ~]$ docker version Client: Docker Engine - Community Version: 20.10.17 API version: 1.41 Go version: go1.17.11 Git commit: 100c701 Built: Mon Jun 6 23:03:11 2022 OS/Arch: linux/amd64 Context: default Experimental: true Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running? [xx@CentOS8 ~]$ docker-compose version Docker Compose version v2.10.0 centOS 8 通过命令systemctl start docker来运行docker服务。\n本次搭建使用的redis 官方镜像，版本7.0.4:\ndocker pull redis:7.0.4 创建自定义docker网络模式 # docker network create redis-net --subnet 192.168.10.0/24 --gateway=192.168.10.1 --driver bridge 上述命令创建了一个桥接网络，使用192.168.10.0网段。\n创建桥接网络后，方便后续在编写docker-compose配置时，为每个redis节点指定ipv4_address。\n--subnet参数必须要指定，不指定的话，docker默认为其分配一个网段。但此时，docker-compose配置里便不能手动指定ipv4_address了。\n编写配置文件 # 为了搭建redis集群，我们需要运行6个redis服务端容器，组成一个最简单的3主3从的集群结构。我们需要自定义redis的配置（服务端口及映射ip）、持久化数据。因此，你需要在“合适的地方”新建一个文件夹，用于容器运行时候的 挂载目录。\n此次搭建我在centOS的家目录下新建了redis-cluster目录，作为容器运行的工作目录，目录结构如下：\n|-- redis-cluster |-- docker-compose.yml |-- redis-cluster.tmp # redis集群配置文件模板 |-- redis-6379 #节点1 |-- conf # 配置文件目录 |-- redis.conf # 配置文件 |--data # redis数据目录 |-- .... 以下省略... redis节点主要配置如下信息：\nport：节点端口； requirepass：添加访问认证； masterauth：如果主节点开启了访问认证，从节点访问主节点需要认证； protected-mode：保护模式，默认值 yes，即开启。开启保护模式以后，需配置 bind ip 或者设置访问密码；关闭保护模式，外部网络可以直接访问； daemonize：是否以守护线程的方式启动（后台启动），默认 no； appendonly：是否开启 AOF 持久化模式，默认 no； cluster-enabled：是否开启集群模式，默认 no； cluster-config-file：集群节点信息文件； cluster-node-timeout：集群节点连接超时时间； cluster-announce-ip：集群节点 IP，填写宿主机的 IP（通过ifconfig获得），用于宿主机访问redis容器； cluster-announce-port：集群节点映射端口； cluster-announce-bus-port：集群节点总线端口，redis集群节点端口+10000。 可以使用shell命令快速创建节点的配置文件及目录结构，为此，我们需要一个redis.conf的模板文件redis-cluster.tmp，内容如下：\nport ${PORT} cluster-enabled yes cluster-config-file node-${PORT}.conf cluster-node-timeout 5000 appendonly yes daemonize no protected-mode no requirepass 123456 masterauth 123456 pidfile /var/run/redis-${PORT}.pid cluster-announce-ip 10.211.55.3 cluster-announce-port ${PORT} cluster-announce-bus-port 1${PORT} 随即可以通过shell命令，快速创建上述目录结构及配置文件(当前工作目录为redis-cluster)：\nfor port in `seq 6379 6384`; do \\ mkdir -p redis-${port}/conf \\ \u0026amp;\u0026amp; PORT=${port} envsubst \u0026lt; redis-cluster.tmp\u0026gt; redis-${port}/conf/redis.conf \\ \u0026amp;\u0026amp; mkdir -p redis-${port}/data;\\ done 编写docker-compose脚本 # 使用docker-compose脚本是YAML风格，可以替代docker run命令，通过配置文件之间启动容器，并且可以更加直观、不易出错地配置容器使用的镜像、网络等内容。\n本次搭建的docker-compose.yml脚本内容如下：\nversion: \u0026#34;3.7\u0026#34; x-image: \u0026amp;default-image redis:7.0.4 networks: redis-net: name: redis-net services: redis-6379: image: *default-image container_name: redis-6379 volumes: - ./redis-6379/conf/redis.conf:/usr/local/etc/redis/redis.conf - ./redis-6379/data:/data ports: - 6379:6379 - 16379:16379 command: redis-server /usr/local/etc/redis/redis.conf networks: redis-net: ipv4_address: 192.168.10.9 redis-6380: image: *default-image container_name: redis-6380 volumes: - ./redis-6380/conf/redis.conf:/usr/local/etc/redis/redis.conf - ./redis-6380/data:/data ports: - 6380:6380 - 16380:16380 command: redis-server /usr/local/etc/redis/redis.conf networks: redis-net: ipv4_address: 192.168.10.10 redis-6381: image: *default-image container_name: redis-6381 volumes: - ./redis-6381/conf/redis.conf:/usr/local/etc/redis/redis.conf - ./redis-6381/data:/data ports: - 6381:6381 - 16381:16381 command: redis-server /usr/local/etc/redis/redis.conf networks: redis-net: ipv4_address: 192.168.10.11 redis-6382: image: *default-image container_name: redis-6382 volumes: - ./redis-6382/conf/redis.conf:/usr/local/etc/redis/redis.conf - ./redis-6382/data:/data ports: - 6382:6382 - 16382:16382 command: redis-server /usr/local/etc/redis/redis.conf networks: redis-net: ipv4_address: 192.168.10.12 redis-6383: image: *default-image container_name: redis-6383 volumes: - ./redis-6383/conf/redis.conf:/usr/local/etc/redis/redis.conf - ./redis-6383/data:/data ports: - 6383:6383 - 16383:16383 command: redis-server /usr/local/etc/redis/redis.conf networks: redis-net: ipv4_address: 192.168.10.13 redis-6384: image: *default-image container_name: redis-6384 volumes: - ./redis-6384/conf/redis.conf:/usr/local/etc/redis/redis.conf - ./redis-6384/data:/data ports: - 6384:6384 - 16384:16384 command: redis-server /usr/local/etc/redis/redis.conf networks: redis-net: ipv4_address: 192.168.10.16 运行脚本并创建集群 # 以上工作完成之后，便可以通过docker-compose运行容器。\ndocker-compose up -d -d参数指示后台运行。\n若脚本运行无误，即可看到docker已经成功运行6个redis容器，但是此时集群还没有搭建起来。\n可以通过docker container ls查看正在运行的容器。\n可以通过docker network inspect redis-net查看在文章开头创建的网络信息：\n[xx@centOS8 ~]$ docker network inspect redis-net [ { \u0026#34;Name\u0026#34;: \u0026#34;redis-net\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;0a1f6b466e5af068f42f64968ba39b0b6bf08df972b913d1f7060128b015c10f\u0026#34;, \u0026#34;Created\u0026#34;: \u0026#34;2022-08-26T09:51:21.510880934+08:00\u0026#34;, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;bridge\u0026#34;, \u0026#34;EnableIPv6\u0026#34;: false, \u0026#34;IPAM\u0026#34;: { \u0026#34;Driver\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;Options\u0026#34;: {}, \u0026#34;Config\u0026#34;: [ { \u0026#34;Subnet\u0026#34;: \u0026#34;192.168.10.0/24\u0026#34;, \u0026#34;Gateway\u0026#34;: \u0026#34;192.168.10.1\u0026#34; } ] }, \u0026#34;Internal\u0026#34;: false, \u0026#34;Attachable\u0026#34;: false, \u0026#34;Ingress\u0026#34;: false, \u0026#34;ConfigFrom\u0026#34;: { \u0026#34;Network\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;ConfigOnly\u0026#34;: false, \u0026#34;Containers\u0026#34;: { \u0026#34;1c89a8b2e1eaf33f4664873b726bdbfce3ebdc9ae4bbdb3e3326db8f3501f57e\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;redis-6383\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;3f4ad0bec008b14f6799bb341651f18846f5ae468d80296c265424f708079f32\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:c0:a8:0a:0d\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;192.168.10.13/24\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;2a259630bb33d10b274d4ab1a1f50850c445bb299dbbbde55710ae59bc578f68\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;redis-6379\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;2f57c1a336d8a08606eb9f0d1077da2cdc8e6744a147040b840c78a42ebdc2a3\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:c0:a8:0a:09\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;192.168.10.9/24\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;7ace535271e764554e08c4528a713657002c543f30f183454410f7d4b9e92d9d\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;redis-6381\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;89507334eef9eb9a907b6f5edeca8aee01fcace9982dc41a1e620c8c0d41113c\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:c0:a8:0a:0b\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;192.168.10.11/24\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;a0f6dc1fe2520f43ad3babdac39b782be7b277bc368138d65593e2bf3a04214c\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;redis-6380\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;1b0320a540085673eebda450036d386e50eb168d7221e09471bed1074fb685d2\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:c0:a8:0a:0a\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;192.168.10.10/24\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;a2308807a6502efce0a3e316df5c1a261e529b81613d29ef52a045e17eb87b13\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;redis-6384\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;fab8518518d19e2308eaa309aef8665e708ffa0e37a2e5ba9200a620b04e7108\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:c0:a8:0a:10\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;192.168.10.16/24\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;a42b71abb59b5267dcf77bf592afbe2fefa89191348a796b9b44e08fdf239a49\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;redis-6382\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;15755c329085da197f7afc5c5e0fbe8ecd1e9cd8fabc83fd3918d82653f7112b\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:c0:a8:0a:0c\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;192.168.10.12/24\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; } }, \u0026#34;Options\u0026#34;: {}, \u0026#34;Labels\u0026#34;: {} } ] 可以看到，返回的container域列出了刚才运行脚本所创建的容器的详细信息。说明，docker-compose的网络配置生效了。\n剩下来的工作就是创建集群了。\n运行命令docker exec -it redis-6379 /usr/local/bin/redis-cli -c -h redis-6380 -p 6380 -a 123456来查看redis以及集群的状态：\n[xx@centOS8 ~]$ docker exec -it redis-6379 /usr/local/bin/redis-cli -c -h redis-6380 -p 6380 -a 123456 set foo bar Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. (error) CLUSTERDOWN Hash slot not served [xx@centOS8 ~]$ 上述命令说明几点信息：\n通过6379实例连接6380实例成功，说明基于之前的网络配置，redis容器之间可以通过容器名相互连接（当然，也可以使用配置的ip地址）； set foo bar命令失败，错误信息显示，集群的槽并没有分配成功 更直观地，可以通过docker exec -it redis-6379 /usr/local/bin/redis-cli -a 123456 --cluster check redis-6379:6379检查集群信息：\n[xx@CentOS8 ~]$ docker exec -it redis-6379 /usr/local/bin/redis-cli -a 123456 --cluster check redis-6379:6379 Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. redis-6379:6379 (6466d336...) -\u0026gt; 0 keys | 0 slots | 0 slaves. [OK] 0 keys in 1 masters. 0.00 keys per slot on average. \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node redis-6379:6379) M: 6466d33686f7c629d70d19ad31fe5d77ec3a6879 redis-6379:6379 slots: (0 slots) master [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [ERR] Not all 16384 slots are covered by nodes. 说明，集群确实还没成功搭建。\n接下来，我们通过redis-cli --cluster create命令创建集群。\n使用docker exec -it redis-6379 bash进入6379节点，其中，redis-6379可以替换成本次搭建中任何其他节点。\n执行命令：\nredis-cli -a 123456 --cluster create \\ 192.168.10.9:6379 192.168.10.10:6380 192.168.10.11:6381 \\ 192.168.10.12:6382 192.168.10.13:6383 192.168.10.14:6384 \\ --cluster-replicas 1 其中指明了6个节点，并且--cluster-replicas 1说明为一主一从的结构，6个节点构成了3主3从的集群架构。\n上述命令将产生如下输出：\nWarning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. \u0026gt;\u0026gt;\u0026gt; Performing hash slots allocation on 6 nodes... Master[0] -\u0026gt; Slots 0 - 5460 Master[1] -\u0026gt; Slots 5461 - 10922 Master[2] -\u0026gt; Slots 10923 - 16383 Adding replica 192.168.10.12:6382 to 192.168.10.9:6379 Adding replica 192.168.10.13:6383 to 192.168.10.10:6380 Adding replica 192.168.10.14:6384 to 192.168.10.11:6381 M: 6466d33686f7c629d70d19ad31fe5d77ec3a6879 192.168.10.9:6379 slots:[0-5460] (5461 slots) master M: f8bc3dcb0ea4a93733d16c18eba7a92cee8d4a8f 192.168.10.10:6380 slots:[5461-10922] (5462 slots) master M: 0321e838b8b9a179612d2c3fa21ff544723598b6 192.168.10.11:6381 slots:[10923-16383] (5461 slots) master S: 5ec421c294038ff745c0b637bbe426d182ad32cc 192.168.10.12:6382 replicates 6466d33686f7c629d70d19ad31fe5d77ec3a6879 S: 84fbb314009f34ad8a1a2ca19746dc31866d009f 192.168.10.13:6383 replicates f8bc3dcb0ea4a93733d16c18eba7a92cee8d4a8f S: c124a8eaafd919015ab618edf8441a7b925d8a2f 192.168.10.14:6384 replicates 0321e838b8b9a179612d2c3fa21ff544723598b6 Can I set the above configuration? (type \u0026#39;yes\u0026#39; to accept): yes \u0026gt;\u0026gt;\u0026gt; Nodes configuration updated \u0026gt;\u0026gt;\u0026gt; Assign a different config epoch to each node \u0026gt;\u0026gt;\u0026gt; Sending CLUSTER MEET messages to join the cluster Waiting for the cluster to join .. \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node 192.168.10.9:6379) M: 6466d33686f7c629d70d19ad31fe5d77ec3a6879 192.168.10.9:6379 slots:[0-5460] (5461 slots) master 1 additional replica(s) S: c124a8eaafd919015ab618edf8441a7b925d8a2f 10.211.55.3:6384 slots: (0 slots) slave replicates 0321e838b8b9a179612d2c3fa21ff544723598b6 M: 0321e838b8b9a179612d2c3fa21ff544723598b6 10.211.55.3:6381 slots:[10923-16383] (5461 slots) master 1 additional replica(s) S: 84fbb314009f34ad8a1a2ca19746dc31866d009f 10.211.55.3:6383 slots: (0 slots) slave replicates f8bc3dcb0ea4a93733d16c18eba7a92cee8d4a8f S: 5ec421c294038ff745c0b637bbe426d182ad32cc 10.211.55.3:6382 slots: (0 slots) slave replicates 6466d33686f7c629d70d19ad31fe5d77ec3a6879 M: f8bc3dcb0ea4a93733d16c18eba7a92cee8d4a8f 10.211.55.3:6380 slots:[5461-10922] (5462 slots) master 1 additional replica(s) [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [OK] All 16384 slots covered. 从上述输出可以看到，6379、6380、6381为3个主节点，6382、6383、6384分别设置为它们的从节点。\n集群的16384个槽被分配到6379、6380和6381三个主节点上。\n至此，集群的搭建工作大抵完成了，还需要做一些验证工作。\n验证集群可用性 # 运行docker exec -it redis-6379 /usr/local/bin/redis-cli --cluster check redis-6379:6379 -a 123456查看集群信息：\n[xx@CentOS8 ~]$ docker exec -it redis-6379 /usr/local/bin/redis-cli --cluster check redis-6379:6379 -a 123456 Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. redis-6379:6379 (6466d336...) -\u0026gt; 0 keys | 5461 slots | 1 slaves. 10.211.55.3:6381 (0321e838...) -\u0026gt; 0 keys | 5461 slots | 1 slaves. 10.211.55.3:6380 (f8bc3dcb...) -\u0026gt; 0 keys | 5462 slots | 1 slaves. 10.211.55.3 为宿主机ip。\n运行docker exec -it redis-6379 /usr/local/bin/redis-cli -c -h redis-6379 -p 6379 -a 123456 cluster nodes查看集群节点信息：\n[xx@CentOS8 ~]$ docker exec -it redis-6379 /usr/local/bin/redis-cli -c -h redis-6379 -p 6379 -a 123456 cluster nodes Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. 6466d33686f7c629d70d19ad31fe5d77ec3a6879 10.211.55.3:6379@16379 myself,master - 0 1661484250000 1 connected 0-5460 c124a8eaafd919015ab618edf8441a7b925d8a2f 10.211.55.3:6384@16384 slave 0321e838b8b9a179612d2c3fa21ff544723598b6 0 1661484248833 3 connected 0321e838b8b9a179612d2c3fa21ff544723598b6 10.211.55.3:6381@16381 master - 0 1661484250857 3 connected 10923-16383 84fbb314009f34ad8a1a2ca19746dc31866d009f 10.211.55.3:6383@16383 slave f8bc3dcb0ea4a93733d16c18eba7a92cee8d4a8f 0 1661484250353 2 connected 5ec421c294038ff745c0b637bbe426d182ad32cc 10.211.55.3:6382@16382 slave 6466d33686f7c629d70d19ad31fe5d77ec3a6879 0 1661484249341 1 connected f8bc3dcb0ea4a93733d16c18eba7a92cee8d4a8f 10.211.55.3:6380@16380 master - 0 1661484249000 2 connected 5461-10922 分别运行\ndocker exec -it redis-6379 /usr/local/bin/redis-cli -c -h redis-6379 -p 6379 -a 123456 info replication\n和\ndocker exec -it redis-6379 /usr/local/bin/redis-cli -c -h redis-6382 -p 6382 -a 123456 info replication\n查看单个节点的信息：\n[xx@CentOS8 ~]$ docker exec -it redis-6379 /usr/local/bin/redis-cli -c -h redis-6379 -p 6379 -a 123456 info replication Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. # Replication role:master connected_slaves:1 slave0:ip=192.168.10.1,port=6382,state=online,offset=2520,lag=1 master_failover_state:no-failover master_replid:75b44c0a227fa29a6faf0be53aba63a47e615fa0 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:2534 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:2534 [xx@CentOS8 ~]$ docker exec -it redis-6379 /usr/local/bin/redis-cli -c -h redis-6382 -p 6382 -a 123456 info replication Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. # Replication role:slave master_host:10.211.55.3 master_port:6379 master_link_status:up master_last_io_seconds_ago:7 master_sync_in_progress:0 slave_read_repl_offset:2814 slave_repl_offset:2814 slave_priority:100 slave_read_only:1 replica_announced:1 connected_slaves:0 master_failover_state:no-failover master_replid:75b44c0a227fa29a6faf0be53aba63a47e615fa0 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:2814 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:2814 接下来，进入某个节点，进行一些简单的读写操作，\n[xx@CentOS8 ~]$ docker exec -it redis-6382 bash root@e7c5c96e43c3:/data# redis-cli -c -p 6382 -a 123456 Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. 127.0.0.1:6382\u0026gt; setex foo 1000 bar -\u0026gt; Redirected to slot [12182] located at 10.211.55.3:6381 OK 10.211.55.3:6381\u0026gt; setex hello 1000 redis -\u0026gt; Redirected to slot [866] located at 10.211.55.3:6379 OK 10.211.55.3:6379\u0026gt; set hey 1000 you -\u0026gt; Redirected to slot [10667] located at 10.211.55.3:6380 (error) ERR syntax error 10.211.55.3:6380\u0026gt; setex hey 1000 you OK 10.211.55.3:6380\u0026gt; get foo -\u0026gt; Redirected to slot [12182] located at 10.211.55.3:6381 \u0026#34;bar\u0026#34; 10.211.55.3:6381\u0026gt; ttl foo (integer) 938 10.211.55.3:6381\u0026gt; keys * 1) \u0026#34;foo\u0026#34; 10.211.55.3:6381\u0026gt; get hello -\u0026gt; Redirected to slot [866] located at 10.211.55.3:6379 \u0026#34;redis\u0026#34; 10.211.55.3:6379\u0026gt; keys * 1) \u0026#34;hello\u0026#34; 10.211.55.3:6379\u0026gt; 提示：redis-cli -c中-c参数指示使用集群模式，上述交互日志可以看出，集群基本上是可用的。\n接下来，我们模拟一个主节点下线，看看集群是否能够作出响应。前面说过，6379\u0026ndash;\u0026gt;6382、6380\u0026ndash;\u0026gt;6383、6381\u0026ndash;\u0026gt;6384分别为3对主从节点，此时强制停止6380节点：\ndocker container stop redis-6380\n接下来，使用docker exec -it redis-6379 /usr/local/bin/redis-cli -c -h redis-6379 -p 6379 -a 123456 cluster nodes查看节点信息：\n[xx@CentOS8 ~]$ docker exec -it redis-6379 /usr/local/bin/redis-cli -c -h redis-6379 -p 6379 -a 123456 cluster nodes Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. 6466d33686f7c629d70d19ad31fe5d77ec3a6879 10.211.55.3:6379@16379 myself,master - 0 1661486336000 1 connected 0-5460 c124a8eaafd919015ab618edf8441a7b925d8a2f 10.211.55.3:6384@16384 slave 0321e838b8b9a179612d2c3fa21ff544723598b6 0 1661486336865 3 connected 0321e838b8b9a179612d2c3fa21ff544723598b6 10.211.55.3:6381@16381 master - 0 1661486335556 3 connected 10923-16383 84fbb314009f34ad8a1a2ca19746dc31866d009f 10.211.55.3:6383@16383 master - 0 1661486335556 7 connected 5461-10922 5ec421c294038ff745c0b637bbe426d182ad32cc 10.211.55.3:6382@16382 slave 6466d33686f7c629d70d19ad31fe5d77ec3a6879 0 1661486336000 1 connected f8bc3dcb0ea4a93733d16c18eba7a92cee8d4a8f 10.211.55.3:6380@16380 master,fail - 1661486269058 1661486267032 2 disconnected 可以看到，6380节点的状态为fail，并且，其从节点6383升级为主节点了，集群状态正常。\n[parallels@CentOS8 redis-cluster]$ docker exec -it redis-6382 bash root@e7c5c96e43c3:/data# redis-cli -c -h redis-6383 -p 6383 -a 123456 Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. redis-6383:6383\u0026gt; info replication # Replication role:master connected_slaves:0 master_failover_state:no-failover master_replid:7c94538adb23f4c95ea6085af34ca40a6c20ca00 master_replid2:b6f2d9ac88cd6b4cdb097464ec271a1b96647ed2 master_repl_offset:5328 second_repl_offset:5329 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:5328 redis-6383:6383\u0026gt; keys * (empty array) redis-6383:6383\u0026gt; windows WSL主从同步失败的处理办法 # 在windosw上，按照上文思路搭建redis集群的过程中，可能会遇到主从节点同步失败的错误，具体错误信息为：\nFailed trying to load the MASTER synchronization DB from disk: No such file or directory 在这之前，通过docker-compose启动容器的过程中，还可以看到一句警告信息：\nWARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add \u0026#39;vm.overcommit_memory = 1\u0026#39; to /etc/sysctl.conf and then reboot or run the command \u0026#39;sysctl vm.overcommit_memory=1\u0026#39; for this to take effect. 先处理这个警告。由于windows下docker使用WSL，所以这个配置和WSL有关，在C:\\Users\\\u0026lt;username\u0026gt;下创建.wslconfig文件，写入以下内容：\n[wsl2] kernelCommandLine = \u0026#34;sysctl.vm.overcommit_memory=1\u0026#34; 然后重启wsl和docker：\nwsl --shtdown 此时，docker的启动警告应该消失了。\n接着，在所有节点的配置文件中，增加一行配置：\nrepl-diskless-load on-empty-db # Use diskless load only when it is completely safe. 此时重新启动所有节点，即可。\n本文完\n参考 # 使用Docker部署Redis集群-三主三从 docker安装redis cluster集群 Docker实战-部署「Redis集群」 bitnami/redis-cluster 处理windows WSL主从同步失败 "},{"id":36,"href":"/zh/docs/java/spring/%E5%9C%A8SpringBoot%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%BD%BF%E7%94%A8MockMvc%E8%BF%9B%E8%A1%8C%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95/","title":"在SpringBoot项目中使用MockMvc进行接口测试","section":"Spring","content":"现在流行在项目中使用 swagger对接口进行测试，这确实很方便、直观。\n但是MockMvc作为spring-test包中指定的测试框架，在没有使用swagger的项目中，使用其进行测试是很好的选择。\n本文简单介绍在springboot项目中使用 Mockito和 MockMvc对控制器进行测试。\n1 了解Mockito # 简单来说， Mockito是一个模拟创建对象的框架，利用它提供的API，可以简化单元测试工作。Mockito的API易读性是很好的，并且错误信息也很简明。spring-boot-starter-test模块中引入了mockito依赖，如果你使用springboot，那么就可以直接使用Mockito进行单元测试。\n我们从Mockito 官方API文档的的引例开始，看看Mockito是如何工作的。\n1.1 mock一个对象 # // 学会使用静态导入，代码会更简洁 import static org.mockito.Mockito.*; // mock List接口对象 List mockedList = mock(List.class); // 使用Mock的List对象 mockedList.add(\u0026#34;one\u0026#34;); mockedList.clear(); // 校验某个行为是否发生过1次 verify(mockedList).add(\u0026#34;one\u0026#34;); verify(mockedList).clear(); 一旦mock对象被创建，mock会记住对其的所有操作，之后，你便可以选择性的校验这些操作。\n1.2 绑定方法参数和返回值 # // 也可以mock实体类对象 LinkedList mockedList = mock(LinkedList.class); // 为指定参数的操作绑定返回值（stubbing） when(mockedList.get(0)).thenReturn(\u0026#34;first\u0026#34;); when(mockedList.get(1)).thenThrow(new RuntimeException()); // 打印 first System.out.println(mockedList.get(0)); // 抛出 RunTimeException System.out.println(mockedList.get(1)); // 打印null，因为get(999)的返回值没有指定 System.out.println(mockedList.get(999)); // 尽管也可以对绑定操作进行校验，不过这通常是非必要的 // 如果你关注get(0)的返回值，那么你应该在代码里进行测试 // 如果get(0)的返回值无关紧要，那么就没有必要进行绑定 verify(mockedList).get(0); 一般来说，对于任意有返回值的方法，mockito都会返回null、原始类型/原始类型的包装类、或者一个空的集合。\n返回值的绑定操作可以被覆盖。\n// 返回值的绑定可以连续设置 // 最后一次绑定就是实际调用的返回值 // 例如，mock.someMethod(\u0026#34;some arg\u0026#34;)将返回“foo” when(mock.someMethod(\u0026#34;some arg\u0026#34;)) .thenThrow(new RuntimeException()) .thenReturn(\u0026#34;foo\u0026#34;); // 连续绑定的简单形式： when(mock.someMethod(\u0026#34;some arg\u0026#34;)) .thenReturn(\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;); // 等价于： when(mock.someMethod(\u0026#34;some arg\u0026#34;)) .thenReturn(\u0026#34;one\u0026#34;) .thenReturn(\u0026#34;two\u0026#34;); // 抛出异常的简单形式： when(mock.someMethod(\u0026#34;some arg\u0026#34;)) .thenThrow(new RuntimeException(), new NullPointerException()); 一旦方法的返回值被绑定，那么其将一直返回绑定的值，无论其被调用多少次。\n1.3 参数匹配器 # 上面形式的返回值绑定在测试时似乎很好用，我们构建参数，设置预期的返回结果，再进行校验即可。但仔细想想，或许少了点什么？对，少了参数的模糊匹配，比如我想绑定get(int)方法的返回值，无论其参数是多少。mockito自然能够为我们做到这些：\n// 使用mockito内建的anyInt()来进行匹配 when(mockedList.get(anyInt())).thenReturn(\u0026#34;element\u0026#34;); //stubbing using custom matcher (let\u0026#39;s say isValid() returns your own matcher implementation): // 使用自定义matcher进行绑定 when(mockedList.contains(argThat(isValid()))).thenReturn(true); //following prints \u0026#34;element\u0026#34; // 打印999 System.out.println(mockedList.get(999)); // 也可以校验方法被调用了一次 verify(mockedList).get(anyInt()); // mockito同样支持java8的lambda表达式进行参数匹配 verify(mockedList).add(argThat(someString -\u0026gt; someString.length() \u0026gt; 5)); 参数匹配可以方便地进行动态返回值绑定校验。\n想了解更多关于 argument matcher和hamcrest matcher的内容，可参考：\nhttps://javadoc.io/static/org.mockito/mockito-core/3.8.0/org/mockito/ArgumentMatchers.html https://javadoc.io/static/org.mockito/mockito-core/3.8.0/org/mockito/hamcrest/MockitoHamcrest.html 除了使用matcher之外，mockito还支持使用类型（class）匹配，这种参数匹配方式在进行MVC测试时，对json参数进行序列化和反序列化时尤其有用：\nwhen(spittleService.pageQuerySpittlesByTimeLine(any(SpittleDTO.class))).thenReturn(page); ResultActions resultActions = mockMvc .perform(MockMvcRequestBuilders.post(\u0026#34;/spittle/range/spittles\u0026#34;) .contentType(MediaType.APPLICATION_JSON) .content(jsonString) ); 就像上面那样，在使用RequestBody传参时，若使用JSON，需要对json字符串进行反序列化。这种情形，在进行参数绑定时，自然不能使用\nwhen(spittleService.pageQuerySpittlesByTimeLine(spittleDTO).thenReturn(page); 这样的形式，因为控制器接收到的必然不是这个指定的spittleDTO对象。使用类类型参数，mockito进行参数匹配时，使用equals方法比较的对象的相等性，因此可以获取绑定的返回值。\nSometimes its just better to refactor the code to allow equals() matching or even implement equals() method to help out with testing.\n1.4 检验方法被调用的次数 # 前文我们提到，verify()方法可以校验指定方法被调用过一次。\nmokito提供了更加灵活的校验API，可以用来检验指定方法被调用的次数：\n//using mock mockedList.add(\u0026#34;once\u0026#34;); mockedList.add(\u0026#34;twice\u0026#34;); mockedList.add(\u0026#34;twice\u0026#34;); mockedList.add(\u0026#34;three times\u0026#34;); mockedList.add(\u0026#34;three times\u0026#34;); mockedList.add(\u0026#34;three times\u0026#34;); // 当verify方法不指定次数时，默认检验方法调用1次，以下2个调用是等价的 verify(mockedList).add(\u0026#34;once\u0026#34;); verify(mockedList, times(1)).add(\u0026#34;once\u0026#34;); // add(\u0026#34;twice)被调用了2次 verify(mockedList, times(2)).add(\u0026#34;twice\u0026#34;); // add(\u0026#34;three times\u0026#34;)被调用了3次 verify(mockedList, times(3)).add(\u0026#34;three times\u0026#34;); // add(\u0026#34;never happened\u0026#34;)方法没有被调用 // 等价于 times(0) verify(mockedList, never()).add(\u0026#34;never happened\u0026#34;); // 使用atLeast()/atMost()可以校验参数至少/至多被调用几次 verify(mockedList, atMostOnce()).add(\u0026#34;once\u0026#34;); verify(mockedList, atLeastOnce()).add(\u0026#34;three times\u0026#34;); verify(mockedList, atLeast(2)).add(\u0026#34;three times\u0026#34;); verify(mockedList, atMost(5)).add(\u0026#34;three times\u0026#34;); times(1)是默认，因此verify(mockedList, times(1)).add(\u0026quot;once\u0026quot;)这样的形式是不必要的。\n除了上面介绍的之外，moikito还有很多使用的测试方法，具体可以参考API文档：\nhttps://javadoc.io/doc/org.mockito/mockito-core/latest/org/mockito/Mockito.html#in_order_verification 2 使用MockMvc测试控制器 # 介绍了mockito的基本用法，可以开始用它测试控制器了。\nspring web项目的测试使用的是Spring MVC测试框架（Spring MVC Test framework(MockMvc)），其使用方式和Mockito很像，实际上MockMvc借用了Mockito的API，因此，熟悉Mockito的使用对使用MockMVC测试web服务大有裨益。\n2.1 熟悉这几个静态导入 # MockMvcBuilders.* MockMvcRequestBuilders.* MockMvcResultMatchers.* MockMvcResultHandlers.* 和Mockito一样，熟悉并使用静态导入会让代码看起来更简洁。不过，对刚使用MockMVC进行测试的新手来说，使用静态导入可能会陷入一个麻烦：方法这么多，我怎么记得这个方法该使用哪个静态导入，容易陷入混乱。\n不过，记住他们的惯用法就行了：\n// MockMvcBuilders.* 用于构建MockMvc应用 MockMvc mockMvc = MockMvcBuilders.stansaloneSetup(controller).build(); // MockMvcRequestBuilders.*用于构建请求 ResultActions resultActions = mockMvc.perform(MockMvcRequestBuilders.get(url)); ResultActions resultActions = mockMvc.perform(MockMvcRequestBuilders.post(url)); // MockMvcResultMatchers.*用于请求结果匹配 resultActions.andExpect(MockMvcResultMatchers.status().isOK()) // MockMvcResultHandlers.* 嘛，用得少，其提供一个print()方法，可以打印请求信息 resultActions.andDo(MockMvcResultHandlers.print()); 2.2 测试示例 # 在进行单元测试时，通常习惯将通用模版进行抽象，本示例中也是如此，我们建立一个抽象测试类，用于准备数据、提供通用方法等：\n@SpringBootTest @TestPropertySource(\u0026#34;classpath:application-test.properties\u0026#34;) public class BaseMockInit { // @Autowired // protected ObjectMapper objectMapper; protected ObjectMapper objectMapper = Jackson2ObjectMapperBuilder.json().build(); protected @Mock ISpitterService spitterService; protected @Mock ISpittleService spittleService; protected SpitterController spitterController; protected SpittleController spittleController; @BeforeEach void initMock() { MockitoAnnotations.initMocks(this); spitterController = new SpitterController(); spitterController.setSpitterService(spitterService); spittleController = new SpittleController(); spittleController.setSpittleService(spittleService); } } 你可能注意到上面的示例中使用的@Mock注解和MockitoAnnotations.initMocks(this);方法，实际作用就是mock web测试中所需要使用到的服务层service，因为测试web模块不涉及到数据服务层的业务，因此借助Mockito即可轻松创建测试所需要的实例。\n2.2.1 简单路径参数GET请求测试 # @Test public void getSpitterById() throws Exception { SpitterVO source = new SpitterVO(1, \u0026#34;alan\u0026#34;, \u0026#34;walker\u0026#34;, \u0026#34;aw\u0026#34;, \u0026#34;xxx\u0026#34;); Spitter spitter = new Spitter(); BeanUtils.copyBeanProp(spitter, source); when(spitterService.getById(1)).thenReturn(spitter); spitterController.setSpitterService(spitterService); MockMvc mockMvc = standaloneSetup(spitterController).build(); // perform get request with path variables ResultActions resultActions = mockMvc.perform(get(\u0026#34;/spitter/1\u0026#34;)); log.info(resultActions.andReturn().getResponse().getContentAsString(StandardCharsets.UTF_8)); resultActions.andExpect(status().isOk()) .andExpect(content().contentType(MediaType.APPLICATION_JSON)) .andExpect(jsonPath(\u0026#34;$.data\u0026#34;) .value(objectMapper.convertValue(spitter, HashMap.class))); verify(spitterService).getById(1); } 观察上面的测试用例，我们首先使用Mockito对数据层的mock对象进行了参数和返回值绑定，这在前文已经提及：\nwhen(spitterService.getById(1)).thenReturn(spitter); 随即使用MockMvc发起get请求，发起请求的方式有多种：\nResultActions resultActions = mockMvc.perform(get(\u0026#34;/spitter/1\u0026#34;)); // 等价于 ResultActions resultActions = mockMvc.perform(get(\u0026#34;/spitter/{id}\u0026#34;, 1)); 当请求进入控制器时，根据控制器的业务逻辑，调用spitterService.getById(1)方法，该方法返回之前绑定的返回值，进行封装之后，返回web请求的结果。\n上述请求返回一个ResultActions结果，web请求的结果被封装在内，我们可以对这个结果进行校验：\nresultActions.andExpect(status().isOk()) .andExpect(content().contentType(MediaType.APPLICATION_JSON)) .andExpect(jsonPath(\u0026#34;$.data\u0026#34;) .value(objectMapper.convertValue(spitter, HashMap.class))); 注意到，jsonPath(\u0026quot;$.data\u0026quot;)，这意味着请求返回的json字串中包含一个data键，.value()操作暗示其对应的内容就是spitterService.getById(1)的返回对象。所以这个请求返回的json应该像这样：\n{ \u0026#34;code\u0026#34;: 200, \u0026#34;message\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;id\u0026#34;: 1, \u0026#34;usename\u0026#34;: \u0026#34;aw\u0026#34;, \u0026#34;firstname\u0026#34;: \u0026#34;alan\u0026#34;, \u0026#34;lastname\u0026#34;: \u0026#34;walker\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xxx\u0026#34; } } .andExpect(jsonPath(\u0026#34;$.data\u0026#34;).value(objectMapper.convertValue(spitter, HashMap.class))); 的意义是比较通过jsonPath(\u0026quot;$.data\u0026quot;)解析到的对象和objectMapper.convertValue(spitter, HashMap.class))获取到的对象的相等性。\n实际上，通过jsonPath(\u0026quot;$.data\u0026quot;)获取到的内容是一个LinkedHashMap，而.value()的相等性比较的是map中对应键的值的相等性，单单从这个示例来讲，这个比较是可行的1。\n最后，我们使用verify方法对mock对象的方法调用进行了测试：\nverify(spitterService).getById(1); 不过，由于我们已经校验了web接口的返回值，那么mock对象的方法一定被调用了，所以一般我们无需这么做。\n2.2.2 拼接参数的GET方法测试 # 除了路径参数，使用最多的就是形如?para1=xxx\u0026amp;para2=xxx这样的请求参数，MockMvc同样对这样的web服务提供测试支持\n@Test public void getUserSpittlesPageTest() throws Exception { // ... 省略准备数据 // 此处必须使用类类型作为参数 when(spittleService.pageQuerySpittleBySpitterId(any(SpittleDTO.class))).thenReturn(page); // perform get with request params transferred by pojo ResultActions resultActions = mockMvc .perform(get(\u0026#34;/spittle/user/spittles?spitterId={spitterId}\u0026#34;, 4)) // get element from json // see https://github.com/json-path/JsonPath .andExpect(jsonPath(\u0026#34;$.data.currentPage\u0026#34;) .value(pageDomain.getCurrentPage())) .andExpect(jsonPath(\u0026#34;$.data.pageSize\u0026#34;) .value(pageDomain.getPageSize())) .andExpect(jsonPath(\u0026#34;$.data.pages\u0026#34;) .value(pageDomain.getPages())) .andExpect(jsonPath(\u0026#34;$.data.total\u0026#34;) .value(pageDomain.getTotal())) .andDo(print()); /* 报错原因 ：long和integer的问题*/ // .andExpect(jsonPath(\u0026#34;$.data.records[0]\u0026#34;) // .value(objectMapper.convertValue(sample, HashMap.class))); String jsonResult = resultActions.andReturn().getResponse().getContentAsString(StandardCharsets.UTF_8); log.info(jsonResult); // verify is not necessary here verify(spittleService).pageQuerySpittleBySpitterId(any(SpittleDTO.class)); assertEquals((int) jsonPathParser(jsonResult).read(\u0026#34;$.data.records.length()\u0026#34;), 1); SpittleVO rvo = jsonPathParser(jsonResult).read(\u0026#34;$.data.records[0]\u0026#34;, SpittleVO.class); assertEquals(sample, rvo); } 这个测试和上一个测试有一些区别，首先第一个区别就是mock对象的参数与返回值绑定方式变了：\nwhen(spittleService.pageQuerySpittleBySpitterId(any(SpittleDTO.class))).thenReturn(page); 多数情况下，我们不会直接在控制器中使用具体的参数，而是使用Java Bean作为控制器的参数。这个时候，Spring MVC的MappingJasksonHttpMessageConverter将会发挥作用2，将请求中的中的参数转换为对应的Java Bean实例。\n这样一来，我们便不能指定某一个实例作为mock对象的参数了，只能使用any(class)这样的形式进行模糊匹配。\n其次，关于使用地址栏参数的参数传递，除了使用上述的方式（最简单）之外，还有其他的方式：\nResultActions resultActions = mockMvc.perform(get(\u0026#34;/spittle/user/spittles?spitterId={spitterId}\u0026#34;, 4)) // 等价于 ResultActions resultActions = mockMvc.perform(get(\u0026#34;/spittle/user\u0026#34;)).param(\u0026#34;spitterId\u0026#34;, 4) 第三，如果再次使用类似于 上一个示例那样校验返回数据的方法校验$.data.records[0]，将会得到一个错误。原因也和前文描述的一样。我们必须使用更为稳妥的方法。\n第四，对于同一个控制器的测试，我们可以预先做一些设置，比如依赖@BeforeEach注解，约定好一些通用的内容：\nclass MyWebTests { MockMvc mockMvc; @BeforeEach void init(){ mockMvc = standaloneSetup(spittleController) .alwaysExpect(status().isOk()) .alwaysExpect(content().contentType(MediaType.APPLICATION_JSON)) .build(); } } 上述方法在每一个测试之前准备mockMvc对象，并且约定了servlet的返回状态和返回类型。\n2.2.3 POST请求方法测试 # 如前所述，在发起POST请求时，一般使用JSON，此时MappingJasksonHttpMessageConverter便会介入。它负责将JSON对象反序列化为控制器指定的Java Baean。在使用MockMvc进行测试时，我们直接使用JSON字符串，将其设置在请求体中即可。\n@Test public void postSpittlesTimeLinePageTest() throws Exception { // ... 省略其他设置 dto.setLeftTime(LocalDateTime.parse(\u0026#34;2012-06-09T00:00:00.000\u0026#34;)); dto.setRightTime(LocalDateTime.parse(\u0026#34;2012-06-09T23:59:59.999\u0026#34;)); when(spittleService.pageQuerySpittlesByTimeLine(any(SpittleDTO.class))).thenReturn(page); // perform post request String s = objectMapper.writeValueAsString(dto); log.info(\u0026#34;request body: {}\u0026#34;, s); ResultActions resultActions = mockMvc .perform(post(\u0026#34;/spittle/range/spittles\u0026#34;) .contentType(MediaType.APPLICATION_JSON) .characterEncoding(\u0026#34;utf8\u0026#34;) .content(s)) .andDo(print()); // 以下用来获取MockMvc返回(Json) String jsonResult = resultActions.andReturn().getResponse().getContentAsString(StandardCharsets.UTF_8); log.info(jsonResult); PageDomain\u0026lt;SpittleVO\u0026gt; rpg = jsonPathParser(jsonResult).read(\u0026#34;$.data\u0026#34;, PageDomain.class); assertEquals((int) jsonPathParser(jsonResult).read(\u0026#34;$.data.records.length()\u0026#34;), 1); SpittleVO rvo = jsonPathParser(jsonResult).read(\u0026#34;$.data.records[0]\u0026#34;, SpittleVO.class); rpg.setRecords(new ArrayList\u0026lt;SpittleVO\u0026gt;() {{ add(rvo); }}); assertEquals(rpg, pageDomain); } 可以看到，发起POST请求的方式比较简单：\nResultActions resultActions = mockMvc .perform(post(\u0026#34;/spittle/range/spittles\u0026#34;) .contentType(MediaType.APPLICATION_JSON) .characterEncoding(\u0026#34;utf8\u0026#34;) .content(s)); 设置好请求头接受的文件类型和编码，使用content(json)方法传入json字符串即可。\n在本节的 开头，我们进行了一些通用的配置，你可能暂时还没有注意到这个细节：\n// @Autowired // protected ObjectMapper objectMapper; protected ObjectMapper objectMapper = Jackson2ObjectMapperBuilder.json().build(); 我们注释掉了spring自动装配的ObjectMapper，转而使用了Jackson2ObjectMapperBuilder构建了一个默认的ObjectMapper，这样做是有原因的：\n对于spring自动装配的ObjectMapper，我们在项目改变了其对LocalDateTime的序列化与反序列化规则：\n对于LocalDateTime，默认情况下其字符串输出格式类似于2012-06-09T23:59:59.999，这样的字符串形式非常不利于页面传递参数，因此我们在项目配置中改变了其规则，使得在实际使用时，能够将2012-06-09 23:59:59.999形式的日期字符串直接转化为LocalDateTime对象；反之，LocalDateTime也将会直接转化为2012-06-09 23:59:59.999的形式返回。\n但是在使用MockMvc进行测试时，其进行反序列化时（将请求JSON转化为Java Bean），使用的可能是默认的消息转换规则。而当我们使用自动装配的ObjectMapper将配置好的Bean转化为JSON时，时间的字符串形式是2012-06-09 23:59:59.999，默认的消息转换无法将其转化为LocaldateTime，因此会出现转换异常。\n关于ObjactMapper的详细内容，会在后续博客中详细介绍。\n3 JsonPath # 看到这里，你可能对使用Mockito和MockMvc进行测试有了初步的了解。不过如果你细心的话，就会发现，前面的测试用例对最后的接口的返回校验都没有提及。并且示例代码中关于提取返回内容出现最多的字就是jsonPath。\n并且在前面的测试用例中，我们也通过简单的表达式jsonPath(\u0026quot;$.data\u0026quot;)提取了返回JSON中的结果。\n实际上，Spring MockMvc默认是支持使用JsonPath获取返回内容的，就像jsonPath(\u0026quot;$.data\u0026quot;)那样，不过其灵活性没有直接使用JspnPath大，特别是在反序列化的操作上。\n很多时候，RESTful接口返回的内容实际上是Java Bean序列化之后的JSON串，所以我们希望将获取到的JSON反序列化之后再进行校验，而MockMvc在这方面表现的就比较蹩脚了，其只能转化为Map进行比较，就像 ###2.2.1节中表现的那样3。\n说实话，测试在获取到返回的JSON串，通过控制台打印输出确认符合预期基本上就可以结束，再去检验JSON的内容有点强迫症的意味了。\n其实在 JsonPath的仓库里详细地介绍了JsonPath的基本用法，针对本实例的具体情况，通过阅读文档，我们可以很容易取得想要的值并进行校验。\n{ \u0026#34;code\u0026#34;:20000, \u0026#34;msg\u0026#34;:\u0026#34;http.ok\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;currentPage\u0026#34;:1, \u0026#34;pageSize\u0026#34;:10, \u0026#34;total\u0026#34;:4, \u0026#34;pages\u0026#34;:1, \u0026#34;records\u0026#34;: [ { \u0026#34;id\u0026#34;:1, \u0026#34;spitterId\u0026#34;:4, \u0026#34;message\u0026#34;:\u0026#34;sixth man\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2012-06-09 22:20:00\u0026#34;, \u0026#34;latitude\u0026#34;:0.0, \u0026#34;longitude\u0026#34;:0.0 } ] } } 我们要校验的就是data中的内容，现在我们再回过头来看看上面的 测试代码，实际上很容易理解:\nPageDomain\u0026lt;SpittleVO\u0026gt; rpg = jsonPathParser(jsonResult).read(\u0026#34;$.data\u0026#34;, PageDomain.class); assertEquals((int) jsonPathParser(jsonResult).read(\u0026#34;$.data.records.length()\u0026#34;), 1); SpittleVO rvo = jsonPathParser(jsonResult).read(\u0026#34;$.data.records[0]\u0026#34;, SpittleVO.class); rpg.setRecords(new ArrayList\u0026lt;SpittleVO\u0026gt;() {{ add(rvo); }}); assertEquals(rpg, pageDomain); 首先我们获取了$.data节点的内容，里面也是一个Json对象，按照传统的反序列化理解，这是一个Java Bean，我们该如何将其读取为我们程序中的Bean呢，JsonPath也 作了说明\n默认情况下，通过JsonPath.parse(json).read(\u0026quot;$.data\u0026quot;)获取的到的是Map实例，并不会映射为Java Bean。不过JsonPath也为此提供了可能：\nIf you configure JsonPath to use JacksonMappingProvider or GsonMappingProvider you can even map your JsonPath output directly into POJO\u0026rsquo;s.\n要想映射为JavaBean，我们需要：\n自定义配置JsonProvider 传入类型参数 配置JsonProvider的方式也很简单：\n/** * Use json-path, tweaking configuration\u0026lt;br\u0026gt; * The config below change default action of json-path\u0026lt;br\u0026gt; * Use application-context ObjectMapper config as json and mapper provider\u0026lt;br\u0026gt; * \u0026lt;p\u0026gt; * Reference: \u0026lt;a href=\u0026#34;https://github.com/json-path/JsonPath\u0026#34;\u0026gt; * https://github.com/json-path/JsonPath\u0026lt;/a\u0026gt; * * @param json standard json string * @return {@link DocumentContext} */ protected DocumentContext jsonPathParser(String json) { final JsonProvider jsonProvider = new JacksonJsonProvider(objectMapper); final MappingProvider mappingProvider = new JacksonMappingProvider(objectMapper); Configuration.setDefaults(new Configuration.Defaults() { @Override public JsonProvider jsonProvider() { return jsonProvider; } @Override public Set\u0026lt;Option\u0026gt; options() { return EnumSet.noneOf(Option.class); } @Override public MappingProvider mappingProvider() { return mappingProvider; } }); return JsonPath.parse(json); } 此时，我们就已经获取到了接口返回的对象。不过等等，我们再仔细看看上面的Json，会发现$.data.records节点是一个数组，数组里面又是可以映射为Java Bean的Json。而经过上一步，获取的PageDomain对象中的records域实际上还是一个List\u0026lt;Map\u0026gt;的默认映射结果，所以我们还需要梅开二度。\n4 补充内容：使用idea直接进行RESTful接口测试 # 到这里，本文的主要内容就结束了。\n如果你使用的IDEA，你不妨找找tools-\u0026gt;httpClients，你会发现，idea的绝妙功能：其可以通过脚本文件测试rest接口。\nidea提供了不同HTTP请求的脚本示例，很容易就能上手，脚本文件以.http结尾，你可轻松创建自己的测试脚本。\n例如，我为上面的测试创建一个名为rest-api.http的脚本：\n### get spitter info by spitterId GET {{host}}/spitter/{{spitterId}}?lang={{lang}} Accept: application/json ### 分页获取spittle， 根据用户spitterId，请求参数放在GET请求体中的情形: GET {{host}}/spittle/user/spittles?lang={{lang}} Accept: application/json Content-Type: application/json { \u0026#34;spitterId\u0026#34;: 4, \u0026#34;currentPage\u0026#34;: 1, \u0026#34;pageSize\u0026#34;: 1 } ### 分页获取某个时间段的spittle 1 POST {{host}}/spittle/range/spittles?lang={{lang}} Content-Type: application/json { \u0026#34;leftTime\u0026#34;: \u0026#34;2012-06-09 00:00:00\u0026#34;, \u0026#34;rightTime\u0026#34;: \u0026#34;2012-06-09 23:59:59\u0026#34;, \u0026#34;currentPage\u0026#34;:2, \u0026#34;pageSize\u0026#34;: 1 } 可以看到，.http脚本文件的可读性非常强。其中，为了方便，还使用了用双花括号语法的环境变量，这些变量被命名在一个名为http-client-env.json的json文件中：\n{ \u0026#34;mem\u0026#34;: { \u0026#34;host\u0026#34;:\u0026#34;http://localhost:9000/mem\u0026#34;, \u0026#34;spitterId\u0026#34;: 4, \u0026#34;lang\u0026#34;: \u0026#34;en\u0026#34;, \u0026#34;currentPage\u0026#34;: 1, \u0026#34;pageSize\u0026#34;: 2 }, \u0026#34;mysql\u0026#34;:{ \u0026#34;host\u0026#34;: \u0026#34;http://localhost:9100/dev\u0026#34;, \u0026#34;spitterId\u0026#34;: 2, \u0026#34;lang\u0026#34;: \u0026#34;en\u0026#34; } } 运行脚本时，可以通过执行环境配置传入不同的测试参数，就这么简单。\n参考 # 本文用例所在项目地址：https://www.github.com/wangy325/mybatis-plus-starter mockito官网：https://www.site.mockito.org/ mockito API官网：https://www.javadoc.io/doc/org.mockito/mockito-core/latest/org/mockito/Mockito.html MockMvc java doc：https://www.docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/test/web/servlet/MockMvc.html json-path仓库介绍了其基本使用方法：https://www.github.com/json-path/JsonPath 可能出现的bug：https://www.stackoverflow.com/questions/47276920/mockito-error-however-there-was-exactly-1-interaction-with-this-mock MockMvc官方文档：https://www.docs.spring.io/spring-framework/docs/current/reference/html/testing.html#spring-mvc-test-framework MockMVC官方测试示例代码库：https://www.github.com/spring-projects/spring-framework/tree/master/spring-test/src/test/java/org/springframework/test/web/servlet/samples 这种形式的比较往往会出现问题，例如，如果pojo类中的id字段定义为Long型，使用objectMapper进行转换的时候可能会转换为Integer型。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n关于Spring MVC的消息转换器，参考《Spring实战，第4版》第16章相关内容。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n或许笔者还没有找到更加优雅的方法。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":37,"href":"/zh/docs/java/concurrency/2%E8%B5%84%E6%BA%90%E8%AE%BF%E9%97%AE%E5%8F%97%E9%99%90_1/","title":"资源访问受限--引论","section":"并发编程","content":"在 线程与任务文中，虽然创建了多线程，并且线程之间出现了一些不可预测的CPU调度，但是由于线程之间是相互隔离的——线程没有访问共同的资源，尽管在执行任务的过程可能被CPU剥夺运行权，但是当它们再次获得运行权时对运行结果并没有影响，它们是安全的。\n实际上，上篇文章通过join()方法演示了 一种安全访问共享资源的方法。\n考虑一种情况，如果多个线程访问同一资源，并对资源内容进行修改，会发生什么情况？\n对于非原子性操作，多线程下会出现竞争条件。例如，对于操作accounts[to] += amount，可以被拆分为多个CPU指令：\n加载accounts[to]到寄存器 增加amount 将结果写回acounts[to] 上述3个步骤中，线程执行到任一步骤时都可能被剥夺运行权。\n如此一来，最后的结果就变得不可预测。\n考虑一个经典的“转账”示例：\npublic class UnsynchronizedTransfer { public static void main(String[] args) { double INITIAL_MONEY = 1000; int ACCOUNTS = 100; Bank bank = new Bank(ACCOUNTS, INITIAL_MONEY); // 可以增加循环次数观察“出错”的概率提升 for (int i = 0; i \u0026lt; 2; i++) { // 多个线程使用同一个bank资源 Thread t = new Thread(new TransferTask(bank)); t.start(); } } static class TransferTask implements Runnable { private Bank bank; private int size; private double maxAmount = 1000; public TransferTask(Bank bank) { this.bank = bank; this.size = bank.size(); } @Override public void run() { try { int from = (int) (size * Math.random()); int to = (int) (size * Math.random()); double amount = maxAmount * Math.random(); bank.transfer(from, to, amount); Thread.sleep((long) (size * Math.random())); }catch (InterruptedException e){ // e.printStackTrace(); } } } static class Bank { private final double[] accounts; public Bank(int accountCount, double money) { // initialize bank account accounts = new double[accountCount]; Arrays.fill(accounts, money); } public void transfer(int from, int to, double amount) { if (accounts[from] \u0026lt; amount) return; if (from == to) return; // transfer accounts[from] -= amount; // 这句打印语句增加了调度器剥夺线程运行权的风险 System.out.println(Thread.currentThread() + \u0026#34; move away\u0026#34;); accounts[to] += amount; System.out.printf(\u0026#34;%s: %10.2f from %d to %d, Total Balance: %10.2f%n\u0026#34;, Thread.currentThread(), amount, from, to, totalBalance()); } private double totalBalance() { double sum = 0; for (double a : accounts) { sum += a; } return sum; } int size() { return accounts.length; } } } /* output（sample）: Thread[Thread-1,5,main] move away Thread[Thread-0,5,main] move away Thread[Thread-1,5,main]: 217.65 from 30 to 20, Total Balance: 99445.52 Thread[Thread-0,5,main]: 554.48 from 55 to 53, Total Balance: 100000.00 *///：～ 上例中，使用多个线程访问了Bank类的资源，在Bank类的transfer()方法中，额外增加了一句控制台输出，这是为了增加线程被调度的可能性1 （如果注释这句，会发现程序异常的概率会变小）。Bank类初始化时分配100个“账户”，每个账户1000元，然后不断转账，观察所有账户总额的变化。\n仔细观察输出（循环2次，出现的概率较小），我们看到:\n线程1在输出 move away 之后被剥夺运行权；\n接着线程0在 move away 之后也被剥夺运行权；\n线程1继续运行，此时问题就出现了，总金额不是100000：\n在计算总额时，线程1获取账户55的余额时少了554.48元，这正是第2步中线程0的accounts[from] -= amount将账户55的余额减少的金额。\n实际上CPU的调度过程比上述分析复杂得多，在Bank类的transfer()方法中，每一行代码在运行时都可能被剥夺运行权，值得一提的是，上例输出操作的还不是相同的“账户”，若是操作同样的“账户”，情况将变得更复杂。\n所以说线程不安全是一种不确定性，在有限的线程时，它可能发生也可能不发生，比如main()方法里只循环1次时就不会发生，循环100次就极大概率会发生。并发编程就是要消除这种不确定性。\n接下来的示例，演示一个生成偶数的工具类，在多线程条件下调用生成偶数的方法并加以判断，若发现不是偶数则退出程序：\npublic class UnSynchronizedEvenGenerator { public static void main(String[] args) { System.out.println(\u0026#34;press Ctrl-C to exit\u0026#34;); EvenGenerator evenGenerator = new EvenGenerator(); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i \u0026lt; 3; i++) { executorService.execute(new Thread(new EvenTask(evenGenerator))); } executorService.shutdown(); } static abstract class AbstractIntGenerator { // 此处使用了volatile关键字 private volatile boolean canceled = false; public abstract int next(); public void cancel() { canceled = true; } public boolean isCanceled() { return canceled; } } static class EvenGenerator extends AbstractIntGenerator { private int even = 0; @Override public int next() { ++even; // danger here! ++even; return even; } } static class EvenTask implements Runnable { private EvenGenerator evenGenerator; public EvenTask(EvenGenerator evenGenerator) { this.evenGenerator = evenGenerator; } @Override public void run() { while (!evenGenerator.isCanceled()) { int next = evenGenerator.next(); if (next % 2 != 0) { System.out.println(Thread.currentThread().toString() + next + \u0026#34; not even!\u0026#34;); evenGenerator.cancel(); } } } } } /* output: (sample) press Ctrl-C to exit Thread[pool-1-thread-2,5,main]1427 not even! Thread[pool-1-thread-1,5,main]1425 not even! Thread[pool-1-thread-3,5,main]1429 not even! *///:~ 上例中，使用for循环开启了多个线程，并使用同一个evenGenerator对象作为构造器参数：\nfor (int i = 0; i \u0026lt; 3; i++) { executorService.execute(new Thread(new EvenTask(evenGenerator))); } 当循环次数为1（只有一个线程）时，程序会一直执行，直到按下Ctrl-C手动结束任务；\n而当循环次数大于1时，无论其运行多长时间，其总会结束。\nAbstractIntGenerator类中的canceled标志是基本数据类型，而Java内存模型规定，所有原始类型对象（除了double和long）的读写都是原子的2；并且由volatile修饰，说明其是可见的，因此当发生错误时，所有线程都能读取到cancel信息而退出。\n这个表述没错，程序确实也退出了，但是不够严谨。\n查看示例输出可以看到，有3个线程的输出信息，按照输出顺序可以作如下推测：\n线程2发现奇数，修改cancel为true\n线程1发现奇数，修改cancel为true\n嗯？为什么线程1还会执行？根据volatile的语义，线程1不是应该“发现”线程1对cancel的改动么？\n实际上volatile的语义只能保证在线程2之后执行的语句能够发现对cancel的改动。\n但是由于run()方法没有任何同步，所以线程2可能是在线程1while执行之后剥夺线程1的运行权而运行的。\n2022.05.11注：实际上是volotile关键字的特性，其能保证可见性，但是不能保证有序性。\nEvenGenerator类中通过两次自增运算获取下一个偶数，但是自增运算也不是原子性操作，其仍可被拆分为多个CPU指令3，并且被调度器剥夺运行权，在多线程下问题就会显现。\n如何确定自增运算不是原子性的呢？\n以下是javap -c -v UnSynchronizedEvenGenerator\\$EvenGenerator输出的字节码（部分）\npublic int next(); descriptor: ()I flags: ACC_PUBLIC Code: stack=3, locals=1, args_size=1 0: aload_0 1: dup 2: getfield #2 // Field even:I 5: iconst_1 6: iadd 7: putfield #2 // Field even:I 10: aload_0 11: dup 12: getfield #2 // Field even:I 15: iconst_1 16: iadd 17: putfield #2 // Field even:I 20: aload_0 21: getfield #2 // Field even:I 24: ireturn 可以看到，一个自增操作被拆分为至少43个步骤：\nget字段even add修改even put设置even 在未同步的情况下，其中执行到其中任何一步的时候都可能被CPU剥夺运行权。\n如何解决多线程下共享资源的竞争条件呢？\n基本上所有的并发模式在解决线程冲突问题时，都采用序列化访问共享资源的方式。即同一时刻只允许某一个线程访问资源，其他线程被阻塞。通常是通过在代码前面加上一条锁语句来实现的，由于锁产生了一种互斥的效果，这种机制也被称为互斥量（ mutex ）。\n一般看来，任务越耗时，其被CPU调度剥夺运行权的几率越大。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://docs.oracle.com/javase/specs/jls/se15/html/jls-17.html#jls-17.7\u0026#160;\u0026#x21a9;\u0026#xfe0e;\njava文件编译的字节码会对Java代码进行拆分\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n尚不清楚前面aload_0以及dup的意义。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":38,"href":"/zh/docs/java/collections/2_Queue/","title":"Queue","section":"集合框架","content":"Queue（队列），实际开发过程中，在单线程环境下使用的并不多，Queue作为集合框架中重要组成似乎习惯性被忽略。队列总是先持有元素，再处理元素1。\nQueue继承关系简图\n除了Collection定义的操作之外，Queue定义了额外的插入/删除/检查元素的操作，这些操作有2种形式：\nThrows Exception Returns special value Insert add(e) offer(e) Remove remove() poll() Examine element() peek() 如表所示，add/remove/element方法失败后抛出异常。offer/poll/peek方法失败后返回一个特殊值（null或false，视具体操作不同），需要说明的是，offer()方法主要是为有容量限制的队列设计的 对于有限队列而言，offer()方法比add()方法更可取。\n典型的队列遵从FIFO( first-in-first-out )原则，FIFO队列的新元素总是插入到队尾。\n当然有例外，PriorityQueue 就是之一，它根据给定（或默认）的比较器决定元素顺序；此外还有LIFO( last-in-first-out )队列（如栈）。\n不管是何种队列，都可以使用remove()或poll()移除并返回 队列头元素，至于头元素是“谁”就由队列的排序规则决定。此二者的区别体现在当队列为空时，remove()抛出异常，而poll()返回null。\nelement()和peek()获取但不移除 队列头元素，区别在于当队列为空时，element()抛出异常，而peek()返回null。\noffer()方法尝试向队列中插入一个元素，否则返回false，而Collection.add方法失败之后会抛出（运行时）异常。因此offer()方法适用于定容或有界队列中插入元素。\n队列中不允许插入null，或者说不应将null插入队列中（LinkedList允许空值），因为null会作为队列方法的特殊返回值（空队列指示器）出现，若将null插入队列，会引发歧义。\nQueue有两个子接口：\nBlockingQueue\nQueue中并没有定义 阻塞队列 的相关方法，阻塞队列通常在 并发编程 中使用。阻塞队列的方法会等待元素出现或（有限）集合空间可用这2个条件之一满足才执行。\nDeque\n双端队列 是支持从 队首和队尾添加/删除元素 的线性集合，一般来说，Deque 没有容量限制，但是其也支持有限长度的实现。\n从Deque的定义可知，其比Queue的定义多了队头的入队、队尾的出队以及相应的查看操作：\nFirst Element (Head) Last Element (Tail) Throws exception Special value Throws exception Special value Insert addFirst(e) offerFirst(e) addLast(e) offerLast(e) Remove removeFirst() pollFirst() removeLast() pollLast() Examine getFirst() peekFirst() getLast() peekLast() 与Queue不同的是，获取而不删除的方法由element()变成了getXXX()，这些方法用来在队列头/尾中插入/删除/检查元素，当操作失败时有不同的处理：一组直接抛出异常，一组返回一个特殊值（null或false）。同样地，返回特殊值的方法适用于有限容量的队列。\n由于Deque继承自Queue，当其作为Queue使用时，是一个FIFO队列，新元素会添加至队尾，删除操作删除队首元素，因此下表的方法在Deque作为Queue使用时是等价的：\nQueue Methods Equivalent Deque Methods add(e) addLast(e) offer(e) offerLast(e) remove() removeFirst() poll() pollFirst() element() getFirst() peek() peekFirst() 此外，Deque还可以作为LIFO队列（栈）使用，当作为栈使用时，新元素会从队首添加或删除，这种情况下，java.util.Stack的方法和Deque的方法是等价的：\nStack Methods Equivalent Deque Methods push(e) addFirst(e) pop() removeFirst() peek() peekFirst() ArrayDeque就是一个LIFO队列实现可以用作LIFO队列\nDeque不提供使用索引操作集合的方法。\n和Queue一样，虽然没有严格约束不能插入null到队列中，也强烈不推荐将null值插入。\n除此之外，Deque还提供2个删除元素的方法：\nboolean removeFirstOccurrence(Object o); boolean removeLastOccurrence(Object o); PriorityQueue # 优先级队列不允许null值。\n优先级队列是一个有序队列，其底层是由堆( heap )实现的，堆是一个可以自我调整的二叉树。优先级队列的排序依据可以来自元素的自然排序（实现Comparable接口）或自定义比较器，当使用自然排序规则时，优先级队列不允许插入non-comparable对象。\n优先级队列的第一个元素(head)总是按照排序规则计算出最小元素，如果有几个相等的最小元素，那么head为其中任意一个，当使用poll()或remove()后，其他最小元素自动移动至head。\n从输出来看，优先级队列并没有对所有元素进行完全排序，而是队列发生结构性变化时，保证队头元素一定是满足排序规则的最小元素。\n优先级队列是自动扩容的，其扩容机制为：\n当队列较小时（\u0026lt;64），容量翻倍； 当队列长度\u0026gt;64时，容量增加一半（和ArrayList 一样） 优先级队列也有迭代器，此迭代器不能按照指定排序规则顺序迭代元素——优先级队列并没有对所有元素进行排序，若想获得所有元素的排序，可以使用Arrays.sort(pq.toArray())。\n参考下例：\nstatic void unsorted(){ Queue\u0026lt;Integer\u0026gt; pq = new PriorityQueue\u0026lt;\u0026gt;(); pq.add(7); pq.add(1); pq.add(12); pq.add(6); pq.add(9); pq.add(1); System.out.println(\u0026#34;pq: \u0026#34; + Arrays.toString(pq.toArray())); Object[] array = pq.toArray(); Arrays.sort(array); System.out.println(\u0026#34;sorted array:\u0026#34; + Arrays.toString(array)); // the least element always in the head of queue pq.poll(); pq.forEach((e) -\u0026gt;{ System.out.print(e + \u0026#34;\\t\u0026#34;); }); } /* output: pq: [1, 6, 1, 7, 9, 12] sorted array:[1, 1, 6, 7, 9, 12] 1\t6\t12\t7\t9 *///:~ 和上面的叙述一样，PriorityQueue并没有对所有元素进行排序，不过其保证了最小元素始终在队首，并且队列发生结构性变化时，队列中的元素“位置”也会发生变化。\n下例展示了如何在PriorityQueue中使用自定义比较器：\nstatic void userComparator() { class PC { private String model; private Double price; private PC(String model, Double price) { this.model = model; this.price = price; } } // compare by price descend Queue\u0026lt;PC\u0026gt; pq = new PriorityQueue\u0026lt;\u0026gt;((o1, o2) -\u0026gt; (int) (o2.price - o1.price)); pq.add(new PC(\u0026#34;dell\u0026#34;, 15499d)); pq.add(new PC(\u0026#34;apple\u0026#34;, 18899d)); pq.add(new PC(\u0026#34;samsung\u0026#34;, 8999d)); pq.add(new PC(\u0026#34;asus\u0026#34;, 12999d)); pq.add(new PC(\u0026#34;hp\u0026#34;, 6399d)); pq.add(new PC(\u0026#34;lenovo\u0026#34;, 16999d)); pq.forEach(e -\u0026gt; System.out.print(e.price + \u0026#34;\\t\u0026#34;)); System.out.println(); pq.remove(); pq.forEach(e -\u0026gt; System.out.print(e.price + \u0026#34;\\t\u0026#34;)); System.out.println(); pq.remove(); pq.forEach(e -\u0026gt; System.out.print(e.price + \u0026#34;\\t\u0026#34;)); System.out.println(); // compare by model ascend Queue\u0026lt;PC\u0026gt; pq1 = new PriorityQueue\u0026lt;\u0026gt;((o1,o2) -\u0026gt; (o1.model.compareTo(o2.model))); pq1.add(new PC(\u0026#34;samsung\u0026#34;, 8999d)); pq1.add(new PC(\u0026#34;apple\u0026#34;, 18899d)); pq1.add(new PC(\u0026#34;lenovo\u0026#34;, 16999d)); pq1.add(new PC(\u0026#34;asus\u0026#34;, 12999d)); pq1.add(new PC(\u0026#34;dell\u0026#34;, 15499d)); pq1.add(new PC(\u0026#34;hp\u0026#34;, 6399d)); pq1.forEach(e -\u0026gt; System.out.print(e.model + \u0026#34;\\t\u0026#34;)); System.out.println(); pq1.remove(); pq1.forEach(e -\u0026gt; System.out.print(e.model + \u0026#34;\\t\u0026#34;)); System.out.println(); pq1.remove(); pq1.forEach(e -\u0026gt; System.out.print(e.model + \u0026#34;\\t\u0026#34;)); } /* output: 18899.0\t15499.0\t16999.0\t12999.0\t6399.0\t8999.0 16999.0\t15499.0\t8999.0\t12999.0\t6399.0 15499.0\t12999.0\t8999.0\t6399.0 apple\tasus\thp\tsamsung\tdell\tlenovo asus\tdell\thp\tsamsung\tlenovo dell\tlenovo\thp\tsamsung *///:~ 从结果来看，元素在PriorityQueue里并不是全排序的，不过其会自动将“最小”的元素移动至队首。\n此例中，如果不在构造器中指定比较器，PriorityQueue会在运行时抛出 ClassCastException——试图将PC向上转型为Comparable时异常。\nLinkedList # LinkedList是Deque的实现，可以作为双端队列使用，其实现了Deque声明的所有方法。\n想将LinkedList作为Deque使用，须将其声明为 Deque：\nDeque\u0026lt;String\u0026gt; deque = new LinkedList\u0026lt;\u0026gt;(); LinkedList得益于双向链表节点的灵活性，很容易就能够实现在首尾两端对元素进行操作。\nArrayDeque # ArrayDeque是由循环数组实现的双端队列，没有容量限制，并且能够自动扩容，不允许 插入null值。\nArrayDeque作为栈（ LIFO 队列）使用时，效率比java.util.Stack高。\nArrayDeque作为Queue使用时，效率比LinkedList高。\nArrayDeque的迭代器也是 fail-fast 的，意味着和ArrayList一样，在获取迭代器之后使用集合方法对队列进行结构性修改会引发 ConcurrentModificationException。\nArrayDeque主要的字段域有：\ntransient Object[] elements; transient int head; transient int tail; private static final int MIN_INITIAL_CAPACITY = 8; elements用于存储数据，head和tail分别用来标记队列的头尾。 MIN_INITIAL_CAPACITY 是创列的最小容量（23）。当构造器没有指定容量时，初始化容量为16；只有当指定容量且数值小于8时才会使用8作为初始容量。\n参考如下源码：\n// ArrayDeque初始化时容量的计算 private static int calculateSize(int numElements) { int initialCapacity = MIN_INITIAL_CAPACITY; // Find the best power of two to hold elements. // Tests \u0026#34;\u0026lt;=\u0026#34; because arrays aren\u0026#39;t kept full. if (numElements \u0026gt;= initialCapacity) { initialCapacity = numElements; initialCapacity |= (initialCapacity \u0026gt;\u0026gt;\u0026gt; 1); initialCapacity |= (initialCapacity \u0026gt;\u0026gt;\u0026gt; 2); initialCapacity |= (initialCapacity \u0026gt;\u0026gt;\u0026gt; 4); initialCapacity |= (initialCapacity \u0026gt;\u0026gt;\u0026gt; 8); initialCapacity |= (initialCapacity \u0026gt;\u0026gt;\u0026gt; 16); initialCapacity++; if (initialCapacity \u0026lt; 0) // Too many elements, must back off initialCapacity \u0026gt;\u0026gt;\u0026gt;= 1;// Good luck allocating 2 ^ 30 elements } return initialCapacity; } 若指定容量\u0026gt;8时，那么需要对其进行 5次右移及位或运算保证最终的容量大小是2n，比如传进来的参数是13，那么最后得到的容量就是24。\nArrayDeque中，当head==tail2时触发扩容，容量增加一倍。\nTODO\n参考如下源码：\npublic void addFirst(E e) { //... if (head = (head - 1) \u0026amp; (elements.length - 1) == tail) doubleCapacity(); //... } public void addLast(E e) { //... if (tail = (tail + 1) \u0026amp; (elements.length - 1) == head) doubleCapacity(); //... } public E pollFirst() { //... if (head = (h + 1) \u0026amp; (elements.length - 1) == tail) doubleCapacity(); //... } public E pollLast() { //... if (tail = (tail - 1) \u0026amp; (elements.length - 1) == head) doubleCapacity(); //... } // 扩容 private void doubleCapacity() { assert head == tail; int p = head; int n = elements.length; int r = n - p; // number of elements to the right of p int newCapacity = n \u0026lt;\u0026lt; 1; if (newCapacity \u0026lt; 0) throw new IllegalStateException(\u0026#34;Sorry, deque too big\u0026#34;); Object[] a = new Object[newCapacity]; System.arraycopy(elements, p, a, 0, r); System.arraycopy(elements, 0, a, r, p); elements = a; head = 0; tail = n; } 一般地，循环队列都是使用模运算实现的，而ArrayDeque通过位运算来实现循环队列，Java集合框架中很多地方都使用了位运算（如HashMap的扩容），位运算和模运算有 如下关系：\nx % 2n = x \u0026amp; (2n - 1)\n并且位运算的效率远远高出模运算，这就是Java设计的高明之处。\n当触发扩容时，将容量增加一倍，同时使用两次System.arraycopy将原数组拷贝到新数组中，现引用 ArrayDeque扩容将其机制作简要阐述：\n假如默认容量16，此时数组情况如图 当再次调用addFirst(\u0026quot;G\u0026quot;)时，\n此时head==tail，触发扩容，将会创建一个大小为 16*2 的新数组，然后通过两次拷贝将原数组的数据复制到新数组\n第一次将G-H拷贝到新数组 第二次将A-F拷贝到新数组 ArrayDeque扩容图解 来源见水印\n参考如下示例：\nvoid initializationTest() throws Exception { Deque\u0026lt;Integer\u0026gt; aq = new ArrayDeque\u0026lt;\u0026gt;(5); // actual circle array size: 8 System.out.println(\u0026#34;array size : \u0026#34; + getElements(aq).length); // double capacity while i = 7 for (int i = 0; i \u0026lt; 8; i++) { aq.offerLast(i); } Object[] elements = getElements(aq); System.out.println(Arrays.toString(elements)); aq.addLast(19); aq.forEach(e-\u0026gt; System.out.print(e + \u0026#34;\\t\u0026#34;)); } private \u0026lt;T\u0026gt; T[] getElements(Deque\u0026lt;?\u0026gt; aq) throws Exception { Class\u0026lt;?\u0026gt; cls = ArrayDeque.class; Field ef = cls.getDeclaredField(\u0026#34;elements\u0026#34;); ef.setAccessible(true); return (T[]) ef.get(aq); } /* output: array size : 8 [0, 1, 2, 3, 4, 5, 6, 7, null, null, null, null, null, null, null, null] 0\t1\t2\t3\t4\t5\t6\t7\t19 *///~ ArrayDeque的具体方法就不再赘述了，其囊括了作为Queue以及Stack的的实现。\nA collection designed for holding elements prior to processing\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhead和tail在循环数组中的行为是如何？\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":39,"href":"/zh/docs/java/basic/3_%E4%BC%A0%E5%80%BC%E8%BF%98%E6%98%AF%E4%BC%A0%E5%BC%95%E7%94%A8/","title":"传值还是传引用","section":"面向对象","content":" 传值还是传引用 # Java语言设计总是按值调用\n按值调用：方法接收的是调用者提供的值\n按引用调用：方法接收的是调用者提供的变量地址\n一个方法可以修改传递引用所对应的变量值，但是不能修改传递值所对应的变量值。\n基本数据类型参数 # 一个方法不能修改一个基本数据类型的参数（数值类型或布尔值）。\n参考如下代码：\n// doesn\u0026#39;t work class ByValue { static void tripleValue(int x) { x = 3 * x; System.out.println(\u0026#34;x = \u0026#34; + x); } public static void main(String[] args) { int y = 10; tripleValue(y); System.out.println(\u0026#34;y = \u0026#34; + y); } } /* output: x = 30 y = 10 *///:~ 方法执行时，x被初始化为y值的一个拷贝，方法执行后 ，x值变为30，y仍为10，之后x不再使用。\n对象引用 # (引用的)对象可变 # 一个方法可以改变一个对象参数的状态\n参考如下代码：\npublic class ByRef { static void raiseSalary(Employee2 o) { o.raiseSalary(3); System.out.println(\u0026#34;after salary of o = \u0026#34; + o.getSalary()); } public static void main(String[] args) { Employee2 a = new Employee2(\u0026#34;ali\u0026#34;, 1200); System.out.println(\u0026#34;before salary = \u0026#34; + a.getSalary()); raiseSalary(a); System.out.println(\u0026#34;after salary of a = \u0026#34; + a.getSalary()); } } class Employee2 { private String name; private int salary; public Employee2(String name, int salary) { this.name = name; this.salary = salary; } public String getName() { return name; } public int getSalary() { return salary; } void raiseSalary(int multiple) { this.salary = salary * multiple; } } /* output: before salary = 1200 after salary of o = 3600 after salary of a = 3600 *///:~ 方法执行时，o被初始化为a值的拷贝，其中a的值为对象的引用；raiseSalary方法作用与o和a同时引用的那个对象；方法结束后，o对象不再使用，结果是a对象的薪水涨至原来3倍。\n既然如此，那是否可以将 基本类型参数转化为其包装类型呢，这样就可以实现小节1中的期望了：\n// doesn\u0026#39;t work class ByValue { static void tripleValue(Integer x) { x = 3 * x; System.out.println(\u0026#34;x = \u0026#34; + x); } public static void main(String[] args) { Integer y = 10; tripleValue(y); System.out.println(\u0026#34;y = \u0026#34; + y); } } /* output: x = 30 y = 10 *///:~ 非常遗憾，也失败了。这是因为包装器类型是final的，其value域(包装类型的值)也是final的。\n⚠️上例中的的测试是存在问题的，当使用Integer y = 10;初始化y时，Java会将y自动拆箱为int；\n同样地，x = 3 * x;对Integer类型作操作符运算也会拆箱。\n引用不可变 # 一个方法不能让对象参数引用一个新的对象\n当试图去交换两个对象引用的值时，参考如下代码 Employee2：\n// 继续使用上例中的Employee2 public class ByRef { // doesn\u0026#39;t work static void swap(Employee2 j, Employee2 k){ System.out.println(\u0026#34;before swap j.name = \u0026#34; + j.getName()); System.out.println(\u0026#34;before swap k.name = \u0026#34; + k.getName()); Employee2 temp = j; j = k; k = temp; System.out.println(\u0026#34;after swap j.name = \u0026#34; + j.getName()); System.out.println(\u0026#34;after swap k.name = \u0026#34; + k.getName()); } public static void main(String[] args) { Employee2 a = new Employee2(\u0026#34;ali\u0026#34;, 1200); Employee2 b = new Employee2(\u0026#34;bad\u0026#34;, 1300); swap(a,b); System.out.println(\u0026#34;after swap a.name = \u0026#34; + a.getName()); System.out.println(\u0026#34;after swap b.name = \u0026#34; + b.getName()); } } /* output: before swap j.name = ali before swap k.name = bad after swap j.name = bad after swap k.name = ali after swap a.name = ali after swap b.name = bad *///:~ 方法执行时，j和k分别是a和b值的拷贝，也就是说j和k分别是a和b的对象引用，swap方法交换了这两个拷贝，但是方法结束后，j和k不再使用，而a和b还是指向方法调用前所指向的对象。\n也就是说，对于对象参数，对象参数的引用也是按值传递的。\n如何理解这句话？\n引用数据类型的参数传递实际上是对象的一个引用（按引用传递）\n被传递的这个引用本身是值传递性质（引用无法被方法更改）\n"},{"id":40,"href":"/zh/docs/java/concurrency/","title":"并发编程","section":"Java","content":"本部分主要讨论了Java并发相关的内容。主要分为几大部分：\n线程与任务的概念\n第一部分主要讨论线程相关的\n创建 生命周期 优先级 守护线程 中断状态 等相关问题，其中以线程的中断状态这一概念最为重要难懂。\n第二部分主要讨论了线程Thread类提供的相关方法，以及创建线程的惯用法，包括\n线程让步（yield） 线程休眠（sleep） 加入线程（join） 自管理线程- 创建线程的惯用法 捕获线程的异常 其中，join()方法和sleep()方法，比较常用。\n资源访问受限\n并发代码比较“危险”的根本原因，就在于不同的线程，操作了同一份数据。这份数据就是“共享资源”。因此，要想并发程序健壮，这份资源的访问必须受到限制，进程们可不能像无事发生一样，任意地去访问它们。\n这就是这部分讨论的主题。\n这部分由一个经典的 转帐问题切入。引入了Java并发中的一系列同步机制和概念：\n锁和条件 synchronized关键字 原子性和可见性 线程本地存储 获取任务的返回值\n讨论了另一种创建线程的方式。以及从执行任务的线程中获取任务执行的结果，便于后续计算。\nJUC使用Callable和Future接口完成这些工作。\n另外，还讨论了Runnable和Callable的结合体——FutureTask。\n死锁\n简单地讨论了死锁出现的可能原因以及避免死锁的方式。\n终结任务\n主要讨论了多线程协同的情况下，如何合适地终止任务。\n生产-消费模式及阻塞队列\n讨论了生产-消费模型，以及使用阻塞队列实现安全生产-消费的原理。\n简单介绍了3种阻塞队列：\nArrayBlockQueue LinkedBlockingQueue SynchronousQueue 的工作原理以及存取元素的阻塞机制。\n执行器和线程池\n这部分介绍Java的线程池“框架”。主要介绍了ThreadPoolExecutor的 核心概念，以及线程在线程池中的 执行流程。\n顺便讨论了如何优雅地关闭线程池。\n最后，介绍了一个新的接口CompletionService，它利用一个阻塞队列来管理多个任务的返回值。\n计划执行任务\n这部分是Java线程池的延伸，主要讨论了如何让任务有计划地执行。主要使用了ScheduledExecutorService，和第8部分一样，分别讨论了 核心概念和 执行流程。\n最后，讨论了关闭线程池的方法。\n重要的并发组件\nJava 1.5以后的并发类库新加入了一些用于解决并发问题的新构件，合理地使用这些构件能够帮助我们写出更加简单且健壮的并发程序。本节内容介绍java.util.concurrent包中一些具有代表性的构件，包括\nCountDownLatch CyclicBarrier Semaphore Exchanger PriorityBlockingQueue 和 DelayQueue TODO:\nAQS Fork/Join "},{"id":41,"href":"/zh/docs/note/pys/4_func/","title":"函数式编程","section":"Python","content":" "},{"id":42,"href":"/zh/docs/craft/design_pattern/behaviour/4_template_method/","title":"模板方法模式","section":"行为型","content":" 模板方法模式 # 模板方法模式在一个方法中定义一个算法的骨架，而将一些步骤 延迟到子类中。模板方法可以使得子类在不改变算法结构的前提 下，重新 定义算法的某些步骤。\n开发原则 # 针对接口编程，而不是针对实现编程 多用组合，少用继承 为交互对象之间的松耦合而努力 类应该对拓展开放，而对修改关闭 （开放-关闭原则） 依赖抽象，而不依赖具体类 （依赖倒置原则） \u0026ldquo;最少知识原则\u0026rdquo;——只和你的朋友交谈，不要让太多的类耦合在一起 \u0026ldquo;好莱坞原则\u0026rdquo;——别调用我们，我们会调用你 好莱坞原则：定义 # 好莱坞原则定义了一种防止\u0026quot;依赖腐败\u0026quot;的方法。当高层组件依赖底层组件时， 而低层组件又依赖高层组件，而高层组件又依赖边侧组件，边侧组件又 依赖低层组件时，依赖腐败就发生了。\n简而言之，「好莱坞原则」希望系统设计能规避环形依赖。\n在好莱坞原则上，高层组件依赖低层组件（违反依赖倒置原则），但是 高层组件决定什么时候如何使用低层组件，而低层组件不允许调用 高层组件。\n好莱坞原则：和模板方法的关系 # 模板方法运用了好莱坞原则，模板方法需要子类来实现具体细节。只有在需要 子类来实现细节时，才会调用子类的方法。而子类如果没有主动调用，绝对 不会调用抽象类。\n工厂方法，观察者模式也运用了「好莱坞模式」。\n在模板方法中使用钩子（Hook） # 在模板方法中，还有一种特殊的运用——钩子。利用钩子，可以使子类实现 细节的策略更加灵活。\n钩子利用在模板内实现，是否覆盖由子类决定。\nUML简图 # classDiagram direction RL class AbstractTemplate { \u003c\u003c Abstract \u003e\u003e +final templateMethod() +step1()* +step2()* +hook() } ProgressA --|\u003e AbstractTemplate class ProgressA{ +step1() +step2() } ProgressB --|\u003e AbstractTemplate class ProgressB{ +step1() +step2() } classDiagram direction RL class AbstractTemplate { \u0026lt;\u0026lt;Abstract\u0026gt;\u0026gt; +final templateMethod() +step1()* +step2()* +hook() } ProgressA --|\u0026gt; AbstractTemplate class ProgressA{ +step1() +step2() } ProgressB --|\u0026gt; AbstractTemplate class ProgressB{ +step1() +step2() } 要点 # 模板方法定义了算法的步骤，并且把步骤的实现延迟到子类。 利用模板方法，代码可以很好的复用。 模板方法的抽象类可以定义具体方法，抽象方法和钩子。 钩子是一种方法，它在模板方法中不做事，或者只做默认的事情。 模板方法可以声明为final，以防止子类篡改算法逻辑。 好莱坞原则允许高层组件依赖低层组件，但是低层组件不能调用 高层组件的方法，必须由高层组件决定何时、如何调用。 策略模式和模板方法都是封装算法，前者使用组合，后者使用继承。 工厂方法是模板方法的特殊版本。 示例代码 # 以下示例代码由 gpt4o生成。\n// 抽象类定义算法骨架 abstract class Game { // 模板方法，为防止子类修改，一般使用final修饰 public final void play() { initialize(); startPlay(); endPlay(); } // 具体方法 private void initialize() { System.out.println(\u0026#34;Game is initializing...\u0026#34;); } // 抽象方法 protected abstract void startPlay(); // 具体方法 private void endPlay() { System.out.println(\u0026#34;Game is ending...\u0026#34;); } } // 具体子类实现特定步骤 class Cricket extends Game { @Override protected void startPlay() { System.out.println(\u0026#34;Cricket Game Started. Enjoy the game!\u0026#34;); } } class Football extends Game { @Override protected void startPlay() { System.out.println(\u0026#34;Football Game Started. Enjoy the game!\u0026#34;); } } // 测试模板方法模式 public class TemplateMethodPatternDemo { public static void main(String[] args) { Game game = new Cricket(); game.play(); System.out.println(); game = new Football(); game.play(); } } 在这个示例中：\nGame类是一个抽象类，定义了play方法作为模板方法。这个方法定义了算法的骨架，依次调用initialize，startPlay 和 endPlay 方法。 initialize 和 endPlay 方法在 Game 类中是具体方法，所有子类都共享这部分实现。 startPlay 方法在 Game 类中是抽象方法，具体的实现留给子类 Cricket 和 Football 来完成。 在 TemplateMethodPatternDemo 类中，我们创建了 Cricket 和 Football 对象，并调用它们的 play 方法，这将触发模板方法模式中的一系列步骤。 运行上述代码，输出结果为：\nGame is initializing... Cricket Game Started. Enjoy the game! Game is ending... Game is initializing... Football Game Started. Enjoy the game! Game is ending... 更加详细的示例代码\n"},{"id":43,"href":"/zh/docs/craft/design_pattern/structure/4_%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F/","title":"外观模式","section":"结构型","content":" 外观模式（Facade） # 外观模式提供了一个统一的（简单）接口，用来访问子 系统中的一群接口。外观定义了一个高层接口，让系统更 容易使用。\n设计原则 # 针对接口编程，而不是针对实现编程 多用组合，少用继承 为交互对象之间的松耦合而努力 类应该对拓展开放，而对修改关闭 （开放-关闭原则） 依赖抽象，而不依赖具体类 （依赖倒置原则） \u0026ldquo;最少知识原则\u0026rdquo;——只和你的朋友交谈，不要让太多的类耦合在一起。 最少知识原则：定义 # 在设计系统中，不管是任何对象，都需要注意它所交互的类有哪些，并注意这些类是怎么交互的。\n最少知识原则希望，在设计系统的过程中，不要让太多的类交杂在一起，免得修改系统中的一部分， 需要修改其他的部分。如果许多部分相互耦合，系统将会变得复杂、脆弱且不易于维护。\n最少知识原则：如何遵循？ # 设计系统的过程中，就任何对象而言，在对象的方法内，应该只调用属于一下范畴的方法：\n对象本身的方法 被当作方法参数而传递进来的对象的方法 方法内创建或实例化的对象的方法 对象的任何组件（域、field）的方法 不要调用从上述方法中返回的对象支持的方法。\n请看如下例：\npublic float getTemp(){ Thermometer thermometer = station.getThermometer(); return thermometer.getTemperature(); } 应该优化为：\npublic float getTemp(){ return station.getTemperature(); } 而getTemperature方法由station域提供。这样做的好处是，我们 不需要认识Thermometer对象了。让我们始终保持最小的朋友圈！\n最少知识原则：缺点 # 是的，任何事情都是两面。最少知识原则使得系统耦合度降低，减轻了维护成本， 但同时禁止调用中间对象的方法，这不得不让我们制造更多的\u0026quot;包装\u0026quot;类来处理和 其他组件之间的沟通，这可能会导致开发难度增加。\n让我们接着回到『外观模式』吧。\nUML简图 # 要点 # 外观模式中的Facade就是那个\u0026quot;密友\u0026quot;，它封装了其他要用到的方法，满足了最少知识原则。 当要简化并统一一堆接口时，可以使用外观模式。 外观将客户从一个复杂的系统中解耦。 实现外观，需要将子系统组合进外观中，然后将具体的工作委托给子系统执行。 一个复杂的子系统，可以有多个外观。 示例代码 # 外观模式（Facade Pattern）是一种结构型设计模式，它提供了一个统一的接口来访问子系统中的一群接口。外观模式定义了一个高层接口，让子系统更容易使用。\n在这个例子中，我们将创建一个简单的家庭影院系统，它包含了放映机、DVD播放器和音响系统等组件。我们将使用外观模式来提供一个简化的接口来控制这些组件，使得客户端不需要与各个子系统的复杂性直接交互。\n首先，定义子系统的类：\n// 放映机 class Projector { void on() { System.out.println(\u0026#34;Projector on\u0026#34;); } void off() { System.out.println(\u0026#34;Projector off\u0026#34;); } } // DVD播放器 class DvdPlayer { void on() { System.out.println(\u0026#34;DVD Player on\u0026#34;); } void play(String movie) { System.out.println(\u0026#34;Playing \u0026#34;\u0026#34; + movie + \u0026#34;\u0026#34;\u0026#34;); } void stop() { System.out.println(\u0026#34;Stop playing DVD\u0026#34;); } void off() { System.out.println(\u0026#34;DVD Player off\u0026#34;); } } // 音响系统 class SoundSystem { void on() { System.out.println(\u0026#34;Sound system on\u0026#34;); } void setVolume(int level) { System.out.println(\u0026#34;Setting volume to \u0026#34; + level); } void off() { System.out.println(\u0026#34;Sound system off\u0026#34;); } } 接下来，创建外观类HomeTheaterFacade，它提供了简单的方法来处理复杂的子系统操作：\nclass HomeTheaterFacade { private Projector projector; private DvdPlayer dvdPlayer; private SoundSystem soundSystem; public HomeTheaterFacade(Projector projector, DvdPlayer dvdPlayer, SoundSystem soundSystem) { this.projector = projector; this.dvdPlayer = dvdPlayer; this.soundSystem = soundSystem; } // 观看电影 void watchMovie(String movie) { System.out.println(\u0026#34;Get ready to watch a movie...\u0026#34;); projector.on(); soundSystem.on(); soundSystem.setVolume(10); dvdPlayer.on(); dvdPlayer.play(movie); } // 结束观看 void endMovie() { System.out.println(\u0026#34;Shutting movie theater down...\u0026#34;); projector.off(); soundSystem.off(); dvdPlayer.stop(); dvdPlayer.off(); } } 最后，客户端代码可以通过外观类来简化对子系统的操作：\npublic class FacadePatternDemo { public static void main(String[] args) { Projector projector = new Projector(); DvdPlayer dvdPlayer = new DvdPlayer(); SoundSystem soundSystem = new SoundSystem(); HomeTheaterFacade homeTheater = new HomeTheaterFacade(projector, dvdPlayer, soundSystem); homeTheater.watchMovie(\u0026#34;The Shawshank Redemption\u0026#34;); homeTheater.endMovie(); } } 在这个示例中，HomeTheaterFacade类提供了一个简化的接口watchMovie和endMovie，使得客户端不需要直接与放映机、DVD播放器和音响系统等子系统交互，从而简化了客户端的使用。这就是外观模式的魅力所在，它通过提供一个统一的接口来隐藏子系统的复杂性，使得子系统更加容易使用。\n外观模式和宏命令的区别 # 感觉外观模式有点类似于命令模式的宏命令，都是通过接口组合抽取特定的行为组成 符合需求的逻辑，供客户调用。\n不过，外观模式和命令模式的主要诉求不同：\n命令模式的诉求是将对接口的请求封装成对象，以便于参数化，甚至于结合队列来使用。 外观模式的诉求是从一堆可以满足需求的接口中简化逻辑和依赖，简化开发。 至于撤销操作，当然也可以通过外观模式来封装。 以下是chaggpt总结的外观模式和命令模式的宏命令的区别\n外观模式（Facade Pattern）和命令模式中的“宏命令”（Macro Command）都可以用来简化客户端与一组操作之间的交互，但它们的设计目的、实现方式以及应用场景有所不同。\n外观模式 # 外观模式提供了一个统一的高层接口，用来访问子系统中的一群接口。它的主要目的是隐藏系统的复杂性，并提供一个客户端可以访问系统的简单接口。外观模式通常在系统设计初期用于将各个复杂的子系统分离，以减少系统之间的依赖。在系统后期，外观模式可以用于简化客户端的调用，改善子系统之间的交互。\n意图：提供一个统一的接口，用来访问子系统中的一群接口。外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。 应用场景：当你要为一个复杂子系统提供一个简单接口时；当客户端与多个子系统之间存在很大的依赖性时，引入外观模式以将这个子系统与客户端及其他子系统分离，可以提高子系统的独立性和可移植性。 命令模式的“宏命令” # 命令模式将请求封装成对象，从而允许用户使用不同的请求、队列或者日志来参数化其他对象。命令模式也支持可撤销的操作。宏命令是命令模式的一种扩展，它可以执行一组命令，将多个命令封装为一个“宏”命令来执行。\n意图：将一个请求封装为一个对象，从而使你可用不同的请求对客户进行参数化；对请求排队或记录请求日志，以及支持可撤销的操作。 应用场景：当你需要参数化对象根据请求执行操作时；当你需要实现请求排队系统时；当你需要支持撤销操作时；当你需要将一组操作组合成一个大型操作时（即宏命令）。 区别 # 设计目的： 外观模式主要是为了隐藏系统的复杂性，提供一个简单的接口给外部调用。 命令模式的宏命令则是为了将多个命令组合成一个命令，以便统一调用。 实现方式： 外观模式通常只有一个外观类，这个类将客户端的请求代理给相应的子系统处理。 宏命令则是通过命令模式的结构，将多个命令对象组合成一个宏命令对象，这个宏命令也实现了命令接口，但它的execute方法会依次调用组合命令对象的execute方法。 应用场景： 外观模式适用于为复杂系统提供一个简单接口的场景。 宏命令适用于需要将多个操作组合为一个操作执行，并可能支持撤销/重做等操作的场景。 总的来说，外观模式和命令模式的宏命令虽然都可以简化客户端的操作，但它们的关注点不同：外观模式关注于简化系统接口，命令模式的宏命令关注于将多个操作组合成单一操作，以便统一管理和调用。\n"},{"id":44,"href":"/zh/docs/craft/algo/%E4%BD%8D%E8%BF%90%E7%AE%97%E7%9A%84%E5%B0%8F%E6%8A%80%E5%B7%A7/","title":"位运算的小技巧","section":"算法讨论","content":"在 移位运算和 异或运算中讨论了这两种位运算。计算机中还有一些其他的位运算，它们比较简单，但也还有一些巧妙的作用，本文将逐一介绍它们。\n按位与 # 按位与（bitwise and）记作\u0026amp;，只有2个操作数都为1时，结果才为1，否则为0。按位与的真值表为：\n1\u0026amp;1 = 1 1\u0026amp;0 = 0 0\u0026amp;1 = 0 0\u0026amp;0 = 0 看来，通过与1进行与运算，可以判断该位是0或者是1；通过与0进行位运算，可以将该位置为0。利用这些性质，可以用来：\n判断奇偶性：一个数\u0026amp;1，为0则为偶数，为1则为基数； val a = 0xf5 println(a and 1 == 0) 取一个数中的指定位； // 取低4位 val a = 0xf5 var b = a and 0xf println(\u0026#34;0x${b.toString(16)\u0026#34;) // 0x5 清零：将一个数\u0026amp;0，即可清零。 按位或 # 按位或（bitwise or）记作|，两个操作数任意一个为1，则结果为1，其真值表为：\n1|1 = 1 1|0 = 1 0|1 = 1 0|0 = 0 和按位与相反，一个数|1，则可以将其置为1。\n按位取反 # 按位取反（bitwise not）记作~，即0变成1，1变成0\n位运算的小技巧 # 位运算程序中运行最高效的代码，在实际编程经验中使用颇少。而复杂的位运算代码往往晦涩难懂（Java集合框架源码就大量使用了位运算）。这里总结一些和位运算有关的小技巧，增强对位运算的理解。\n\u0026gt;\u0026gt;\u0026gt;和\u0026lt;\u0026lt;的简单乘除法\n\u0026amp;操作的奇偶性判断\n^操作的交换2个数\n~操作的取相反数：-x = ~x + 1\n取绝对值\n正数的绝对值是其本身，负数的绝对值是其正数。对于一个任意数，先判断其符号，之后即可取得其绝对值。\nfun abs(a:Int): Int { var i = a shr 31 // a \u0026gt;\u0026gt; 31 return if (i == 0 ) a else a.inv() + 1 } 将一个Int型整数逻辑右移31位，若为0，则为正数，若为负数，则为1。\n因i的值为0或-1（0xffffffff），而异或运算有如下性质：\n一个数与0异或，返回其自身；与1异或，相当于取反。故上述代码还可以进行优化：\nfun abs(a:Int):Int { var i = a shr 31 return (a.xor(i)) - i } 位操作进行高低位交换\n给定一个16位的无符号数，将其高8位和低8位进行交换，求交换后的值。\nvar j = 0x86c8 var k = ((j shr 8) or (j shl 8)) println(\u0026#34;0x${(k and 0xffff).toString(16)}\u0026#34;) // 0xc886 将一个数右移8位，即可得到低8位的数；将一个数左移8位，即可得到高8位的数。然后将两个数进行按位或（|）运算，即可。\nkotlin/java中无法表示无符号数1，因此例子中使用整型参与运算，最后的结果与0xffff进行按位与（\u0026amp;）操作，将高位置0，即可得到反转的数。\n位操作二进制逆序\n位操作统计二进制中1的个数\n位运算计算2个整数的和： (a ^ b) + (a \u0026amp; b \u0026lt;\u0026lt; 1)\n位操作有哪些奇淫技巧？ kotlin中已经有UShort、UInt等无符号数据类型，但是shr等位操作符号不支持这些数据类型。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":45,"href":"/zh/docs/craft/design_pattern/creation/4_builder/","title":"建造者模式","section":"创建型","content":" 本文由Gemini AI生成。\n建造模式 # 建造模式是一种创建型设计模式，它将一个复杂对象的构建与其表示分离。它允许你通过一步一步地构建对象来创建不同的表示。\n结构 # 建造模式包含以下角色：\n抽象建造者（Builder）: 定义一个接口，指定构建复杂对象各个部分的步骤。 具体建造者（ConcreteBuilder）: 实现抽象建造者接口，具体实现构建复杂对象的步骤。 指挥者（Director）: 负责调用具体建造者的方法，构建复杂对象。 产品（Product）: 最终构建出来的复杂对象。 UML简图 # classDiagram class Builder { \u003c\u003c interface \u003e\u003e +buildPartA() +buildPartB() +buildPartC() +getResult() } class ConcreteBuilder1 { +buildPartA() +buildPartB() +buildPartC() +getResult() } class ConcreteBuilder2 { +buildPartA() +buildPartB() +buildPartC() +getResult() } class Director { +construct() } class Product { +partA +partB +partC } Builder \u003c|.. ConcreteBuilder1 Builder \u003c|.. ConcreteBuilder2 Director --\u003e Builder Director --\u003e Product Product ..\u003e ConcreteBuilder1 Product ..\u003e ConcreteBuilder2 classDiagram class Builder { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; +buildPartA() +buildPartB() +buildPartC() +getResult() } class ConcreteBuilder1 { +buildPartA() +buildPartB() +buildPartC() +getResult() } class ConcreteBuilder2 { +buildPartA() +buildPartB() +buildPartC() +getResult() } class Director { +construct() } class Product { +partA +partB +partC } Builder \u0026lt;|.. ConcreteBuilder1 Builder \u0026lt;|.. ConcreteBuilder2 Director --\u0026gt; Builder Director --\u0026gt; Product Product ..\u0026gt; ConcreteBuilder1 Product ..\u0026gt; ConcreteBuilder2 示例代码 # 建造者 # 首先是建造者及其实现：\n// 抽象建造者 interface CarBuilder { void buildModel(); void buildEngine(); void buildColor(); Car getCar(); } // 具体建造者 class BenzCarBuilder implements CarBuilder { private Car car = new Car(); @Override public void buildModel() { car.setModel(\u0026#34;奔驰\u0026#34;); } @Override public void buildEngine() { car.setEngine(\u0026#34;V8发动机\u0026#34;); } @Override public void buildColor() { car.setColor(\u0026#34;黑色\u0026#34;); } @Override public Car getCar() { return car; } } class BMWCarBuilder implements CarBuilder { private Car car = new Car(); @Override public void buildModel() { car.setModel(\u0026#34;宝马\u0026#34;); } @Override public void buildEngine() { car.setEngine(\u0026#34;直列六缸发动机\u0026#34;); } @Override public void buildColor() { car.setColor(\u0026#34;白色\u0026#34;); } @Override public Car getCar() { return car; } } 产品 # 接下来是产品及其实现：\n// 产品 class Car { private String model; private String engine; private String color; public void setModel(String model) { this.model = model; } public void setEngine(String engine) { this.engine = engine; } public void setColor(String color) { this.color = color; } public String getModel() { return model; } public String getEngine() { return engine; } public String getColor() { return color; } } 指挥者 # 最后是指挥者：\n// 指挥者 class CarDirector { private CarBuilder builder; public CarDirector(CarBuilder builder) { this.builder = builder; } public Car constructCar() { builder.buildModel(); builder.buildEngine(); builder.buildColor(); return builder.getCar(); } } 测试代码 # // 使用建造模式 public class BuilderPatternDemo { public static void main(String[] args) { CarDirector director = new CarDirector(new BenzCarBuilder()); Car benzCar = director.constructCar(); System.out.println(\u0026#34;奔驰汽车: \u0026#34; + benzCar.getModel() + \u0026#34;，\u0026#34; + benzCar.getEngine() + \u0026#34;，\u0026#34; + benzCar.getColor()); director = new CarDirector(new BMWCarBuilder()); Car bmwCar = director.constructCar(); System.out.println(\u0026#34;宝马汽车: \u0026#34; + bmwCar.getModel() + \u0026#34;，\u0026#34; + bmwCar.getEngine() + \u0026#34;，\u0026#34; + bmwCar.getColor()); } } 抽象建造者接口 CarBuilder： 定义了构建汽车的步骤，包括设置模型、发动机和颜色。 具体建造者 BenzCarBuilder 和 BMWCarBuilder： 分别实现了 CarBuilder 接口，并具体实现了构建奔驰汽车和宝马汽车的步骤。 产品 Car： 代表最终构建出来的汽车对象。 指挥者 CarDirector： 通过调用具体建造者的方法，来构建不同的汽车。 优点 # 将复杂对象的构建与表示分离。 可以更容易地创建不同的表示。 可以方便地扩展新类型。 建造模式和工厂模式的区别 # Generated by chatgpt.\n建造者模式（Builder Pattern）和工厂模式（Factory Pattern，包括简单工厂模式、工厂方法模式和抽象工厂模式）都是用来创建对象的设计模式，但它们在意图、应用场景和实现方式上有所不同。\n建造者模式 # 建造者模式主要用于创建一种复杂的对象，其产品通常需要多个部分按特定的过程组合而成。这种模式允许用户通过指定复杂对象的类型和内容就可以构建它们，用户不需要知道内部的具体构建细节。\n意图：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。 应用场景：当创建复杂对象的算法应该独立于该对象的组成部分以及它们的装配方式时；当构造过程必须允许被构造的对象有不同的表示时。 实现方式：通常由Director（指挥者）、Builder（建造者接口）、ConcreteBuilder（具体建造者）和Product（产品）组成。客户端创建Director对象，并用它所需要的Builder对象进行配置。Director决定如何以及何时让建造者产生部件，然后组合成产品返回。 工厂模式 # 工厂模式主要用于创建对象，特别是在创建某个类的对象时不希望指定确切的类。工厂模式通过调用一个工厂方法而不是直接调用构造函数来创建对象（可能是指定的接口或抽象类的具体实现）。\n意图：定义一个用于创建对象的接口，让子类决定实例化哪一个类。工厂方法使一个类的实例化延迟到其子类。 应用场景：当一个类不知道它所必须创建的对象的类的时候；当一个类希望由它的子类来指定创建的对象时；当类将创建对象的职责委托给多个帮助子类中的某一个，并且你希望将哪个帮助子类是代理者这一信息局部化时。 实现方式：可以分为三种： 简单工厂模式：不属于GOF的23种设计模式，它实际上是一种编程习惯。一个工厂类根据传入的参数决定创建出哪一种产品类的实例。 工厂方法模式：定义一个用于创建对象的接口，让子类决定将哪一个类实例化。使用一个类的实例来创建另一个类的实例。 抽象工厂模式：提供一个创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。 区别 # 目的不同： 建造者模式主要用于创建复杂对象，强调的是一步步构造一个复杂对象，可以用不同的组合或顺序得到不同的结果。 工厂模式主要用于创建类型族的对象，强调的是为客户端提供一个创建对象的接口，隐藏创建逻辑。 应用场景不同： 建造者模式适用于那些产品对象的内部结构比较复杂，需要多步骤构建的场景。 工厂模式适用于创建对象时，不希望客户端知道创建逻辑的场景。 实现复杂度不同： 建造者模式的实现比工厂模式复杂，因为它通常需要多个步骤来创建一个对象，而工厂模式通常通过调用一个方法就可以直接创建对象。 总的来说，选择哪种模式取决于具体需求，如果需要更加精细和控制的对象创建过程，建造者模式可能是更好的选择。如果只是需要一个简单的接口来创建一系列相关或依赖的对象，工厂模式可能更适合。\n"},{"id":46,"href":"/zh/docs/java/spring/spring-transaction-propagation/","title":"spring声明式事务的使用","section":"Spring","content":" 1 从@Transactional注解开始 # @Transactional注解是使用spring-transaction的最便捷方式。也是使用Spring框架开发最先接触的内容。\n当你在一个服务的方法上使用@Transactional注解时，意味着你希望为此方法开启事务支持。如果你的项目成功配置了数据源和事务管理器，Spring会为此方法使用如下默认设置开启事务：\n事务传播属性：PROPAGATION.REQUIRED 事务隔离级别：ISOLATION_DEFAULT （使用数据库的默认隔离级别） 只读事务：否 事务超时时间取决与数据库的事务超时设置（MYSQL innodb默认为50s），若数据库不支持事务超时则不设置 事务回滚：RuntimeException时回回滚（unchecked exception）; Error和CheckedException（如IOException等）时不回滚 像这样，不做任何其他的配置，就可轻松使用事务控制。这是Spring给Java开发带来的便利，对于业务简单的场景，简单的@Transactional注解即可满足业务需求——完全使用数据库的事务来处理业务。\n使用@Transactional注解之前，需要配置相关TransactionManager； 对于Spring-Boot项目，可以使用@EnableTransactionManagement注解，该注解的作用和\u0026lt;tx: annotation-driven/\u0026gt;相当，其为Spring事务控制开启注解支持。\n1.1 普通方法调用@Transactional方法 # 声明式事务的开启都是由@Transactional注解开始的，事务的开始必然是从普通方法到@Transactional方法的调用。因此，形如如下的方法调用，事务必然生效：\npublic void A() throws Exception{ service.B(); } @Transactional public void B() throws Exception{ // ... } 上述代码片段中，方法B的事务会生效，并且和方法A方法没有关系；而方法A是不受事务控制的。\n这种行为较容易理解， @Transactional注解的作用范围只在注解的方法内生效。\n1.2 @Transactional方法调用普通方法 # 如果反过来，当@Transactional方法调用普通方法，会有怎样的事务行为呢？\n@Transactional public void A() throws Exception{ B(); } public void B() throws Exception{ // ... } 实际上，此种情形只有A方法存在事务，B方法没有事务，不过，有一些行为表现得好像方法B 使用了方法A的事务一样：\n此种情形下，方法B实际上被方法A的事务所管理：\n当B抛出异常时： 若方法A捕获异常，则方法A和方法B均提交； 若方法A不捕获异常，则方法A和方法B均回滚； 当方法A抛出异常时，方法A和方法B均回滚； 总之，若方法A捕获了方法B抛出异常，则事务提交；若方法A没有捕获方法B抛出的异常，则认为方法A抛出异常，则事务回滚。\n若A方法抛出异常，则事务回滚，值得一题的是，这种情形下，B方法若执行，也会回滚。\n2 理解Spring声明式事务 # 仅仅依靠@EnableTransactionManagement和@Transactional注解来使用Spring声明式事务显然是不够的，你必须理解其实现原理，才能有效配置使其按照预期工作。Spring事务实际上是通过Spring AOP代理来对目标类/方法添加环绕通知增强来实现的。事务通知（transaction advice）通过XML或者注解的形式配置。\n借助AOP代理以及元数据（XML或注解）配置，Spring会使用合适的TransactionManager以及TransactionInterceptor来对调用方法增强。\nSpring 事务支持2种编程模型：强制性（imperative programming model）和响应式（reactive programming model），目前前者使用的比较多。\n强制性事务使用PlatformTransactionManager，这是常见且应熟识的；而响应式事务使用ReactiveTransactionManager。\n@Transactional注解的作用域为当前执行线程，即当前方法及其调用方法中发生的数据访问和操作，均被PlatformTransactionManager所提供的事务所管理。不过，对于方法内部新启动的线程，事务不会生效。\n下图粗略展示了调用使用@Transactional注解的方法时，事务代理的作用方式：\n3 配置@Transactional注解 # @Transactional 注解能够在接口，类和方法上使用。\n当在类上使用@Transactional注解时，该类所有的方法以及其子类的方法都会被Spring事务管理。\n在方法上使用@Transactional注解时，意味着为这个方法开启Spring事务，这是最常用的方式。需要注意的是，如果在非public方法上使用@Transactional注解，Spring不会抛出任何异常，但是Spring事务不会生效。\n在接口或接口方法上使用@Transactional注解，Spring事务只有在使用基于接口的代理时才会生效。所以当你在使用基于\n"},{"id":47,"href":"/zh/docs/craft/db/sql/4_MySQL%E4%BA%8B%E5%8A%A1%E4%B8%8E%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/","title":"事务隔离级别与MVCC","section":"mysql","content":" 开发过程中，或多或少会碰到需要使用数据库事务的业务场景，而Spring框架提供的能力使得开发者无需过多地关注事务本身，这带来诸多便利，但也带来弊端：开发者只知其貌，而不知其理，一旦Spring框架抛出异常，便往往手足无措。本文简单地介绍了MySQL事务相关的基本概念，使用例证阐述了不同事务隔离级别下MySQL的数据可见性，简单讨论了MySQL如何保证数据一致性。有了这些基本的概念，遇到事务与数据库锁相关的问题时，开发者能够多一点思考。\n事务的概念可以这样理解：\n在MySQL中，有些操作必须要分步完成，那么我们可以把这些分步完成的操作声明为一个“事务”，用来保证MySQL数据一致性。\n对于单条SQL语句而言，MySQL将其处理为一个「隐式事务」。\n看起来，事务的概念还是有些空泛。事实上，了解并发的概念之后，更加容易理解事务这个概念，这并不是说事务一个并发概念，不过，事务是有了并发之后才衍生的概念，这很容易理解。试想一个只容许一个客户端连接的MySQL服务，是否需要“事务”呢？答案应该是否定的。单个客户端执行SQL语句总是有序的，数据一致性就能得到保证了1。试想，如果是多客户端的系统（事实上正是如此）同时执行SQL语句，就好似多线程同时访问资源一样，对于数据库系统而言，所有的数据表都是共享资源2，那么事务就像是那把保证并发安全的“锁”。\n1 事务的ACID性质 # 事务可以保证被声明为事务的分步操作要么都成功执行，要么都不执行。若某一分步遇到错误，执行成功的那些步骤操作会被回滚，这样不会对MySQL的数据完整性进行破坏。\nAtomicity 原子性\n原子性的概念和所有并发编程的概念一样，如果声明一个操作是原子的，那么这个操作要么执行，要么不执行。如果声明了一个事务，那么就可以把事务开启之后执行的SQL语句看作一个「并发编程里面的临界区」中的代码，它只能允许一个SQL连接访问数据。包含的SQL分步操作要么全部执行，要么全不执行。\nConsistency 一致性\n数据库的状态只会从一个一致状态转移到另一个一致状态，事务操作不应该影响数据的一致性。比如转账操作，A账户转出100，B账户一定会转入100。若A账户转出100之后系统崩溃，账户A也不会损失100元，因为事务没有提交，所有事务的修改不会提交到数据库中。\nIsolation 隔离性\n如果有多个事务并发执行，那么事务之间应该不能产生干扰，这也是保证数据安全性的重要环节。比如A账户转出100元，此时有另一个事务读取了A账户的值，读取到的账户的值不应该是A账户减去100元的值，而应该是原始值。\nDurability 持久性\n一旦事务被提交，其对数据的修改是永久性的。即使系统崩溃，修改的数据也不会丢失。\n2 事务的隔离级别 # 如果事务满足ACID性质，那么数据安全性就不会受到威胁。那么，设计一个逻辑来保证事务的ACID性质不就解决问题了么，为什么还要设计事务的隔离级别呢？结合实际情况来看，并非所有的事务都需要满足ACID特性，有些数据对准确性要求不高的的事务，是允许读取到其他事务修改的数据例证。另外，在实现过程中，一个满足ACID特性的数据库系统要复杂的多，系统需要做很多额外的操作来满足ACID特性，这样会造成额外的性能开销，系统会占用更多的资源而影响数据库的执行效率。这也是数据库中仍然有不支持事务的存储引擎一席之地的原因3。\n事务的隔离级别并不是MySQL独有的，它是SQL标准中定义的，每种隔离级别都规定了一个事务中所做的修改在哪些事务内和事务间是可见的，哪些是不可见的。较低的隔离级别支持更高的并发、拥有更高的效率。\nREAD UNCOMMITTED（读未提交）\n这个隔离级别中，事务中的修改，即使没有提交，对其他事务都是可见的。其他事务可以读取到未提交的数据，这种情况称为脏读（dirty read）。这个级别会导致很多问题，一般很少使用。\nREAD COMMITTED（读已提交）\n这个隔离级别中，满足隔离性的简单定义，一个事务开始前，只能读取到已经提交的事务所做的修改。换言之，一个事务对数据库所做的任何修改在其提交之前都其他事务都是不可见的。这会导致是个现象：一个事务可能2次读取到的数据是不一致的（事务A提交前与提交后），这种情况称为不可重复读（nonrepeatable read）\nREPEATABLE READ（可重复读）\n可重复读解决了脏读的问题，同时也保证了在事务了多次对同一个数据取样，读取到的数据是一致的。\n但是，理论上，该隔离级别的不能解决幻读（phantom read）的问题：幻读指的是某个事务在读取某个范围的记录时，另外一个事务又在该范围内插入了新的记录，那么，当之前的事务再次读取这个范围的记录时，就会出现幻行（phantom row）。\n不过InnoDB引擎通过MVCC(multi version concurrency control)多版本并发控制解决了幻读的问题。\n可重复读是MySQL的默认隔离级别\nSERIALIZABLE（串行化）\nSERIALIZABLE是最高的隔离级别，它通过强制所有的SQL语句串行执行来避免幻读的问题。该隔离级别下，每一行使用到的数据都会加锁，所以当数据库请求量大的时候，就有可能造成大量的超时等待4和锁争用的问题。这个隔离级别很少使用，因为其牺牲了很大量的性能来保证数据一致性。如果不是严格地要求数据一致性，一般不考虑此隔离级别。\n下表展示了事务隔离级别以及其可能引起的后果之间的关系：\n隔离级别 脏读可能性 不可重复读可能性 幻读可能性 加锁读 READ UNCOMMITTED Y Y Y N READ COMMITTED N Y Y N REPEATABLE READ N N Y N SERIALIZABLE N N N Y 3 查看数据库的基本信息 # 在实例演示之前，需要查看几个基本信息，来确保测试环境的一致性与可行性。这些基本信息包括，数据库当前所使用的引擎，数据库当前的事务隔离级别。\n3.1 引擎 # 使用下面的命令查看当前数据库的引擎信息\nmysql\u0026gt; show variables like \u0026#39;%engine%\u0026#39;; +----------------------------------+--------+ | Variable_name | Value | +----------------------------------+--------+ | default_storage_engine | InnoDB | | default_tmp_storage_engine | InnoDB | | disabled_storage_engines | | | internal_tmp_disk_storage_engine | InnoDB | +----------------------------------+--------+ 4 rows in set (0.01 sec) 看到系统当前数据库（版本5.7）的默认存储引擎是InnoDB，InnoDB引擎支持事务，就用这个引擎测试。\n我们使用供应商表vendors完成接下来的测试，先看看vendors表所使用的引擎：\nmysql\u0026gt; show table status like \u0026#39;vendors\u0026#39; \\G *************************** 1. row *************************** Name: vendors Engine: InnoDB Version: 10 Row_format: Dynamic Rows: 6 Avg_row_length: 2730 Data_length: 16384 Max_data_length: 0 Index_length: 0 Data_free: 0 Auto_increment: 1008 Create_time: 2020-11-25 18:37:46 Update_time: NULL Check_time: NULL Collation: utf8_general_ci Checksum: NULL Create_options: Comment: 1 row in set (0.00 sec) 我们看到vendors表的引擎也是InnoDB。\n3.2 隔离级别 # 使用如下命令查看当前数据库的事务隔离级别\nmysql\u0026gt; show variables like \u0026#39;tx_isolation\u0026#39;; +---------------+-----------------+ | Variable_name | Value | +---------------+-----------------+ | tx_isolation | REPEATABLE-READ | +---------------+-----------------+ 1 row in set (0.01 sec) 当前数据库的事务隔离级别为可重复读，加上InnoDB引擎的MVCC，基本上是满足事务的ACID特性的数据库系统。\n在进行测试时，我们可以通过\nmysql\u0026gt; SET TRANSACTION ISOLATION LEVEL [tx_isolation]; 来控制当前客户端连接的下个事务隔离级别——只对当前连接的下一次事务生效生效，这样便于测试。\n更多关于set transaction命令的内容: https://dev.mysql.com/doc/refman/8.0/en/set-transaction.html\nmysql 8查看以及设置事务隔离级别的命令有所变化：\n查看事务隔离级别：\nselect @@global.transaction_isolation, @@transaction_isolation; 设置事务隔离级别：\nset session transaction isolation level read committed; set global transaction isolation level read committed; 在测试过程中，涉及到的客户端命令有：\nbegin或者start transaction开始事务 rollback回滚/结束事务 commit提交/结束事务 4 读未提交 READ UNCOMMITTED # READ UNCOMMITTED 隔离级别出现脏读和不可重复读的问题\n从上面的执行图可以看到：\n会话1（左）和会话2（右）的事务隔离级别都设置为READ UNCOMMITTED 会话1将vend_id=1007对应的vend_address改为sz； 此时会话2中去读取vend_id=1007的数据，已经读取到了会话1未提交的更改；\u0026lt;==脏读 接着会话1将更改回滚； 会话2再次读取vend_id=1007的数据，发现数据列vend_address变为初始值。\u0026lt;==不可重复读 上面的执行流程完整的演示了在READ UNCOMMITTED隔离级别下的脏读和不可重复读现象。\n5 读已提交 READ COMMITTED # READ COMMITTED 隔离级别出现不可重复读的问题\n从上面的执行图可以看到：\n会话1和会话2的事务隔离级别都设置为READ COMMITTED； 会话1将vend_id=1007对应的vend_address改为sz； 此时会话2中去读取vend_id=1007的数据，不能读取到会话1未提交的更改；\u0026lt;==旧数据 会话1提交更改 会话2再次读取vend_id=1007的数据，读取到数据列vend_address的更改。\u0026lt;==新数据 上面的执行流程完整演示了在READ COMMITTED隔离级别下，两次读取到的结果不一致的现象，即在此隔离级别下不可重复读。\n6 多版本并发控制（MVCC） # 前文提到，mysql的InnoDB引擎使用MVCC解决了在可重复读(REPEATABLE READ)隔离级别下幻读(phantom read)的问题。因此，在执行可重复读隔离级别的测试之前，先介绍一下多版本并发控制(Multi Version Cocurrency Control)5。\n可以认为，MVCC是行级锁的一个变种，但是其在很多情况下避免了加锁操作6，因此可以节省部分开销，获得更好的性能。\n在InnoDB的MVCC中，通过在每行记录之后添加2个隐藏的列来实现的：\n\\\\ 隐藏列1 隐藏列2 记录内容 行的创建时间 行的过期时间（删除时间） 要注意的是，实际上存储的并不是实际的时间值，而是当前的系统版本号（system version number）。系统版本号有如下特征：\n每开始一个新事务，系统版本号都会递增 ； 事务开始时的版本号作为事务的版本号； 事务的版本号用来和查询到的每条记录的版本号对比，决定语句的操作； 在REPEATABLE READ隔离级别下，MVCC的具体行为是：\nSELECT InnoDB会根据一下条件检查每行记录：\nInnoDB只查找版本号早于当前事务版本号的数据（小于等于事务的版本号） 。这样做，可以保证当前事务只能读取事务开始前已经存在的数据行，或者该事务自身插入或者修改的数据行； 行的删除版本要么未定义，要么大于当前事务版本号。这可以保证事务开始前，读取到的行未被删除。 INSERT InnoDB为新插入的每一行保存当前系统版本号所为行版本号。\nDELETE InnoDB为删除的每一行保存当前系统版本号作为删除标识。\nINSERT InnoDB为插入一行新纪录保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为行删除标识\n事实上，MVCC是通过保存数据在某个时间点的快照（snapshot）来实现的，也就是说不管事务执行多长时间，其所能看到的数据都是一致的。这就可能造成一个现象：\n根据事务开始的时间的不同，每个事务对同一张表，同一时刻看到的数据可能是不一致的。\n在接下来的演示中，我们将会看到MVCC在事务执行过程中的行为。\n7 可重复读 REPEATABLE READ # REPEATABLE READ 是默认的事务隔离级别\n这是一个相对完整的示例，演示了InnoDB引擎在默认事务隔离级别下，不同事务在处理同一行数据之间的表现，其中有一些结果出乎意料却又在MVCC以及事务隔离级别的“情理之中”。在这个示例中我们可以看到以下重要内容：\n事务只能读取到在其开始之前就已经存在的数据，或者其自身修改的数据； 事务使用了行级锁来保证数据一致； 事务B可以修改事务A创建但未提交的数据，并且事务B随即可读取之，这验证了第1点； 事务A无法读取到事务B的修改（只要这个修改发生在事务A开始之后，无论事务B是否提交），这保证了可重复读； 如果数据行在事务A在开始前已经存在，但随即被事务B删除，那么事务A无法再对数据行进行修改。但是事务A依旧可以读取到数据行的内容。这就是“快照”的概念在MVCC中的行为。 遗憾的是，笔者试图从MVCC“系统版本号”的概念去推断事务的执行，始终无法得出与预期一致的结果，所以关于MVCC“系统版本号”的工作机制，此文尚不能详述，不过，程序的执行期望却和前文描述的MVCC行为是一致的。其实，使用“快照”的概念去理解MVCC的行为，会显得更容易。\n8 串行 SERIALIZABLE # SERIALIZABLE 隔离级别效率很低\n当使用最高的事务级别同时开启2个事务时，2个事务只能依次执行，换言之，会话2会阻塞会话1的insert操作，只有当会话2commit/rollback之后，会话1才会结束阻塞。\n上图中第一次执行insert的时候，发现语句迟迟不返回，以为是语句故障，使用ctrl-c结束了语句执行，控制台输出：\nERROR 1317 (70100): Query execution was interrupted 看到关键字interruptted，证明了insert操作确实是处于阻塞状态。\n9 参考 # 高性能mysql 第3版 廖雪峰的官方网站-数据库事务 mysql document page 【推荐】数据库的事务和锁7 类比资源的序列访问，可能不太恰当。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n当然可以使用权限控制将某个资源排除对特定连接的共享。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n这也是有些业务不需要事务支持，使用MyISAM(indexed sequencial access method)作为数据库引擎的原因。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n一些存储引擎在处理数据库死锁的时选用的方法。InnoDB并不是采用的此方法，其是将持有最少行锁的事务回滚。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n不仅仅mysql，很多数据库系统包括Oracle，PostGreSQL都实现了MVCC，尽管其实现机制不尽相同。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMVCC的并发控制有乐观加锁和悲观加锁两种方式，并不是所有的实现都不加锁，只有使用乐观锁是不加锁的。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n此链接正文部分关于索引的讨论有些谬误，这些谬误在评论区可找到相关讨论。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":48,"href":"/zh/docs/craft/db/redis/bloom-filter/","title":"布隆过滤器(转)","section":"redis","content":"海量数据处理以及缓存穿透这两个场景让我认识了 布隆过滤器 ，我查阅了一些资料来了解它，但是很多现成资料并不满足我的需求，所以就决定自己总结一篇关于布隆过滤器的文章。希望通过这篇文章让更多人了解布隆过滤器，并且会实际去使用它！\n下面我们将分为几个方面来介绍布隆过滤器：\n什么是布隆过滤器？ 布隆过滤器的原理介绍。 布隆过滤器使用场景。 通过 Java 编程手动实现布隆过滤器。 利用Google开源的Guava中自带的布隆过滤器。 Redis 中的布隆过滤器。 1.什么是布隆过滤器？ # 首先，我们需要了解布隆过滤器的概念。\n布隆过滤器（Bloom Filter）是一个叫做 Bloom 的老哥于1970年提出的。我们可以把它看作由二进制向量（或者说位数组）和一系列随机映射函数（哈希函数）两部分组成的数据结构。相比于我们平时常用的的 List、Map 、Set 等数据结构，它占用空间更少并且效率更高，但是缺点是其返回的结果是概率性的，而不是非常准确的。理论情况下添加到集合中的元素越多，误报的可能性就越大。并且，存放在布隆过滤器的数据不容易删除。\n位数组中的每个元素都只占用 1 bit ，并且每个元素只能是 0 或者 1。这样申请一个 100w 个元素的位数组只占用 1000000Bit / 8 = 125000 Byte = 125000/1024 kb ≈ 122kb 的空间。\n总结：一个名叫 Bloom 的人提出了一种来检索元素是否在给定大集合中的数据结构，这种数据结构是高效且性能很好的，但缺点是具有一定的错误识别率和删除难度。并且，理论情况下，添加到集合中的元素越多，误报的可能性就越大。\n2.布隆过滤器的原理介绍 # 当一个元素加入布隆过滤器中的时候，会进行如下操作：\n使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。 根据得到的哈希值，在位数组中把对应下标的值置为 1。 当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行如下操作：\n对给定元素再次进行相同的哈希计算； 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。 举个简单的例子：\n如图所示，当字符串存储要加入到布隆过滤器中时，该字符串首先由多个哈希函数生成不同的哈希值，然后在对应的位数组的下表的元素设置为 1（当位数组初始化时 ，所有位置均为0）。当第二次存储相同字符串时，因为先前的对应位置已设置为 1，所以很容易知道此值已经存在（去重非常方便）。\n如果我们需要判断某个字符串是否在布隆过滤器中时，只需要对给定字符串再次进行相同的哈希计算，得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。\n不同的字符串可能哈希出来的位置相同，这种情况我们可以适当增加位数组大小或者调整我们的哈希函数。\n综上，我们可以得出：布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。\n3.布隆过滤器使用场景 # 判断给定数据是否存在：比如判断一个数字是否存在于包含大量数字的数字集中（数字集很大，5亿以上！）、 防止缓存穿透（判断请求的数据是否有效避免直接绕过缓存请求数据库）等等、邮箱的垃圾邮件过滤、黑名单功能等等。 去重：比如爬给定网址的时候对已经爬取过的 URL 去重。 4.通过 Java 编程手动实现布隆过滤器 # 我们上面已经说了布隆过滤器的原理，知道了布隆过滤器的原理之后就可以自己手动实现一个了。\n如果你想要手动实现一个的话，你需要：\n一个合适大小的位数组保存数据 几个不同的哈希函数 添加元素到位数组（布隆过滤器）的方法实现 判断给定元素是否存在于位数组（布隆过滤器）的方法实现。 下面给出一个我觉得写的还算不错的代码（参考网上已有代码改进得到，对于所有类型对象皆适用）：\nimport java.util.BitSet; public class MyBloomFilter { /** * 位数组的大小 */ private static final int DEFAULT_SIZE = 2 \u0026lt;\u0026lt; 24; /** * 通过这个数组可以创建 6 个不同的哈希函数 */ private static final int[] SEEDS = new int[]{3, 13, 46, 71, 91, 134}; /** * 位数组。数组中的元素只能是 0 或者 1 */ private BitSet bits = new BitSet(DEFAULT_SIZE); /** * 存放包含 hash 函数的类的数组 */ private SimpleHash[] func = new SimpleHash[SEEDS.length]; /** * 初始化多个包含 hash 函数的类的数组，每个类中的 hash 函数都不一样 */ public MyBloomFilter() { // 初始化多个不同的 Hash 函数 for (int i = 0; i \u0026lt; SEEDS.length; i++) { func[i] = new SimpleHash(DEFAULT_SIZE, SEEDS[i]); } } /** * 添加元素到位数组 */ public void add(Object value) { for (SimpleHash f : func) { bits.set(f.hash(value), true); } } /** * 判断指定元素是否存在于位数组 */ public boolean contains(Object value) { boolean ret = true; for (SimpleHash f : func) { ret = ret \u0026amp;\u0026amp; bits.get(f.hash(value)); } return ret; } /** * 静态内部类。用于 hash 操作！ */ public static class SimpleHash { private int cap; private int seed; public SimpleHash(int cap, int seed) { this.cap = cap; this.seed = seed; } /** * 计算 hash 值 */ public int hash(Object value) { int h; return (value == null) ? 0 : Math.abs(seed * (cap - 1) \u0026amp; ((h = value.hashCode()) ^ (h \u0026gt;\u0026gt;\u0026gt; 16))); } } } 测试：\nString value1 = \u0026#34;https://javaguide.cn/\u0026#34;; String value2 = \u0026#34;https://github.com/Snailclimb\u0026#34;; MyBloomFilter filter = new MyBloomFilter(); System.out.println(filter.contains(value1)); System.out.println(filter.contains(value2)); filter.add(value1); filter.add(value2); System.out.println(filter.contains(value1)); System.out.println(filter.contains(value2)); Output:\nfalse false true true 测试：\nInteger value1 = 13423; Integer value2 = 22131; MyBloomFilter filter = new MyBloomFilter(); System.out.println(filter.contains(value1)); System.out.println(filter.contains(value2)); filter.add(value1); filter.add(value2); System.out.println(filter.contains(value1)); System.out.println(filter.contains(value2)); Output:\nfalse false true true 5.利用Google开源的 Guava中自带的布隆过滤器 # 自己实现的目的主要是为了让自己搞懂布隆过滤器的原理，Guava 中布隆过滤器的实现算是比较权威的，所以实际项目中我们不需要手动实现一个布隆过滤器。\n首先我们需要在项目中引入 Guava 的依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.google.guava\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;guava\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;28.0-jre\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 实际使用如下：\n我们创建了一个最多存放 最多 1500个整数的布隆过滤器，并且我们可以容忍误判的概率为百分之（0.01）\n// 创建布隆过滤器对象 BloomFilter\u0026lt;Integer\u0026gt; filter = BloomFilter.create( Funnels.integerFunnel(), 1500, 0.01); // 判断指定元素是否存在 System.out.println(filter.mightContain(1)); System.out.println(filter.mightContain(2)); // 将元素添加进布隆过滤器 filter.put(1); filter.put(2); System.out.println(filter.mightContain(1)); System.out.println(filter.mightContain(2)); 在我们的示例中，当mightContain（） 方法返回true时，我们可以99％确定该元素在过滤器中，当过滤器返回false时，我们可以100％确定该元素不存在于过滤器中。\nGuava 提供的布隆过滤器的实现还是很不错的（想要详细了解的可以看一下它的源码实现），但是它有一个重大的缺陷就是只能单机使用（另外，容量扩展也不容易），而现在互联网一般都是分布式的场景。为了解决这个问题，我们就需要用到 Redis 中的布隆过滤器了。\n6.Redis 中的布隆过滤器 # 6.1介绍 # Redis v4.0 之后有了 Module（模块/插件） 功能，Redis Modules 让 Redis 可以使用外部模块扩展其功能 。布隆过滤器就是其中的 Module。详情可以查看 Redis 官方对 Redis Modules 的介绍 ：https://redis.io/modules\n另外，官网推荐了一个 RedisBloom 作为 Redis 布隆过滤器的 Module,地址：https://github.com/RedisBloom/RedisBloom. 其他还有：\nredis-lua-scaling-bloom-filter （lua 脚本实现）：https://github.com/erikdubbelboer/redis-lua-scaling-bloom-filter pyreBloom（Python中的快速Redis 布隆过滤器） ：https://github.com/seomoz/pyreBloom \u0026hellip;\u0026hellip; RedisBloom 提供了多种语言的客户端支持，包括：Python、Java、JavaScript 和 PHP。\n6.2使用Docker安装 # 如果我们需要体验 Redis 中的布隆过滤器非常简单，通过 Docker 就可以了！我们直接在 Google 搜索docker redis bloomfilter 然后在排除广告的第一条搜素结果就找到了我们想要的答案（这是我平常解决问题的一种方式，分享一下），具体地址：https://hub.docker.com/r/redislabs/rebloom/ （介绍的很详细 ）。\n具体操作如下：\n➜ ~ docker run -p 6379:6379 --name redis-redisbloom redislabs/rebloom:latest ➜ ~ docker exec -it redis-redisbloom bash root@21396d02c252:/data# redis-cli 127.0.0.1:6379\u0026gt; 6.3常用命令一览 # 注意： key:布隆过滤器的名称，item : 添加的元素。\nBF.ADD ：将元素添加到布隆过滤器中，如果该过滤器尚不存在，则创建该过滤器。格式：BF.ADD {key} {item}。 BF.MADD : 将一个或多个元素添加到“布隆过滤器”中，并创建一个尚不存在的过滤器。该命令的操作方式BF.ADD与之相同，只不过它允许多个输入并返回多个值。格式：BF.MADD {key} {item} [item ...] 。 BF.EXISTS : 确定元素是否在布隆过滤器中存在。格式：BF.EXISTS {key} {item}。 BF.MEXISTS ： 确定一个或者多个元素是否在布隆过滤器中存在格式：BF.MEXISTS {key} {item} [item ...]。 另外，BF.RESERVE 命令需要单独介绍一下：\n这个命令的格式如下：\nBF.RESERVE {key} {error_rate} {capacity} [EXPANSION expansion] 。\n下面简单介绍一下每个参数的具体含义：\nkey：布隆过滤器的名称 error_rate :误报的期望概率。这应该是介于0到1之间的十进制值。例如，对于期望的误报率0.1％（1000中为1），error_rate应该设置为0.001。该数字越接近零，则每个项目的内存消耗越大，并且每个操作的CPU使用率越高。 capacity: 过滤器的容量。当实际存储的元素个数超过这个值之后，性能将开始下降。实际的降级将取决于超出限制的程度。随着过滤器元素数量呈指数增长，性能将线性下降。 可选参数：\nexpansion：如果创建了一个新的子过滤器，则其大小将是当前过滤器的大小乘以expansion。默认扩展值为2。这意味着每个后续子过滤器将是前一个子过滤器的两倍。 6.4实际使用 # 127.0.0.1:6379\u0026gt; BF.ADD myFilter java (integer) 1 127.0.0.1:6379\u0026gt; BF.ADD myFilter javaguide (integer) 1 127.0.0.1:6379\u0026gt; BF.EXISTS myFilter java (integer) 1 127.0.0.1:6379\u0026gt; BF.EXISTS myFilter javaguide (integer) 1 127.0.0.1:6379\u0026gt; BF.EXISTS myFilter github (integer) 0 点击查看原文\n"},{"id":49,"href":"/zh/docs/java/concurrency/2%E8%B5%84%E6%BA%90%E8%AE%BF%E9%97%AE%E5%8F%97%E9%99%90_2_%E9%94%81%E5%92%8C%E6%9D%A1%E4%BB%B6/","title":"锁和条件","section":"并发编程","content":" 可重入锁 # Java SE 5之后提供了位于java.util.concurrent.locks包下的显式互斥机制——Lock对象（显式锁），Lock对象必须被显式的创建，锁定和释放。\n一般情况下 ，ReentrantLock保护代码块的基本结构是：\nmyLock.lock(); // 可重入锁 try{ // 临界区代码 }finally{ myLock.unlock(); } 这个结构可以确保同一时间只有一个线程进入临界区( critical section )，其他线程调用lock()时会被阻塞，直到第一个线程释放锁。\n我们利用锁机制来修改之前的转账逻辑，看看会发生什么：\nstatic class Bank { private final double[] accounts; // lock private Lock lock; public Bank(int accountCount, double money) { // initialize bank account accounts = new double[accountCount]; Arrays.fill(accounts, money); // 使用JDK提供的可重入锁 lock = new ReentrantLock(); } public void transfer(int from, int to, double amount) throws InterruptedException { lock.lock(); try { if (accounts[from] \u0026lt; amount) return; if (from == to) return; // transfer accounts[from] -= amount; System.out.println(Thread.currentThread() + \u0026#34; move away\u0026#34;); accounts[to] += amount; System.out.printf(\u0026#34;%s: %10.2f from %d to %d, Total Balance: %10.2f%n\u0026#34;, Thread.currentThread(), amount, from, to, totalBalance()); } finally { // 确保锁被释放 lock.unlock(); } } private double totalBalance() { double sum = 0; for (double a : accounts) { sum += a; } return sum; } int size() { return accounts.length; } } /* output: (partial) Thread[Thread-0,5,main] move away Thread[Thread-0,5,main]: 948.12 from 22 to 50, Total Balance: 100000.00 Thread[Thread-2,5,main] move away Thread[Thread-2,5,main]: 722.25 from 36 to 84, Total Balance: 100000.00 Thread[Thread-4,5,main] move away Thread[Thread-4,5,main]: 621.82 from 62 to 45, Total Balance: 100000.00 Thread[Thread-6,5,main] move away Thread[Thread-6,5,main]: 628.81 from 18 to 51, Total Balance: 100000.00 Thread[Thread-8,5,main] move away ... *///:~ 上例中，我们对transfer()方法里的核心代码块加锁，执行完成之后释放锁。每个线程在执行任务时都会获取锁，此时其他尝试进入方法的线程将被阻塞。从控制台输出来看，也是这样的：线程是有序执行的，下一个线程总是等待上一个线程执行完才开始执行，这样，无论多少次转账，总金额也不会变。\n思考一个问题：totalBalance()方法是否需要加锁？\n上面的示例使用了可重入锁1（ReentrantLock），可重入的意思是同一个线程可以重复获取锁，由一个计数器来记录锁获取的次数2，它实现了Lock接口的所有方法：\npublic void lock() {\u0026hellip;}\n若锁未被其他线程获取，获取锁，并将锁的计数器置为1，立即返回\n若当前线程已经获取锁，锁的计数器+1，立即返回\n若锁被其他线程占有，那么此线程休眠3\npublic void lockInterruptibly() throws InterruptedException {\u0026hellip;}\n同lock()，不过此法可以被中断（interrupted）\npublic boolean tryLock() {\u0026hellip;}\n尝试获取锁并立即返回，成功获取同lock()并返回true，失败则返回false\npublic boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {\u0026hellip;}\n带有超时机制的尝试获取锁，此法可被中断\npublic void unlock() {\u0026hellip;}\n若计数器\u0026gt;1，则计数器-1，不释放锁，否则计数器置为0并释放锁\npublic Condition newCondition() {\u0026hellip;}\n获取锁的条件对象\n下例展示了尝试获取锁的情况：\npublic class AttemptLocking { private Lock lock = new ReentrantLock(); public static void main(String[] args) throws InterruptedException { AttemptLocking al = new AttemptLocking(); al.untimed(); al.timed(); new Thread(() -\u0026gt; { al.lock.lock(); System.out.println(\u0026#34;fetched\u0026#34;); }).start(); // let thread-0 finish Thread.sleep(100); al.untimed(); al.timed(); } void untimed() { boolean b = lock.tryLock(); try { System.out.println(\u0026#34;tryLock(): \u0026#34; + b); } finally { if (b) lock.unlock(); } } void timed() { boolean b = false; try { b = lock.tryLock(2, TimeUnit.SECONDS); System.out.println(\u0026#34;tryLock(2, TimeUnit.SECONDS): \u0026#34; + b); } catch (InterruptedException e) { // e.printStackTrace(); } finally { if (b) lock.unlock(); } } } /* output: tryLock(): true tryLock(2, TimeUnit.SECONDS): true fetched tryLock(): false tryLock(2, TimeUnit.SECONDS): false *///:~ 可以看到，main()方法中使用新线程获取了锁而不释放，此时再使用方法获取锁时失败，注意timed()方法在2s等待之后才返回失败。\n可重入锁可以构建公平锁或非公平锁，默认使用非公平锁（上下文切换少，吞吐量高）。\n条件 # 思考转账的逻辑，当从from转帐amount到to账户时，若from余额不足，任务会直接返回。\n若想在from账户余额足够时再执行任务而不是直接退出，应该怎样做呢？\njava.util.concurrent.locks包下还提供了Condition对象，这个对象用来管理那些获得锁但是不能执行任务（条件不满足）的线程，条件可以这样使用：\npublic void transfer(int from, int to, double amount) throws InterruptedException { lock.lock(); try { if (accounts[from] \u0026lt; amount) { // could be interrupted suficient.await(); }; if (from == to) return; // transfer accounts[from] -= amount; System.out.println(Thread.currentThread() + \u0026#34; move away\u0026#34;); accounts[to] += amount; System.out.printf(\u0026#34;%s: %10.2f from %d to %d, Total Balance: %10.2f%n\u0026#34;, Thread.currentThread(), amount, from, to, totalBalance()); // invoke all waited condition suficient.signalAll(); } finally { lock.unlock(); } } 此时，当余额不足时，线程不再退出，而时等待其他转账线程唤醒之，知道满足条件继续执行任务。\nvoid await() throws InterruptedException;\n使当前线程等待，和条件相关的锁被释放。等待的线程可以被singal()或singalAll()唤醒；若线程被中断也会解除等待状态；解除状态的线程重新排队获取锁\nvoid signalAll();\n唤醒所有在此条件上等待的线程，被唤醒的线程需要重新获取锁\nvoid signal();\n唤醒在此条件上等待的任一线程，此方法具有随机性\n此外，Condition还有一些带有超时参数和阻止中断的方法，请参照 Java SE API。\n到此为止，我们可以利用锁和条件将转账任务改进为线程安全，功能更丰富类：\npublic class SynchronizedTransfer { static double INITIAL_MONEY = 1000; public static void main(String[] args) { int ACCOUNTS = 100; Bank bank = new Bank(ACCOUNTS, INITIAL_MONEY); for (int i = 0; i \u0026lt; ACCOUNTS; i++) { Thread t = new Thread(new TransferTask(bank)); t.start(); // test thread /* new Thread(new Runnable() { @Override public void run() { double v = bank.totalBalance(); BigDecimal bigDecimal = new BigDecimal(v) .setScale(2,BigDecimal.ROUND_HALF_UP); if (bigDecimal.intValue() != 100000){ System.out.println(bigDecimal + \u0026#34; is not even!\u0026#34;); } } }).start();*/ } } static class TransferTask implements Runnable { private Bank bank; private int size; private double maxAmount = INITIAL_MONEY; public TransferTask(Bank bank) { this.bank = bank; this.size = bank.size(); } @Override public void run() { try { int from = (int) (size * Math.random()); int to = (int) (size * Math.random()); // int to = (from + 1 \u0026gt;= size) ? 0 : from + 1; double amount = maxAmount * Math.random(); bank.transfer(from, to, amount); Thread.sleep((long) (size * Math.random())); } catch (InterruptedException e) { // e.printStackTrace(); } } } static class Bank { private final double[] accounts; // lock private Lock lock; // condition private Condition suficient; public Bank(int accountCount, double money) { // initialize bank account accounts = new double[accountCount]; Arrays.fill(accounts, money); lock = new ReentrantLock(); suficient = lock.newCondition(); } public void transfer(int from, int to, double amount) throws InterruptedException { lock.lock(); try { if (accounts[from] \u0026lt; amount) { // could be interrupted suficient.await(); }; if (from == to) return; // transfer accounts[from] -= amount; System.out.println(Thread.currentThread() + \u0026#34; move away\u0026#34;); accounts[to] += amount; System.out.printf(\u0026#34;%s: %10.2f from %d to %d, Total Balance: %10.2f%n\u0026#34;, Thread.currentThread(), amount, from, to, totalBalance()); // invoke all waited condition suficient.signalAll(); } finally { lock.unlock(); } } private double totalBalance() { double sum = 0; for (double a : accounts) { sum += a; } return sum; } int size() { return accounts.length; } } } 实际上，上例在totalBalance()方法不加锁的情况下，转账任务也是安全的。\n回答之前提出的问题：totalBalance()方法究竟是否需要加锁？\n请注意main()方法中被注释的部分，它创建一个线程（记为T）去读取所有账户的余额，判断余额是否和初始化时相等。使用BigDecimal是为了处理Double数据类型的精度丢失。在totalBalance()不加锁的情况下，我们很容易看到这样的输出：\n/* Thread[Thread-0,5,main] move away Thread[Thread-0,5,main]: 793.81 from 86 to 37, Total Balance: 100000.00 99206.19 is not even! Thread[Thread-2,5,main] move away Thread[Thread-2,5,main]: 814.24 from 30 to 49, Total Balance: 100000.00 ... *///:~ 这给出一个暗示：在有其他的线程访问totalBalance()方法时，totalBalance()不是线程安全的。尽管transfer()方法加锁了，任意时刻只有一个线程访问totalBalance()方法，但是T和转账线程不相关，它可被CPU调度与转账线程竞争对totalBalance()方法中的accounts资源的访问，正如上述输出所显示的那样。\n所以，是否加锁应该以资源是否共享为参照\n当没有被注释的部分时，由于transfer()方法加锁了，线程在transfer()方法中调用totalBalance()不会受到其他线程的影响；当被注释的线程运行时，这时totalBalance资源可能被共享访问了，为保证安全就必须加锁。\n可重入锁是典型的独占锁。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n计数器最大231-1。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n实际上线程进入同步队列中排队，并自旋尝试获取锁，获取失败则线程的中断状态置位。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":50,"href":"/zh/docs/java/collections/3_Set/","title":"Set","section":"集合框架","content":"Set是不含重复元素的集，严格来讲，Set不允许当e1.equals(e2)为真时， e1 和 e2 同时出现在集合中。Set最多允许一个null元素。\n将可变对象置入Set时需要特别小心，当对象的改动影响到了元素之间的equals()比较的结果，那么Set的行为就变得不确定了。因此，不能将Set本身作为Set的元素。\n散列集 # ⚠️关于散列的桶与桶中的元素，还有部分描述可能存在问题。\n数组和链表能够记录元素的插入顺序，这对于通过索引快速对元素执行操作很有利，但是如果忘记了索引，那么需要从头遍历，这在数据量很大的情况下效率低下。在不考虑元素的顺序情况下，能提供快速查询所需要的数据，这就是散列表(hash table)。\n散列表为每个对象计算一个整数，称为散列码( hash code )，这意味着如果将自定义对象作为Set的对象，那么必须要负责实现这个类的 hashCode 方法，还有一点要注意的是，hashCode和equals方法之间存在约束关系？，因此最好也重写equals方法以保证一致性。\nJava中的散列表是用链表数组实现的，每个链表称为桶。\n散列表(hash table) form Core Java\n设有散列表桶数为 x ，有对象 y ，那么散列表如何存入对象呢？\n\\[z = hash(y) \\% x\\] 那么对象 y 应该放在 z 号桶中。\n若桶被占满1了，就会发生散列冲突(hash collection)，散列表会尽量避免散列冲突。\n在Java 8 中，桶满时链表会转换成为平衡二叉树。\n保证散列中桶数富余能够有效提升散列表的性能，反之若要插入的元素过多，散列表的性能就会降低。\n散列表一般可初始化桶数，通常将桶数设置为容量的75%～150%。若不知道元素的个数，散列表太满就会导致再散列（ rehashed ），在散列就是创建一个桶数更多的表（加倍），将所有的元素copy到新表，丢弃原来的表。在散列由桶数和**装填因子（ load factor ）**两方面决定，如果不加指定，装填因子默认为0.75，若\n$$ 散列元素数 \u0026gt; 桶数 * 装填因子 $$\n就会发生再散列\nJava标准类库中，散列表的桶数总是2n，默认值是16。\nHashSet # HashSet是由HashMap实现的基于散列表的集合，允许至多一个null元素。\n不论桶数，当元素被合理地分配在散列表的桶中时，HashSet的基本操作（add，remove，contains和size）的效率是一致的；但是迭代HashSet所需要的时间则与元素数量以及组成集的HashMap桶数正相关。因此合理的设置桶数非常有必要。\n与List不同的是，HashSet的迭代器不能保证元素的迭代顺序，并且迭代器也是 fail-fast 的，在使用迭代器时同样需要留意 ConcurrentModificationException。\nHashSet主要字段：\nprivate transient HashMap\u0026lt;E,Object\u0026gt; map; // Dummy value to associate with an Object in the backing Map private static final Object PRESENT = new Object(); HashSet构造器：\npublic HashSet() {map = new HashMap\u0026lt;\u0026gt;();} public HashSet(Collection\u0026lt;? extends E\u0026gt; c) {...} public HashSet(int initialCapacity, float loadFactor) {...} public HashSet(int initialCapacity) {...} 所以HashSet就是一个所有值为PRESENT常量的 HashMap的KeySet，参考如下示例：\nstatic void initializationTest() throws Exception { Set\u0026lt;Integer\u0026gt; hs = new HashSet\u0026lt;\u0026gt;(); hs.add(1); hs.add(2); Class\u0026lt;?\u0026gt; cls = HashSet.class; Field fm = cls.getDeclaredField(\u0026#34;map\u0026#34;); fm.setAccessible(true); System.out.println(fm.get(hs).getClass()); @SuppressWarnings(\u0026#34;unchecked\u0026#34;) HashMap\u0026lt;Integer, Object\u0026gt; o = (HashMap\u0026lt;Integer, Object\u0026gt;) fm.get(hs); for (Map.Entry\u0026lt;Integer, Object\u0026gt; entry : o.entrySet()) { System.out.println(entry.getKey() + \u0026#34;:\u0026#34; + entry.getValue()); } } /* output class java.util.HashMap 1:java.lang.Object@1540e19d 2:java.lang.Object@1540e19d *///:~ 如果将自定义对象存入HashSet，必须覆盖 equals 和 hashCode 方法\nLinkedHashSet # HashSet的子类，与HashSet的 区别在于LinkedHashSet使用双端链表维护集中的元素，因此元素能够被有序迭代（迭代顺序是元素的插入顺序），当元素添加到集中时，便会并入LinkedList中。\n链表散列表 from Core Java\nHashSet中有一个包访问权限的构造器，专门用来构造LinkedHashSet：\nHashSet(int initialCapacity, float loadFactor, boolean dummy) { map = new LinkedHashMap\u0026lt;\u0026gt;(initialCapacity, loadFactor); } 可以看到，LinkedHashSet实质上是LinkedHashMap的是个KeySet\n和HashSet的区别（性能上）:\n性能稍微比HashSet低一点 由于加入了链表，迭代LinkedHashSet时只与集合的容量(size)有关，而与桶数无关；而HashSet的迭代效率与二者都有关 LinkedHashSet设置过大的桶数所带来的性能（负）影响小于HashSet TreeSet # 树集是由红—黑树实现的有序集合(sorted collection)。在Java集合框架中，TreeSet由TreeMap实现，和HashSet一样，TreeSet是TreeMap的所有值为new Object()的keySet。\nTreeSet是NavigableSet和SortedSet的实现，其中NavigableSet接口继承了SortedSet接口\nSortedSet接口定义了如下方法：\nComparator\u0026lt;? super E\u0026gt; comparator(); 获取用于排序的比较器，若使用comparable则返回null SortedSet\u0026lt;E\u0026gt; subSet(E fromElement, E toElement); 返回一个子集，元素范围从 fromElement （含）到 toElement （不含）， 当 fromElement 和 toElement 相等时，返回空集， 返回的集合是一个视图，对此视图的修改会作用到原集合上，反之亦然 SortedSet\u0026lt;E\u0026gt; headSet(E toElement); SortedSet\u0026lt;E\u0026gt; tailSet(E fromElement); 返回一个子集，元素小于/大于 toElement/fromElement ， 返回的集合是一个**视图**，对此视图的修改会作用到原集合上，反之亦然 E first(); E last(); 获取集合中最小/最大的元素 NavigableSet继承了SortedSet，并新增了方法：\nE lower(E e); E higher(E e); 返回小于 *e* 的最大/大于 *e* 的 最小元素，若不存在则返回null E floor(E e);** E ceiling(E e);** 返回小于等于 *e* 的最大/大于等于 *e* 的 最小元素，若不存在则返回null pollFirst(); E pollLast(); 获取并删除集合中的最小/最大元素，若集合为空则返回null Iterator\u0026lt;E\u0026gt; descendingIterator(); 获取倒序迭代器 TreeSet中的元素总是有序的，排序规则可以是默认的自然排序（ comparable ）或在构造器中指定比较器（ comparator ），和PriorityQueue一样，若向TreeSet插入未排序的元素，会抛出 ClassCastException\n需要注意的是，在使用自定义比较规则时，置入TreeSet中的元素需要考虑到comparable/comparator 方法和 equals 方法的一致性\n参考如下示例：\n//... 省略头部 static void consistenceTest() { class Item implements Serializable { private int code; private String name; public Item(int code, String name) { this.code = code; this.name = name; } @Override public boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Item item = (Item) o; if (code != item.code) return false; return Objects.equals(name, item.name); } @Override public int hashCode() { int result = code; result = 31 * result + (name != null ? name.hashCode() : 0); return result; } } // 故意修改比较器的相等逻辑 SortedSet\u0026lt;Item\u0026gt; ss = new TreeSet\u0026lt;\u0026gt;((o1, o2) -\u0026gt; o1.code - o2.code + 1); Item item = new Item(1, \u0026#34;apple\u0026#34;); ss.add(item); ss.add(item); // Set中出现重复元素 ss.forEach(System.out::println); } /* output: TreeSetTest$1Item@58b8379 TreeSetTest$1Item@58b8379 *///:~ 上例中，对于Item对象 a 和 b ，以及Item的比较器 c ，有\na.equals(b) \u0026amp;\u0026amp; c.compare(a,b)!=0 成立，那么第二次add()就会返回true，此时TreeSet中出现了重复的元素！这与Set.add方法的约束相悖，为什么？原因在于尽管Set是以equals来判断元素相等的，但是TreeSet使用的是比较器规定的方法，上例在TreeSet的角度看， a 和 b 并不等，这样会使集合出现难以理解的行为。\n因此，保持比较器和equals方法的一致性是很重要的。\n值得一提的是，NavigableSet的获取子集的方法，可以用来对原集合进行修改；同样地，若原集合发生改变，子集也会随之改变\n这与ArrayList的SubList不同，SubList获取子集后对原集合的修改会引发ConcurrentModificationException\n//...省略头部 static void eleTest() { TreeSet\u0026lt;String\u0026gt; ss = new TreeSet\u0026lt;String\u0026gt;() {{ add(\u0026#34;nokia\u0026#34;); add(\u0026#34;motorola\u0026#34;); add(\u0026#34;apple\u0026#34;); add(\u0026#34;samsung\u0026#34;); add(\u0026#34;mi\u0026#34;); add(\u0026#34;oppo\u0026#34;); add(\u0026#34;vivo\u0026#34;); add(\u0026#34;sony\u0026#34;); add(\u0026#34;google\u0026#34;); }}; SortedSet\u0026lt;String\u0026gt; headSet = ss.headSet(\u0026#34;oppo\u0026#34;, false); // equals // SortedSet\u0026lt;String\u0026gt; headSet = ss.headSet(\u0026#34;oppo\u0026#34;); ss.add(\u0026#34;huawei\u0026#34;); // 之前的子集中也会添加 Iterator\u0026lt;String\u0026gt; i = headSet.iterator(); int j = 0; while (i.hasNext()) { j++; i.next(); if (j % 2 == 0) { i.remove(); } } headSet.forEach(System.out::println); System.out.println(\u0026#34;contains google? \u0026#34; + ss.contains(\u0026#34;google\u0026#34;)); // 获取当前集合的逆序迭代器 Iterator\u0026lt;String\u0026gt; i2 = ss.descendingIterator(); System.out.println(\u0026#34;vivo\u0026#34;.equals(i2.next())); } /* output: apple huawei motorola contains google? false true *///:~ 上例中，获取headSet之后对原集合添加元素，且添加的元素正好在子集的范围中 ，那么子集中也会添加这个元素；\n每个桶里都有元素么？每个桶至多有多少元素？通过源码来看HashSet和HashMap一个桶里至多有一个元素\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":51,"href":"/zh/docs/java/basic/4_final%E5%85%B3%E9%94%AE%E5%AD%97/","title":"final关键字","section":"面向对象","content":" final关键字 # 不同的使用环境下，final关键字的含义有细微差别，但通常它指“这是无法改变的”。\nfinal数据 # final关键字通常用来表示一块数据是恒定不变的：\n常量 # 比如一个永不改变的编译时常量 \u0026mdash;\u0026gt; 对应前文所谓静态常量\npublic final double PI = 3.14\n如果使用static final来修饰变量，那么它就是一个标准的编译时常量（静态常量）\npublic static final double PI = 3.14\n在Java中，编译时常量必须是基本数据类型或字符串，声明时必须赋值\n一个在运行时被初始化的值，你不希望它被改变\npublic final int RANDOM = new Random().nextInt(47)\n一个既是final也是static的域只占用一段不能改变的存储空间\n当对非基本数据类型使用final时，其含义稍微有点变化，其使引用恒定不变，这就是说被final修饰的对象引用无法使其指向另一个对象，但是对象内容却是可以被修改的。\nJava允许声明一个空白final域，但是这个final域在使用前必须使用构造器（常见）或表达式初始化。\n参数 # 此外，Java允许参数列表中将参数指明为final，这意味着你无法在方法中更改参数引用所指向的对象，但是对象状态也是可变的。\n注意此处的表述。作为对比，Java引用对象作为参数时， 参数引用指向的对象是可以改变的（尽管这个改变不能应用到对象引用上\u0026mdash;对象引用不可变）\n参考如下代码 Employee2：\n// 继续使用上例中的Employee2 public class FinalParam { static void with(final Employee2 e){ raiseSalary(e); // object it\u0026#39;s self can be modified System.out.println(\u0026#34;salary of e = \u0026#34; + e.getSalary()); } static void raiseSalary(final Employee2 e){ e.raiseSalary(3); } static void swap(final Employee2 j, final Employee2 k){ Employee temp = j; // object reference can not be modified // k = temp; // not allowed // j = k; // not allowed } static void g(final int i){ // i++; // not allowed } public static void main(String[] args) { Employee x = new Employee(\u0026#34;ali\u0026#34;, 1000); with(x); System.out.println(\u0026#34;salary of x = \u0026#34; + x.getSalary()); } } /* output: salary of e = 3000 salary of x = 3000 *///:~ final参数一般用来向匿名内部类中传递数据。\n实际上，Java并没有提供任何对象恒定不变的途径，虽然可以通过编程取得对象恒定不变的效果单例。\nfinal方法\u0026ndash;阻止继承 # 当将一个方法声明为final时，其主要作用就是锁定方法，阻止继承，这往往是出于设计的考虑。\n需要特殊说明的是：如果一个方法是private的，那么它就被隐式地声明为final了，因为由于无法取用private方法，也就无法覆盖之。\n参考如下代码：\npublic class FinalMethodT{ public static void main(String[] args) { FinalMethodExt x = new FinalMethodExt(); x.f(); x.g(); x.p(); System.out.println(\u0026#34;----\u0026#34;); // upcast FinalMethod y = x; y.f(); y.g(); // y.p() // can\u0026#39;t access System.out.println(\u0026#34;----\u0026#34;); FinalMethod z = new FinalMethod(); z.f(); z.g(); // z.p(); // can\u0026#39;t access } } class FinalMethod { void f(){ System.out.println(\u0026#34;f()\u0026#34;); } final void g(){ System.out.println(\u0026#34;g()\u0026#34;); } // final is redundant actually private final void p(){ System.out.println(\u0026#34;p()\u0026#34;); } } class FinalMethodExt extends FinalMethod{ void f() { System.out.println(\u0026#34;ext f()\u0026#34;); } // cannot override // final void g(){ System.out.println(\u0026#34;ext g()\u0026#34;); } final void p(){ System.out.println(\u0026#34;ext p()\u0026#34;); } } /* output: ext f() g() ext p() ---- ext f() g() ---- f() g() *///:~ 基类和导出类的p方法，看上去像是导出类覆盖了基类的方法，实际上这是一种“字面”的覆盖，因为private方法并不是基类接口的一部分，它和导出类的p方法只是具有相同名称而已。\n还需要注意的是，即使使用了向上转型试图调用基类的方法，实际上却失败了，因为子类覆盖了这个方法。这种行为在Java中被称为动态绑定，即编译器知道实际引用的对象类型，从而去调用对应的方法。\nfinal类\u0026ndash;阻止继承 # 如果将一个类声明为final的（通常使用final class ...），意味着这个类不能被继承。\n也就是说，该类的所有方法都含有一个隐式的final修饰符。\nfinal类的域可以是或不是final，规则同 final数据一致。\nhttps://docs.oracle.com/javase/specs/jls/se18/html/jls-17.html#jls-17.5\n"},{"id":52,"href":"/zh/docs/note/course/","title":"课程笔记","section":"Note","content":"本部分内容记录了系列课程的学习笔记。\n这可能是一个漫长、缓慢且很难坚持的的过程。\n操作系统原理 # Algorithms, Part I # "},{"id":53,"href":"/zh/docs/craft/algo/","title":"算法讨论","section":"Craft","content":"此目录下的内容从记录一个牛客网上的机试题开始。\n涉及的内容比较倾向于设计合适的算法解决特定的问题，如果想提升薪水能力，熟悉算法是不可缺少的能力啊。\n当然，也会记录相关算法书籍中的内容，目前手头的算法书籍只有\n数据结构与算法分析（纸质） 算法导论（第三版 pdf） 算法图解(pdf) 后续希望通过试题和书籍这种交叉学习的方式，扩充算法方面的知识。\n当然，解决方案都是Java语言描述的。\n"},{"id":54,"href":"/zh/docs/note/pys/4_important_funcs/","title":"4个重要的内置函数","section":"Python","content":" "},{"id":55,"href":"/zh/docs/craft/db/sql/5_%E4%BD%BF%E7%94%A8mysql%E7%9A%84%E8%A1%8C%E9%94%81/","title":"MySQL显式锁简单介绍","section":"mysql","content":"对于MySQL数据库而言， 事务的隔离级别在不同程度上保证了数据一致性。\n我们知道，事务的四大特性：原子性、一致性、隔离性、持久性，其中隔离性就是通过锁机制来保证的。\n另外3个性质，通过MySQL的redo log 和undo log来保证。\nMySQL对每条SQL语句的执行，都添加了一个隐式事务，言外之意，就是添加了隐式锁。\n除了隐式锁之外，MySQL还可以使用显式锁。\n这是从锁的可见性（或者使用方式）上来区分锁。本文不讨论MySQL的粒度锁（表锁，行锁，页锁）。\n实际开发中，很少的业务场景需要使用显式锁，基本上运用好MySQL的事务隔离机制，就可以处理好基本上95%大体上的问题。 本文简单地讨论了MySQL显式锁的使用。\nMySQL显式锁可以简单地分为2类：\n读锁（S锁，共享锁，Shared Lock） 写锁（X锁，排它锁，Exclusive Lock） 读锁 # MySQL使用\nselect ... lock in share mode 或者（8）\nselect ... for share 意思很明确，读锁是共享的，不同的会话可以同时获取读锁，因为读并不会改变共享数据，可以提升并发性能。实际上，读”可能“不需要加锁。\n耗时长的事务，可以对“读”加锁，来防止其他会话对数据进行改动。\n在MVCC的行为中，可重复读隔离级别下，新会话是可以改动其他事务读取的数据的，不过这个改动，在已经开始的事务中是不可见的（快照，以及保证可重复读）。\nmysql\u0026gt; begin; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from user where id = 1 for share; +----+------+--------+------+------------+ | id | name | gender | age | note | +----+------+--------+------+------------+ | 1 | anna | 1 | 17 | quiet girl | +----+------+--------+------+------------+ 1 row in set (0.00 sec) 会话1: 开启事务，并且对id=1的数据行添加读锁\nmysql\u0026gt; begin; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from user where id = 1 for share; +----+------+--------+------+------------+ | id | name | gender | age | note | +----+------+--------+------+------------+ | 1 | anna | 1 | 17 | quiet girl | +----+------+--------+------+------------+ 1 row in set (0.00 sec) mysql\u0026gt; select * from user where id = 1 for update; ^C^C -- query aborted ERROR 1317 (70100): Query execution was interrupted mysql\u0026gt; update user set age = 16 where id = 1 ; ^C^C -- query aborted ERROR 1317 (70100): Query execution was interrupted 会话2: 开启事务，更新id=1的数据失败\n很明显可以看到：\n不同的会话可以对同一数据加读锁； 不同的会话无法获取同一数据的写锁； 加读锁可以保护数据免被修改； 写锁 # MySQL使用\nselect ... for update 对数据加写锁。\nmysql\u0026gt; begin; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from user where id = 1 for update; +----+------+--------+------+------------+ | id | name | gender | age | note | +----+------+--------+------+------------+ | 1 | anna | 1 | 17 | quiet girl | +----+------+--------+------+------------+ 1 row in set (0.00 sec) mysql\u0026gt; update user set name = \u0026#39;annie\u0026#39; where id = 1; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 会话1: 开启事务，对id=1的数据行添加写锁\nmysql\u0026gt; select * from user where id = 1 for share ; ^C^C -- query aborted ERROR 1317 (70100): Query execution was interrupted mysql\u0026gt; update user set name = \u0026#39;anna\u0026#39; where id = 1 ; ^C^C -- query aborted ERROR 1317 (70100): Query execution was interrupted mysql\u0026gt; select * from user where id = 1 for share skip locked; Empty set (0.00 sec) mysql\u0026gt; select * from user where id = 1; +----+------+--------+------+------------+ | id | name | gender | age | note | +----+------+--------+------+------------+ | 1 | anna | 1 | 17 | quiet girl | +----+------+--------+------+------------+ 1 row in set (0.00 sec) 会话2: 开启事务，尝试获取id=1的数据行的锁\n可以看到，对数据加写锁之后：\n其他会话无法获取读锁； 其他会话无法更新数据； MySQL提供了 skip locked 语句来跳过锁 可以查询事务开始前的数据，无法获取事务开始后其他会话的更新（MVCC）。 在开发实践中，一般使用乐观锁机制。一些中间件框架（如mybatis-plus）支持使用乐观锁更新数据。\n乐观锁是一种思想，它默认没有其他会话更改数据，因此总是尝试直接更改数据，而不是去加锁。这样可以提高读取性能。\n常用“版本号”来作为乐观锁的实现机制。意思就是在表中添加version字段。\n其基本逻辑是：\nflowchart LR A(更新前获取版本号 v1) --\u003e B(更新时获取版本号 v2) B --\u003e C{v1 == v2?} C --\u003e |Y| D(更新 v = v1 + 1) C --\u003e |N| E(不更新) update ... set version = version + 1 where `version` = version; 拓展阅读：\nhttps://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html#innodb-shared-exclusive-locks https://dev.mysql.com/doc/refman/8.0/en/innodb-locks-set.html https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html "},{"id":56,"href":"/zh/docs/craft/algo/01%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/","title":"背包问题2例","section":"算法讨论","content":"背包问题其实属于动态规划（ Dynamic Programming ）问题的一种。动态规划的手段是将大问题拆解为多个小问题，小问题解决之后，大问题也就随之而解。\n背包问题的典型描述是：\n给定n种物品和一背包。物品 i 的重量似乎 wi，其价值为 vi，背包的容量为 c。问应该如何选择装入背包中的物品， 使得装入背包中物品的总价值最大？\n引例 # 为了阐述问题方便，引用算法图解一书中关于此书的图解好了(没有比这更好的解释方法了)。首先引入问题：\n假设你是一个小偷，有一个可以装下4磅东西的背包，你可以偷窃的商品有:\n4磅的音响，价值3000 3磅的笔记本电脑，价值2000 1磅的吉他，价值1500 当然，这个问题很简单，就算是遍历所有的可能性，也不过8种而已($2^3$)，不过当商品的数量增加时，可能性是指数式增长的，所以这种计算方式的运算时间复杂度是$O(2^n)$。现在尝试使用动态规划的方法来解决问题。\n动态规划算法从一个网格开始，如下表的空白部分表示了示例问题中需要填充的表格：\n重量 价值 商品 \\ 背包重量 1 2 3 4 4 3000 音响 3 2000 笔记本电脑 1 1500 吉他 比如音响行第1列表示重量为1的背包装入音响所能获取的最大价值，笔记本电脑行第2列的表示重量为2的背包装入音响和笔记本电脑所能获取的最大价值\u0026hellip;以此类推。现在我们尝试填充此表格，按照行的顺序\n音响行\n根据音响的重量，我们很容易就知道，重量为1、2、3的背包无法装下音响，当背包重量为4时，可以装下音响，此时的价值是3000，所以音响行填充完毕后，表格应该长这样：\n重量 价值 商品 \\ 背包重量 1 2 3 4 4 3000 音响 0 0 0 3000 3 2000 笔记本电脑 1 1500 吉他 笔记本电脑行\n接下来继续填充笔记本电脑行，记住，此时背包可以选择的物品有音响和笔记本电脑2种。\n当背包重量为1、2时，装不下笔记本电脑和音响中的任意一件商品，最大价值为0； 当背包重量为3时，不放入笔记本电脑时的最大价值为0（上一行已经计算得知），当放入笔记本电脑时，获得笔记本的电脑的价值2000，其剩余重量为0，无法装入音响；2000\u0026gt;0，因此背包重量为3时获得的最大价值就是2000； 当背包重量为4时，不放入笔记本电脑获得的最大价值是3000，当放入笔记本电脑时，获得笔记本的电脑的价值2000，其剩余重量为1，由音响行的计算结果可知，当背包重量为1时获得的最大价值是0（音响行第一列的值）；3000\u0026gt;2000+0，因此背包重量为3时获得的最大价值就是3000； 所以填充第二行之后的表格长这样：\n重量 价值 商品 \\ 背包重量 1 2 3 4 4 3000 音响 0 0 0 3000 3 2000 笔记本电脑 0 0 2000 3000 1 1500 吉他 吉他行\n接下来填充吉他行，此时，背包可以选择的物品有音响、笔记本电脑和吉他3种。\n当背包重量为1时，恰好可以装入吉他，因此其获得的最大价值就是1500； 当背包重量为2时，不放入吉他所能获得的最大价值是0，装入吉他之后，其获得价值1500；剩余重量为1，装入笔记本电脑和音响的最大价值就是0（笔记本电脑行的第1列）；因此最大价值是1500； 当背包重量为3时，不放入吉他所能获得的最大价值是2000，装入吉他之后获得价值1500，剩余重量为2，装入笔记本电脑和音响所能获取的最大价值是0（笔记本电脑行的第2列）；因此最大价值是2000； 当背包重量为4时，不放入吉他所能获取的最大价值是3000，装入吉他之后获得价值1500，剩余重量为3，装入笔记本电脑和音响所能获取的最大价值是2000（笔记本电脑行的第3列），1500+2000\u0026gt;3000，故获得的最大价值是3500 所以填充第三行之后的表格长这样：\n重量 价值 商品 \\ 背包重量 1 2 3 4 4 3000 音响 0 0 0 3000 3 2000 笔记本电脑 0 0 2000 3000 1 1500 吉他 1500 1500 2000 3500 到此为止，表格填充完毕，从表格中可以直观地看到容量为4的背包所能获取的最大价值是3500。除此之外，还可以看到，表格的行从左至右，列从上至下（填充顺序）所获得的最大价值都是递增的（或维持不变），不可能出现最大价值变小的情况！同时，计算容量较小的背包的最大价值这个工作并没有白费，它将用来帮助快速计算大容量的背包所能获取的最大价值。\n关于背包问题，行（商品）的顺序并不影响最终的结果。对上例而言，任意打乱行的顺序获得的结果都是一样的。\n上例中，若在可选商品列表中添加一个重1磅，价值2000美元的iphone，结果会如何呢？\n我们可以在已完成的表格中继续添加一个iphone行，得到的结果应该是这样的：\n重量 价值 商品 \\ 背包重量 1 2 3 4 \u003e 4 3000 音响 0 0 0 3000 \u003e 3 2000 笔记本电脑 0 0 2000 3000 \u003e 1 1500 吉他 1500 1500 2000 3500 \u003e 1 2000 iphone 2000 3500 3500 4000 如果新增一个商品，重量为1.5磅，价值为2000元，动态规划表应该如何变化呢？\n只需要将动态规划表格的列粒度变为0.5，再重新规划即可\n状态转移方程 # 对于商品而言，其只有2个状态：放入背包或者不放入背包。动态规划的过程就是计算出不同承重的背包所能装入的最大价值，当考虑是否应当将物品装入背包时，比较其装入背包和不装入背包2种情况下获得的最大价值即可得到该背包的最大价值。\n我们可以使用一个二维数组dp[i][j]表示i件物品放入重量为j的背包所能获取的最大价值。\n如dp[3][4]=3500表示3件可选物品，放入容量为4的背包所获得的最大价值为3500。\n和前面讨论的一样，dp[i][j]的计算分为3步：\n该物品不放入背包的最大价值 v1 = dp[i-1][j] 该物品放入背包的最大价值 v2 = vi + dp[i-1][j-wi]，其中 vi表示物品i的价值 dp[i-1][j-wi]表示前i-1件物品放入容量为j-wi的背包中获取的最大价值，wi为物品i的重量 比较v1和v2，取较大值作为dp[i][j] 综上，背包问题的状态转移方程可以总结为：\n$$ dp[i][j] = max(dp[i-1][j],dp[i-1][j-w[i]]+v[i]) $$\nJava代码示例 # 了解了思路，我们就可以轻松地将其使用编程语言解释：\npublic class PackIssue { public static void main(String[] args) { Good[] gs = new Good[]{ null, new Good(4, 3000), new Good(3, 2000), new Good(1, 1500) }; int N = 4; // 背包最大容量 // 物品数, 空一行是为了防止计算dp时数组指针越界 // 不然计算dp时i = 0需要单独讨论 int m = gs.length - 1; // 最大价值表是一张N*m的二维表格，表格的每一格数据dp[i][j]表示i件物品放入容量为j的背包中 // 所能获取的最大价值，这个最大价值的形成有2个条件：物品i要么放入背包，要么不放入背包 // 典型的dp公式 // dp[i][j] = max{dp[i-1][j], dp[i-1,j-w[i]] + v[i]} // N也无需从0开始，没有意义 int[][] dp = new int[m + 1][N + 1]; for (int i = 1; i \u0026lt; m + 1; i++) { int w = gs[i].w; for (int j = 1; j \u0026lt; N + 1; j++) { if (j \u0026gt;= w) { dp[i][j] = Math.max( dp[i - 1][j], dp[i - 1][j - w] + gs[i].v ); } else { dp[i][j] = dp[i - 1][j]; } } } for (int i = 1; i \u0026lt; m + 1; i++) { for (int j = 1; j \u0026lt;= N; j++) { System.out.printf(\u0026#34;%5d\\t\u0026#34;, dp[i][j]); } System.out.println(); } System.out.println(dp[m][N]); } } class Good { // 物品重量 int w; // 物品价值 int v; public Good(int w, int v) { this.w = w; this.v = v; } } /* output 0\t0\t0\t3000 0\t0\t2000\t3000 1500\t1500\t2000\t3500 3500 *///:~ 复杂的背包问题 # 这个问题发现自华为的机试题库，来源：https://www.nowcoder.com/questionTerminal/f9c6f980eeec43ef85be20755ddbeaf4\n王强今天很开心，公司发给N元的年终奖。王强决定把年终奖用于购物，他把想买的物品分为两类：主件与附件，附件是从属于某个主件的，下表就是一些主件与附件的例子：\n主件 附件 电脑 打印机，扫描仪 书柜 图书 书桌 台灯，文具 工作椅 无 如果要买归类为附件的物品，必须先买该附件所属的主件。每个主件可以有 0 个、 1 个或 2 个附件。附件不再有从属于自己的附件。王强想买的东西很多，为了不超出预算，他把每件物品规定了一个重要度，分为 5 等：用整数 1 ~ 5 表示，第 5 等最重要。他还从因特网上查到了每件物品的价格（都是 10 元的整数倍）。他希望在不超过 N 元（可以等于 N 元）的前提下，使每件物品的价格与重要度的乘积的总和最大。\n设第 j 件物品的价格为 v[j] ，重要度为 w[j] ，共选中了 k 件物品，编号依次为 j 1 ， j 2 ，……， j k ，则所求的总和为： v[j 1 ]*w[j 1 ]+v[j 2 ]*w[j 2 ]+ … +v[j k ]*w[j k ] 。（其中 * 为乘号）\n请你帮助王强设计一个满足要求的购物单。\n输入描述:\n输入的第 1 行，为两个正整数，用一个空格隔开：N m。（其中 N （ \u0026lt;32000 ）表示总钱数， m （ \u0026lt;60 ）为希望购买物品的个数。） 从第 2 行到第 m+1 行，第 j 行给出了编号为 j-1 的物品的基本数据，每行有 3 个非负整数 v p q 其中 v 表示该物品的价格（ v\u0026lt;10000 ）， p 表示该物品的重要度（ 1 ~ 5 ）， q 表示该物品是主件还是附件。如果 q=0 ，表示该物品为主件，如果 q\u0026gt;0 ，表示该物品为附件， q 是所属主件的编号 输出描述:\n输出一个正整数，为不超过总钱数的物品的价格与重要度乘积的总和的最大值（ \u0026lt;200000 ）。\n示例输入：\n1000 5\n800 2 0\n400 5 1\n300 5 1\n400 3 0\n500 2 0\n示例输出：\n2200\n这个问题和简单的背包问题有诸多类似，差别在于，每一个物品多了附件，因此计算dp[i][j]时需要考虑的情况变得复杂了。将主件+附件看作一个整体计算dp，问题也就得到解决了。\n除了动态规划之外，这个题目的题干也给出了很多有用的信息（审题也很重要啊）：\n每个主件只有至多2个附件； 每一行（n）输入的数据都有一个id（n-1）； 若q = 0 并不是其id为0，而是指示其是主件，其id由输入次序指定； 若q\u0026gt;0，指示其是附件，q的值是其主件的id，其id由输入次序指定； 物品价格是10的倍数——指定表格列的粒度 获取并理解上面的信息，对于构建模型和录入数据都是非常有利的。就使用示例输入来分析，示例输入了5个物品，id为1～5。其中id=2和id=3的物品为id=1的附件，id=4和id=5的物品为主件。\n回归到背包问题，由于附件是绑定主件的，所以解题时直接将附件的价值归结到主件中，那么问题就变成了1000元购买3件物品所能获取的最大价值。而对应于每一个主件，其最大价值的组成有多种可能性，我们需要在所有的可能性中找出最大价值：\n不买主件，dp[i][j] = dp[i-1][j]； 只买主件，dp[i][j] = dp[i-1][j-wi] + vi； 买主件+附件1，dp[i][j] = dp[i-1][j-wi-wa1i] + vi + va1i； 买主件+附件2，dp[i][j] = dp[i-1][j-wi-wa2i] + vi + va2i； 买主件+附件1+附件2，dp[i][j] = dp[i-1][j-wi-wa1i-wa2i] + vi + va1i + va2i； 以下是该问题的java语言解决方式：\npublic class PackIssue2 { public static void main(String[] args) { Scanner in = new Scanner(System.in); int N = in.nextInt(); // price limit if (N \u0026gt;= 32000) return; int m = in.nextInt(); // goods want buy if (m \u0026gt;= 60) return; Tar[] tars = new Tar[m + 1]; // index from 1 for (int i = 1; i \u0026lt; m + 1; i++) { int v = in.nextInt(); int p = in.nextInt(); int q = in.nextInt(); Tar tar = new Tar(v, p, q \u0026gt; 0); if (q \u0026gt; 0) { if (tars[q].a1 == 0) { tars[q].setA1(i); } else { tars[q].setA2(i); } } // add all goods to Tar[] tars[i] = tar; } // dp int[][] dp = new int[m + 1][N + 1]; for (int i = 1; i \u0026lt; m + 1; i++) { Tar tar = tars[i]; int vi = tar.v; for (int j = 10; j \u0026lt; N + 1; j += 10) { if (tar.isAttach) { // skip attachments dp[i][j] = dp[i - 1][j]; continue; } if (j \u0026gt;= vi) { // only main int dp1 = vi * tar.p; int dp2 = dp1, dp3 = dp1, dp4 = dp1; int lv2 = vi, lv3 = vi, lv4 = vi; int lj = j - vi; // main + attachment1 if (tar.a1 \u0026gt; 0) { Tar a1 = tars[tar.a1]; if (lj \u0026gt;= a1.v) { dp2 += a1.v * a1.p; lv2 += a1.v; } } // main + attachment2 if (tar.a2 \u0026gt; 0) { Tar a2 = tars[tar.a2]; if (lj \u0026gt;= a2.v) { dp3 += a2.v * a2.p; lv3 += a2.v; } } // main + attachment1 + attachment2 if (tar.a1 \u0026gt; 0 \u0026amp;\u0026amp; tar.a2 \u0026gt; 0) { Tar a1 = tars[tar.a1]; Tar a2 = tars[tar.a2]; if (lj \u0026gt;= a1.v) { dp4 += a1.v * a1.p; lj -= a1.v; lv4 += a1.v; if (lj \u0026gt;= a2.v) { dp4 += a2.v * a2.p; lv4 += a2.v; } } } dp[i][j] = Math.max(dp[i - 1][j], dp[i - 1][j - vi] + dp1); dp[i][j] = Math.max(dp[i][j], dp[i - 1][j - lv2] + dp2); dp[i][j] = Math.max(dp[i][j], dp[i - 1][j - lv3] + dp3); dp[i][j] = Math.max(dp[i][j], dp[i - 1][j - lv4] + dp4); } else { dp[i][j] = dp[i - 1][j]; } } } System.out.println(dp[m][N]); } } class Tar { int v; // price int p; // priority, from 1-5 boolean isAttach; int a1; // index of attachment 1 in Tar[] int a2; // index of attachment 2 in Tar[] public Tar(int p, int w, boolean isAttach) { this.v = p; this.p = w; this.isAttach = isAttach; } public void setA1(int a1) { this.a1 = a1; } public void setA2(int a2) { this.a2 = a2; } } 参考 # 0-1背包问题 购物车问题 算法图解-像小说一样有趣的算法入门书 "},{"id":57,"href":"/zh/docs/java/concurrency/2%E8%B5%84%E6%BA%90%E8%AE%BF%E9%97%AE%E5%8F%97%E9%99%90_3_synchronized/","title":"synchronized关键字","section":"并发编程","content":"自Java 1.0开始，每一个对象都有一个隐式内部锁（ intrinsic lock ），在Java API Specification中通常被称为监视器（ monitor ）。这个内部锁由synchronized关键字提供支持。synchronized关键字的语义就是“同步的”，这意味着使用这个关键字可以处理共享资源的冲突。\n当访问被synchronized关键字保护的方法或代码块时，它将检查锁能否获得——这个锁可以是当前类对象的锁，也可以是一个临时锁( ad-hoc lock )，取决你如何使用，任务执行完成之后会释放锁。\n和ReentrantLock一样，synchronized关键字获取的锁也是独占锁，并且也是“可重入”的，某个任务可以多次获得对象的锁，并由计数器维护获得锁的次数，当退出一个方法时，计数器-1，完全退出时，才释放锁，这和可重入锁的机制是一样的。\n类对象也持有一个锁，也就是说synchronized关键字可作用于静态方法。\n关于什么时候该使用同步， Brian Goetz 提出过同步规则：\n若向一个变量写入值，它可能接下来被另一个线程读取，或者正在读取一个上一次由另一个线程写过的值，那么必须使用同步，并且读写线程都必须使用相同的监视器同步。\n监视器是由 Per Brinch Hansen 和 Tony Hoare 提出的一种无锁机制，最初的监视器具有如下特性：\n监视器是只包含私有域的类 每个监视器的类对象有一个相关的锁 使用该锁对所有相关的方法加锁 该锁可以有任意多个相关条件 Java不完全地采用了监视器的设计概念，这就是synchronized关键字。\n在使用synchronized关键字时，将共享域设为私有是非常重要的。由于域只能通过方法访问，而synchronized保证方法执行的有序性；\n若域不是私有的，其他任务可以直接操作域，这就可能产生冲突。\n同步方法 # 当synchronized关键字作用于方法时，表示这个方法是同步的，执行方法时，首先会尝试获取当前对象的锁——这个对象一般是类的实例对象（ this ），若是静态方法，便是类对象。\npublic synchronized void transfer(int from, int to, double amount) throws InterruptedException { if (accounts[from] \u0026lt; amount) wait(); // can be interrupted if (from == to) return; // transfer accounts[from] -= amount; System.out.println(Thread.currentThread() + \u0026#34; move away\u0026#34;); accounts[to] += amount; System.out.printf(\u0026#34;%s: %10.2f from %d to %d, Total Balance: %10.2f%n\u0026#34;, Thread.currentThread(), amount, from, to, totalBalance()); notifyAll(); // wake up all threads waiting on this monitor } 考虑转账的任务，只需要将transfer()方法加上synchronized关键字即可保证安全，运行此方法时，线程会先去获取Bank实例的内部锁，并将其他线程阻塞，此线程完成之后会释放这个对象锁，其他线程方可继续运行。\n继续思考之前的问题，对于使用synchronized关键字的transfer()方法，里面调用了totalBalance()方法，那totalBalance()方法是否需要同步呢？前面说过「是否加锁应该以 资源是否共享为参照」，这其实和“同步法则“是的表述是一致的。如果有多个线程访问transfer()方法，正好此方法是串行访问（有序访问）的，那么totalBalance()方法无需同步；若还有其他线程对访问totalBalance()方法的资源，那么必须使用同步。\n同步代码块 # synchronized关键字也可以用于同步代码块（同步阻塞）。\n在用于同步方法时，相当于synchronized(this)，而同步代码块则多了一点灵活性。\nsynchronized (obj){ // synchronized block // critical section } 示例中的obj可以是 this ，也可以是其他对象。\n考虑 资源访问受限引论中的EvenGenerator类，在next()方法中可以使用同步代码块加锁可保证安全性：\nstatic class EvenGenerator extends AbstractIntGenerator { private Integer even = 0; private Object lock = new Object(); @Override public int next() { // equals to using // synchronized (this){ synchronized (lock) { ++even; Thread.yield(); ++even; // return语句必须包含在同步代码块里 return even; } } } 上例中，synchronized关键字使用了“其他对象”作为“监视器”，注意，synchronized代码块必须包括所有读写域的代码，包括return语句。\n从 字节码来看，return语句也不是原子性的——它要先加载并获取变量域even的值，然后再返回\nJava语言规范规定对变量的读写都是原子的（long和double）除外，因此return语句是原子的。但是单一语句的原子性并不能保证多线程的安全性，如果锁在return之前被释放，那么return可能获取到其他线程修改后的值。\n可以看到，使用synchronized关键字比使用显式锁代码更加简洁。\n需要注意的是，尽管synchronized代码块中的锁可以是任意对象的，但是尽量不要把这种任意性视为绝对安全的。一般在同步代码块中使用this或某“不可变”域（上例中）的锁。\n考虑如下示例：\nstatic class Bank { private final Vector\u0026lt;Double\u0026gt; accounts; public Bank(int accountCount, double money) { // initialize bank account accounts = new Vector\u0026lt;\u0026gt;(accountCount); List\u0026lt;Double\u0026gt; doubles = Collections.nCopies(accountCount, money); accounts.addAll(doubles); } public void transfer(int from, int to, double amount) { synchronized (accounts) { if (accounts.get(from) \u0026lt; amount) return; if (from == to) return; // transfer accounts.set(from, accounts.get(from) - amount); System.out.println(Thread.currentThread() + \u0026#34; move away\u0026#34;); accounts.set(to, accounts.get(to) + amount); System.out.printf(\u0026#34;%s: %10.2f from %d to %d, Total Balance: %10.2f%n\u0026#34;, Thread.currentThread(), amount, from, to, totalBalance()); } } } 上例中使用Vector作为账户的容器，Vector是线程安全的实现，是否可以不加锁呢？\n不是的，Vector只能保证其实现方法是线程安全的，并不能保证transfer方法是同步的。换言之，accounts.set()方法是同步的，其完成之后该线程可能被剥夺运行权。\n作为改进，在transfer()方法中截获了accounts的锁，尝试使其同步，它是可行的。但是这是否意味着可以任意使用其他对象的锁呢？Java核心卷I给出一段晦涩的评论1：\n如果冒昧地使用某个其他域（客户端锁定）的锁，可能不能保证安全性\nThis approach works, but it is entirely dependent on the fact that the Vector class uses the intrinsic lock for all of its mutator methods. However, is this really a fact? The documentation of the Vector class makes no such promise. You have to carefully study the source code and hope that future versions do not introduce unsynchronized mutators. As you can see, client-side locking is very fragile and not generally recommended.\n其晦涩之处在于，synchronized使用accounts的内部锁保证同步，和Vector方法使用的锁是不是accounts的内部锁有什么联系？\n如何使用同步 # 从之前的阐述我们知道，如果多个线程同时对共享资源进行访问，并且至少有一个线程对资源进行了写操作，那就需要同步。\n在编写同步代码的时候，我常常困惑，应该在哪里使用同步呢？究竟是在线程上同步还是应该在资源方法上同步，还是所有位置都需要同步？\n接下来我们从两个维度去剖析“在哪里同步”这个问题。\n在资源上同步 # // 资源 synchronized void next(){ x++; } // 任务1 run(){ next(); } // 任务2 run(){ next(); } 这是常见的模式。当在资源上同步时，使用多线程执行任务1和任务2，都不会出现线程安全的问题。因为每一个对x进行操作的线程都会被同步阻塞。这就是资源的序列化访问。\n在任务上同步 # final Lock lock ; // 资源 void next(){ x++; } // 任务1 run(){ synchronized(lock){ next(); } } // 任务2 run(){ next(); } 如上代码示例所示，我们在任务1的run()方法上使用同步，当多个线程实例执行任务1时，x是线程安全的。\n需要提出的是，run()方法中的synchronized使用的锁不能是this，如果是this，那么同步块将毫无作用。\n因为synchronized是对持有对象的可重入锁，而this并不是指代的某个实例，而是所有构造的实例。\n可以使用ClassName.class来持有类对象的锁来代替。\n但是若此时有线程执行任务2，那么此代码的安全隐患就出现了：任务2的操作和任务1的操作就会互相干扰!\n若想保证线程安全，那么任务2的next方法也要和任务1一样使用同步，并且使用相同的对象锁。\n这样的条件下，同时运行任务1和任务2，那么线程会在lock对象上获取锁而进入同步阻塞，从而保证安全性，和在资源上同步的效果是等同的。\n建议 # 从代码的简洁性，可读性与可复用性上来讲，在资源上使用同步显得更加优雅，两种实现方式的代码可以进行比较直观的对比：\n// 在任务上同步 public TV call() { while (true) { synchronized (tick) { TV tv = tl.get(); tv.setT(Thread.currentThread()); if (tick.getTick()) { tv.setV((tv.getV() == null ? 0 : tv.getV()) + 1); tl.set(tv); try { // 给其他线程机会 tick.wait(10); } catch (InterruptedException e) { e.printStackTrace(); } } else { if (!tick.isTickSupply) break; } } } return tl.get(); } // 在资源上使用同步 public TV call() { while (true) { TV tv = tl.get(); tv.setT(Thread.currentThread()); // getTick()方法同步 if (tick.getTick()) { tv.setV((tv.getV() == null ? 0 : tv.getV()) + 1); tl.set(tv); TimeUnit.MILLISECONDS.sleep(1); } else { if (!tick.isTickSupply) break; } } return tl.get(); } 上述代码的作用是一样的，可以看到，在资源上使用同步比在任务上使用同步的代码更加易读，简洁。\n正如之前所说的，在资源上使用同步还可以避免新建任务时又重新设计同步逻辑。\n因此，在资源上使用同步是建议的方式。\n扩展阅读: https://docs.oracle.com/javase/tutorial/essential/concurrency/syncmeth.html\nJava核心技术卷1 第14章并发第14.5.6节同步阻塞\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":58,"href":"/zh/docs/java/collections/4_Map_hash_tree_map/","title":"HashMap和TreeMap","section":"集合框架","content":"由于Map的键是Set，因此使用可变对象作为Map的key时，需要覆盖 equals 和 hashCode 方法，Map不能使用自身作为key。\nJava 8对Map接口进行了优化，新增了主要是针对函数式接口的 默认 方法（方法体被省略）：\ndefault V merge (K key, V value, BiFunction\u0026lt;? super V, ? super V, ? extends V\u0026gt; remappingFunction) {...} default V compute (K key, BiFunction\u0026lt;? super K, ? super V, ? extends V\u0026gt; remappingFunction) {...} default V computeIfPresent (K key, BiFunction\u0026lt;? super K, ? super V, ? extends V\u0026gt; remappingFunction) {...} default V computeIfAbsent (K key, Function\u0026lt;? super K, ? extends V\u0026gt; mappingFunction) {...} default V replace (K key, V value) {...} default boolean replace(K key, V oldValue, V newValue) {...} default boolean remove (Object key, Object value) {...} default V putIfAbsent (K key, V value) {...} default void replaceAll ( BiFunction\u0026lt;? super K, ? super V, ? extends V\u0026gt; function) {...} default V getOrDefault (Object key, V defaultValue) {...} 上述方法使用的不多，主要用来对Map键值进行更新，按需查阅API文档。\nHashMap # HashMap是由散列表对键进行散列的，允许null键和null值。HashMap是无序的，这点和HashSet是一样的\nHashMap和Hashtable大致相同，区别在与Hashtable是同步的，且Hashtable不允许null\nHashMap的初始化和扩容机制叙述参见 散列表，如果初始化时不指定容量（桶数？容量不是键值对数目），默认为16。容量总是2n，最大容量是230，每次扩容加倍，当桶数大于最大桶数后，不再rehash。容量总是为2的幂次的原理和 ArrayDeque一致，通过5次位运算将低位全部转为1，然后执行+1操作进位，变成下一个2n。因此HashMap带参构造器指定的capacity最后会初始化为大于其的最近的2n（1变2，3变4，5变8，9变16\u0026hellip;）。\nHashMap使用table和entrySet分别表示桶数和当前映射中的键值对数：\ntransient Node\u0026lt;K,V\u0026gt;[] table;\t桶数组，桶由链表构成； transient Set\u0026lt;Map.Entry\u0026lt;K,V\u0026gt;\u0026gt; entrySet; 映射中的键值对数，size int threshold; 临界键值对数，等于 table.length * loadFactor，当size \u0026gt; threshold时，触发扩容 final float loadFactor; 装载因子，默认0.75 static void bucketsTest() throws Exception { //load factor 0.75 HashMap\u0026lt;String, String\u0026gt; hm = new HashMap\u0026lt;\u0026gt;(7); hm.put(\u0026#34;1\u0026#34;, \u0026#34;ok\u0026#34;); hm.put(\u0026#34;2\u0026#34;, \u0026#34;fine\u0026#34;); hm.put(\u0026#34;3\u0026#34;, \u0026#34;nice\u0026#34;); hm.put(\u0026#34;4\u0026#34;, \u0026#34;no\u0026#34;); hm.put(\u0026#34;5\u0026#34;, \u0026#34;ops\u0026#34;); hm.put(\u0026#34;6\u0026#34;, \u0026#34;fuck\u0026#34;); Class\u0026lt;?\u0026gt; cls = HashMap.class; Field table = cls.getDeclaredField(\u0026#34;table\u0026#34;); Field threshold = cls.getDeclaredField(\u0026#34;threshold\u0026#34;); // can not access // Class\u0026lt;?\u0026gt; node = Class.forName(\u0026#34;java.util.HashMap$Node\u0026#34;); table.setAccessible(true); threshold.setAccessible(true); // Node\u0026lt;K,V\u0026gt;[] Object[] o = (Object[]) table.get(hm); System.out.println(\u0026#34;initial buckets size: \u0026#34; + o.length); System.out.println(\u0026#34;initial threshold: \u0026#34; + threshold.get(hm)); Set\u0026lt;Map.Entry\u0026lt;String, String\u0026gt;\u0026gt; entries = hm.entrySet(); System.out.println(\u0026#34;number of entries: \u0026#34; + entries.size()); // 遍历 /*entries.forEach((e) -\u0026gt; { System.out.println(e.getKey() + e.getValue()); });*/ hm.put(\u0026#34;apple\u0026#34;, \u0026#34;music\u0026#34;); // reshash needed System.out.println((\u0026#34;buckets after rehash: \u0026#34; + ((Object[]) table.get(hm)).length)); } /* output: initial buckets size: 8 initial threshold: 6 number of entries: 6 buckets after rehash: 16 *///:~ 上例证实了HashMap的扩容过程，当映射中的元素数大于桶数与装载因子之积时，便会扩容。\nMap中提供3种集合视图，键的，值的和entry的，视图并不能对映射进行完全结构性控制，比如向Map中添加条目，则只能使用Map.put方法，使用视图时，除了删除这一改变Map结构的操作，其他操作会抛出UnsurportedOperationException。\nHashMap的集合视图都支持迭代器，并可以通过任意视图的迭代器删除键值对，但是不支持新增和替换键值对。\nprivate static void viewTest() { Map\u0026lt;Integer, String\u0026gt; hm = new HashMap\u0026lt;\u0026gt;(8); hm.put(1,\u0026#34;难忘的一天\u0026#34;); Set\u0026lt;Integer\u0026gt; keySet = hm.keySet(); //keySet.add(2); // unsupported operation exception Iterator\u0026lt;Integer\u0026gt; ikey = keySet.iterator(); ikey.next(); // can remove key-value pair by keySet ikey.remove(); ikey.forEachRemaining(System.out::println); Collection\u0026lt;String\u0026gt; values = hm.values(); // already deleted System.out.println(\u0026#34;values contains: \u0026#34; + values.contains(\u0026#34;难忘的一天\u0026#34;)); // values.add(\u0026#34;你瞒我瞒\u0026#34;); // unsupported either hm.put(1,\u0026#34;你瞒我瞒\u0026#34;); hm.put(2,\u0026#34;樱花树下\u0026#34;); // ikey.next(); // fast-fail iterator, ikey is out of date boolean remove = values.remove(\u0026#34;你瞒我瞒\u0026#34;); Iterator\u0026lt;String\u0026gt; ivalue = values.iterator(); ivalue.next(); ivalue.remove(); hm.put(1,\u0026#34;红豆\u0026#34;); hm.put(2,\u0026#34;风衣\u0026#34;); Set\u0026lt;Map.Entry\u0026lt;Integer, String\u0026gt;\u0026gt; entries = hm.entrySet(); // entries.add() // unsupported either System.out.println(\u0026#34;entry size: \u0026#34; + entries.size()); // remove entry with particular key-value entries.remove(new Map.Entry\u0026lt;Integer, String\u0026gt;() { @Override public Integer getKey() { return 1; } @Override public String getValue() { return \u0026#34;红豆\u0026#34;; } @Override public String setValue(String value) { return null; } }); hm.forEach((k,v) -\u0026gt; System.out.println(\u0026#34;key:\u0026#34; + k + \u0026#34;, value:\u0026#34; + v)); Iterator\u0026lt;Map.Entry\u0026lt;Integer, String\u0026gt;\u0026gt; ientry = entries.iterator(); ientry.next(); ientry.remove(); ientry.forEachRemaining(System.out::println); } /* output values contains: false entry size: 2 key: 2, value:风衣 *///:~ 值得一提的事，和 SortedSet的子集视图一样，对原集合和视图的修改是相互的，不会引发 ConcurrentModificationException ，但是其对映射的操作是有限的，比如keySet.add(2)就抛出 UnsupportedOperationException ，迭代器不支持操作。查看源码即可知：\nHashMap内部视图和迭代器方法表\n可以看到，视图实现的方法有限，并没有实现集合的所有方法。因此当使用视图调用add()方法时，直接在AbstractCollection里抛出异常：\npublic boolean add(E e) { throw new UnsupportedOperationException(); } TreeMap # TreeSet是TreeMap的KeySet的封装，TreeMap是使用红—黑树对键进行排序的有序映射。\nTreeMap的继承结构和TreeSet极为相似，对应地，TreeMap是SortedMap和NavigableMap的实现，SortedMap/NavigableMap的接口声明和SortedSet/NavgableSet相似，所声明的方法名都是自解释型的，具体可查看JDK文档。\n要将条目插入TreeMap中，key必须是可排序的，排序方式可以是自然排序或者定义比较器，和TreeSet一样，比较器规则必须和equals方法的结果保持一致，以避免映射中出现重复key-value。\nTreeMap的集合视图和对应的迭代器表现和HashMap一致。\n视图和映射的作用是相互的，即修改映射，视图随之修改，反之亦然，但是视图支持的操作是有限的，注意 UnsupportedOperationException； 迭代器是 fail-fast 的， 只支持remove一个改变映射结构的方法； static { map.put(\u0026#34;hebe\u0026#34;, \u0026#34;不醉不会\u0026#34;); map.put(\u0026#34;AMIT\u0026#34;,\u0026#34;母系社会\u0026#34;); map.put(\u0026#34;Lin\u0026#34;,\u0026#34;可惜没如果\u0026#34;); map.put(\u0026#34;andy\u0026#34;, \u0026#34;一起走过的日子\u0026#34;); map.put(\u0026#34;lala\u0026#34;, \u0026#34;寻人启事\u0026#34;); map.put(\u0026#34;yoga\u0026#34;, \u0026#34;说谎\u0026#34;); } static void treeMapTest() { Map\u0026lt;String, String\u0026gt; tm = new TreeMap\u0026lt;\u0026gt;(map); Set\u0026lt;Map.Entry\u0026lt;String, String\u0026gt;\u0026gt; entries = tm.entrySet(); tm.put(\u0026#34;andy\u0026#34;, \u0026#34;来生缘\u0026#34;); // 映射和entrySet是互相作用的 for (Map.Entry\u0026lt;String, String\u0026gt; entry : entries) { entry.setValue(\u0026#34;难搞\u0026#34;); break; } tm.computeIfPresent(\u0026#34;lala\u0026#34;, (k, v) -\u0026gt; \u0026#34;失落沙洲\u0026#34;); // Unsupported Operation Exception // entries.add(new Map.Entry\u0026lt;String, String\u0026gt;() {...}); tm.forEach((k, v) -\u0026gt; System.out.println(k + \u0026#34;: \u0026#34; + v)); // test iterator Iterator\u0026lt;Map.Entry\u0026lt;String, String\u0026gt;\u0026gt; ie = entries.iterator(); ie.next(); ie.remove(); // tm.putAll(map); //ConcurrentModificationException ie.next(); ie.forEachRemaining(x -\u0026gt; System.out.print(x + \u0026#34;\\t\u0026#34;)); // 指定比较器 Map\u0026lt;String, String\u0026gt; tm2 = new TreeMap\u0026lt;\u0026gt;(String::compareToIgnoreCase); tm2.putAll(map); System.out.println(); tm2.forEach((k,v)-\u0026gt; System.out.println(k +\u0026#34;: \u0026#34; + v)); } /* output: AMIT: 难搞 Lin: 可惜没如果 andy: 来生缘 hebe: 不醉不会 lala: 失落沙洲 yoga: 说谎 andy=来生缘\thebe=不醉不会\tlala=失落沙洲\tyoga=说谎 AMIT: 母系社会 andy: 一起走过的日子 hebe: 不醉不会 lala: 寻人启事 Lin: 可惜没如果 yoga: 说谎 *///:~ 上例中分别对HashMap使用自然排序和指定比较器的方法，可以看到映射中key的排序差异。\n当指定TreeMap实现类的名字SortedMap或NavigableMap的实现时，方可使用SortedMap和NavigableMap的实用方法，由于方法名都是解释型的，此处不多作表述：\nstatic void navigableTest() { TreeMap\u0026lt;String, String\u0026gt; tm = new TreeMap\u0026lt;\u0026gt;(map); System.out.println(tm.firstEntry().getKey()); // 使用一个比key \u0026#39;andy\u0026#39;大的值，即可包含这个key，\u0026#34;+ 0\u0026#34;是一个实用手段 SortedMap\u0026lt;String, String\u0026gt; subMap = tm.subMap(\u0026#34;AMIT\u0026#34;, \u0026#34;andy\u0026#34; + \u0026#34;0\u0026#34;); subMap.compute(\u0026#34;AMIT\u0026#34;, (k, v) -\u0026gt; \u0026#34;彩虹\u0026#34;); subMap.forEach((k, v) -\u0026gt; System.out.println(k + \u0026#34;, \u0026#34; + v)); //NavigableMap接口方法，返回大于或等于给定key的一个entry System.out.println(tm.ceilingEntry(\u0026#34;AMIT\u0026#34;).getValue()); } /* output: AMIT AMIT, 彩虹 Lin, 可惜没如果 andy, 一起走过的日子 彩虹 *///:~ 由于subMap方法是“包前不包尾”的（其他获取子映射视图的方法也一样），为了包尾，可以使用上例的方法。\nNavigableMap对获取子映射视图的方法进行了扩展，不作过多表述。\n"},{"id":59,"href":"/zh/docs/java/basic/5_Object%E8%B6%85%E7%B1%BB/","title":"Object超类","section":"面向对象","content":" Object超类 # 在Java中，如果一个类没有明确地指出超类，那么Object就是这个类的超类。实际上，Object类是所有类超类，这个类定义了一些重要的方法。\nequals # equals方法用来比较两个对象是否相等。不过，在Object类中，这是判断两个对象是否具有相同的引用。\n当对象引用a和b指向同一个对象即认为a等于b，看起来，这似乎合乎情理，但是在很多情况下，需要比较对象的状态的相等性，所以，Object类的equals方法往往是没有什么用处的。\nJava语言规范要求equals方法具有以下特性：\n自反性：对于任何非空引用x，x.equals(x)为true； 对称性：对于任何引用x、y，当且仅当y.equals(x)为true时，x.equals(y)才为true； 传递性：对于任何引用x、y、z，若x.equals(y)为true，y.equals(z)为true，那么x.equals(z)也应该为true； 一致性：对于任何引用x、y，若对象引用和equals方法未发生变化，那么多次调用应返回一致的结果； 对于任何非空引用x，x.equals(null)为false。 参考之前Employee2类的equals方法：\nclass Employee2 { // skip... @Override public boolean equals(Object o) { if (this == o) return true; if (o == null) return false; if (o.getClass() != getClass()) return false; Employee2 employee2 = (Employee2) o; /*if (salary != employee2.salary) return false; return name != null ? name.equals(employee2.name) : employee2.name == null;*/ // or using Objects.equals(Object a, Object b) to compare return Objects.equals(name,employee2.name) \u0026amp;\u0026amp; salary == employee2.salary; } 这是一个典型的覆盖equals方法的策略：\n检测o和this是否同一引用，若是，则返回true 检测o是否为空，若为空，则返回false 检测o和this是否是同一类型，若否，则返回false 将o转换为this类 比较o和this域的相等性 在导出类中调用equals方法时，要先调用基类的equals方法，基类的方法通过之后，再比较导出类的相关域的相等性。\n参考如下例子：\nclass Manager extends Employee2{ // skip... @Override public boolean equals(Object o) { if(!super.equals(o)) return false; // super.equals checked that o and this belong to same class Manager m = (Manager)o; return bonus == m.bonus; } } 以上的2个equals方法说明的是若导出类拥有自己的相等概念，那么在第3步类型判断中必须使用getClass，这样，基类和导出类（或者不同导出类）之前必然是不等的。\n考虑一种情况：若想在基类和导出类之间（或不同导出类之间）进行相等比较，那么只需要比较基类共有的域即可，即是否相等由基类判断，该如何处理呢？\n参考如下例子：\nclass Stu{ // skip... @Override public final boolean equals(Object o) { if (this == o) return true; if (o == null) return false; if (!(o instanceof Stu)) return false; Stu stu = (Stu) o; return stu.age == age \u0026amp;\u0026amp; Objects.equals(stu.name, name) \u0026amp;\u0026amp; Objects.equals(stu.code, code); } } 这个equals方法有几处变化：\n这个方法是final的 判断类型使用的是instanceof而非getClass 将方法声明为final即保证了基类对相等概念的控制权（导出类无法覆盖equals方法），这还不够，使用instanceof保证了基类和导出类（或不同导出类）之间域的相等性比较的可能\n应该谨慎使用instanceof判断操作符号。\nhashCode # hash code （散列码）是由对象导出的一个整型值\nJava语言对hashCode方法有如下规范：\n在同一次Java程序运行过程中，无论调用多少次对象的hashCode方法，返回的应该是同一个整型值；而在不同程序运行过程中则无此要求； 对于任何对象a、b，若a.equals(b)为true，那么a和b的hashCode返回值应该相等； 对于任何对象a、b，若a.equals(b)为false，a和b的hashCode返回值没有必要一定不等；需要指出的是，给不同对象分配不同的hashcode值有利于提升哈希表的性能； 基于第2点规范，若重新定义了equals方法，那么必须重新定义hashCode方法。\npublic class HashT { public static void main(String[] args) { String s = \u0026#34;s\u0026#34;; String t = new String(\u0026#34;s\u0026#34;); StringBuilder sb = new StringBuilder(s); StringBuilder tb = new StringBuilder(t); System.out.println(s.hashCode() + \u0026#34; : \u0026#34; +sb.hashCode()); System.out.println(t.hashCode() + \u0026#34; : \u0026#34; +tb.hashCode()); } } /* output 115 : 1956725890 115 : 356573597 *///:~ 注意，s和t哈希值相同时因为String类覆盖了hashCode方法，其值是由字符串字面量值计算来的，而StringBuilder没有覆盖hashCode方法，其值是Object默认的hashCode方法导出的对象存储地址。\n"},{"id":60,"href":"/zh/docs/java/basic/5_%E5%8A%A8%E6%80%81%E7%BB%91%E5%AE%9A%E4%B8%8E%E9%9D%99%E6%80%81%E7%BB%91%E5%AE%9A/","title":"动态绑定与静态绑定","section":"面向对象","content":" 动态绑定与静态绑定 # 这是Java方法调用的2个术语，用来描述Java虚拟机方法调用的2种机制。\n6.1 动态绑定 # 方法的名字和参数列表构成了方法的签名。\n返回类型并不是方法签名的一部分，因此在覆盖方法时，允许将导出类的方法返回类型定义为基类返回类型的子类型\n方法调用时，虚拟机为每个类创建一个方法表，列出所有的方法签名和实际调用的方法，调用方法时按表查找即可，例如方法表可能是这样的：\nFinalMethod: f() -\u0026gt; FinalMethod.f(); g() -\u0026gt; FinalMethod.g(); p() -\u0026gt; FinalMethod.p(); // skip Object method... FinalMethodExt f() -\u0026gt; FinalMethodExt.f(); p() -\u0026gt; FinalMethodExt.p(); // skip Object method... 当对象引用o调用方法时，其过程可归纳为：\n虚拟机提取o的实际类型的方法表 在方法表中搜索调用的方法，若有满足，则直接调用 若无满足，则在o实际类型的父类中搜索调用的方法 调用方法或抛出异常 从上面的描述可以看出，继承体系中的方法调用可能出现不同的结果（导出类覆盖和未覆盖基类方法时的差异现象）。\n6.2 静态绑定 # 当方法被private，static，final修饰或调用构造器（构造器可看作是static方法）的时候，编译器即可准确的知道该调用哪个类的哪个方法，这一过程就是静态绑定。\n"},{"id":61,"href":"/zh/docs/craft/db/sql/6_mysql%E6%AD%BB%E9%94%81/","title":"MySQL死锁","section":"mysql","content":"MySQL死锁是指多个事务之间，由于每个事务持有另一个事务所需的锁而无法继续执行的情况。因所有事务都在等待相同的资源变得可用，而没有一个事务释放它所持有的锁。\n多个事务以相反的顺序锁定多个表中的行（通过诸如UPDATE或SELECT \u0026hellip; FOR UPDATE之类的语句），就可能发生死锁。\n死锁也可能发生在这些语句锁定索引记录和间隙范围时，每个事务获取一些锁但由于时间问题而没有获取其他锁。\n以下是一个死锁的栗子：\n使用SET GLOBAL innodb_print_all_deadlocks = ON命令，可以查看死锁信息。 首先客户端A，开启事务，并获取animals表的相关锁：\nmysql\u0026gt; set global innodb_print_all_deadlocks = on; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; create table animals (name varchar(10) primary key, value int) engine = InnoDB; Query OK, 0 rows affected (0.03 sec) mysql\u0026gt; create table birds (name varchar(10) primary key, value int ) engine = InnoDB; Query OK, 0 rows affected (0.03 sec) mysql\u0026gt; insert into animals(name, value) values (\u0026#39;cow\u0026#39;, 1); Query OK, 1 row affected (0.01 sec) mysql\u0026gt; insert into birds(name, value) values (\u0026#39;pigeon\u0026#39;, 1); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; start transaction; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select value from animals where name = \u0026#39;cow\u0026#39; for share; +-------+ | value | +-------+ | 1 | +-------+ 1 row in set (0.00 sec) 接着，客户端B开启事务，并且获取birds表相关锁，并视图更新animals表事务A获得锁的内容：\nmysql\u0026gt; start transaction; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select value from birds where name = \u0026#39;pigeon\u0026#39; for share; +-------+ | value | +-------+ | 1 | +-------+ 1 row in set (0.00 sec) mysql\u0026gt; update animals set value = 2 where name = \u0026#39;cow\u0026#39;; 这时候可以看到更新操作是被阻塞的，它在等待客户端A释放锁。\n再打开一个新客户端，查看InnoDB的事务和锁信息：\nmysql\u0026gt; SELECT ENGINE_TRANSACTION_ID as Trx_Id, -\u0026gt; OBJECT_NAME as `Table`, -\u0026gt; INDEX_NAME as `Index`, -\u0026gt; LOCK_DATA as Data, -\u0026gt; LOCK_MODE as Mode, -\u0026gt; LOCK_STATUS as Status, -\u0026gt; LOCK_TYPE as Type -\u0026gt; FROM performance_schema.data_locks; +-----------------+---------+---------+----------+---------------+---------+--------+ | Trx_Id | Table | Index | Data | Mode | Status | Type | +-----------------+---------+---------+----------+---------------+---------+--------+ | 422089830973440 | birds | NULL | NULL | IS | GRANTED | TABLE | | 422089830973440 | birds | PRIMARY | \u0026#39;pigeon\u0026#39; | S,GAP | GRANTED | RECORD | | 422089830973440 | birds | PRIMARY | \u0026#39;pigeon\u0026#39; | S,REC_NOT_GAP | GRANTED | RECORD | | 422089830972632 | animals | NULL | NULL | IS | GRANTED | TABLE | | 422089830972632 | animals | PRIMARY | \u0026#39;cow\u0026#39; | S,REC_NOT_GAP | GRANTED | RECORD | +-----------------+---------+---------+----------+---------------+---------+--------+ 5 rows in set (0.01 sec) mysql\u0026gt; SELECT REQUESTING_ENGINE_LOCK_ID as Req_Lock_Id, -\u0026gt; REQUESTING_ENGINE_TRANSACTION_ID as Req_Trx_Id, -\u0026gt; BLOCKING_ENGINE_LOCK_ID as Blk_Lock_Id, -\u0026gt; BLOCKING_ENGINE_TRANSACTION_ID as Blk_Trx_Id -\u0026gt; FROM performance_schema.data_lock_waits; +----------------------------------------+------------+----------------------------------------+-----------------+ | Req_Lock_Id | Req_Trx_Id | Blk_Lock_Id | Blk_Trx_Id | +----------------------------------------+------------+----------------------------------------+-----------------+ | 140614854262784:69:4:2:140614746300912 | 6700 | 140614854261976:69:4:2:140614746294048 | 422089830972632 | +----------------------------------------+------------+----------------------------------------+-----------------+ 1 row in set (0.01 sec) 从performance_schema.data_lock_waits表可以看到，此时有2个事务，422089830973440和422089830972632，分别代表客户端Bbirds表的锁和客户端Aanimals表的锁。\n从等待锁的信息来看，等待锁的事务Id是6700，而等待释放锁的事务Id是422089830972632，正是客户端A开启的事务锁占用的animals表的锁。\n若此时再次查看事务信息：\nmysql\u0026gt; SELECT ENGINE_LOCK_ID as Lock_Id, -\u0026gt; ENGINE_TRANSACTION_ID as Trx_id, -\u0026gt; OBJECT_NAME as `Table`, -\u0026gt; INDEX_NAME as `Index`, -\u0026gt; LOCK_DATA as Data, -\u0026gt; LOCK_MODE as Mode, -\u0026gt; LOCK_STATUS as Status, -\u0026gt; LOCK_TYPE as Type -\u0026gt; FROM performance_schema.data_locks; +----------------------------------------+-----------------+---------+---------+----------+---------------+---------+--------+ | Lock_Id | Trx_id | Table | Index | Data | Mode | Status | Type | +----------------------------------------+-----------------+---------+---------+----------+---------------+---------+--------+ | 140614854262784:1135:140614746303224 | 6700 | animals | NULL | NULL | IX | GRANTED | TABLE | | 140614854262784:1136:140614746303136 | 6700 | birds | NULL | NULL | IS | GRANTED | TABLE | | 140614854262784:70:4:2:140614746300224 | 6700 | birds | PRIMARY | \u0026#39;pigeon\u0026#39; | S,GAP | GRANTED | RECORD | | 140614854262784:70:4:2:140614746300568 | 6700 | birds | PRIMARY | \u0026#39;pigeon\u0026#39; | S,REC_NOT_GAP | GRANTED | RECORD | | 140614854261976:1135:140614746297040 | 422089830972632 | animals | NULL | NULL | IS | GRANTED | TABLE | | 140614854261976:69:4:2:140614746294048 | 422089830972632 | animals | PRIMARY | \u0026#39;cow\u0026#39; | S,REC_NOT_GAP | GRANTED | RECORD | +----------------------------------------+-----------------+---------+---------+----------+---------------+---------+--------+ 6 rows in set (0.00 sec) 可以发现，事务（客户端B）相关的birds表的事务Id从422089830973440变成了6700。\n这是因为，当事务（客户端B）尝试修改数据库时，InnoDB使用序列事务Id，这就会改变事务（客户端B）的Id。\n所以，这和上面的信息对应。实际上就是客户端B等待客户端A释放animals表的锁。\n这时，如果在客户端A尝试修改birds表的内容，那么就会发生死锁：\nmysql\u0026gt; update birds set value = 2 where name = \u0026#39;pigeon\u0026#39;; ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction InnoDB的死锁是立刻发生的，并且InnoDB回滚了造成死锁的事务，也就是上述客户端A的更新操作。\n因此，客户端B的更新操作可以继续执行了。\nmysql\u0026gt; update animals set value = 2 where name = \u0026#39;cow\u0026#39;; Query OK, 1 row affected (19.42 sec) Rows matched: 1 Changed: 1 Warnings: 0 此时，事务A确实被回滚了。可以通过查询performance_schema.data_locks表得到验证：\nmysql\u0026gt; SELECT ENGINE_LOCK_ID as Lock_Id, -\u0026gt; ENGINE_TRANSACTION_ID as Trx_id, -\u0026gt; OBJECT_NAME as `Table`, -\u0026gt; INDEX_NAME as `Index`, -\u0026gt; LOCK_DATA as Data, -\u0026gt; LOCK_MODE as Mode, -\u0026gt; LOCK_STATUS as Status, -\u0026gt; LOCK_TYPE as Type -\u0026gt; FROM performance_schema.data_locks; +----------------------------------------+--------+---------+---------+----------+---------------+---------+--------+ | Lock_Id | Trx_id | Table | Index | Data | Mode | Status | Type | +----------------------------------------+--------+---------+---------+----------+---------------+---------+--------+ | 140614854262784:1135:140614746303224 | 6700 | animals | NULL | NULL | IX | GRANTED | TABLE | | 140614854262784:1136:140614746303136 | 6700 | birds | NULL | NULL | IS | GRANTED | TABLE | | 140614854262784:70:4:2:140614746300224 | 6700 | birds | PRIMARY | \u0026#39;pigeon\u0026#39; | S,GAP | GRANTED | RECORD | | 140614854262784:70:4:2:140614746300568 | 6700 | birds | PRIMARY | \u0026#39;pigeon\u0026#39; | S,REC_NOT_GAP | GRANTED | RECORD | | 140614854262784:69:4:2:140614746301256 | 6700 | animals | PRIMARY | \u0026#39;cow\u0026#39; | X,REC_NOT_GAP | GRANTED | RECORD | +----------------------------------------+--------+---------+---------+----------+---------------+---------+--------+ 5 rows in set (0.00 sec) 可以看到，事务ID全部是6700，说明是客户端B的事务，已经没有客户端A相关的信息了。\n虽然死锁发生后很快被InnoDB处理，我们还是可以查看到死锁的信息：\n通过Information Schema可以查看死锁的数量：\nmysql\u0026gt; SELECT `count` FROM INFORMATION_SCHEMA.INNODB_METRICS WHERE NAME=\u0026#34;lock_deadlocks\u0026#34;; +-------+ | count | +-------+ | 1 | +-------+ 1 row in set (0.00 sec) 此外，通过SHOW ENGINE INNODB STATUS 命令可以查看存储引擎的相关信息，里面包含了死锁的信息：\nmysql\u0026gt; show engine innodb status ; ------------------------ LATEST DETECTED DEADLOCK ------------------------ 2024-08-05 13:51:17 140614374082112 *** (1) TRANSACTION: TRANSACTION 6700, ACTIVE 608 sec starting index read mysql tables in use 1, locked 1 LOCK WAIT 5 lock struct(s), heap size 1128, 4 row lock(s) MySQL thread id 10, OS thread handle 140614683272768, query id 70 localhost root updating update animals set value = 2 where name = \u0026#39;cow\u0026#39; *** (1) HOLDS THE LOCK(S): RECORD LOCKS space id 70 page no 4 n bits 72 index PRIMARY of table `foobar`.`birds` trx id 6700 lock mode S locks rec but not gap Record lock, heap no 2 PHYSICAL RECORD: n_fields 4; compact format; info bits 0 0: len 6; hex 706967656f6e; asc pigeon;; 1: len 6; hex 000000001a2b; asc +;; 2: len 7; hex 81000001220110; asc \u0026#34; ;; 3: len 4; hex 80000001; asc ;; *** (1) WAITING FOR THIS LOCK TO BE GRANTED: RECORD LOCKS space id 69 page no 4 n bits 72 index PRIMARY of table `foobar`.`animals` trx id 6700 lock_mode X locks rec but not gap waiting Record lock, heap no 2 PHYSICAL RECORD: n_fields 4; compact format; info bits 0 0: len 3; hex 636f77; asc cow;; 1: len 6; hex 000000001a29; asc );; 2: len 7; hex 810000011b0110; asc ;; 3: len 4; hex 80000001; asc ;; *** (2) TRANSACTION: TRANSACTION 6701, ACTIVE 651 sec starting index read mysql tables in use 1, locked 1 LOCK WAIT 4 lock struct(s), heap size 1128, 2 row lock(s) MySQL thread id 8, OS thread handle 140614684329536, query id 71 localhost root updating update birds set value = 2 where name = \u0026#39;pigeon\u0026#39; *** (2) HOLDS THE LOCK(S): RECORD LOCKS space id 69 page no 4 n bits 72 index PRIMARY of table `foobar`.`animals` trx id 6701 lock mode S locks rec but not gap Record lock, heap no 2 PHYSICAL RECORD: n_fields 4; compact format; info bits 0 0: len 3; hex 636f77; asc cow;; 1: len 6; hex 000000001a29; asc );; 2: len 7; hex 810000011b0110; asc ;; 3: len 4; hex 80000001; asc ;; *** (2) WAITING FOR THIS LOCK TO BE GRANTED: RECORD LOCKS space id 70 page no 4 n bits 72 index PRIMARY of table `foobar`.`birds` trx id 6701 lock_mode X locks rec but not gap waiting Record lock, heap no 2 PHYSICAL RECORD: n_fields 4; compact format; info bits 0 0: len 6; hex 706967656f6e; asc pigeon;; 1: len 6; hex 000000001a2b; asc +;; 2: len 7; hex 81000001220110; asc \u0026#34; ;; 3: len 4; hex 80000001; asc ;; *** WE ROLL BACK TRANSACTION (2) TODO：\n死锁的检测和处理 如何避免死锁 References # https://dev.mysql.com/doc/refman/8.0/en/innodb-deadlock-example.html https://dev.mysql.com/doc/refman/8.0/en/innodb-deadlocks.html "},{"id":62,"href":"/zh/docs/note/pys/5_file_io/","title":"格式化输出与文件I/O","section":"Python","content":" "},{"id":63,"href":"/zh/docs/java/concurrency/2%E8%B5%84%E6%BA%90%E8%AE%BF%E9%97%AE%E5%8F%97%E9%99%90_4_%E5%8E%9F%E5%AD%90%E6%80%A7%E4%B8%8E%E5%8E%9F%E5%AD%90%E7%B1%BB/","title":"原子性和可见性","section":"并发编程","content":"原子性一般指原子操作，原子操作不能被线程调度机制中断，一旦操作开始，那么它一定可以在可能发生的上下文切换之前完成。Java语言规范规定了对基本对象(long和double除外)的读写操作是原子的。\n不能将原子性和同步划等号！更不能使用原子性来代替同步，当你想使用原子性代替同步写出无锁代码时，思考 Brain Goetz 的建议：\nIf you can write a high-performance JVM for a modern microprocessor, then you are qualified to think about whether you can avoid synchronizing.\n考虑如下几个操作：\nint x = 1; // s1 原子操作 boolean flag = flase; // s2 原子操作 int y = x; // s3 x++; // s4 double d = 1.9d; // s5 只有前2个操作是原子操作，后面的操作都不是原子操作。\n对于s3来说，可以拆分为读取x的值和将y赋值两个操作，虽然这两个操作都是原子的，但是合起来就不是原子操作了；s4就更复杂了；对于double和long类型的变量， JMM（Java Memory Model）规定了对其的写操作分为2步，每步写入32位1，因此也不是原子的。\n原子性的误用 # 查看一个误用原子性的例子：\npublic class AtomicTest implements Runnable { private int i = 0; public int getValue() { // atomic operation return i; } private synchronized void increment() { i++; i++; // equals to // i += 2; } @Override public void run() { while (true) increment(); } public static void main(String[] args) throws InterruptedException { AtomicTest at = new AtomicTest(); // 线程1 new Thread(at).start(); TimeUnit.MILLISECONDS.sleep(1); while (true) { // the value can still be odd int value = at.getValue(); if (value % 2 != 0) { System.out.println(value); System.exit(0); } } } } /* output: (sample) 145881 *///:~ 上例过分高估了原子性的能力，当另一个线程（mian线程）调用getValue()去访问共享变量时，尽管getValue()方法只有一个return语句，是原子性的，但还是获得了一个不希望的结果——奇数，为什么？虽然increment()方法是同步的，但是getValue()方法不需要锁即可访问共享域，此时的i可能在一个不稳定的中间状态。\nJava内存模型有如下约定2\nJava的域都储存在主存（即物理内存）中\nJava的工作线程有独立的内存（CPU缓存）\n同步保证可见性\n原子操作不保证可见性\n依据上面的论断，尝试分析这个不稳定状态：increment()方法使用了同步，即increment()每次自增后都将变量i的结果写入主存；由于getValue()是无锁访问i，它可能获取的可能是increment()方法第一次自增的结果。\n那么解决办法有：\n同步getValue()方法； 将2步自增换成一步操作(并不能保证每次getValue()获取的都是期望值，只是不再出现奇数罢了)； 使用原子类 Java SE 5 引入了java.util.concurrent.atomic包，里面提供了原子性变量类，这些类提供了一些原子性操作，实际应用的不多，但合理应用可以提升应用性能。\n不要过分依赖原子类，就像不要过分依赖原子性一样。\n谨慎使用原子类 # 可以使用AtomicInteger类对AtomicTest类进行优化，使其得到预期的结果：\npublic class AtomicClassTest implements Runnable { private AtomicInteger i = new AtomicInteger(0); public int getValue() { // atomic operation return i.get(); } /** * 无锁的原因不是因为原子性，而是因为有且只有一个原子操作 * 若此处使用 * \u0026lt;pre\u0026gt; * i.incrementAndGet(); * i.incrementAndGet(); * \u0026lt;/pre\u0026gt; * 那么依旧和{@link AtomicTest}一样失败 */ private void increment() { i.addAndGet(2); } @Override public void run() { while (true) increment(); } public static void main(String[] args) throws InterruptedException { AtomicClassTest act = new AtomicClassTest(); ExecutorService executor = Executors.newSingleThreadExecutor(); executor.execute(act); ScheduledExecutorService s = Executors.newSingleThreadScheduledExecutor(); s.schedule(() -\u0026gt; { // 此方法不会主动退出 System.out.println(\u0026#34;Aborting...\u0026#34;); executor.shutdown(); s.shutdown(); System.exit(0); }, 5, TimeUnit.SECONDS); while (true) { int value = act.getValue(); // the value can still be odd if (value % 2 != 0) { System.out.println(value); System.exit(0); } } } } 上面的示例中，方法不用同步，获取到的i的值也不会是奇数。\n思考这个问题，main线程每次读取的都是最新修改的i么？\n不一定\n因为原子性并不能保证可见性，main线程也并不能保证每次获取的都是最新的i值。\n可见性（volatile） # 在讨论原子性的时候，提到了原子操作并不能保证可见性。什么是可见性？可见性指的是一个变量被被线程修改后，另一个线程能够马上知道这一修改。\nJava SE 5 提供了volatile关键字保证可见性，对volatail域的修改会马上写入到主存中，其他线程会的本地缓存会失效而从主存中去读取。\n听起来不错，volatile似乎可以解决资源共享的问题，真的是这样么？\n遗憾的是，volatile并不能保证原子性：\npublic class VolatileIsNotAtomic { // 将变量设置为volatile并不能保证并发安全 private volatile int sum; void increase() { sum++; } void multiThread2() throws InterruptedException { for (int i = 0; i \u0026lt; 10; i++) { Thread thread = new Thread(() -\u0026gt; { for (int j = 0; j \u0026lt; 1000; j++) { increase(); } }); thread.start(); } Thread.sleep(3000); System.out.println(sum); } public static void main(String[] args) throws InterruptedException { VolatileIsNotAtomic va = new VolatileIsNotAtomic(); va.multiThread2(); } } /* output:(sample) 8806 *///:~ 上例中将域设置为volatile并不能解决多线程环境下的资源共享问题，原因在于，volatile只保证了可见性，没有保证共享资源的有序访问。\nvolatile关键字的使用非常有限，当想使用volatile关键字的时候，需要仔细考量，因为其可能有潜在的多线程风险。\nvolatiile关键字最著名的应用是在双重检查( double-check-lock ) 单例中：\npublic class DoubleCheckSingleton { private static volatile DoubleCheckSingleton instance; private DoubleCheckSingleton() { } public static DoubleCheckSingleton getInstance() { if (instance == null) { synchronized (DoubleCheckSingleton.class) { // the double check lock if (instance == null) { instance = new DoubleCheckSingleton(); } } } return instance; } } 更详细的关于volatile关键字的介绍： Java内存模型与volatile关键字\n写64位数据的需要2次独立的写入过程，每次写32位\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n不一定正确，还需要查阅资料进行确认\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":64,"href":"/zh/docs/java/collections/4_Map_linkedhashmap/","title":"LinkedHashMap","section":"集合框架","content":"LinkedHashMap(链表散列映射)是HashMap的导出类，像LinkedHashSet与HashSet的关系一样。\n其与HashMap的差别在于其使用LinkedList来维护键值对插入的顺序，其插入机制和HashMap是一致的。\nLinkedHashMap和HashMap的性能相差不大，与HashSet和LinkedHashSet 一致：\n集合 特征 HashMap HashMap基于散列表，插入和查询键值对的开销是固定的 LinkedHashMap 和HashMap类似，不过其使用LinkedList维护内部次序，因此其迭代顺序是插入顺序或者LRU（最近最少使用）次序，性能稍差于HashMap 元素排序 # 一般地，LinkedHashMap使用插入顺序（ insertion order ）。但有特殊情况，LinkedHashMap提供构造参数accessOrder，来根据访问顺序（ access order ）对映射条目进行迭代。\n主要构造器：\n/** * Constructs an empty LinkedHashMap instance with the * specified initial capacity, load factor and ordering mode. * * @param initialCapacity the initial capacity * @param loadFactor the load factor * @param accessOrder the ordering mode - true for * access-order, false for insertion-order * @throws IllegalArgumentException if the initial capacity is negative * or the load factor is nonpositive */ public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) { super(initialCapacity, loadFactor); this.accessOrder = accessOrder; } 当使用访问顺序时，映射条目的会按照最少访问——最多访问的顺序迭代，也就是说每次有效访问，受到影响的条目都会“移动”到链表的尾部，这个性质非常适合 “最近最少使用”（LRU）高速缓存。\n有效访问 # 那么哪些方法是有效访问呢？\nput get putIfAbsent getOrdefault compute computeIfAbsent computeIfPresent merge replace 其中，replace方法只有成功替换值之后才是有效访问\nstatic { map.put(\u0026#34;hebe\u0026#34;, \u0026#34;不醉不会\u0026#34;); map.put(\u0026#34;andy\u0026#34;, \u0026#34;谢谢你的爱\u0026#34;); map.put(\u0026#34;lala\u0026#34;, \u0026#34;寻人启事\u0026#34;); map.put(\u0026#34;yoga\u0026#34;, \u0026#34;成全\u0026#34;); } static void accessOrderTest() { Map\u0026lt;String, String\u0026gt; lhm = new LinkedHashMap\u0026lt;\u0026gt;(8, 0.75f, true); lhm.putAll(map); System.out.println(\u0026#34;entry in access order:\u0026#34;); // 有效访问会将entry移动至队尾 lhm.replace(\u0026#34;yoga\u0026#34;, \u0026#34;说谎\u0026#34;); // Java 8新增方法 lhm.computeIfPresent(\u0026#34;hebe\u0026#34;, (k, v) -\u0026gt; \u0026#34;魔鬼中的天使\u0026#34;); lhm.put(\u0026#34;chua\u0026#34;, \u0026#34;坠落\u0026#34;); lhm.get(\u0026#34;lala\u0026#34;); lhm.forEach((k, v) -\u0026gt; System.out.println(\u0026#34;\\t\u0026#34; + k + \u0026#34;: \u0026#34; + v)); } /* output: entry in access order: andy: 谢谢你的爱 yoga: 说谎 hebe: 魔鬼中的天使 chua: 坠落 lala: 寻人启事 *///:~ 值得一提的是，对LinkedHashMap的视图操作不影响迭代顺序：\nstatic void viewTest() { Map\u0026lt;String, String\u0026gt; lhm = new LinkedHashMap\u0026lt;\u0026gt;(8, 0.75f, true); lhm.putAll(map); lhm.forEach((k, v) -\u0026gt; System.out.println(\u0026#34;\\t\u0026#34; + k + \u0026#34;: \u0026#34; + v)); Set\u0026lt;Map.Entry\u0026lt;String, String\u0026gt;\u0026gt; entries = lhm.entrySet(); // 视图操作不会影响映射的排序 Iterator\u0026lt;Map.Entry\u0026lt;String, String\u0026gt;\u0026gt; i = entries.iterator(); for (Map.Entry\u0026lt;String, String\u0026gt; entry : entries) { entry.setValue(\u0026#34;魔鬼中的天使\u0026#34;); break; } System.out.println(\u0026#34;------\u0026#34;); lhm.forEach((k, v) -\u0026gt; System.out.println(\u0026#34;\\t\u0026#34; + k + \u0026#34;: \u0026#34; + v)); i.next(); } /* output: hebe: 不醉不会 lala: 寻人启事 yoga: 成全 andy: 谢谢你的爱 ------ hebe: 魔鬼中的天使 lala: 寻人启事 yoga: 成全 andy: 谢谢你的爱 *///：～ 移除最老K-V对 # 关于LinkedHashMap的一个重要的用途，还有一个重要的方法，利用好此方法可以将LinkedHashMap作为缓存使用。\nprotected boolean removeEldestEntry(Map.Entry\u0026lt;K,V\u0026gt; eldest) { return false; } 这个方法在put或者putAll方法插入新条目到映射之后被调用，也就是说，使用put更新已有key的value不会触发此操作1。\n如果方法返回false，不执行操作；返回true，则移除参数eldest条目。\n参数 eldest是映射的“最旧的”元素——当前最先插入/最少访问的元素，即队头元素：\nvoid afterNodeInsertion(boolean evict) { // possibly remove eldest LinkedHashMap.Entry\u0026lt;K,V\u0026gt; first; // if true，移除队头元素 if (evict \u0026amp;\u0026amp; (first = head) != null \u0026amp;\u0026amp; removeEldestEntry(first)) { K key = first.key; removeNode(hash(key), key, null, false, true); } } 不重写的前提下，removeEldestEntry方法始终返回false——也就是说永远不会作任何操作，可以继承此方法（从访问权限修饰符也知道），改变方法行为。\n此法可以用来在put和putAll之后操作映射，如此做之后，此法一定要返回false，不再允许映射有后续的操作，原因很简单——若在操作时就remove了eldest，返回true之后该如何？\nremoveEldestEntry可以作用于插入顺序和访问顺序的LinkedeHashMap中：\nprivate static void eldestRemoveTest() { class Access\u0026lt;K, V\u0026gt; extends LinkedHashMap\u0026lt;K, V\u0026gt; { @Override protected boolean removeEldestEntry(Map.Entry\u0026lt;K, V\u0026gt; eldest) { return size() \u0026gt; 1; } } Access\u0026lt;Integer, String\u0026gt; access = new Access\u0026lt;\u0026gt;(); access.put(1, \u0026#34;apple\u0026#34;); // Access中始终只有最后插入的一个条目 access.put(2, \u0026#34;google\u0026#34;); access.forEach((k, v) -\u0026gt; System.out.println(k + \u0026#34;: \u0026#34; + v)); } /* output 2: google *///:~ 上例中，每次put后调用removeEldestEntry方法，最终映射中只有最后插入的条目。\nstatic void lruCacheTest() { class Cache\u0026lt;K, V\u0026gt; extends LinkedHashMap\u0026lt;K, V\u0026gt; { private final int count = 50; private Cache(int initialCapacity, float loadFactor, boolean accessOrder) { super(initialCapacity, loadFactor, accessOrder); } /** * 此方法总是返回false * * @param eldest * @return false */ @Override protected boolean removeEldestEntry(Map.Entry\u0026lt;K, V\u0026gt; eldest) { Set\u0026lt;Map.Entry\u0026lt;K, V\u0026gt;\u0026gt; entries = entrySet(); // lambda表达式中使用外部变量需要保证线程安全 AtomicInteger vs = new AtomicInteger(); entries.removeIf(next -\u0026gt; { V value = next.getValue(); if (value instanceof Integer) { if ((Integer) value \u0026gt; 0) { vs.addAndGet((Integer) value); return (Integer) value \u0026lt; 10; } } return false; }); // 打印次数反映此法的调用次数 System.out.println(vs.intValue() == count); //若在此方法中对集合进行修改，那么必须返回false return false; } } Cache\u0026lt;Integer, Integer\u0026gt; cache = new Cache\u0026lt;\u0026gt;(8, 0.75f, true); // 初始化映射集， afterNodeInsertion cache.put(1, 0); cache.put(2, 0); cache.put(3, 0); cache.put(4, 0); cache.put(5, 0); for (int i = 0; i \u0026lt; cache.count; i++) { int key = new Random().nextInt(50) % 5 + 1; int value = cache.get(key); if (i == cache.count - 1) { //保证最后一次访问removeEldestEntry方法 cache.remove(key); } // 将值增1，实现计数器效果 // 此处不能使用compute方法，因此法会调用afterNodeInsertion // 设计的目的在最后一次put之后调用afterNodeInsertion方法，而使用compute会调用2次 // cache.put(key, cache.compute(key, (k, v) -\u0026gt; Integer.sum(value, 1))); cache.put(key, ++value); } System.out.println(\u0026#34;-------\u0026#34;); cache.forEach((k, v) -\u0026gt; System.out.println(k + \u0026#34;: \u0026#34; + v)); } /* output: false false false false false true ------- 1: 11 2: 12 4: 14 *///:~ 上例对一个容量为5的LinkedList进行50次随机访问，每次访问后记录访问次数（用value自增），最后删除访问次数不到10次的条目。可以看到，removeEldestEntry方法调用了6次，最后映射集中只有访问次数大于10次的键值对了。\n如何链接节点 # 我们知道，LinkedHashMap在HashMap的基础上使用LinkedList（并不是集合框架中的LinkedList，独立实现）将键值对链接起来，因此键值对才能够被有序迭代，那么这一动作是在什么时候发生的呢？\n这一过程涉及到2个方法：\n// 覆盖了HashMap的newNode方法 Node\u0026lt;K,V\u0026gt; newNode(int hash, K key, V value, Node\u0026lt;K,V\u0026gt; e) { LinkedHashMap.Entry\u0026lt;K,V\u0026gt; p = new LinkedHashMap.Entry\u0026lt;K,V\u0026gt;(hash, key, value, e); // 链接节点 linkNodeLast(p); return p; } // link at the end of list private void linkNodeLast(LinkedHashMap.Entry\u0026lt;K,V\u0026gt; p) { LinkedHashMap.Entry\u0026lt;K,V\u0026gt; last = tail; tail = p; if (last == null) head = p; else { p.before = last; last.after = p; } } 上面的两个方法可以看到，每次插入键值对到映射中时，总会和前一个节点建立连接。\n回调方法 # LinkedHashMap中有3个重要的回调方法，是LinkedHashMap维护链表以及实现顺序迭代的重要依赖。\nafterNodeRemoval # // 删除键值对之后调用 void afterNodeRemoval(Node\u0026lt;K,V\u0026gt; e) { // unlink LinkedHashMap.Entry\u0026lt;K,V\u0026gt; p = (LinkedHashMap.Entry\u0026lt;K,V\u0026gt;)e, b = p.before, a = p.after; p.before = p.after = null; if (b == null){ // e = head head = a; }else{ // 将b.after指向a b.after = a; } if (a == null){ // e = tail tail = b; }else{ // 将a.before指向b a.before = b; } // 连接完成 } afterNodeInsertion # // 插入新节点之后调用 void afterNodeInsertion(boolean evict) { // possibly remove eldest LinkedHashMap.Entry\u0026lt;K,V\u0026gt; first; // 注意判断条件，需要removeEldestEntry方法返回true // removeEldestEntry方法默认返回false //因此默认行为是不删除节点 if (evict \u0026amp;\u0026amp; (first = head) != null \u0026amp;\u0026amp; removeEldestEntry(first)) { K key = first.key; // 移除队头节点 removeNode(hash(key), key, null, false, true); //will call afterNodeRemoval } } afterNodeAccess # 如果构造LinkedHashMap时指定构造参数accessOrder=true，那么此法将访问的节点移动至队尾\nvoid afterNodeAccess(Node\u0026lt;K,V\u0026gt; e) { // move node to last LinkedHashMap.Entry\u0026lt;K,V\u0026gt; last; // 访问顺序，且访问节点不为tail if (accessOrder \u0026amp;\u0026amp; (last = tail) != e) { LinkedHashMap.Entry\u0026lt;K,V\u0026gt; p = (LinkedHashMap.Entry\u0026lt;K,V\u0026gt;)e, b = p.before, a = p.after; // 置空p.after，因要将p放到队尾 p.after = null; if (b == null){ // b == null说明e==head head = a; }else{ // 将e的前一节点与e的后一节点连接 b.after = a; } if (a != null){ // 将e的后一节点与e的前一节点连接 a.before = b; }else{ // 这个条件会被满足吗？ last = b; } if (last == null){ // 这个条件会被满足吗 head = p; }else { // 将p作为最后节点 p.before = last; last.after = p; } tail = p; ++modCount; } } 上述方法的流程图为：\n实际上使用put方法更新已有键值对时，触发的是另一个方法：afterNodeAccess，此方法将条目移动至队尾（如果使用访问顺序）。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":65,"href":"/zh/docs/java/basic/6_%E6%8A%BD%E8%B1%A1%E7%B1%BB%E4%B8%8E%E6%8E%A5%E5%8F%A3/","title":"抽象类与接口","section":"面向对象","content":" 抽象类与接口 # 抽象类是由abstract关键字修饰的类。将一个普通类用abstract修饰，它就是抽象类。\n若使用abstract修饰方法，那么称该方法为抽象方法，抽象方法没有方法体。\n抽象类 # 但是抽象类有一些特征：\n抽象类不能被实例化（虽然抽象类可以声明域和构造器） 抽象方法必须置于抽象类中 如果你继承某抽象类，但是却不想实现某个抽象方法，可以继续让方法保持抽象，如此做导出类也要被声明为抽象类。\npublic class AbsTest { public static void main(String[] args) { S s = new S(); s.f(); s.g(); } } abstract class F{ public F() { System.out.println(\u0026#34;F constructor\u0026#34;); } abstract void f(); void g(){ System.out.println(\u0026#34;F.g()\u0026#34;); } } class S extends F{ public S() { super(); System.out.println(\u0026#34;S constructor\u0026#34;); } @Override void f() { System.out.println(\u0026#34;S.f()\u0026#34;); } } /* output F constructor S constructor S.f() F.g() *///:~ 接口 # 接口的存在，解决了抽象类只能单继承的不足——同一个类可以实现多个接口。\n接口有如下特点：\n接口不是类，不能使用new实例化一个接口，但是可以声明一个接口变量：\nList x = new ArrayList();\n如上，变量必须引用实现了接口的类对象\n可以使用instanceof操作符判断一个类是否是接口的实现类：\nIf (ObjectA instanceof List) {\u0026hellip;}\n接口的方法都是public的，无论是否使用public修饰；\n接口可以有常量，即public static final CONSTANT = 1，如你所见，接口的常量自动设为静态常量。\n静态方法 # Java SE 8允许在接口中增加 静态方法。\n在Java SE 8之前，通常的做法是将静态方法放在伴随类中，如Java标准库中成对出现的接口和工具类如Collection/Collections或Path/Paths。\n实际上在Java SE 8，我们可以将 Paths的静态方法置于Path接口中：\npublic interface Path{ //... // 通过Path.get(a, b)直接调用 public static Path get(String first, String... more){ return FileSystems.getDefault().getPath(first, more); } } 实现类不可覆盖接口的静态方法。\n默认方法 # 使用default关键字为接口方法提供一个默认实现\n/** @since 1.8 */ public interface java.util.Collection{ //... default Stream\u0026lt;E\u0026gt; parallelStream() { return StreamSupport.stream(spliterator(), true); } } 接口默认方法能够有效地解决“接口演化”问题——不会影响实现类原有逻辑。\n当实现类没有覆盖默认方法时，会调用接口的默认方法。\n参考如下实例：\npublic class InterfaceTest { public static void main(String[] args) { System.out.println(I.get()); I i = new L(); i.j(); i.k(); } } interface I { int CONSTANT = 1; // static method in a interface static int get() { return CONSTANT; } // abstract method void j(); // default method default void k() { System.out.println(\u0026#34;I.k()\u0026#34;); } } class L implements I { @Override public void j() { System.out.println(\u0026#34;L.j()\u0026#34;); } } /* output 1 L.j() I.k() *///:~ 默认方法的冲突 # 考虑如下情况：\n若2个接口提供了同样的默认方法 若超类定义了和接口中默认方法同名同参数的具体方法 情况1中，实现类必须手动覆盖默认方法（一般无需覆盖）来告诉编译器调用哪个方法——实际上是调用类自己的。\npublic class InterfaceTest { public static void main(String[] args) { C c = new C(); c.di(); } } interface I1 { default void di() { System.out.println(\u0026#34;I1.di()\u0026#34;); } } interface I2 { default void di() { System.out.println(\u0026#34;I2.di()\u0026#34;); } } class C implements I1, I2 { // 必须覆盖方法以消除歧义性 @Override public void di() { System.out.println(\u0026#34;calling C.di()\u0026#34;); // 这里使用了I1的实现，注意这里的写法 Interface.super.default_method I1.super.di(); } } /* output calling C.di() I1.di() *///:~ 若上例中I2.di()是抽象方法，是不是就不存在歧义了呢？并不是，编译器还是会提醒覆盖di()方法。\n情况2中，Java使用“类优先”原则，即编译器只会考虑超类的方法而忽略接口的默认方法。\npublic class InterfaceTest2 { public static void main(String[] args) { W w = new W(); w.pType(); } } interface Vita{ default void pType(){ System.out.println(\u0026#34;Vita 柠檬茶\u0026#34;); } } abstract class Drink{ public void pType(){ System.out.println(\u0026#34;Vita 奶\u0026#34;); } } class W extends Drink implements Vita{ // empty body } /* Vita 奶 *///:~ 当然，也可以通过手动覆盖来指定实现，就像情况1中的那样：\n@Override public void pType() { super.pType(); // Vita.super.pType(); } 接口与工厂 # 工厂方法用来生成实现了某个接口的对象，这一过程并不直接调用构造器，而是调用工厂类的创建方法。\n考虑如下示例：\npublic class SimpleFactory { public void serviceConsumer(ServiceFactory sf) { Service s = sf.getService(); s.service_a(); s.service_b(); } public static void main(String[] args) { SimpleFactory sf = new SimpleFactory(); sf.serviceConsumer(new NameServiceFactory()); sf.serviceConsumer(new AgeServiceFactory()); } } interface Service { void service_a(); void service_b(); } interface ServiceFactory { Service getService(); } // 服务1 class NameService implements Service { NameService() {} @Override public void service_a() {System.out.println(\u0026#34;NameService.service_a()\u0026#34;);} @Override public void service_b() {System.out.println(\u0026#34;NameService.service_b()\u0026#34;);} } // 服务1的工厂 class NameServiceFactory implements ServiceFactory { @Override public Service getService() {return new NameService();} } // 服务2 class AgeService implements Service { AgeService() {} @Override public void service_a() {System.out.println(\u0026#34;AgeService.service_a()\u0026#34;);} @Override public void service_b() {System.out.println(\u0026#34;AgeService.service_b()\u0026#34;);} } // 服务2的工厂 class AgeServiceFactory implements ServiceFactory { @Override public Service getService() {return new AgeService();} } /* NameService.service_a() NameService.service_b() AgeService.service_a() AgeService.service_b() *///:~ 上例中，服务类没有提供公有构造器，而其实例化由工厂了完成。这样做的好处在于，在使用服务方法时，无需知道确切服务的类型而去调用构造器，代码完全与接口的实现（本例中为NameService和AgeService）分离，具体应用过程中可以轻易的将A实现替换为B实现。\n"},{"id":66,"href":"/zh/docs/note/pys/6_try_excep/","title":"异常处理","section":"Python","content":" "},{"id":67,"href":"/zh/docs/java/collections/5_HashMap%E7%9A%84%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","title":"HashMap的源码分析","section":"集合框架","content":"HashMap基于散列表，散列表中每一个Node节点（桶）是链表，当两个条目（entry）的key的hash值对桶数（capacity）取模的值相等时，这两个entry会存储在同一个链表中。但当链表中元素达到一定数目时，链表结构会转变为树结构。\n本文从初始化，扩容，插入，获取，删除这几个方面深入讨论了HashMap的实现细节。\n此文中没有讨论HashMap中涉及到树结构的源码。\n基础字段 # HashMap中定义了如下字段：\n// 默认初始容量为16 static final int DEFAULT_INITIAL_CAPACITY = 1 \u0026lt;\u0026lt; 4; //最大容量为2^30 static final int MAXIMUM_CAPACITY = 1 \u0026lt;\u0026lt; 30; //默认装载因子 0.75 static final float DEFAULT_LOAD_FACTOR = 0.75f; //“树化”临界值，当链表数组中的条目数\u0026gt;=8时转变为树结构 static final int TREEIFY_THRESHOLD = 8; // static final int UNTREEIFY_THRESHOLD = 6; // static final int MIN_TREEIFY_CAPACITY = 64; //hashmap存放键值对的容器，Node[]数组的大小就是hashmap的容量大小 transient Node\u0026lt;K,V\u0026gt;[] table; //键值对集 transient Set\u0026lt;Map.Entry\u0026lt;K,V\u0026gt;\u0026gt; entrySet; //键值对数目 transient int size; //hashmap发生结构变化的计数器 transient int modCount; //扩容临界键值对数临界值，当size\u0026gt;threshold时扩容 int threshold; //装载因子，初始化时不指定默认为0.75 final float loadFactor; 初始化 # 构造器 # HashMap提供了以下几个构造器\npublic HashMap(int initialCapacity, float loadFactor){ if (initialCapacity \u0026lt; 0) throw new IllegalArgumentException( \u0026#34;Illegal initial capacity: \u0026#34; + initialCapacity); if (initialCapacity \u0026gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor \u0026lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException( \u0026#34;Illegal load factor: \u0026#34; + loadFactor); // 字段初始化 this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); } // 获取table size容量的方法，结果总是为2的幂 static final int tableSizeFor(int cap) { int n = cap - 1; n |= n \u0026gt;\u0026gt;\u0026gt; 1; n |= n \u0026gt;\u0026gt;\u0026gt; 2; n |= n \u0026gt;\u0026gt;\u0026gt; 4; n |= n \u0026gt;\u0026gt;\u0026gt; 8; n |= n \u0026gt;\u0026gt;\u0026gt; 16; return (n \u0026lt; 0) ? 1 : (n \u0026gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; } public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); } public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted } public HashMap(Map\u0026lt;? extends K, ? extends V\u0026gt; m) { this.loadFactor = DEFAULT_LOAD_FACTOR; // 0.75 putMapEntries(m, false); } // 使用已有Map初始化 final void putMapEntries(Map\u0026lt;? extends K, ? extends V\u0026gt; m, boolean evict) { int s = m.size(); if (s \u0026gt; 0) { if (table == null) { // pre-size // 若无键值对在HashMap中，此处的计算出table size float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft \u0026lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); if (t \u0026gt; threshold) threshold = tableSizeFor(t); } //若参数集过大，先对原集合扩容 else if (s \u0026gt; threshold) resize(); // 将参数集中的键值对填入新的HashMap中 for (Map.Entry\u0026lt;? extends K, ? extends V\u0026gt; e : m.entrySet()) { K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); } } } 可以看到，除了最后一个构造器额外调用了putVal()方法外，构造器都只做了一些字段初始化工作，那么HashMap的键值对是如何“放入”的呢？\n插入键值对 # 键值对的插入与扩容密不可分，接下来从这两个方法来阐述HashMap的键值对插入过程\n当使用put(K,V)向映射中插入键值对时，实际上调用的是putVal()方法\npublic V put(K key, V value) { return putVal(hash(key), key, value, false, true); } /** * Implements Map.put and related methods. 向HashMap中插入元素 * * @param hash key的hash值 * @param key * @param value * @param onlyIfAbsent 若真，那么不修改原键的值（若原键值不为null） * @param evict if false, the table is in creation mode. * @return 之前键映射的值，若之前键不存在则返回null */ final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { // HashMap的数据拷贝一份先 Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) /* * 若是第一次插入，则执行此操作 * 此操作调用了resize方法，实际上做的是初始化table的操作 */ n = (tab = resize()).length; if ((p = tab[i = (n - 1) \u0026amp; hash]) == null) // (n-1) \u0026amp; hash == hash % n, 用于计算key-value放在哪个桶中 // 若桶中尚未有内容，则新建一节点 插入新值 // 良好的散列表应该走这里 tab[i] = newNode(hash, key, value, null); else { // 若桶中有内容 Node\u0026lt;K,V\u0026gt; e; K k; if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) // 并且第一个节点和新节点的key值一样（更新值） // 更新已经存在的k-v值，在桶中直接命中 e = p; else if (p instanceof TreeNode) // 如果已经树化，使用树化后的相关方法 // 不好 e = ((TreeNode\u0026lt;K,V\u0026gt;)p).putTreeVal(this, tab, hash, key, value); else { // 开始找在桶中的位置 for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { // 桶中只有一个元素，但是key没命中，说明这个桶要来新客人了 // 向桶中插入新值 //遍历桶中的节点，若至链尾，则在链尾加入节点 p.next = newNode(hash, key, value, null); //同时判断此时链表中的node数，若 \u0026gt; 8，则由链表转化为二叉树 // binCount = 7时说明链表中已经有8个节点了，此时节点数已经 \u0026gt;8个了 if (binCount \u0026gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st //树化 // sad treeifyBin(tab, hash); break; } if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) // 命中，跳出 更新已有k-v对 //同理，key已存在，跳出for循环 break; // 将p顺延 p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; // 满足条件会更新 if (!onlyIfAbsent || oldValue == null) e.value = value; // LinkedHashMap中用到 afterNodeAccess(e); return oldValue; } } ++modCount; // 扩容判断 if (++size \u0026gt; threshold) resize(); // LinkedHashMap中用到 afterNodeInsertion(evict); //key不存在，插入新key，返回null return null; } 综上， 插入键值对的流程可以概括为：\nflowchart TD a([putVal]) --\u003e b{\"bucket is empty?\"} --\u003e |Yes| c(Insert new k-v) c --\u003e m(afterNodeInsertion)--\u003ez([return]) b --\u003e |No|d{bucket.hash = k.hash?} --\u003e |Yes|o(update exist k-v) o --\u003e y(afterNodeAccess) --\u003e z d --\u003e |No|e{treeified?} e --\u003e|No|g[search buckets] --\u003e| for cycle| g e --\u003e |Yes| f(putTreeNode)--\u003ey g --\u003e h{bucket.k = k} --\u003e |Yes|o h --\u003e |No| j[add new k-v in bucket] --\u003e k{bucket elements \u003e 8?} k --\u003e |Yes| l(Trrify)--\u003eo k --\u003e |No| o 扩容 # 由putVal()方法可知，resize()方法在初始化过程中也发挥了作用。\n/** * 初始化或扩容table * * @return the table */ final Node\u0026lt;K,V\u0026gt;[] resize() { /* * 初始化时，table == null， threshold=0或2^n，视构造器而定 */ Node\u0026lt;K,V\u0026gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap \u0026gt; 0) { if (oldCap \u0026gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } else if ((newCap = oldCap \u0026lt;\u0026lt; 1) \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; oldCap \u0026gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr \u0026lt;\u0026lt; 1; // double threshold } else if (oldThr \u0026gt; 0) // 有参构造使用传入值的2^n作为table size newCap = oldThr; else { // 无参构造器初始化使用默认值作为table size newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } if (newThr == 0) { float ft = (float)newCap * loadFactor; //若table size \u0026gt; 2^30则使threshold为最大整数，扩容不再发生 newThr = (newCap \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; ft \u0026lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; //以下是扩容之后的内容拷贝 @SuppressWarnings({\u0026#34;rawtypes\u0026#34;,\u0026#34;unchecked\u0026#34;}) Node\u0026lt;K,V\u0026gt;[] newTab = (Node\u0026lt;K,V\u0026gt;[])new Node[newCap]; table = newTab; if (oldTab != null) { for (int j = 0; j \u0026lt; oldCap; ++j) { Node\u0026lt;K,V\u0026gt; e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) //桶中只有一个元素，重新计算key值在桶中的位置 newTab[e.hash \u0026amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode\u0026lt;K,V\u0026gt;)e).split(this, newTab, j, oldCap); else { // preserve order //桶中有多个元素 //那么将桶中的元素分裂到2个链表里面去，然后分别放入新table //比如原桶数是4，新桶数即为8，原3号桶中有3，7，11，15四个hash //那么3\u0026amp;4和11\u0026amp;4为0，放在新桶的3号桶；7\u0026amp;4和15\u0026amp;4不为0，放在新桶的7号桶 //元素在新桶中保持原顺序不变，3的下一节点hash由7变成11 Node\u0026lt;K,V\u0026gt; loHead = null, loTail = null; Node\u0026lt;K,V\u0026gt; hiHead = null, hiTail = null; Node\u0026lt;K,V\u0026gt; next; do { next = e.next; // 此处的逻辑比较晦涩，需仔细推敲 if ((e.hash \u0026amp; oldCap) == 0) { /* * 此处的逻辑为： * 第一次循环将loTail和loHead均初始化为e * 第二次将loTail.next改为满足条件 * ((e.hash \u0026amp; oldCap) == 0)的e的更新值 * 这一过程将跳过中间不满足条件的节点 * 由于loHead和loTail都是指向e的引用，loHead.next随之而变 * 接下来将loTail指向e的更新值 * 如此往复，loHead-loTail形成一个新链 */ if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { // 去尾 // 有可能loTail还有子节点，而子节点不应该出现在当前链中 loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; } 上述resize()方法的结论可以通过以下代码验证\npublic class NodeTest\u0026lt;K, V\u0026gt; { final Node\u0026lt;K, V\u0026gt;[] table = new Node[4]; final Node\u0026lt;K, V\u0026gt;[] newtab = new Node[8]; // 构造代码块，构造NodeTest实例时执行 { Node node = new Node(5, \u0026#34;five\u0026#34;, null); Node node1 = new Node(3, \u0026#34;four\u0026#34;, null); Node node2 = new Node(7, \u0026#34;three\u0026#34;, node1); Node node3 = new Node(11, \u0026#34;two\u0026#34;, node2); Node node4 = new Node(15, \u0026#34;one\u0026#34;, node3); Node node5 = new Node(17, \u0026#34;six\u0026#34;, node4); Node node6 = new Node(21, \u0026#34;seven\u0026#34;, node5); Node node7 = new Node(22, \u0026#34;eight\u0026#34;, null); Node node8 = new Node(23, \u0026#34;nine\u0026#34;, null); table[0] = node; table[1] = node7; table[2] = node6; table[3] = node8; } public static void main(String[] args) { NodeTest\u0026lt;Integer, String\u0026gt; nt = new NodeTest\u0026lt;\u0026gt;(); // 看看HashMap源码的resize方法的复制部分究竟搞什么飞机 nt.resize(nt.table, nt.newtab); // 看看此时的newtab nt.printTable(nt.newtab); } public void printTable(Node\u0026lt;K, V\u0026gt;[] newtab) { Node\u0026lt;K, V\u0026gt; g, h; for (int i = 0; i \u0026lt; newtab.length; i++) { if ((g = newtab[i]) != null) { if (g.next == null) { System.out.println(\u0026#34;newtab[\u0026#34; + i + \u0026#34;]\u0026#34; + g.getKey() + \u0026#34;, \u0026#34; + g.getValue()); } else { do { h = g.next; System.out.println(\u0026#34;newtab[\u0026#34; + i + \u0026#34;]\u0026#34; + g.getKey() + \u0026#34;, \u0026#34; + g.getValue()); } while ((g = h) != null); } } } } public void resize(Node\u0026lt;K, V\u0026gt;[] table, Node\u0026lt;K, V\u0026gt;[] newtab) { int oldcap = table.length; for (int j = 0; j \u0026lt; oldcap; ++j) { Node\u0026lt;K, V\u0026gt; e; if ((e = table[j]) != null) { table[j] = null; if (e.next == null) { newtab[j] = e; } else { // preserve order Node\u0026lt;K, V\u0026gt; loHead = null, loTail = null; Node\u0026lt;K, V\u0026gt; hiHead = null, hiTail = null; Node\u0026lt;K, V\u0026gt; next; do { next = e.next; if ((e.key.hashCode() \u0026amp; oldcap) == 0) { if (loTail == null) { loHead = e; } else { loTail.next = e; } loTail = e; } else { if (hiTail == null) { hiHead = e; } else { hiTail.next = e; } hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newtab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newtab[j + oldcap] = hiHead; } } } } } static class Node\u0026lt;K, V\u0026gt; implements Map.Entry\u0026lt;K, V\u0026gt; { K key; V value; Node\u0026lt;K, V\u0026gt; next; public Node(K key, V value, Node\u0026lt;K, V\u0026gt; next) { this.key = key; this.value = value; this.next = next; } @Override public K getKey() { return key; } @Override public V getValue() { return value; } @Override public V setValue(V value) { return null; } } } /* newtab[0]5, five newtab[1]22, eight newtab[2]17, six newtab[2]11, two newtab[2]3, four newtab[3]23, nine newtab[6]21, seven newtab[6]15, one newtab[6]7, three *///:~ 从输出可以看到，原table[2]的节点被拆分后分别放在newtab[2]和newtab[6]的桶里，并且节点的顺序没有变化\n获取键值对 # 一般使用get(K key)方法获取映射中指定键的值，get方法相较putVal()要简单许多\npublic V get(Object key)\npublic V get(Object key) { Node\u0026lt;K,V\u0026gt; e; //有key则返回对应value，否则返回null return (e = getNode(hash(key), key)) == null ? null : e.value; } final Node\u0026lt;K,V\u0026gt; getNode(int hash, Object key) { Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; first, e; int n; K k; // 直接通过hash找到key值存放的桶 if ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp; (first = tab[(n - 1) \u0026amp; hash]) != null) { if (first.hash == hash \u0026amp;\u0026amp; // always check first node // 先从第一个节点查看，如key相等则返回此节点 // 积极处理，好的散列桶中只有一个元素 ((k = first.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) return first; if ((e = first.next) != null) { // 否则查找链表中的其他节点 if (first instanceof TreeNode) // 若已经树化 return ((TreeNode\u0026lt;K,V\u0026gt;)first).getTreeNode(hash, key); do { if (e.hash == hash \u0026amp;\u0026amp; // 遍历寻找 ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null; } 另外判断一个映射中是否存在某个键对应的值对应的方法\npublic boolean containsKey(Object key) { return getNode(hash(key), key) != null; } 实际上也是调用的上面提到的getNode()方法\n删除键值对 # 使用remove(K key)删除映射中的键值对\npublic V remove(Object key) { Node\u0026lt;K,V\u0026gt; e; //返回null或对应key的value return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; } /** * Implements Map.remove and related methods. * * @param hash hash for key * @param key the key * @param value the value to match if matchValue, else ignored * @param matchValue if true only remove if value is equal * @param movable if false do not move other nodes while removing * @return the node, or null if none */ final Node\u0026lt;K,V\u0026gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) { Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; p; int n, index; // 直接定位存放键值对的桶 if ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp; (p = tab[index = (n - 1) \u0026amp; hash]) != null) { Node\u0026lt;K,V\u0026gt; node = null, e; K k; V v; if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) // 若第一个节点就是，那就是它了 node = p; else if ((e = p.next) != null) { if (p instanceof TreeNode) node = ((TreeNode\u0026lt;K,V\u0026gt;)p).getTreeNode(hash, key); else { // 遍历链表定位key do { if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) { node = e; break; } p = e; } while ((e = e.next) != null); } } // 调整链表 if (node != null \u0026amp;\u0026amp; (!matchValue || (v = node.value) == value || (value != null \u0026amp;\u0026amp; value.equals(v)))) { if (node instanceof TreeNode) ((TreeNode\u0026lt;K,V\u0026gt;)node).removeTreeNode(this, tab, movable); else if (node == p) // 第一个节点 tab[index] = node.next; else // 非第一个节点 // else语句快的do循环保证了p一定是node的前一个节点 p.next = node.next; ++modCount; --size; // LinkedHashMap用到 afterNodeRemoval(node); return node; } } return null; } "},{"id":68,"href":"/zh/docs/java/concurrency/2%E8%B5%84%E6%BA%90%E8%AE%BF%E9%97%AE%E5%8F%97%E9%99%90_5_%E7%BA%BF%E7%A8%8B%E6%9C%AC%E5%9C%B0%E5%AD%98%E5%82%A8/","title":"线程本地存储","section":"并发编程","content":"使用synchronized关键字对整个方法加锁（防止其他线程访问整个方法）往往会带来更大的性能开销，如果你只想保护某些代码块，可以使用同步代码块，这一段被锁保护的代码块就称为临界区（ critical section ），前面的显式锁所保护的区域以及使用synchronized保护的代码块都是临界区。\n线程本地存储 # 既然共享资源需要考虑同步问题，那么阻止资源共享就可避免线程冲突1。java.lang.ThreadLoacl类提供了一种机制，为使用相同变量的不同线程提供不同的存储，称为线程本地存储。\n考虑SimpleDateFormat类，它不是线程安全的，如果作为全局变量，在多线程情况下可能会出现问题。使用同步的开销太大，一般是直接使用局部变量来解决问题，不过这也很浪费资源。因为SimpleDateFormat不必是共享资源，这时候，可以使用线程本地存储：\npublic static final ThreadLocal\u0026lt;SimpleDateFormat\u0026gt; dateFormat = ThreadLoacal.withInitial(()-\u0026gt;{ new SimpleDateFormat(\u0026#34;yyyy-MM-dd\u0026#34;); }) 这样每个线程都有一个dataFormat实例。\n下例中，每个线程都有一个线程本地存储，用于存储一个0-100的随机数，然后对其进行自增运算：\npublic class ThreadLocalVariableHolder { // Java 8 提供的方法 private static final ThreadLocal\u0026lt;Integer\u0026gt; value = ThreadLocal.withInitial(new Supplier\u0026lt;Integer\u0026gt;() { @Override public Integer get() { Random r = new Random(); return r.nextInt(100); } }); static class Task implements Runnable { static void increment() { value.set(value.get() + 1); } static Integer getValue() { return value.get(); } @Override public String toString() { return Thread.currentThread() + \u0026#34;: \u0026#34; + getValue(); } @Override public void run() { while (!Thread.currentThread().isInterrupted()) { increment(); System.out.println(this); } } } public static void main(String[] args) throws InterruptedException { for (int i = 0; i \u0026lt; 2; i++) { new Thread(new Task()).start(); } TimeUnit.MILLISECONDS.sleep(1); System.exit(0); } } /* output(sample): Thread[Thread-1,5,main]: 41 Thread[Thread-3,5,main]: 19 Thread[Thread-1,5,main]: 42 Thread[Thread-3,5,main]: 20 Thread[Thread-1,5,main]: 43 Thread[Thread-3,5,main]: 21 ... *///:~ 可以看到，虽然没有同步，但是也无需担心资源冲突的问题，线程1和线程3的数据不会互相干扰。\nThreadLoacl通常作为静态域存储，虽然多个线程只有一个ThreadLocal实例，但是每个实例都有自己的存储，并不会有竞争条件。\n一个使用TheadLocal的例子\n深入理解ThreadLocal\n再论Object超类 # 之前的讨论中，我们说到了 Object超类的hashCode和equals方法，这次在多线程环境下阐释Object超类的其他几个重要方法。\n多线程条件下，使用互斥（mutex）来解决资源共享问题时常用手段，接下来讨论的是如何让2个线程之间协同起来。\n其实在可重入锁的 条件对象的使用中，就使用了对象之间的协作——当要转账时，发现余额不足则当前转账线程等待，而被其他线程唤醒以继续执行（虽然它可能又进入等待）。它工作的机制是线程A获得了锁，但是发现其必须在某个条件上等待（余额充足），于是其阻塞并释放锁（可被中断），线程B得以获得锁并执行，B执行完成之后唤醒线程A，其进入Runnable状态。\n线程在条件上等待的工作逻辑 Object对象的wait()，notify()和notifyAll()方法提供了线程线程之间协作的能力。\nwait()方法使当前线程进入等待，其还可以接受一个超时参数。\nwait()方法必须配合synchronized关键字使用，原因是调用wait()方法时，该对象的监视器被释放了——前提是必须要先持有对象的监视器。\nnotify()用于唤醒一个在当前监视器（如果是临界区，则是指定对象锁；若是同步方法，则是实例锁）上等待的线程，notify方法有相当的局限性：\n并不是唤醒所有的wait()线程，它没有这个能力，只能唤醒在相同锁（监视器）上等待的线程； 并不是唤醒指定当前监视器的线程，它只唤醒一个，至于是哪一个是不确定的； notifyAll()用于唤醒在当前监视器上等待的所有线程。\nnotify()和notifyAll()方法也只能在获取锁之后执行，被唤醒的线程也只有等调用notify()和notifyAll()方法的锁被释放之后才可能继续执行。\n考虑下面的例子：\npublic class WaitOnCondition { private volatile boolean tracked = false; synchronized void playTrack() throws InterruptedException { if (!tracked) { // 在WaitOnCondition实例上等待 wait(); } System.out.println(\u0026#34;play \u0026#34;); tracked = false; } synchronized void recordTrack() { if (tracked) { return; } System.out.println(\u0026#34;record \u0026#34;); tracked = true; // 最好不要使用notify,除非你明确地知道期待的线程一定被唤醒 notifyAll(); } class Play implements Runnable { @SneakyThrows @Override public void run() { while (true) { playTrack(); TimeUnit.MILLISECONDS.sleep(1000); } } } class Record implements Runnable { @SneakyThrows @Override public void run() { while (true) { recordTrack(); TimeUnit.MILLISECONDS.sleep(1000); } } } public static void main(String[] args) throws InterruptedException { WaitOnCondition tp = new WaitOnCondition(); var pool = Executors.newCachedThreadPool(); pool.submit(tp.new Play()); pool.submit((tp.new Record())); TimeUnit.SECONDS.sleep(5); System.exit(0); } } /* output: record play record play record play record play *///:~ record和play任务本来是可以无序运行的，但是由于play任务在playTrack()方法上使用了wait()，条件是布尔值tracked，该值由record任务在recordTrack时修改，修改完成之后record任务负责唤醒等待的线程。这样就完成了线程的交互。\n将tracked设置为volatile变量是volatile关键字的典型应用场景。\n在使用条件时，应当谨慎地避免死锁。\n有时候资源共享是必须的，同步也是必须的。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":69,"href":"/zh/docs/java/basic/7_lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/","title":"Lambda与函数式接口","section":"面向对象","content":" Java 函数式接口和Lambda表达式是 Java 8 中引入的一个重要概念，它允许你将行为作为参数传递给方法，从而实现更简洁、更灵活的代码。\nLambda表达式 # Lambda表达式是一个可传递的代码块，可以在以后执行一次或多次。\n从一个比较器说起：\npublic class Intro { public static void main(String[] args) { String[] s = new String[]{\u0026#34;baidu\u0026#34;,\u0026#34;alibaba\u0026#34;,\u0026#34;tencent\u0026#34;,\u0026#34;baida\u0026#34;,\u0026#34;kingdee\u0026#34;}; // String类实现了Comparable接口，可以直接使用sort方法实现字典序排序 // 为什么是字典序？因为String类的实现逻辑是字典序 Arrays.sort(s); System.out.println(Arrays.toString(s)); Arrays.sort(s, new StringLengthComparator()); //等效使用Lambda表达式实现 //Arrays.sort(s, (o1, o2) -\u0026gt; o1.length() - o2.length()); System.out.println(Arrays.toString(s)); } } // 比较器实现——先按字符串长度排序 class StringLengthComparator implements Comparator\u0026lt;String\u0026gt;{ @Override public int compare(String o1, String o2) { return o1.length() - o2.length(); } } /* output [alibaba, baida, baidu, kingdee, tencent] [baida, baidu, alibaba, kingdee, tencent] *///:~ 上例中，compare方法不是立即调用，在数组完成排序之前，sort方法会一直调用compare方法，只要元素的排列顺序不正确就会重新排列元素。\nAPI:\tpublic static \u0026lt;T\u0026gt; void sort(T[] a, Comparator\u0026lt;? super T\u0026gt; c) sort方法需要一个比较器作为参数，接口Comparator只有一个抽象方法compare，要实现排序，实现compare方法即可，这正是StringLengthComparator类所做的事情。\n由于StringLengthComparator类只有一个方法，这相当于将一段代码块（函数）传递给sort。实际上这就是Java处理函数式编程的方式：Java是面向对象语言，因此必须构造一个对象，这个对象有一个方法包含所需的逻辑代码。\n此例中，如果使用Lambda表达式Arrays.sort(s, (o1, o2) -\u0026gt; o1.length() - o2.length());，那么Arrays.sort会接收实现了Comparator\u0026lt;String\u0026gt;的某个类的对象，并在这个对象上调用compare方法去执行Lambda表达式的“体”，这些对象和类的管理完全取决于具体实现，与传统的内联类相比，更加高效。\nLambda表达式可以将代码块传递给某个对象。形如：\n(String o1, String o2) -\u0026gt; o1.length() - o2.length() 就是一个Lambda表达式，由参数、箭头（-\u0026gt;）以及表达式3部分组成。为什么和代码示例中有细微差别？这里声明了String参数类型。\n如果可以推导出Lambda表达式的参数类型（多数情况如此），那么可以省略类型声明：\n(o1, o2) -\u0026gt; o1.length() - o2.length() 即便Lambda表达式没有参数，也必须保留参数括号，以下Lambda展示了表达式有多句的情况——使用{}，看起来就像一个Java方法：\n() -\u0026gt; {for (int i = 0, i\u0026lt;10, i++) System.out.println(i);} 如果Lambda表达式只有一个参数，并且这个参数类型可以推导得出，甚至连()都可以省略：\nnew ArrayList().removeIf(e -\u0026gt; e == null) 无需指定Lambda表达式的返回类型。Lambda表达式的返回类型总是可以根据上下文推导得出。\n函数式接口 # 对于只有一个抽象方法的接口，需要这种接口的对象时，就可以提供一个Lambda表达式，这种接口叫函数式接口\njava.util.Comparator接口就是一个函数式接口，它只有一个抽象方法：\nint compare(T o1, T o2); 其他方法均被声明为默认方法。\njava.util.function包中定义了很多通用的函数式接口，上文中的Predicate便是。ArrayList中的forEach方法参数就是此包中的另一个函数式接口Consumer:\npublic void forEach(Consumer\u0026lt;? super E\u0026gt; action) 可以用此接口快速遍历集合元素\nlist.forEach(e -\u0026gt; System.out.println(e))\nlist.forEach(System.out::println)方法引用\nJava API使用@FunctionalInterface注解来标注函数式接口。\n类似地，org.springframework.jdbc.core.RowMapper也被声明为一个函数式接口，它只有一个方法mapRow，用来处理SQL语句的回调：\nT mapRow(ResultSet rs,int rowNum) throws SQLException 方法引用 # 如果有现成的方法完成想要传递到其他代码的操作，例如你只想通过forEach打印集合中的元素，可以使用\nlist.forEach(e -\u0026gt; System.out.println(e)) 就像之前提到的那样，但是，也可以直接把println方法传递给forEach，就像这样：\nlist.forEach(System.out::println) 这就是方法引用，它和上面的Lambda表达式是等价的。\n如果Lambda表达式的“体”直接调用了某个方法，而没有其他多余代码，那么这个Lambda表达式可以等价转换为方法引用。\n还是参考比较器的例子：\npublic class Intro { public static void main(String[] args) { String[] s = new String[]{\u0026#34;baidu\u0026#34;, \u0026#34;alibaba\u0026#34;, \u0026#34;tencent\u0026#34;, \u0026#34;baida\u0026#34;, \u0026#34;kingdee\u0026#34;}; // lmabda statement original /*Arrays.sort(s, (o1,o2) -\u0026gt; { if (o1.length() != o2.length()) return o1.length() - o2.length(); return o1.compareTo(o2); })*/ // Lambda expression with method reference Arrays.sort(s, (o1,o2) -\u0026gt; localCompare(o1, o2) ); // method reference Arrays.sort(s, Intro::localCompare) System.out.println(Arrays.toString(s)); private static int localCompare(String o1, String o2) { if (o1.length() != o2.length()) return o1.length() - o2.length(); return o1.compareTo(o2); } } 原始的Lambda表达式有2行代码（2个逻辑），可以将其重构为一个方法，并在Lambda表达式中引用该方法，这样做之后，原Lambda表达式的“体”就变成了一个简单的方法调用，那么它便可以等价为方法引用：\nArrays.sort(s, Intro::localCompare) 方法引用根据调用者和方法类型区分，有3种形式\nobject.instanceMethod：对象调用实例方法\nClass.staticMethod：类调用静态方法\nClass.instanceMethod：类调用实例方法\n前2者较容易理解，第3种情况需要特殊说明，参考如下示例：\n//... Arrays.sort(s, new Comparator\u0026lt;String\u0026gt;() { @Override public int compare(String s3, String str) { return s3.compareToIgnoreCase(str); } }); Arrays.sort(s, (s3, str) -\u0026gt; s3.compareToIgnoreCase(str)); Arrays.sort(s, String::compareToIgnoreCase); //... 当使用类调用实例方法时，第一个参数会成为方法的目标，第二个参数作为方法的参数需求证。\n方法引用种可以使用this和super关键字，分别表示调用当前类和超类的方法。\n变量作用域 # 在使用Spring JDBC操作数据库时，需要用到RowMapper的回调来处理返回数据，前文已提及，RowMapper是一个函数式接口，可以等价为Lambda表达式：\npublic List\u0026lt;Spitter\u0026gt; findAll() { return jdbcOperations.query(SPITTER_SELECT, (rs, rowNum) -\u0026gt; this.mapResult(rs, rowNum)); } // skip mapResult... 可以看到，Lambda表达式中使用了this关键字，指定的是创建这个Lambda表达式的方法的this，通俗地讲，就是调用传入Lambda参数方法的实例，此处的this可以省略。\n之前的所述的Lambda表达式都没有涉及一个概念：自由变量，这是除了表达式和参数之外，Lambda的另一个组成部分，指的是不是参数且不在表达式中定义的变量。\nstatic void repeatMessage(String msg, int delay) { ActionListener listener = e -\u0026gt; { System.out.println(msg); Toolkit.getDefaultToolkit().beep(); }; new Timer(delay, listener).start(); } 当调用repeatMessage(\u0026quot;Hello World\u0026quot;, 1000);时，控制台每隔1s输出Hello World\n上例的Lambda中，msg就是一个自由变量，它来自于repeatMessage方法的参数变量。在运行过程中，Lambda表达式可能会延迟执行或者执行很多次，这时候主线程可能已经结束，repeatMessage方法的参数变量也可能已经销毁了，这个变量是如何保存的呢？\n实际上，Lambda表达式在运行时“捕获”了自由变量的值，可以把Lambda表达式理解为一个含有方法的实例对象，自由变量的的值便复制到了这个实例对象中\n当在Lambda表达式中使用自由变量时，有几个约束：\n1） 不能在Lambda表达式中改变自由变量的值\nstatic void countDown(int start, int delay){ ActionListener listener = evevt -\u0026gt; { // start--; // ERROR! can\u0026#39;t mutate captured variable System.out.println(start); }; new Timer(delay, listener).start(); } 这是出于线程安全的考虑。\n2） 不能引用在外部改变了值的自由变量\nstatic void repeat(String text, int count){ for (int i = 1, i\u0026lt;= count, i++){ ActionListener listener = evevt -\u0026gt; { // System.out.println(i + \u0026#34;text\u0026#34;); // ERROR! can\u0026#39;t refer to changing i }; new Timer(1000, listener).start(); } } 3） 注意变量的命名\nint first = 1; Compartor\u0026lt;String\u0026gt; comp = (first, second) -\u0026gt; first.length() - senond.length(); // ERROR variable first already exists Lambda表达式的“体”和“嵌套块”具有相同的作用域。\n"},{"id":70,"href":"/zh/docs/note/pys/7_scope/","title":"命名空间与作用域","section":"Python","content":" "},{"id":71,"href":"/zh/docs/java/concurrency/3%E8%8E%B7%E5%8F%96%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%94%E5%9B%9E%E5%80%BC/","title":"获取任务的返回值","section":"并发编程","content":" 获取任务的返回值 # 要创建一个任务，通常实现Runnable接口。不幸的是，Runnable接口的run()方法返回void，因此，其并不适合处理计算任务。\n考虑一个经典的问题：用多线程分段计算0-100的加和，我们需要把每个线程计算的值汇总，然后再求和，那么应该怎样获取每个任务返回值呢？\nJava提供了Callable和Future接口，使任务有提供返回值的能力。\nCallable 接口 # V call() throws Exception\nCallable接口只有一个方法call()，和Runnable接口不同的是call()方法有返回值并且抛出受查异常(checked exception)。\n利用Callable接口，上述问题可以轻松解决：\npublic class DividedCalculate { static class Task implements Callable\u0026lt;Integer\u0026gt; { int min; int max; public Task(int min, int max) { this.min = min; this.max = max; } @Override public Integer call() { int sum = 0; for (int i = min; i \u0026lt; max; i++) { sum += i; } return sum; } } @SneakyThrows public static void main(String[] args) { ExecutorService pool = Executors.newCachedThreadPool(); Future\u0026lt;Integer\u0026gt; s3 = pool.submit(new Task(51, 76)); Future\u0026lt;Integer\u0026gt; s2 = pool.submit(new Task(26, 51)); Future\u0026lt;Integer\u0026gt; s4 = pool.submit(new Task(76, 101)); Future\u0026lt;Integer\u0026gt; s1 = pool.submit(new Task(1, 26)); pool.shutdown(); System.out.printf(\u0026#34;%d + %d + %d + %d = %d\u0026#34;, s1.get(), s2.get(), s3.get(), s4.get(), s1.get() + s2.get() + s3.get() + s4.get()); } } /* output: 325 + 950 + 1575 + 2200 = 5050 *///：～ 我们使用执行器提交任务，执行器的submit()方法返回一个带有返回值参数类型的Future\u0026lt;T\u0026gt;对象：\n\u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Callable\u0026lt;T\u0026gt; task)\nFuture 接口 # pubic interface Future\u0026lt;V\u0026gt;\n上面的示例中我们使用Future\u0026lt;Integer\u0026gt;来接收任务的返回值，由此可见接口声明的类型参数就是Callable接口的返回类型。\nFuture封装了异步计算的返回结果。除此之外，Future还提供了一些实用方法来判断任务的执行状态。\nFuture接口支持的方法 # boolean cancel(boolean mayInterruptIfRunning) 尝试取消任务的执行，实际上是向任务发送一个中断（interrupt()）信号。 布尔值参数为true表示向这个任务发送中断信号，false则不发送中断信号。 这个方法返回之后调用isDone()总是返回true； 如果此方法返回true，调用isCanceled()总是返回true。 返回false的情形： - 任务已经执行完毕； - 任务已经被取消； - 由于某些原因不能被取消； 返回true表示任务被成功取消。 boolean isCancelled() 如果任务**正常**完成之前被取消则返回true。 boolean isDone() 如果任务完成则返回true。 注意任务可能是正常执行完成，抛出异常而终止，或者通过isCancel()方法被取消。 上述3种情况任意一种都会导致此方法返回true。 V get() throws InterruptedException,ExecutionException 等待任务执行完成并获取返回值。 调用此方法会抛出异常 - 若方法被取消，抛出CancellationException； - 若方法执行异常，抛出ExecutionException； - 若方法在等待过程中被中断，则抛出InterruptedException； V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException,TimeoutException 在指定超时限制内等待任务执行并获取返回值。 抛出异常和get()方法一样，除外多了一个TimeOutException，超时异常。 特别地，如果只想使用Future的可取消任务的特性，而不需要任务返回值，那么可以将Future声明为Future\u0026lt;?\u0026gt;并且将任务返回null。\npublic class CancelableTask { static class Cancelable\u0026lt;V\u0026gt; implements Callable\u0026lt;V\u0026gt; { @Override public V call() throws Exception { System.out.println(\u0026#34;---\u0026#34;); int i = 0; while (true) { i++; if (i \u0026gt; 100000) { break; } } return null; } } public static void main(String[] args) { ExecutorService service = Executors.newSingleThreadExecutor(); Future\u0026lt;?\u0026gt; submit = service.submit(new Cancelable\u0026lt;\u0026gt;()); System.out.println(submit.cancel(true)); System.out.println(submit.isCancelled()); System.out.println(submit.isDone()); service.shutdown(); } } /* output: true true true *///~ 由于Callable实例无法通过Thread类运行（Thread类是Runnable接口的实现，并且只能通过Runnable初始化），于是我们在之前的分步计算中使用了执行器的submit()方法来获取任务的返回值。\nJava提供了另一个有用的类FutureTask，用来包装Callable或Runnable实例。由于其实现了Future接口，其能够实现Future接口的功能；又由于其实现了Runnable接口，其又能被显示线程或者执行器执行。\nFutureTask 类 # public class FutureTask\u0026lt;V\u0026gt; extends Object implements RunnableFuture\u0026lt;V\u0026gt; public interface RunnableFuture\u0026lt;V\u0026gt; extends Runnable, Future\u0026lt;V\u0026gt; 从类继承关系可以看到FutureTask类同时实现了Future和Runnable接口，因此FutureTask实例是一个可以取消的异步任务，同步也能够使用Future\u0026lt;V\u0026gt;获取任务返回值。从灵活性上来说，其可以用Thread类包装运行或者直接提交（submit）给执行器。\nFutureTask构造器 # FutureTask(Callable\u0026lt;V\u0026gt; callable) FutureTask(Runnable runnable, V result) result是返回类型，如果不需要，可以使用如下形式： Future\u0026lt;?\u0026gt; f = new FutureTask\u0026lt;Void\u0026gt;(runnable, null) FutureTask方法 # // 实现Future的方法 public boolean isCancelled() public boolean isDone() public boolean cancel(boolean mayInterruptIfRunning) public V get() throws InterruptedException, ExecutionException public V get(long timeout,TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException // 实现Runnable的方法 public void run() // protected方法 protected void done() 这个方法在任务执行（正常执行或抛出异常）完成之后被调用。默认实现不执行任何操作， 导出类可以覆盖这个方法并执行相关操作。覆盖方法可以查询任务状态去判断任务是否被取消。 protected void set(V v) 若任务没有返回值或已取消执行，为Future设置返回值。这个方法在任务成功执行完成之前 被run()方法调用。 protected void setException(Throwable t) 若任务没有设置异常或已取消执行，为任务设置任务执行时抛出的异常（ExecutionException）。 这个方法在任务执行失败时被run()方法调用。 protected boolean runAndReset() 这个方法为那些需要多次执行的任务设计。此方法执行任务但是不设置返回值，并将Future设置 为初始状态。若任务出现异常或被取消或已经执行完成，则此方法执行失败。 下面的代码示例展示了FutureTask类中run()和runAndReset()方法的区别：\npublic class FutureTaskImpl\u0026lt;V\u0026gt; extends FutureTask\u0026lt;V\u0026gt; { private int runTime = 0; private boolean isDone = false; public FutureTaskImpl(Callable\u0026lt;V\u0026gt; callable) { super(callable); } public FutureTaskImpl(Runnable runnable, V result) { super(runnable, result); } @Override protected void done() { if (isCancelled()) { System.out.println(\u0026#34;task is canceled\u0026#34;); return; } isDone = true; runTime++; } @Override protected boolean runAndReset() { if (super.runAndReset()) { runTime++; } else { return false; } return true; } static class Task implements Runnable { @Override public void run() { // do something } } static class Task2 implements Callable\u0026lt;Integer\u0026gt; { @Override public Integer call() throws Exception { int sum = 0; for (int i = 0; i \u0026lt; 100; i++) { sum += i; } return sum; } } /** * 先执行{@link FutureTask#run()}再执行{@link #runAndReset()} * \u0026lt;p\u0026gt; * 任务不可执行 */ void resetAfterRun() { run(); System.out.println(runAndReset()); // false System.out.println(\u0026#34;runTime:\u0026#34; + runTime); System.out.println(\u0026#34;isDone:\u0026#34; + isDone); } /** * 先执行{@link #runAndReset()}再执行{@link FutureTask#run()} * \u0026lt;p\u0026gt; * 任务可以再次执行 * * 对于有返回值的任务，执行{@link #runAndReset()}之后 * 调用{@link FutureTask#get()} * 方法获取返回值会造成阻塞 */ @SneakyThrows void runAfterReset() { for (; ; ) { runAndReset(); if (runTime \u0026gt; 1) break; } // V v = get(); // blocked System.out.println(\u0026#34;isDone: \u0026#34; + isDone); // false run(); System.out.println(\u0026#34;runTime: \u0026#34; + runTime); V v1 = get(); System.out.println(\u0026#34;result: \u0026#34; + v1); System.out.println(\u0026#34;isDone: \u0026#34; + isDone); // true } public static void main(String[] args) { // 构造一个没有返回值的FutureTask FutureTaskImpl\u0026lt;?\u0026gt; ft = new FutureTaskImpl\u0026lt;\u0026gt;(new Task(), null); FutureTaskImpl\u0026lt;?\u0026gt; ft2 = new FutureTaskImpl\u0026lt;\u0026gt;(new Task2()); ft2.runAfterReset(); // ft.resetAfterRun(); } } /* output: isDone: false runTime: 3 result: 4950 isDone: true *///~ 可以看到，我们计划在循环中让任务执行runAndReset()2次，之后尝试去调用get()方法，发现进程会一直阻塞，这也和api文档中描述的一致（without setting its result, and then resets this future to initial state），说明任务没有执行完成而且是处于初始状态。\n接下来的isDone()方法返回false也验证了这点，接着调用run()方法再次运行任务，最后获取任务的返回值，看到任务共执行了3次，最后的结果是最后一次run()方法返回的结果，接着的isDone()方法返回true，说明任务执行完成。\n相反地，如果先运行run()方法，再尝试运行runAndReset()，后者直接返回false。\n应用示例 # 在 抢票问题中，为了获取每个线程抢到的票数，我们使用了ThreadLocal来存放当前线程和其抢到的票（自定义bean）的信息，并在任务执行完成之后将其返回，以便程序完成之后明确地知道每个线程抢到的票数。\n之所以使用自定义bean使任务包含线程信息而不使任务直接返回其抢到的票数，是因为线程池无法操作线程，更加无法在线程池的维度获取当前运行任务的线程信息。\n利用FutureTask对象，我们则可以通过显示的构造线程来简化任务的代码：\npublic class TicketIssueWithFutureTask extends TicketIssue { private final HashMap\u0026lt;Thread, Future\u0026lt;Integer\u0026gt;\u0026gt; resultMap = new HashMap\u0026lt;\u0026gt;(); static class Purchase implements Callable\u0026lt;Integer\u0026gt; { // 线程抢到的票计数器 // 线程内部存储一般声明为static private static ThreadLocal\u0026lt;Integer\u0026gt; tl = ThreadLocal.withInitial(() -\u0026gt; 0); private final Tick tick; Purchase(Tick tick) { this.tick = tick; } @Override public Integer call() { while (true) { synchronized (tick) { if (tick.getTick()) { tl.set(tl.get() + 1); try { // 给其他线程机会 tick.wait(10); } catch (InterruptedException e) { e.printStackTrace(); } } else { if (!tick.isTickSupply) break; } } } return tl.get(); } } @Override void multiPurchase(int threadCount) throws ExecutionException, InterruptedException { for (int i = 0; i \u0026lt; threadCount; i++) { // FutureTask实现了Runnable，可以在显式线程执行之后再通过其获取返回值 // 当然，也可以通过执行器执行 FutureTask\u0026lt;Integer\u0026gt; ft = new FutureTask\u0026lt;\u0026gt;(new Purchase(tick)); Thread t = new Thread(ft); t.start(); resultMap.put(t, ft); } int sum = 0; for (Map.Entry\u0026lt;Thread, Future\u0026lt;Integer\u0026gt;\u0026gt; entry : resultMap.entrySet()) { System.out.println(entry.getKey().getName() + \u0026#34; 抢到票：\u0026#34; + entry.getValue().get() + \u0026#34;张\u0026#34;); s um = sum + entry.getValue().get(); } System.out.println(\u0026#34;已购票数：\u0026#34; + sum); } public static void main(String[] args) throws Exception { TicketIssueWithFutureTask ti = new TicketIssueWithFutureTask(); ti.singleSupply(10); ti.multiPurchase(12); } } 使用FutureTask之后，使用显式的线程对应每个线程的返回值，就可以获得想要的信息。\n"},{"id":72,"href":"/zh/docs/java/collections/6_Collections/","title":"Collections工具类","section":"集合框架","content":"集合框架中一个重要的类，其实是Collection接口的伴随类，其中定义了许多实用方法，用来获取集合视图，或提供一些方便的操作集合元素的算法。\n由于视图是直接封装的Collection接口，因此其方法有些局限，并且由于特殊的设计，部分操作是不允许的（会抛出 UnsupportedOperationExceptin ）。\n不可修改视图 # 顾名思义，一旦获取，其内容不再可以修改，Java集合框架中可以用于获取的不可修改视图有：\nCollections通过静态方法获取的8个不可修改视图\nJava中提供的获取不可修改视图的方法，只能用来遍历原集合中的信息，无法通过任何手段（集合，迭代器，entry等）修改集合，例如，当调用add方法时，Java的处理方式就是抛出 UnsupportedOperationException 异常：\npublic class UnmodifiableViewTest { static List\u0026lt;String\u0026gt; l = new ArrayList\u0026lt;String\u0026gt;() {{ add(\u0026#34;fan\u0026#34;); add(\u0026#34;bar\u0026#34;); add(\u0026#34;foo\u0026#34;); add(\u0026#34;anchor\u0026#34;); add(\u0026#34;ripe\u0026#34;); add(\u0026#34;rope\u0026#34;); add(\u0026#34;hope\u0026#34;); }}; static Set\u0026lt;String\u0026gt; s = new HashSet\u0026lt;\u0026gt;(l); static Map\u0026lt;String, String\u0026gt; m = new HashMap\u0026lt;String, String\u0026gt;() {{ put(\u0026#34;c\u0026#34;, \u0026#34;cable\u0026#34;); put(\u0026#34;b\u0026#34;, \u0026#34;bar\u0026#34;); put(\u0026#34;f\u0026#34;, \u0026#34;floyd\u0026#34;); put(\u0026#34;e\u0026#34;, \u0026#34;echo\u0026#34;); put(\u0026#34;a\u0026#34;, \u0026#34;anchor\u0026#34;); put(\u0026#34;d\u0026#34;, \u0026#34;dribble\u0026#34;); }}; public static void main(String[] args) { // unmodifiableList(); // unmodifiableSet(); unmodifiableMap(); } static void unmodifiableList() { List\u0026lt;String\u0026gt; ul = Collections.unmodifiableList(l); // 对视图集的元素增删会抛出UnsupportedOperationException // strings.add(\u0026#34;add\u0026#34;); // strings.remove(\u0026#34;bar\u0026#34;); // strings.removeAll(l); ul.forEach(System.out::print); //可以操作迭代器 ListIterator\u0026lt;String\u0026gt; iterator = ul.listIterator(); System.out.println(iterator.nextIndex()); // List\u0026lt;String\u0026gt; ul_sub = l.subList(1, 3); List\u0026lt;String\u0026gt; ul_sub = ul.subList(1, 3); // 子集对元素的操作也是不支持的 // ul_sub.removeIf(s -\u0026gt; s.equals(\u0026#34;foo\u0026#34;)); ul_sub.forEach(System.out::println); } static void unmodifiableSet() { Set\u0026lt;String\u0026gt; set = Collections.unmodifiableSet(s); System.out.println(set.contains(\u0026#34;anchor\u0026#34;)); Iterator\u0026lt;String\u0026gt; i = set.iterator(); i.next(); // 迭代器无法移除元素是必然的 // i.remove(); // set.clear(); TreeSet\u0026lt;String\u0026gt; ts = new TreeSet\u0026lt;\u0026gt;(s); // 使用sorted set构建 NavigableSet\u0026lt;String\u0026gt; ns = Collections.unmodifiableNavigableSet(ts); // 无法从集中移除元素 UnsupportedOperationException // String s = ns.pollFirst(); System.out.println(ns.first()); NavigableSet\u0026lt;String\u0026gt; anchor = ns.headSet(\u0026#34;anchor\u0026#34;, true); // 子集也不能被修改 // anchor.remove(\u0026#34;anchor\u0026#34;); anchor.forEach(System.out::println); } static void unmodifiableMap() { Map\u0026lt;String, String\u0026gt; map = Collections.unmodifiableMap(m); // 不支持的操作 // map.replace(\u0026#34;a\u0026#34;,\u0026#34;apple\u0026#34;); Set\u0026lt;Map.Entry\u0026lt;String, String\u0026gt;\u0026gt; e = map.entrySet(); System.out.println(map.get(\u0026#34;f\u0026#34;)); TreeMap\u0026lt;String, String\u0026gt; tm = new TreeMap\u0026lt;\u0026gt;(m); // 使用sorted map NavigableMap\u0026lt;String, String\u0026gt; nm = Collections.unmodifiableNavigableMap(tm); System.out.println(nm.ceilingEntry(\u0026#34;car\u0026#34;).getValue()); NavigableMap\u0026lt;String, String\u0026gt; sm = nm.subMap(\u0026#34;b\u0026#34;, true, \u0026#34;d\u0026#34;, true); // 不支持的操作 // sm.remove(\u0026#34;c\u0026#34;); sm.forEach((k, v) -\u0026gt; System.out.println(k + \u0026#34;, \u0026#34; + v)); NavigableMap\u0026lt;String, String\u0026gt; descendingMap = sm.descendingMap(); descendingMap.forEach((k, v) -\u0026gt; System.out.println(k + \u0026#34;, \u0026#34; + v)); } } 稍微查看源码就知道，不可修改视图的工作方式：\nstatic class UnmodifiableList\u0026lt;E\u0026gt; extends UnmodifiableCollection\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt; { //... public E get(int index) {return list.get(index);} public E set(int index, E element) { throw new UnsupportedOperationException(); } public void add(int index, E element) { throw new UnsupportedOperationException(); } public E remove(int index) { throw new UnsupportedOperationException(); } //... } 不可修改视图的封装思路就是，当试图改变集合时，不予处理并抛出异常。\n同步视图 # 由于Java集合框架中的组成都不是同步的（Vector和Hashtable除外）， Java SE 8 API Specification 里面重复出现的一段话就是：\nNote that this implementation is not synchronized. If multiple threads access an ArrayList instance concurrently, and at least one of the threads modifies the list structurally, it must be synchronized externally. (A structural modification is any operation that adds or deletes one or more elements, or explicitly resizes the backing array; merely setting the value of an element is not a structural modification.) This is typically accomplished by synchronizing on some object that naturally encapsulates the list. If no such object exists, the list should be \u0026ldquo;wrapped\u0026rdquo; using the Collections.synchronizedListmethod. This is best done at creation time, to prevent accidental unsynchronized access to the list: List list = Collections.synchronizedList(new ArrayList(...));\n因此同步视图就是用来处理并发访问的，除了同步视图之外，java.util.concurrent包里提供了线程安全的集合，用于并发环境。\nCollections通过静态方法获取的8个同步视图（不包含SynchronizedRandomAccessList）\n受查视图 # 受查视图用来对泛型类发生问题时提供调试支持。\nCollections通过静态方法获取的9个受查视图（不包含checkededRandomAccessList）\n实用方法 # 空集 # Collections提供了一些返回空集合、映射、迭代器的方法，实际上返回的是Collections所封装的对应的对象。\n向返回的空集合中插入元素会抛出 UnsupportedOperationException。\nstatic void emptyList(){ List\u0026lt;Object\u0026gt; emptyList = Collections.emptyList(); //emptyList.add(1); // USOE System.out.println(emptyList.size()); // actual 0 } 单一元素集合 # Collections还提供了返回指定1个元素的集合或映射：\nstatic void singletonList(){ Set\u0026lt;String\u0026gt; singlton = Collections.singleton(\u0026#34;singlton\u0026#34;); System.out.println(singlton.size()); // actual 1 // singlton.add(\u0026#34;sin\u0026#34;); // USOE // singlton.clear(); // USOE } 同样地，单一元素集合也是不可修改的。\n其他有利算法 # Collections类还包含了很多有利的算法，如：\nCollections.sort(List\u0026lt;T\u0026gt;)\n根据对集合元素按照自然顺序升序排序，而\nCollections.binarySearch(List\u0026lt;? extends Comparable\u0026lt;? super T\u0026gt;\u0026gt; list, T key)\n会二分查找集合中的元素，其前提是元素是自然升序排序的1\n除此之外，Collections还定义了一些实用方法，简单列出部分：\npublic static void reverse(List\u0026lt;?\u0026gt; list) public static void shuffle(List\u0026lt;?\u0026gt; list) public static void shuffle(List\u0026lt;?\u0026gt; list, Random rnd) public static \u0026lt;T extends Object \u0026amp; Comparable\u0026lt;? super T\u0026gt;\u0026gt; T min(Collection\u0026lt;? extends T\u0026gt; coll) public static \u0026lt;T\u0026gt; T min(Collection\u0026lt;? extends T\u0026gt; coll, Comparator\u0026lt;? super T\u0026gt; comp) public static \u0026lt;T extends Object \u0026amp; Comparable\u0026lt;? super T\u0026gt;\u0026gt; T max(Collection\u0026lt;? extends T\u0026gt; coll) public static \u0026lt;T\u0026gt; T max(Collection\u0026lt;? extends T\u0026gt; coll, Comparator\u0026lt;? super T\u0026gt; comp) 排序和查找有重载方法，具体请查看API文档\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":73,"href":"/zh/docs/java/basic/8_%E5%86%85%E9%83%A8%E7%B1%BB/","title":"内部类","section":"面向对象","content":" 内部类 # 将一个类定义在另一个类的内部，这就是内部类。\n定义言简意赅 ，内涵丰富多彩。\npublic class Flight2 { // inner class class Comp{ private String name; public String getName(){ return name; } public void setName(String name) { this.name = name; } } class Dest{ private String to; public Dest(String to) { this.to = to; } public String showDest(){ return to; } } // use method to get inner class instance public Comp comp(){ return new Comp(); } // use method to get inner class instance public Dest dest(String to){ return new Dest(to); } public void ship(){ Comp c = comp(); c.setName(\u0026#34;South Air\u0026#34;) Dest d = dest(\u0026#34;HK\u0026#34;); System.out.println(\u0026#34;the flight is \u0026#34; + c.getName() + \u0026#34; to \u0026#34; + d.showDest()); } public static void main(String[] args) { Flight2 f2 = new Flight2(); f2.ship(); // OuterClassName.InnerClassName to refer inner class Flight2 f2s = new Flight2(); Flight2.Comp comp = f2s.comp(); Flight2.Dest d2 = f2s.dest(\u0026#34;New York\u0026#34;); } } 通过new关键字实例化内部类和使用普通类并没有什么区别。\n需要说明的是：当创建一个内部类的引用时，需要使用OuterClassName.InnerClassName这样的格式指明内部类的类型。\n访问外部类 # 当生成一个内部类对象时，此对象与制造它的外围对象（ enclosing object ）就形成了某种联系，内部类能够访问外围对象的所有成员，而不需要任何特殊条件。\n考虑如下示例：\n// 内部类实现的接口 interface Selector{ boolean end(); Object current(); void next(); } public class Sequence { private Object[] items; private int next = 0; public Sequence(int size) { items = new Object[size]; } public void add(Object o){ if (next \u0026lt; items.length){ items[next++] = o; } } // 内部类实现自接口 // 这是一个private修饰的内部类 private class SequenceSelector implements Selector{ private int i = 0; // 内部类直接访问了外围类的私有域 @Override public boolean end() { return i == items.length; } @Override public Object current() { return items[i]; } @Override public void next() { if (i \u0026lt; items.length) i++; } } // 获取内部类实例 public Selector selector(){ return new SequenceSelector(); } public static void main(String[] args) { Sequence s = new Sequence(10); for (int i = 0; i \u0026lt;10 ; i++) { s.add(Integer.toString(i)); } Selector selector = s.selector(); // equals to // Sequence.SequenceSelector selector = s.selector(); while (!selector.end()){ System.out.println(selector.current()); selector.next(); } } } 这是一个简单的“迭代器”的例子，这个说明的是，在内部类里，无需任何说明，即可访问外围类的私有域。这是由于内部类在实例化时，必定捕获一个创建此内部类的外围类对象的引用（静态内部类除外），当在内部类访问外围类成员时，就使用那个引用访问。\n当使用private来修饰内部类时，情况有一些特殊。结论是当使用private修饰内部类时，内部类仅在外围类作用域中可用，在其他作用域内不可用，我们将上面的例子试图作如下修改：\ninterface Selector{ boolean end(); Object current(); void next(); } class Sequence1 { private Object[] items; private int next = 0; public Sequence1(int size) { items = new Object[size]; } public void add(Object o){ if (next \u0026lt; items.length){ items[next++] = o; } } private class SequenceSelector implements Selector{ private int i = 0; @Override public boolean end() { return i == items.length; } @Override public Object current() { return items[i]; } @Override public void next() { if (i \u0026lt; items.length) i++; } } // 此处返回内部类或其基类类型都可以 public SequenceSelector selector(){ return new SequenceSelector(); } } public class Sequence{ public static void main(String[] args) { Sequence1 s = new Sequence1(10); for (int i = 0; i \u0026lt;10 ; i++) { s.add(Integer.toString(i)); } // 此处的返回只能向上转型为基类 Selector selector = s.selector(); // illegal！can not access. private class // Sequence.SequenceSelector selector = s.selector(); while (!selector.end()){ System.out.println(selector.current()); selector.next(); } } } 可以看到，当试图在另一个类中访问内部类时，编译器会给出错误信息——不能访问私有内部类，它被隐藏了。\n这是一种保护机制，除了内部类的外部类之外，任何人无法访问内部类，这样可以将内部类的实现（甚至其他不属于接口的实现）隐藏起来，这给Java编译器提供了生成高效代码的机会。\n.this和.new # 在拥有外部类的引用之前，是不能创建内部类对象的，因为内部类总是和外部类建立着联系\n当然，这个规则不适用于静态内部类（嵌套类）\n如果需要在内部类中生成对外部类对象的引用，就需要用到.this。\n如果创建一个内部类对象，可以使用.new。\n正如前面提到的，此例中的内部类不能使用private修饰。\npublic class ThisNew { public static void main(String[] args) { DotThis d = new DotThis(); // OuterClassName.InnerClassName语法 DotThis.Inner ti = d.inner(); ti.outer().f(); DotNew n = new DotNew(); // 使用 .new 获取内部类引用 DotNew.Inner ni = n.new Inner(); ni.f(); } } class DotThis{ void f(){System.out.println(\u0026#34;DotThis.f()\u0026#34;);} class Inner{ // 在内部类中生成外部类对象引用 public DotThis outer(){return DotThis.this;} } Inner inner(){ return new Inner(); } } class DotNew{ class Inner{ void f(){ System.out.println(\u0026#34;DotNew.Inner.f()\u0026#34;); } } } 局部内部类 # 之前提到的示例中，内部类都是一个“单独的作用域”，那些内部类看起来都很容易理解，直观上都是把一个普通的Java类“放置”在另一个Java类内部\n然而 ，内部类可以定义在一个方法里甚至任意的作用域内。\n方法中的内部类 # interface Dest{ String showDest(); } public class Flight3 { public Dest dest(String to){ // 内部类在方法的作用域中 class PDest implements Dest{ private String to; // 私有构造器 private PDest(String dest) { this.to = dest; } @Override public String showDest() { return to; } } // 构造内部类实例，向上转型 return new PDest(to); } public static void main(String[] args) { Flight3 f = new Flight3(); Dest d = f.dest(\u0026#34;Macao\u0026#34;); System.out.println(d.showDest()); } } /* Macao *///:~ 内部类PDest在dest()方法体内，只能在dest()中能够访问，其他地方无法访问，引出几个内涵：\nPDest类使用权限修饰符没有意义，编译器也警告你不能使用任何修饰符 PDest类的构造器是私有的，实际上由于作用域的限制，其访问权限无论是私有还是公有意义不大 任意域中的内部类 # 参考如下例子\npublic class Flight4 { private void flight(boolean fly){ if (fly) { // inner class scope class InternalFlight { private String to; InternalFlight(String to) { this.to = to; } String showDest(){return to;} } // instance can only initialized here(in scope) InternalFlight f = new InternalFlight(\u0026#34;TaiPei\u0026#34;); System.out.println(f.showDest()); } // illegal access! out of scope // InternalFlight f = new InternalFlight(\u0026#34;TaiPei\u0026#34;); } public static void main(String[] args) { Flight4 f = new Flight4(); f.flight(true); } } /* TaiPei *///:~ 内部类InternalFlight定义在if语句的作用域内，无法在if语句的作用域之外创建对内部类的引用。\n同样地，定义在语句作用域的内部类也可以继承自接口，参考下例：\nclass FlightShip { Dest flight(boolean fly){ if (fly) { // inner implements interface class InternalFlight implements Dest { private String to; InternalFlight(String to) { this.to = to; } @Override public String showDest(){return to;} } InternalFlight f = new InternalFlight(\u0026#34;TaiPei\u0026#34;); System.out.println(f); System.out.println(f.showDest()); // upcast to interface return f; } return null; // illegal access! // InternalFlight f = new InternalFlight(\u0026#34;TaiPei\u0026#34;); } } public class Flight4{ public static void main(String[] args) { FlightShip f = new FlightShip(); Dest dest = f.flight(true); System.out.println(dest.showDest()); } } /* innerclass.FlightShip$1InternalFlight@74a14482 TaiPei TaiPei *///:~ 上例中，定义在if语句块的内部类继承了Dest接口，并且包含内部类的方法返回了一个Dest引用（实际上是内部类对象引用的向上转型）。\n它像不像一个工厂方法？\n匿名内部类 # 不负责任地说，匿名内部类应该是实际应用中使用最多的内部类了。\n实现接口 # 当你需要“创建一个接口的匿名类的对象”时，通过new表达式返回的引用被自动向上转型为接口的引用。\n参考下例：\npublic class Flight5 { public static void main(String[] args) { AnonFlight af = new AnonFlight(); Dest hk = af.flight(\u0026#34;HK\u0026#34;); System.out.println(hk.showDest()); } } class AnonFlight { Dest flight(String dest) { // 实现了Dest接口的匿名内部类 return new Dest() { // 匿名内部类中还可以进行字段初始化 private String to = dest; @Override public String showDest() { return to；} }; } } /* HK *///:~ 匿名内部类常见的语法格式为：\n* new SuperType(construction parameters){ inner class method and data } * 上例中，我们传递“构造器参数”，实际上它不是构造器参数，只是用于内部类的字段初始化。\n继承超类 # 匿名内部类还可以继承自某个普通类，此种情况下，内部类还可能有一些特殊的行为——调用构造器实现实例初始化。\n实际上匿名内部类没有名字，也不可能有构造器。\npublic class Flight6 { public static void main(String[] args) { Pistol p = new Pistol(); Wrap wrap = p.wrap(3); System.out.println(wrap.value()); } } class Pistol { Wrap wrap(int x) { // 继承类的匿名内部类 return new Wrap(x) { int v; // 使用{}实现类似构造器的行为（初始化字段） { System.out.println(\u0026#34;extended initialized\u0026#34;); // 字段初始化 v = super.value() *3; } @Override int value() { return v ; } }; } } // 基础类 class Wrap { private int i; public Wrap(int i) { this.i = i; System.out.println(\u0026#34;base constructor\u0026#34;); } int value() { return i; } } /* base constructor extended initialized 9 *///:~ 上例中，匿名内部类new Wrap(x)中由wrap(int x)传递来的参数x作为了基类的构造器参数，在构造内部类的时候首先调用了基类的构造器，这是可以预想的结果。同时，在匿名内部类中使用了{}语句来模拟匿名内部类的构造器行为——初始化字段信息， super.value()的返回值也说明了基类已经在构造内部类之前就已经实例化成功了。\n双花括号语法：{{\u0026hellip;}}\n其实上例给了一个启示：在内部类中使用{}进行了字段初始化，那么{{}}是否可以用来实例初字段始化呢？答案是肯定的，比如在初始化一个数组列表时\nList\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;String\u0026gt;(){{add(\u0026quot;ali\u0026quot;); add(\u0026quot;google\u0026quot;); add(\u0026quot;amazon\u0026quot;);}};\n这样有一个便利，当一个对象只需要使用一次的时候，可以使用匿名数组列表\n再论工厂方法 # 在讨论接口的过程中，讨论了利用接口使代码与实现分离的 工厂模式，下例中使用匿名内部类优化代码时，会发现代码变得更加优雅。\n下例展示了如何使用静态工厂方法获取实例：\npublic class SimpleFactory2 { public void serviceConsumer(ServiceFactory sf){ Service s = sf.getService(); s.service_a(); s.service_b(); } public static void main(String[] args) { SimpleFactory2 sf = new SimpleFactory2(); sf.serviceConsumer(NameService.factory); sf.serviceConsumer(AgeService.factory); } } interface Service { void service_a(); void service_b(); } interface ServiceFactory { Service getService(); } class NameService implements Service { private NameService() {} @Override public void service_a() {System.out.println(\u0026#34;NameService.service_a()\u0026#34;);} @Override public void service_b() {System.out.println(\u0026#34;NameService.service_b()\u0026#34;);} // 使用匿名内部类获取工厂类 // 使用static避免服务的初始化，因为工厂是来获取实例的，已经初始化了就没意义了 public static ServiceFactory factory = new ServiceFactory() { @Override public Service getService() { return new NameService(); } }; // same as lambda expression below // public static ServiceFactory factory = () -\u0026gt; new NameService(); } class AgeService implements Service { private AgeService() { } @Override public void service_a() {System.out.println(\u0026#34;AgeService.service_a()\u0026#34;);} @Override public void service_b() {System.out.println(\u0026#34;AgeService.service_b()\u0026#34;);} public static ServiceFactory factory = new ServiceFactory() { @Override public Service getService() { return new AgeService(); } }; // same as lambda expression below // public static ServiceFactory factory = () -\u0026gt; new AgeService(); } 服务类的构造器私有，使得无法从外部实例化构造器 静态字段获取工厂，实际上也只能使用静态字段 匿名内部类可以等价转换为lambda表达式 与lambda表达式 # Java SE 8引入lambda表达式之后，匿名内部类与lambda表达式的关系变得亲密起来，匿名内部类可以等价转换为lambda表达式，但这不是绝对的。\nlambda表达式的本质是一个函数，在一般来讲，lambda表达式“实例化接口”时，该接口一般为 函数式接口，只需覆盖一个抽象方法，这是lambda能做的全部。\n而匿名内部类则要复杂的多，它是一个完整的类，除了没有构造器之外，其可以有字段利用参数进行初始化，其可以有{}statement实现类实例化操作等等，这种形式的匿名内部类，是无法等价为lambda表达式的。\n考虑lambda表达式体中 自由变量的几个约束，除了变量命名规则之外 ，其他规则同样在匿名内部类中适用，一些较老的资料（Java SE 7或之前）甚至常有这样的描述：\nJava编译器要求传入内部类（包括lambda表达式）的的参数必须显示使用final修饰\n就像这样：\nclass AnonFlight { Dest flight(final int dest) { return new Dest() { private int to = dest; @Override public String showDest() { // dest--； // not allowed! return to；} }; } } 事实上，之前的示例中我们从来没有将内部类的参数引用声明为final，不过，尽管可以不用声明为final，约束依旧是存在的，你不能在内部类中修改参数（的引用）。\n编译器给出的信息像这样：\nVariable \u0026lsquo;variable\u0026rsquo; is accessed from within inner class, needs to be final or effectively final\n值得一提的是，上述约束对于局部内部类的参数引用同样适用\n参考如下局部内部类的示例：\npublic Dest dest(String t) { class PDest implements Dest { private String to; private PDest(String dest) {this.to = dest;} @Override public String showDest() { // t = t.concat(\u0026#34;xxx\u0026#34;); // not allowed! return to; } } return new PDest(t); } 静态内部类 # 非静态内部类编译的时候，会提供一个对外部类的引用，这是在内部类中使用.this的前提。\n如果不需要这种内部类和外部类的联系，可以将内部类声明为static，这通常称为静态内部类或嵌套类。\n如果使用静态内部类，那么意味着：\n不需要外围类即可创建静态内部类对象\n静态内部类无法访问外围类的非静态对象\n静态内部类可以有static字段和数据\n普通内部类也能有静态字段，但是必须配合final声明为静态常量。原因很简单，Java希望静态字段只有一个实例，但是对每个外围类对象，会分别有一个内部类实例，如果这个字段不是final，那它可能不是唯一的\n普通内部类不能有static方法\n静态内部类可以嵌套静态内部类内部类\n普通内部类也可以嵌套，这种嵌套关系变得愈发复杂\npublic class Flight7 { public static void main(String[] args) { // ERROR! out of scope! // StaticFlight.InnerComp comp = StaticFlight.comp(); // private inner class must upcast Comp comp = StaticFlight.comp(); StaticFlight.InnerDest dest = StaticFlight.dest(\u0026#34;GZ\u0026#34;); // ERROR! cannot access! // StaticFlight.InnerComp.g(); // 访问内部类静态域 System.out.println(\u0026#34;StaticFlight.InnerDest.x = \u0026#34; + StaticFlight.InnerDest.x); System.out.println(comp.showComp()); System.out.println(dest.showDest()); // 访问内部类嵌套类静态方法 StaticFlight.InnerDest.AnotherLevel.f(); // 获取内部类嵌套类实例并调用方法 StaticFlight.InnerDest.AnotherLevel l = dest.anotherLevel(); System.out.println(\u0026#34;StaticFlight.InnerDest.AnotherLevel.p(): \u0026#34;+ l.p()); } } interface Dest { String showDest(); } interface Comp{ String showComp(); } class StaticFlight{ private int constant = 10; private static int constant_b = 10; // 私有静态内部类 private static class InnerComp implements Comp { private String comp = \u0026#34;AIR CHINA\u0026#34;; // ERROR! cannot access non-static filed of outer class // private int a = constant; @Override public String showComp() { return comp; } // 有限作用域 static void g(){ System.out.println(\u0026#34;g()\u0026#34;); } } // 静态内部类 static class InnerDest implements Dest{ private String to; private InnerDest(String to) { this.to = to; } @Override public String showDest() { return to; } // 静态域，能够访问外围类静态域 static int x = constant_b; // 嵌套静态内部类 static class AnotherLevel{ // 静态方法 static void f(){ System.out.println(\u0026#34;StaticFlight.InnerDest.AnotherLevel.x = \u0026#34; + y); } int p(){ return ++x; } static int y = constant_b; // same as // static int y = x } AnotherLevel anotherLevel(){ return new AnotherLevel(); } } static InnerComp comp(){ return new InnerComp(); } static InnerDest dest(String s){ return new InnerDest(s); } } /* StaticFlight.InnerDest.x = 10 AIR CHINA GZ StaticFlight.InnerDest.AnotherLevel.x = 10 StaticFlight.InnerDest.AnotherLevel.p(): 11 *///:~ 上面的实例展示了上述静态内部类的性质。\n外围类的comp()和dest()方法被声明为静态的（非必须），说明不需要外围类实例即可创建内部类实例，在main方法里也是这么做的，而这是普通内部类无法完成的，如果试图这样做，会得到错误消息。\n​\t\u0026lsquo;xx.xx.x.outerClass.this\u0026rsquo; cannot be referenced from a static context\n外围类定义了非静态字段constant和静态字段constan_b，在静态内部类中无法访问constant，却可以访问constant_b。\n静态内部类可以嵌套，嵌套的内部类可以访问嵌入其的所有外围类的。\n静态内部类除了static数据和域存在特殊性之外，其他的使用和普通内部类无异。\n接口中的内部类 # 接口中的任何类都是public和static的，因此将静态内部类置于接口中并不违反接口的规则。\n甚至可以使接口中的内部类实现自其外围接口，参考下例：\npublic interface InnerclassInterface { void m(); class Test implements InnerclassInterface{ @Override public void m() {System.out.println(\u0026#34;man!\u0026#34;);} } // static method in interface static Test test(){return new Test();} class Main{ public static void main(String[] args) { Test test = test(); test.m(); } } } /* man! *///:~ "},{"id":74,"href":"/zh/docs/note/pys/8_class_type/","title":"类与对象","section":"Python","content":" "},{"id":75,"href":"/zh/docs/java/concurrency/4%E6%AD%BB%E9%94%81/","title":"死锁问题2例","section":"并发编程","content":"Java有能力使任务为等待某些条件成立而进入阻塞状态，所以就有可能出现这样一种情况：某个任务在等待另一个任务，而后者又在等待其他的任务，这样一直等待下去，直到等待链上的最后一个任务又在等待第一个任务释放锁，这样就出现了任务之间相互等待的连续循环现象，这种情况出现之后，没有哪个任务能够执行，于是 死锁 出现。\n死锁之所以难以规避，其重要的原因就在于其不确定性，可能程序运行良好，但是有潜在的死锁风险，这个风险在某些域的初始条件变化时，变得特别大，导致程序很快死锁。同时，死锁难以复现，当程序出现死锁时，往往只能通过jvm的堆栈日志来探究原因。\n我们不妨回顾在 转账问题中使用的等待条件——账户余额不足时使任务等待，在余额足够的时候再进行转账。这个程序没有问题，因为有100个账户每个账户初始金额1000元，而转账金额不大于初始金额，所以任一时刻都会有账户的金额满足转账条件。如果去除转账金额不大于1000的限制，死锁就会发生。\n比如有2个账户\n账户A 余额200元 账户B 余额300元 账户A向账户B转账300元，余额不足等待；账户B向账户A转账400，余额不足等待；程序就进入死锁。\n上面描述的死锁，线程的状态并不是BLOCKED，而是WAITING。资源上所有的线程都进入等待，实际上锁并没有被占用，但是程序无法被唤醒而继续运行。\n还有一种死锁，即线程的状态是BLOCKED，这种情形在使用多把锁时容易出现。\n抢票问题 # 下面的示例模拟一个放票与抢票的场景，单线程的放票任务与多线程的抢票任务同时执行，直到停止放票并且所有票售罄程序结束。为了尽可能让更多的任务抢到票，任务中做了特殊处理。\n以下示例代码只为阐述因使用Object.wait()方法，且程序逻辑严密性存在问题的情形下，出现死锁的可能。并不能作为开发实践。\n程序使用了Callable接口和ThreadLocal来获取每个任务抢到的票数。\npublic class TicketIssue { protected final Tick tick = new Tick(0); private final List\u0026lt;Future\u0026lt;TV\u0026gt;\u0026gt; resultList = new ArrayList\u0026lt;\u0026gt;(); static class Tick { // 一般将共享资源设置为私有以降低同步问题的复杂性 int tickCount; boolean isTickSupply = true; public Tick(int tick) { this.tickCount = tick; } boolean getTick() { if (isTick()) { tickCount--; if (getTickCount() \u0026lt; 0) { System.out.println(\u0026#34;余票数 \u0026#34; + tickCount + \u0026#34;不合法，系统错误！\u0026#34;); System.exit(0); } return true; } return false; } // 检查余票 boolean isTick() { return tickCount \u0026gt; 0; } // 获取余票 int getTickCount() { return tickCount; } // 停止放票 void cancelSupply() { isTickSupply = false; } } @Setter @Getter static class TV { Thread t; Integer v = 0; } static class Purchase implements Callable\u0026lt;TV\u0026gt; { // 线程抢到的票计数器 // 线程内部存储一般声明为static private static final ThreadLocal\u0026lt;TV\u0026gt; tl = ThreadLocal.withInitial(TV::new); private final Tick tick; Purchase(Tick tick) { this.tick = tick; } /* 此处在run/call方法里同步 */ @Override public TV call() { while (true) { synchronized (tick) { TV tv = tl.get(); tv.setT(Thread.currentThread()); if (tick.getTick()) { tv.setV((tv.getV() == null ? 0 : tv.getV()) + 1); tl.set(tv); // System.out.println(Thread.currentThread().getName() // + \u0026#34; 抢到票, 余票数: \u0026#34; + tick.getTickCount()); try { // 给其他线程机会 tick.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } else { tick.notifyAll(); if (!tick.isTickSupply) break; } } } return tl.get(); } } void multiPurchase(int threadCount) throws InterruptedException, ExecutionException { ExecutorService pool = Executors.newCachedThreadPool(); for (int i = 0; i \u0026lt; threadCount; i++) { Future\u0026lt;TV\u0026gt; future = pool.submit(new Purchase(tick)); resultList.add(future); } pool.shutdown(); int sum = 0; for (int i = 0; i \u0026lt; resultList.size(); i++) { TV tv = resultList.get(i).get(); System.out.println(tv.getT().getName() + \u0026#34; 抢到票：\u0026#34; + tv.getV() + \u0026#34;张\u0026#34;); sum = sum + tv.getV(); } System.out.println(\u0026#34;已购票数：\u0026#34; + sum); } /** 放票 */ void singleSupply(int count) { new Thread(() -\u0026gt; { for (int i = 0; i \u0026lt; count; i++) { // 此处不使用同步不影响最终结果，线程会一直抢票 // 即使某刻读取到了未刷新的tickCount数值，最终都会抢到票 tick.tickCount++; // 降低出票速率 try { TimeUnit.MILLISECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } } // 停止放票 tick.cancelSupply(); }).start(); } public static void main(String[] args) throws Exception { TicketIssue ti = new TicketIssue(); int count = 10 , threadHold = 10; if (args.length \u0026gt; 1){ count = Integer.parseInt(args[0]); } if (args.length \u0026gt; 2){ threadHold = Integer.parseInt(args[1]); } ti.singleSupply(count); ti.multiPurchase(threadHold); } } /* output (sample) pool-1-thread-1 抢到票：2张 pool-1-thread-2 抢到票：2张 pool-1-thread-3 抢到票：2张 pool-1-thread-4 抢到票：0张 pool-1-thread-5 抢到票：0张 pool-1-thread-6 抢到票：0张 pool-1-thread-7 抢到票：0张 pool-1-thread-8 抢到票：1张 pool-1-thread-9 抢到票：0张 pool-1-thread-10 抢到票：3张 已购票数：10 *///:~ 程序接受2个参数1，第一个为放票数，第二个为抢票线程数，这两个参数的默认值都是10，运行程序我们可以看到每个线程所抢到的票数。\n在call()方法中，为了避免某一任务独占cpu时间，我们让每个抢到票的线程进入等待，若某个线程没有抢到票，则唤醒之。因为放票是有时间间隔的，所以肯定存在某个没有抢到票的线程能够唤醒之前抢到票的线程。\n到目前为止，程序看起来都运行正常。但是，如果抢票线程数远小于票数，或者放票间隔很小(甚至没有间隔)的情况下，死锁很快就会发生。比如我们使用2个线程抢10张票，那么很快将会看到死锁，这是一个很明显的因逻辑漏洞而出现死锁的情况。\n破坏这个死锁的方法也很简单，不让获得票的任务进入永久等待，使用带参数的wait(timeout)方法或者使用休眠即可。\n哲学家就餐问题 # 这个问题2的描述是指定5个哲学家，他们将花部分时间思考，花部分时间就餐。当他们思考的时候，不需要任何共享资源；但当他们就餐时，将使用有限数量的餐具。哲学家们围坐在桌子周围，每人之间放一支筷子（总之筷子和哲学家数量相同），当哲学家想要就餐时，他必须同时获得左边和右边的筷子，如果这个哲学家的左边或者右边已经有人使用筷子了，那么哲学家必须等待，直到他可以获得筷子。\n代码片段1:\npublic class PhilosopherDeadLocking { protected final int id; protected final int ponderFactor; public PhilosopherDeadLocking(int id, int ponderFactor) { this.id = id; this.ponderFactor = ponderFactor; } protected void pause() throws InterruptedException { Random rand = new Random(47); if (ponderFactor == 0) { return; } TimeUnit.MILLISECONDS.sleep(rand.nextInt(ponderFactor * 250)); } @Override public String toString() { return \u0026#34;Philosopher \u0026#34; + id; } static class Chopstick { private boolean taken; private synchronized void take() throws InterruptedException { while (taken) { wait(); } taken = true; } private synchronized void drop() { taken = false; notifyAll(); } } 哲学家有一个构造参数ponderFactor，用来控制哲学家思考的时间；当调用take()方法拿起筷子时，它要先判断筷子是否已经被使用，如果是则进入等待，否则获得筷子并将taken置为true；当调用drop()方法放下筷子时，将taken置为false并唤醒所有在等待使用这个筷子的哲学家。\n代码片段2:\nstatic class Dinner implements Runnable { private Chopstick left; private Chopstick right; private PhilosopherDeadLocking philosopherDeadLocking; public Dinner(Chopstick left, Chopstick right, PhilosopherDeadLocking phi) { this.left = left; this.right = right; this.philosopherDeadLocking = phi; } @Override public void run() { try { while (!Thread.interrupted()) { System.out.println(philosopherDeadLocking + \u0026#34; \u0026#34; + \u0026#34;thinking\u0026#34;); philosopherDeadLocking.pause(); // Philosopher becomes hungry System.out.println(philosopherDeadLocking + \u0026#34; \u0026#34; + \u0026#34;grabbing right\u0026#34;); right.take(); System.out.println(philosopherDeadLocking + \u0026#34; \u0026#34; + \u0026#34;grabbing left\u0026#34;); left.take(); System.out.println(philosopherDeadLocking + \u0026#34; \u0026#34; + \u0026#34;eating\u0026#34;); philosopherDeadLocking.pause(); System.out.println(philosopherDeadLocking + \u0026#34; \u0026#34; + \u0026#34;drop right\u0026#34;); right.drop(); System.out.println(philosopherDeadLocking + \u0026#34; \u0026#34; + \u0026#34;drop left\u0026#34;); left.drop(); } } catch (InterruptedException e) { System.out.println(philosopherDeadLocking + \u0026#34; \u0026#34; + \u0026#34;exiting via interrupt\u0026#34;); } } } 在哲学家就餐的run()方法中，哲学家只是不停的思考和吃饭，如果ponderFactor不为0，那么哲学家先会思考一会儿，然后拿起右边的筷子，再拿起左边的筷子，然后在吃饭上花掉一会时间，然后放下筷子，之后重复此过程。\n代码片段3:\npublic static void main(String[] args) throws Exception { ExecutorService pool = Executors.newCachedThreadPool(); int size = 5, ponder = 0; if (args.length \u0026gt; 0) { ponder = Integer.parseInt(args[0]); } if (args.length \u0026gt; 1) { size = Integer.parseInt(args[1]); } Chopstick[] chopsticks = new Chopstick[size]; for (int i = 0; i \u0026lt; size; i++) { chopsticks[i] = new Chopstick(); } for (int i = 0; i \u0026lt; size; i++) { pool.execute( new Dinner(chopsticks[i], chopsticks[(i + 1) % size], new PhilosopherDeadLocking(i, ponder))); } if (args.length \u0026gt; 2) { TimeUnit.SECONDS.sleep(Integer.parseInt(args[2])); } else { System.out.println(\u0026#34;Press \u0026#39;q\u0026#39; to quit\u0026#34;); System.in.read(); } pool.shutdownNow(); } } main()方法接受3个命令行参数，分别是ponderFactor，筷子数，以及程序结束前运行的时间（程序需要主动结束运行）。这个程序的特别之处在于，它大部分时间是正常运行的——如果哲学家花在思考上的时间足够长，那么死锁可能永远不可能发生，但是如果将ponderFactor设置为0，那么死锁将很快会发生。\n因为每个哲学家都是先拿右边的筷子，后拿左边的筷子，如果哲学家思考的时间很短，就会出现所有的哲学家都拿到了右边的筷子，并等待左边的筷子的情况，如此一来，所有的哲学家都陷入了“等待的陷阱”，这就是循环等待的情形，此时程序的死锁就发生了。如果让最后一位哲学家先拿左边的筷子而非右边的筷子，那么就可以破坏循环等待的条件，阻止死锁的发生：\npublic static void main(String[] args) throws Exception { ExecutorService pool = Executors.newCachedThreadPool(); int size = 5, ponder = 0; if (args.length \u0026gt; 0) { ponder = Integer.parseInt(args[0]); } if (args.length \u0026gt; 1) { size = Integer.parseInt(args[1]); } Chopstick[] chopsticks = new Chopstick[size]; for (int i = 0; i \u0026lt; size; i++) { chopsticks[i] = new Chopstick(); } for (int i = 0; i \u0026lt; size - 1; i++) { pool.execute( new Dinner(chopsticks[i], chopsticks[(i + 1) % size], new PhilosopherDeadLocking(i, ponder))); } // 让最后一位哲学家先拿左边的筷子，破坏可能发生的循环等待 pool.execute( new Dinner(chopsticks[0],chopsticks[size -1], new PhilosopherFixDeadLocking(size-1, ponder))); if (args.length \u0026gt; 2) { TimeUnit.MILLISECONDS.sleep(Integer.parseInt(args[2])); } else { System.out.println(\u0026#34;Press \u0026#39;q\u0026#39; to quit\u0026#34;); System.in.read(); } pool.shutdownNow(); } 就死锁而言，Java并没有就此提供语言上的支持，能否通过仔细地设计程序逻辑来避免死锁，取决于你。\n这个程序使用同步的方式只是为了说明问题，并不是最好的同步方式。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n这是由Edsger Dijkstra提出的一个经典的死锁例证，参考自《Java编程思想 第四版》\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":76,"href":"/zh/docs/note/pys/9_decoration/","title":"闭包与装饰器","section":"Python","content":" "},{"id":77,"href":"/zh/docs/java/concurrency/5%E7%BB%88%E7%BB%93%E4%BB%BB%E5%8A%A1/","title":"终结任务","section":"并发编程","content":" 终结任务 # 一般地，如果程序运行良好，任务执行完所需操作后自然结束，任务终结。\n如果任务执行时出现异常，任务也会终结。\n在设计多个线程协同工作的任务时，需要判断任务终结的条件，以便合适地终结任务，这点尤为重要。\n在本节中主要讨论在多线程协同工作的情况下，如何合适的终结任务。\n响应中断 # 在讨论 Object超类的时候，我们曾通过“录音-播放”模型简单阐述线程之间的协同工作，在那个示例中，方便起见，我们通过System.exit(0);来粗暴地结束程序的运行。这种方式在并发编程实践中是不被允许的。\n接下来的示例中，我们再次以线程之间的协同工作为切点，讨论如何“合理地”终结任务的运行。\n下例模拟汽车的“打蜡-抛光”过程，抛光必须在打蜡完成之后，同样的，打蜡之前汽车必须是抛光过的。\npublic class Wax { static class Car { private boolean waxOn = false; public synchronized void waxed() { waxOn = true; // Ready to buff notifyAll(); } public synchronized void buffed() { waxOn = false; // Ready for another coat of wax notifyAll(); } public synchronized void waitForWaxing() throws InterruptedException { // waxOn = false时一直等待 while (!waxOn) wait(); } public synchronized void waitForBuffing() throws InterruptedException { // waxOn = true时一直等待 while (waxOn) wait(); } } static class WaxOn implements Runnable { private Car car; public WaxOn(Car c) { car = c; } @Override public void run() { try { while (!Thread.interrupted()) { TimeUnit.MILLISECONDS.sleep(100); System.out.print(\u0026#34;Wax On! \u0026#34;); car.waxed(); car.waitForBuffing(); } } catch (InterruptedException e) { System.out.println(\u0026#34;WaxOn Exiting via interrupt\u0026#34;); } System.out.println(\u0026#34;Ending Wax On task\u0026#34;); } } static class BufferOn implements Runnable { private Car car; public BufferOn(Car c) { car = c; } @Override public void run() { try { while (!Thread.interrupted()) { // 任务直接进入等待直到被唤醒, waxOn = true时得以执行 car.waitForWaxing(); System.out.print(\u0026#34;Wax Off! \u0026#34;); TimeUnit.MILLISECONDS.sleep(100); car.buffed(); } } catch (InterruptedException e) { System.out.println(\u0026#34;BufferOn Exiting via interrupt\u0026#34;); } System.out.println(\u0026#34;Ending Buffer On task\u0026#34;); } } public static void main(String[] args) throws Exception { Car car = new Car(); ExecutorService exec = Executors.newCachedThreadPool(); exec.execute(new BufferOn(car)); exec.execute(new WaxOn(car)); TimeUnit.SECONDS.sleep(2); // Run for a while... exec.shutdownNow(); // Interrupt all tasks } } /* Output: (95% match) Wax On! Wax Off! BufferOn Exiting via interrupt WaxOn Exiting via interrupt Ending Wax On task Ending Buffer On task *///:~ 因为两个任务是交互等待-执行的，调用wait()方法而进入WAITING状态的线程可以被中断并抛出异常1，上面的输出显示BufferOn任务先响应中断，这只是可能的情况之一，因为输出 Wax Off! 之后BufferOn任务会进入等待，而正好被中断。\n调用执行器的shutdownNow()方法关闭提交的任务，shutdownNow()方法会立即给已经提交的任务发送一个中断interrupt()命令。调用shutdownNow()之后，可以看到两个任务都抛出InterruptedException。\n⚠️注意： 两个任务都抛出中断异常和任务中的sleep方法有关，由于sleep和wait都可以被中断并抛出异常，所以异常的抛出是由谁引发的并不容易确定。虽然try块位于任务的最外层，但是Thread.interrupted()方法并不抛出异常。\n上例实际上是利用了中断线程而出现的异常而终止线程的运行，然而，BLOCKED2状态下的线程无法响应中断。\n无法中断 # Thread提供了interrupt()方法，用于设置线程的中断状态。为了调用此方法，你必须持有Thread对象。并发编程过程中一般避免显式创建线程，上例中使用了shutdownNow()向任务发送interrup()命令，同样地，Java提供一个带有类型参数的接口 Future\u0026lt;V\u0026gt;，它具有取消任务执行的能力。\n但是，阻塞状态下的线程是否都能响应中断呢？\npublic class Interrupting { private static ExecutorService exec = Executors.newCachedThreadPool(); static void test(Runnable r) throws InterruptedException { // 构造一个可中断的任务 Future\u0026lt;?\u0026gt; f = exec.submit(r); TimeUnit.MILLISECONDS.sleep(100); // 中断任务 System.out.println(r.getClass().getSimpleName() + \u0026#34; Interrupt: \u0026#34; + f.cancel(true)); } public static void main(String[] args) throws Exception { test(new SleepBlocked()); test(new IOBlocked(System.in)); // 不能中断 test(new SynchronizedBlocked()); // 不能中断 TimeUnit.SECONDS.sleep(3); System.exit(0); // ... since last 2 interrupts failed } /** sleep可以被中断 */ static class SleepBlocked implements Runnable { @Override public void run() { try { TimeUnit.SECONDS.sleep(100); } catch (InterruptedException e) { System.out.println(\u0026#34;InterruptedException\u0026#34;); } System.out.println(\u0026#34;Exiting SleepBlocked.run()\u0026#34;); } } /** I/O不可被中断 */ static class IOBlocked implements Runnable { private InputStream in; public IOBlocked(InputStream is) { in = is; } @Override public void run() { try { System.out.println(\u0026#34;Waiting for read():\u0026#34;); in.read(); } catch (Exception e) { if (Thread.currentThread().isInterrupted()) { System.out.println(\u0026#34;Interrupted from blocked I/O\u0026#34;); } else { throw new RuntimeException(e); } } System.out.println(\u0026#34;Exiting IOBlocked.run()\u0026#34;); } } /** 不可被中断 */ static class SynchronizedBlocked implements Runnable { public synchronized void f() { while (true) // Never releases lock Thread.yield(); } public SynchronizedBlocked() { // 构造之后就获取锁而不释放 new Thread(() -\u0026gt; { f(); // Lock acquired by this thread }).start(); } /** run()方法将一直阻塞 */ @Override public void run() { System.out.println(\u0026#34;Trying to call f()\u0026#34;); f(); System.out.println(\u0026#34;Exiting SynchronizedBlocked.run()\u0026#34;); } } } /* output: InterruptedException SleepBlocked Interrupt: true Exiting SleepBlocked.run() Waiting for read(): IOBlocked Interrupt: true Trying to call f() SynchronizedBlocked Interrupt: true *///:~ 由于Future的cancel(boolean)方法也是向执行任务的线程发送interrupt()命令，上例中3个任务，只有SleepBlocked在休眠时被中断并退出运行，其他的两个任务IOBlocked和SynchronizedBlocked均没有被中断。实际上，在编码过程中我们也可以发现，只有sleep()方法需要处理InterruptedException异常，而无论时I/O还是尝试调用synchronized方法，都不需要处理InterruptedException。\n对于I/O阻塞的情况，有一个简单的处理办法——即关闭任务在其上发生阻塞的资源：\npublic class CloseResource { public static void main(String[] args) throws Exception { ExecutorService exec = Executors.newCachedThreadPool(); InputStream socketInput = new Socket(\u0026#34;localhost\u0026#34;, 8080).getInputStream(); exec.execute(new Interrupting.IOBlocked(socketInput)); exec.execute(new Interrupting.IOBlocked(System.in)); TimeUnit.MILLISECONDS.sleep(10); System.out.println(\u0026#34;Shutting down all threads\u0026#34;); // 两个任务都无法响应中断 exec.shutdownNow(); TimeUnit.SECONDS.sleep(1); System.out.println(\u0026#34;Closing \u0026#34; + socketInput.getClass().getName()); // 关闭资源可以使线程响应中断 socketInput.close(); // Releases blocked thread TimeUnit.SECONDS.sleep(1); System.out.println(\u0026#34;Closing \u0026#34; + System.in.getClass().getName()); System.in.close(); // Releases blocked thread } } /* Output: (85% match) Waiting for read(): Waiting for read(): Shutting down all threads Closing java.net.SocketInputStream Interrupted from blocked I/O Exiting IOBlocked.run() Closing java.io.BufferedInputStream Exiting IOBlocked.run() *///:~ 上例中的2个任务都无法响应中断，但是一旦关闭资源，那么阻塞就被中断。\n对于因获取锁失败而阻塞的情况，实际上，上例中的情况可以看作是死锁，由于任务无法获取对象的锁而一直阻塞。幸运的是，Java提供ReentrantLock锁，其具备在因获取锁而阻塞但是又能响应中断的能力。\npublic class LockingInterrupt { // 可重入锁获取锁的时候可以被中断 private Lock lock = new ReentrantLock(); public LockingInterrupt() { // lock the instance once constructed lock.lock(); } void f() { try { // invoke can be interrupted lock.lockInterruptibly(); System.out.println(\u0026#34;acquire lock in f() success\u0026#34;); }catch (InterruptedException e){ System.out.println(\u0026#34;Interrupted from acquire lock in f()\u0026#34;); } } static class MutexTask implements Runnable{ LockingInterrupt mbi = new LockingInterrupt(); @Override public void run() { System.out.println(\u0026#34;waiting for f()\u0026#34;); mbi.f(); System.out.println(\u0026#34;Broken out of blocked call\u0026#34;); } } public static void main(String[] args) throws InterruptedException { Thread t = new Thread(new MutexTask()); t.start(); // 中断t，若不中断，t会一直阻塞 t.interrupt(); } } /* waiting for f() Interrupted from acquire lock in f() Broken out of blocked call *///:~ 上例中，LockingInterrupt初始化的时候就占用锁，并没有释放锁，而在运行f()方法的时候再去获取锁时任务就被阻塞了，在调用interrupt()方法中断的时候，lockInterruptibly()响应了中断，任务结束程序退出。\n惯用法 # 从上面的例子我们已经知道，可以通过检查线程的中断状态来结束任务的执行。下面的例子展示了一种惯用法，它使用try-finally块来紧跟资源，以应对任何时候任务出现中断时保证资源被释放：\npublic class InterruptingIdiom { /** 需要清理的资源类 */ static class NeedsCleanup { private final int id; public NeedsCleanup(int ident) { id = ident; System.out.println(\u0026#34;NeedsCleanup \u0026#34; + id); } public void cleanup() { System.out.println(\u0026#34;Cleaning up \u0026#34; + id); } } static class Blocked3 implements Runnable { private volatile double d = 0.0; @Override public void run() { try { while (!Thread.interrupted()) { NeedsCleanup n1 = new NeedsCleanup(1); // 在n1之后紧跟try-finally块，保证资源被合理的清除 // node 1 try { System.out.println(\u0026#34;Sleeping\u0026#34;); TimeUnit.SECONDS.sleep(1); NeedsCleanup n2 = new NeedsCleanup(2); // 同理 // node2 try { System.out.println(\u0026#34;Calculating\u0026#34;); //耗时操作 for (int i = 1; i \u0026lt; 2500000; i++) { d = d + (Math.PI + Math.E) / d; } // node3 System.out.println( \u0026#34;Finished time-consuming operation\u0026#34;); } finally { n2.cleanup(); } } finally { n1.cleanup(); } } System.out.println(\u0026#34;Exiting via while() test\u0026#34;); } catch (InterruptedException e) { System.out.println(\u0026#34;Exiting via InterruptedException\u0026#34;); } } } public static void main(String[] args) throws Exception { if (args.length != 1) { System.out.println(\u0026#34;usage: java InterruptingIdiom delay-in-mS\u0026#34;); System.exit(1); } Thread t = new Thread(new Blocked3()); t.start(); TimeUnit.MILLISECONDS.sleep(new Integer(args[0])); t.interrupt(); } } /* Output: (Sample) NeedsCleanup 1 Sleeping NeedsCleanup 2 Calculating Finished time-consuming operation Cleaning up 2 Cleaning up 1 NeedsCleanup 1 Sleeping Cleaning up 1 Exiting via InterruptedException *///:~ 上例接收一个参数，表示程序中断之前的运行时间(ms)，由于任务中有一段耗时的循环操作，当参数大小不同时，程序的输出会有所差异：\n任务可能在node1和node2之间中断，因此其输出为：\nNeedsCleanup 1 Sleeping Cleaning up 1 Exiting via InterruptedException 当任务在node2和node3之间设置中断状态，再次进入循环时中断被监测到，程序退出，此时的输出为：\nNeedsCleanup 1 Sleeping NeedsCleanup 2 Calculating Finished time-consuming operation Cleaning up 2 Cleaning up 1 Exiting via while() test 总之，无论任务在何时被释放，其创建的资源都会被合适地释放。\nTIJ第四版第21章并发（694页）在描述线程的状态时，将调用休眠/等待之后线程的状态称为阻塞。为避免混淆，本文采用 Thread.State中关于线程的描述，并认为其不应该被称为阻塞状态。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n本博客约定此状态（等待锁）的线程才处于阻塞状态。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":78,"href":"/zh/docs/note/pys/10_decoration_2/","title":"装饰器2","section":"Python","content":" "},{"id":79,"href":"/zh/docs/java/basic/11_java-new-time-api/","title":"Java8日期和时间API","section":"面向对象","content":" Java8日期和时间API # mybatis自 3.4.5 开始，已经支持使用LocaldateTime作为时间查询入参，映射类型为TimeStamp，参考地址: https://mybatis.org/mybatis-3/zh/configuration.html#typeHandlers\n1 前言 # 在介绍Java SE 8中新的日期时间库前，先了解下Java 8之前的日期时间工具的诟病。\n在Java SE 8前，日期时间工具库在java.util包中，包括：\njava.util.Date：表示日期和时间 java.util.Calendar以及其实现子类：表示各种日历系统，常用的是格林威治日历java.util.GregorianCalendar java.util.TimeZone以及其实现子类：表示时区偏移量和夏令时 以及辅助其进行格式化和解析的工具库在java.text包中，包括：\njava.text.DateFormat：格式化日期时间和解析日期时间的工具抽象类 java.text.SimpleDateFormat：DateDateFormat的实现 从以上的简述中，对java 8之前的日期时间库，有所宏观视觉。下面简要总结下其设计上的瑕疵和被开发者无限吐槽的诟病：\n从以上的api上看，java 8之前的日期时间工具库缺乏年、月、日、时间、星期的单独抽象； Date日期时间类既描述日期又描述时间，耦合，且Date不仅在java.util包中存在，在java.sql中也存在，重复名称，容易导致bug发生； api的设计上晦涩，难用，不够生动，难以以自然人类的思维理解日期时间。年月日需要从Calendar中获取； 最被开发者抱怨的是类型不安全，Calendar类中全局属性是可变的，在多线程访问时，会存在线程安全问题。SimpleDateFormat格式化和解析日期，需要使用年月日时分秒，所以持有了Calendar属性，导致其也是非线程安全； // 以下都是Calendar中持有的全局属性 // 这些全局属性都是可变的，提供了set protected int fields[]; transient private int stamp[]; protected long time; protected boolean isTimeSet; // 在其子类GregorianCalendar中 private transient int[] zoneOffsets; // setTime方法会调用此方法 // 该方法中修改了上述的很多全局属性 public void setTimeInMillis(long millis) { // If we don\u0026#39;t need to recalculate the calendar field values, // do nothing. if (time == millis \u0026amp;\u0026amp; isTimeSet \u0026amp;\u0026amp; areFieldsSet \u0026amp;\u0026amp; areAllFieldsSet \u0026amp;\u0026amp; (zone instanceof ZoneInfo) \u0026amp;\u0026amp; !((ZoneInfo)zone).isDirty()) { return; } time = millis; isTimeSet = true; areFieldsSet = false; computeFields(); areAllFieldsSet = areFieldsSet = true; } 所以在多线程环境中使用Calendar是非线程安全的 ，多个线程修改其属性域会导致数据一致性和可见性问题。\n在DateFormat中持有了Calendar属性，用于解析和格式化日期：\n// 从注释上看，Calendar用于计算日期时间域 /** * The {@link Calendar} instance used for calculating the date-time fields * and the instant of time. This field is used for both formatting and * parsing. * * \u0026lt;p\u0026gt;Subclasses should initialize this field to a {@link Calendar} * appropriate for the {@link Locale} associated with this * \u0026lt;code\u0026gt;DateFormat\u0026lt;/code\u0026gt;. * @serial */ protected Calendar calendar; // Called from Format after creating a FieldDelegate private StringBuffer format(Date date, StringBuffer toAppendTo, FieldDelegate delegate) { // Convert input date to time field list calendar.setTime(date); boolean useDateFormatSymbols = useDateFormatSymbols(); for (int i = 0; i \u0026lt; compiledPattern.length; ) { int tag = compiledPattern[i] \u0026gt;\u0026gt;\u0026gt; 8; int count = compiledPattern[i++] \u0026amp; 0xff; if (count == 255) { count = compiledPattern[i++] \u0026lt;\u0026lt; 16; count |= compiledPattern[i++]; } switch (tag) { case TAG_QUOTE_ASCII_CHAR: toAppendTo.append((char)count); break; case TAG_QUOTE_CHARS: toAppendTo.append(compiledPattern, i, count); i += count; break; default: subFormat(tag, count, delegate, toAppendTo, useDateFormatSymbols); break; } } return toAppendTo; } format方法中设置了全局成员Calendar的time，多线程访问时每次都会改变Calendar类，导致format格式化时会出现线程安全问题。所以DateFormat和其子类SimpleDateFormat都是非类型安全。\n这个可以说是被开发者极度抱怨的。所以在使用日期格式工具时大多数都会重新new或者使用ThreadLocal。\n基于此诸多问题，java设计者终于在Java SE 8中引入了新的日期时间库。新的日期时间库的易用程度会让你振服！下面开始进入主题，Java SE 8中的日期时间库java.time。\n2 概览 # 先认识下 joda项目，joda项目包括：\nJoda-Time - Basic types for Date and Time Joda-Money - Basic types for Money Joda-Beans - Next generation JavaBeans Joda-Convert - String to Object conversion Joda-Collect - Additional collection data structures 其中Joda-Time是日期时间三方库，但是在java 8之前，joda time其实是标准的日期时间库，其出色的语义表达，易用易于理解的api，类型安全的特性，大受开发者的追捧。而且其日历系统遵循的是 IOS_8601国际标准，同时还包括其他的非标准的日历系统。支持时区、持续时间、格式化和解析功能。\n在java 8之前可以依赖joda time三方库，使用其日期时间库。\n但在java 8中提出了 JSR 310: Date and Time API规范，该规范即新版的日期时间库java.time规约。可以说JSR-310的设计上汲取了大量的joda time的特性。新版本的日期时间库基于JSR 310: Date and Time API开发，java.time是基于国际化标准日历系统（International Organization for Standardization）ISO_8601，同时java.time.chrono支持对全球日历系统的扩展。\nJSR-310中设计的java.time包括年、月、星期、日期时间、持续时间段、瞬时、时钟、时区的抽象及处理。且api的设计上使用易读易于理解的名称和设计模式，让使用者欣然接受。而且提供旧版和新版api之间的互通以处理兼容性问题。\n下面看张概览图，从宏观角度了解下java.time\nJava 8的新时间日期API 第一层是对年、月、月中日、星期的抽象； 第二层是对日期、日期时间、时区的抽象，其中时区分为时区Id（Europe/Paris）和时区偏移量(Z/+hh:mm/-hh:mm)； 第三层是对区域时间和便宜时间的抽象； 第四层是对瞬时和时钟的抽象； 第五层是对时序时段和持续周期的抽象 右侧层是辅助工具类，如：日期时间格式、日期时间调整器、其他的日历系统； java 8中日期时间库共分为五个package：\njava.time：基于ISO_8601日历系统实现的日期时间库 java.time.chrono：全球日历系统扩展库，可以自行扩展 java.time.format：日期时间格式，包含大量预定义的格式，可以自行扩展 java.time.zone：时区信息库 java.time.temporal：日期时间调整辅助库 关于日期时间库的使用详细过程，推荐查看oracle提供的java教程 The Java™ Tutorials——Trail: Date Time\n3 java.time优点 # 3.1 设计 # java.time中使用了大量的设计模式：\n工厂模式：now()工厂方法直接生成当前日期时间或者瞬时；of()工厂方法根据年月日时分秒生成日期或者日期时间； 装饰模式：时区时间ZoneDateTime/偏移时间OffsetDateTime，都是在LocalDateTime的基础上加上时区/偏移量的修饰成为时区时间，然后可以进行时区转换； 建造者模式：Calendar中加入建造者类，用于生成新的Calendar对象； 3.2 命名 # java 8中的日期时间库类名、方法名命名上都是极其形象生动，易于理解，让开发者极易于使用——语义清晰精确！如：LocalDate中提供的now表示现在的日期，of用于年月日组成的日期（这里和英文中的of意义非常贴切），plus/minus加减等等；\n3.3 合理的接口设计 # LocalDate表示日期，由年月日组成，提供了获取所在年，所在月，所在日的api，提供所在一年的第几天api，用于比较日期前后api，替换年份、月份、日的api，这些api使得日期或者日期时间的处理上得到的功能上的极大提升； 抽象出年、月、日、星期、日期、日期时间、瞬时、周期诸多接口，对事物本质有了细腻的抽象，并提供了相互转换的能力——提供极强的处理能力和语言表达能力； 对于遗留的日期时间库Calendar/Date/Timezone和新的日期时间库的互通性； 将全球的非标准日历系统单独抽象并支持扩展，从标准日历系统中隔离（符合设计原则：对修改关闭，对扩展开放） 4 java.time使用示例 # 得益于新日期时间框架的设计，无论是类名还是方法名以及可读性，都相当容易理解，其上手成本比Date/Calendar要低得多。\n并且，LocalDateTime/LocalDate之间，以及它们和jdk 1.8之前的Date也可以互相转换。\n以下是一个使用示例：\npublic class Intro { static String yyyy = \u0026#34;yyyy\u0026#34;; static String yyyy_MM = \u0026#34;yyy-MM\u0026#34;; static String yyyy_MM_dd = \u0026#34;yyyy-MM-dd\u0026#34;; static String yyyy_MM_dd_HH_mm_ss = \u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;; static String yyyy_MM_dd_HH_mm_ss_SSS = \u0026#34;yyyy-MM-dd HH:mm:ss.SSS\u0026#34;; /** * If the pattern like \u0026#39;yyyy\u0026#39;, result {@link LocalDateTime} could be like \u0026#39;yyyy-01-01 00:00:00\u0026#39;.\u0026lt;br\u0026gt; * If the pattern like \u0026#39;yyyy-MM\u0026#39;, result {@link LocalDateTime} could be like \u0026#39;yyyy-MM-01 00:00:00\u0026#39;.\u0026lt;br\u0026gt; * If the pattern like \u0026#39;yyyy-MM-dd\u0026#39;, result {@link LocalDateTime} could be like \u0026#39;yyyy-MM-dd 00:00:00\u0026#39;.\u0026lt;br\u0026gt; * Other patterns acts the same. * \u0026lt;p\u0026gt; * * \u0026lt;b\u0026gt;Important:\u0026lt;/b\u0026gt; the pattern and the the {@link LocalDateTime#parse(CharSequence, DateTimeFormatter)} method\u0026#39;s input {@link CharSequence} must match. * e.g. The following method call will throw {@link java.time.format.DateTimeParseException}: * \u0026lt;pre\u0026gt; * LocalDateTime localDateTime = LocalDateTime.parse(\u0026#34;2021\u0026#34;,dtfBuilder(\u0026#34;yyyy-MM\u0026#34;)); * \u0026lt;/pre\u0026gt; * * @param pattern the string pattern * @see DateTimeFormatter javadoc * @see LocalDateTime#parse(CharSequence, DateTimeFormatter) */ static DateTimeFormatter dtfBuilder(String pattern) { return new DateTimeFormatterBuilder() .appendPattern(pattern) .parseDefaulting(ChronoField.YEAR_OF_ERA, LocalDateTime.now().getYear()) .parseDefaulting(ChronoField.MONTH_OF_YEAR, 1) .parseDefaulting(ChronoField.DAY_OF_MONTH, 1) .parseDefaulting(ChronoField.HOUR_OF_DAY, 0) .parseDefaulting(ChronoField.MINUTE_OF_HOUR, 0) .parseDefaulting(ChronoField.SECOND_OF_MINUTE, 0) .parseDefaulting(ChronoField.NANO_OF_SECOND, 0) .toFormatter(); } static SimpleDateFormat sdfBuilder(String pattern) { return new SimpleDateFormat(pattern); } /** * solution1: * Get yyyy-MM-dd 00:00:00, start of the day.\u0026lt;br\u0026gt; * If you use yyyy-MM-dd as parameter */ static Date getStartOfDay() { LocalDateTime localDateTime = LocalDateTime.parse(\u0026#34;2021-02-02\u0026#34;, dtfBuilder(yyyy_MM_dd)); Instant instant = localDateTime.atZone(ZoneId.systemDefault()).toInstant(); return Date.from(instant); } /** * solution2: * get yyyy-MM-dd 00:00:00, start of the day.\u0026lt;br\u0026gt; * If you use yyyy-MM-dd as parameter\u0026lt;br\u0026gt; * \u0026lt;p\u0026gt; * Using {@link LocalDate#atStartOfDay()} * * @param dateString datePattern like 2012-09-08 */ static Date getStartOfDay(String dateString) throws ParseException { //由于dtfBuilder的设置 这里的时间已经是 00:00:00 LocalDate localDate = LocalDate.parse(dateString, dtfBuilder(yyyy_MM_dd)); ZonedDateTime zonedDateTime = localDate.atStartOfDay(ZoneId.systemDefault()); return Date.from(zonedDateTime.toInstant()); // return sdfBuilder().parse(zonedDateTime.format(dtfBuilder(yyyy_MM_dd_HH_mm_ss))); } /** * */ static Date getStartOfDay(LocalDate localDate){ ZonedDateTime zonedDateTime = localDate.atStartOfDay(ZoneId.systemDefault()); LocalDateTime localDateTime = localDate.atStartOfDay(); Instant instant = localDateTime.toInstant(ZoneOffset.of(\u0026#34;+8\u0026#34;)); // return Date.from(zonedDateTime.toInstant()); return Date.from(instant); } /** * Get yyyy-MM-dd 23:59:59.999, end of the day.\u0026lt;br\u0026gt; * By using {@link LocalDateTime#plus(long, TemporalUnit)} */ static Date getEndOfDay() { //由于dtfBuilder的设置 这里的时间已经是 00:00:00 LocalDateTime localDateTime = LocalDateTime.parse(\u0026#34;2020-12-21\u0026#34;, dtfBuilder(yyyy_MM_dd)); //plusXxx()方法没有提供毫秒/微秒的相应方法，直接到纳秒； 相应的，可以使用plus方法指定单位 localDateTime = localDateTime.plusHours(23).plusMinutes(59).plusSeconds(59).plusNanos(999_999_999); /* * 好方法，将其下级单位的值清零 * ChronoUnit.DAYS: 清零hh:mm:ss.SSS * 最大单位 DAYS，也就是说此方法只能用来清零时间 */ localDateTime = localDateTime.truncatedTo(ChronoUnit.DAYS); localDateTime = localDateTime .plus(23, ChronoUnit.HOURS) .plus(59, ChronoUnit.MINUTES) .plus(59, ChronoUnit.SECONDS) .plus(999, ChronoUnit.MILLIS); return Date.from(localDateTime.atZone(ZoneId.systemDefault()).toInstant()); } /** * Get yyyy-MM-dd 23:59:59.999, end of the day.\u0026lt;br\u0026gt; * By using {@link LocalDate#atTime(LocalTime)} * * @param dateString date pattern like \u0026#39;2012-09-18\u0026#39; */ static Date getEndOfDay(String dateString) { LocalDate localDate = LocalDate.parse(dateString, dtfBuilder(yyyy_MM_dd)); // localDate. LocalDateTime localDateTime = localDate.atTime(23, 59, 59, 999_999_999); return Date.from(localDateTime.atZone(ZoneId.systemDefault()).toInstant()); } /** * Get first day of month * * @param dateString pattern like \u0026#39;2020-10-25\u0026#39; * @return */ static Date getFirstDayOfMonth(String dateString) { LocalDateTime localDateTime = LocalDateTime.parse(dateString, dtfBuilder(yyyy_MM_dd)); localDateTime = localDateTime.withDayOfMonth(1); return Date.from(localDateTime.atZone(ZoneId.systemDefault()).toInstant()); } /** * Get the first day of year. * * @param yearString pattern like \u0026#39;2012\u0026#39; */ static Date getFirstDayOfYear(String yearString) { LocalDateTime localDateTime = LocalDateTime.parse(yearString, dtfBuilder(yyyy)); return Date.from(localDateTime.atZone(ZoneId.systemDefault()).toInstant()); } public static void main(String[] args) throws ParseException { System.out.println(sdfBuilder(yyyy_MM_dd_HH_mm_ss).format(getStartOfDay())); System.out.println(sdfBuilder(yyyy_MM_dd_HH_mm_ss).format(getStartOfDay(\u0026#34;2021-02-02\u0026#34;))); System.out.println(sdfBuilder(yyyy_MM_dd_HH_mm_ss_SSS).format(getStartOfDay(LocalDate.parse(\u0026#34;2021-02-22\u0026#34;, dtfBuilder(yyyy_MM_dd))))); System.out.println(sdfBuilder(yyyy_MM_dd_HH_mm_ss_SSS).format(getEndOfDay())); System.out.println(sdfBuilder(yyyy_MM_dd_HH_mm_ss_SSS).format(getEndOfDay(\u0026#34;2020-12-21\u0026#34;))); System.out.println(sdfBuilder(yyyy_MM_dd).format(getFirstDayOfMonth(\u0026#34;2020-12-18\u0026#34;))); System.out.println(sdfBuilder(yyyy_MM_dd_HH_mm_ss).format(getFirstDayOfYear(\u0026#34;2012\u0026#34;))); } } 源码地址：https://github.com/wangy325/java-review/blob/master/src/main/java/com/wangy/common/time/Intro.java\n5 补充内容 # 5.1 时区 # 时区是地球上的区域使用同一个时间定义。以前，人们通过观察太阳的位置（时角）决定时间，这就使得不同经度的地方的时间有所不同（地方时）。1863年，首次使用时区的概念。时区通过设立一个区域的标准时间部分地解决了这个问题。\n世界各个国家位于地球不同位置上，因此不同国家，特别是东西跨度大的国家日出、日落时间必定有所偏差。这些偏差就是所谓的时差。\n理论时区以被15整除的子午线为中心，向东西两侧延伸7.5度，即每15°划分一个时区，这是理论时区。理论时区的时间采用其中央经线（或标准经线）的地方时。所以每差一个时区，区时相差一个小时，相差多少个时区，就相差多少个小时。东边的时区时间比西边的时区时间早。为了避免日期的紊乱，提出国际日期变更线的概念\n但是，为了避开国界线，有的时区的形状并不规则，而且比较大的国家以国家内部行政分界线为时区界线，这是实际时区，即法定时区。请参见 时区列表。\n5.2 子午线 # 即经线，和纬线一样是人类为度量而假设出来的辅助线，定义为地球表面连接南北两极的大圆线上的半圆弧。任两根经线的长度相等，相交于南北两极点。每一根经线都有其相对应的数值，称为经度。经线指示南北方向。\n5.3 本初子午线 # 即0度经线，亦称格林尼治子午线或本初经线，是经过英国格林尼治天文台的一条经线（亦称子午线）。本初子午线的东西两边分别定为东经和西经，于180度相遇。\n5.4 国际标准ISO 8601 # 国际标准ISO 8601：是国际标准化组织的日期和时间的表示方法，全称为《数据存储和交换形式·信息交换·日期和时间的表示方法》。目前是2004年12月1日发行的第三版“ISO8601:2004”以替代1998年的第一版“ISO8601:1988”与2000年的第二版“ISO8601:2000”。\n年由4位数字组成YYYY，或者带正负号的四或五位数字表示±YYYYY。以公历公元1年为0001年，以公元前1年为0000年，公元前2年为-0001年，其他以此类推。应用其他纪年法要换算成公历，但如果发送和接受信息的双方有共同一致同意的其他纪年法，可以自行应用。\n5.5 协调世界时 # 英语：Coordinated Universal Time，\n法语：Temps Universel Coordonné，简称UTC\n是最主要的世界时间标准，其以原子时秒长为基础，在时刻上尽量接近于格林尼治标准时间。中华民国采用CNS 7648的《资料元及交换格式–资讯交换–日期及时间的表示法》（与ISO 8601类似）称之为世界协调时间。中华人民共和国采用ISO 8601:2000的国家标准GB/T 7408-2005《数据元和交换格式 信息交换 日期和时间表示法》中亦称之为协调世界时。\n协调世界时是世界上调节时钟和时间的主要时间标准，它与0度经线的平太阳时相差不超过1秒，并不遵守夏令时。协调世界时是最接近格林威治标准时间（GMT）的几个替代时间系统之一。对于大多数用途来说，UTC时间被认为能与GMT时间互换，但GMT时间已不再被科学界所确定。\n如果时间是以协调世界时（UTC）表示，则在时间后面直接加上一个“Z”（不加空格）。“Z”是协调世界时中0时区的标志。因此，“09:30 UTC”就写作“09:30Z”或是“0930Z”。“14:45:15 UTC”则为“14:45:15Z”或“144515Z”。\n5.6 UTC偏移量 # UTC偏移量用以下形式表示：±[hh]:[mm]、±[hh][mm]、或者±[hh]。如果所在区时比协调世界时早1个小时（例如柏林冬季时间），那么时区标识应为“+01:00”、“+0100”或者直接写作“+01”。这也同上面的“Z”一样直接加在时间后面。 \u0026ldquo;UTC+8\u0026quot;表示当协调世界时（UTC）时间为凌晨2点的时候，当地的时间为2+8点，即早上10点。\n5.7 格林尼治平时 # 英语：Greenwich Mean Time，GMT）\n是指位于英国伦敦郊区的皇家格林尼治天文台当地的平太阳时，因为本初子午线被定义为通过那里的经线。\n自1924年2月5日开始，格林尼治天文台负责每隔一小时向全世界发放调时信息。\n格林尼治平时的正午是指当平太阳横穿格林尼治子午线时（也就是在格林尼治上空最高点时）的时间。由于地球每天的自转是有些不规则的，而且正在缓慢减速，因此格林尼治平时基于天文观测本身的缺陷，已经被原子钟报时的协调世界时（UTC）所取代。\n6 参考 # Java8日期和时间工具库 Is-java-util-calendar-thread-safe-or-no Java8的java.time包 Simp code demo of package java.time Unable-to-obtain-localdatetime-from-temporalaccessor-when-parsing-localdatetime JSR 310 guide "},{"id":80,"href":"/zh/docs/java/concurrency/6%E7%94%9F%E4%BA%A7%E8%80%85-%E6%B6%88%E8%B4%B9%E8%80%85%E4%B8%8E%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97/","title":"生产者-消费者与阻塞队列","section":"并发编程","content":"在讨论线程协作的时候，已经讨论了生产者与消费者雏形，比如录音是生产者，而播放则是消费者；同样的，在汽车打蜡的模型中，打蜡可看作生产者，抛光可看作消费者；只是它们的关系是简单的生产-消费关系。\n除了简单的线程协同之外，Java提供了同步队列来解决线程的协同问题，本节重点讨论这部分的内容。\n线程协同 # 不妨继续查看一个示例：\n饭店类，有一个餐点类和一个使用volatile修饰的计数器，用来统计进餐的次数。\npublic class Restaurant { private Meal meal; private volatile int count; static class Meal { int orderNum; public Meal(int orderNum) { this.orderNum = orderNum; } @Override public String toString() { return \u0026#34;Meal \u0026#34; + orderNum; } } } 厨师线程，负责提供餐点。当饭店有多余餐点时，等待服务员消耗餐点；当餐点消耗完时，则被唤醒继续提供餐点。\nclass Chef implements Runnable { final Restaurant rest; public Chef(Restaurant rest) { this.rest = rest; } @Override public void run() { while (!Thread.interrupted()) { synchronized (rest) { if (rest.meal != null) { try { rest.wait(); } catch (InterruptedException e) { System.out.println(\u0026#34;Exit Chef by Interrupted\u0026#34;); return; } } /* try { TimeUnit.MILLISECONDS.sleep(100); } catch (InterruptedException e) { System.out.println(\u0026#34;Exit Chef Sleep by Interrupted\u0026#34;); return; }*/ rest.meal = new Meal(++rest.count); rest.notifyAll(); } } System.out.println(\u0026#34;Exit Chef\u0026#34;); } } 服务员线程，当饭店没有餐点时，则等待厨师制作餐点；若有餐点，则消耗餐点\nclass Waiter implements Runnable { final Restaurant rest; public Waiter(Restaurant rest) { this.rest = rest; } @Override public void run() { while (!Thread.interrupted()) { synchronized (rest) { if (rest.meal == null) { try { rest.wait(); } catch (InterruptedException e) { System.out.println(\u0026#34;Exit Waiter by Interrupted\u0026#34;); return; } } System.out.println(\u0026#34;order up: \u0026#34; + rest.meal); rest.meal = null; rest.notifyAll(); } } System.out.println(\u0026#34;Exit Waiter\u0026#34;); } } 主线程，不断运行厨师和服务员线程。直到饭店提供10份餐点为止。\npublic static void main(String[] args) { ExecutorService pool = Executors.newCachedThreadPool(); Restaurant restaurant = new Restaurant(); pool.execute(new Waiter(restaurant)); pool.execute(new Chef(restaurant)); while (true) { synchronized (restaurant) { if (restaurant.count == 10) { pool.shutdownNow(); break; } } } // end } /*（sample） order up: Meal 1 order up: Meal 2 order up: Meal 3 order up: Meal 4 order up: Meal 5 order up: Meal 6 order up: Meal 7 order up: Meal 8 order up: Meal 9 order up: Meal 10 exit waiter by interrupted Exit Chef *///:~ 主线程中的while循环必须使用同步块获取restaurant的锁，以保证其在获取count值的时候没有其他线程对其进行修改。可以看到输出结果满足预期，waiter任务执行10次之后程序退出。\n我们不妨关注一下任务结束的方式：在输出样例中，Waiter被中断，而Chef是正常退出1。中断的线程一定是wait状态，此时Waiter在wait，而Chef正好满足运行的条件，但此时主线程的线程池发出了interrupt()命令，所以Chef的while循环的判断条件不成立，不运行while语句而退出。\n如果我们取消Chef任务中的注释部分，那么任务结束的方式又会有所不同：\nExit Chef Sleep by Interrupted Exit Waiter by Interrupted 除此之外，关于此示例，还有一些特别说明：\n可以使用try-catch块包含任务的while循环，这样保证任何时候出现异常都能结束任务；示例中对每个可能出现异常的地方使用try-catch主要是为了明确异常发生的地方罢了；\n关于使任务进入等待的条件，示例中使用了if语句进行判断，实际上更通用的方法是使用while循环(虽然个人感觉没有实质上的差别)。\nsynchronized(monitor){ while(condition){ wait(); } } 类似这样的例子，之前的文章已经讨论过很多次了。实现同步的方式使用同步块+线程等待/唤醒。前文也讨论了Java提供的一些线程交互的API（如join()方法）。\n阻塞队列 # java.util.concurrent包中提供了 同步队列 来解决线程协作的问题，同步队列在任意时刻都只允许一个任务插入或移除元素，juc包中同步队列的顶级接口是BlockingQueue，其有大量实现，LinkedBlockingQueue是一个无界队列；ArrayBlockingQueue具有固定的尺寸，在其元素数达到容量限制时，再向其他插入元素则会阻塞；SynchronousQueue是一个没有容量的同步队列，仅当有任务从队列中移除元素时，另一任务才可以向队列中插入元素，反之亦然。\n操作 抛出异常 返回特殊值 阻塞 超时阻塞 插入 add(e) offer(e) put(e) offer(e, time, unit) 移除 remove() poll() take() poll(time, unit) 检查 element() peek() \u0026mdash; \u0026mdash; 上表展示了阻塞队列的方法概要，与 普通队列相比，阻塞队列添加了阻塞和超时阻塞的方法：\nvoid put(E e) throws InterruptedException 向队列中插入元素，队列中没有空间时一直等待 E take() throws InterruptedException 取出队首的元素，队列为空时一直等待 boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException 向队列中插入元素，超时等待队列中空间可用，超时之前插入则返回true，超时则返回false E poll(long timeout, TimeUnit unit) throws InterruptedException 取出队首的元素，超时等待队首元素可用，返回该元素或者null(超时) 下面我们以ArrayBlockingQueue和LinkedBlockingQueue为例，看看阻塞队列是如何阻塞和唤醒的：\nArrayBlockingQueue # 这是一个典型的FIFO队列，新的元素插入队尾，并从队首移出。ArrayBlockingQueue是有界队列，构造器带有一个初始容量参数，一旦初始化，这个容量不能改变。\n下面列出ArrayBlockingQueue的几个重要成员变量和构造器\n/** The queued items */ final Object[] items; // 可以看到是用对象数组实现 /** Main lock guarding all access */ final ReentrantLock lock; // 唯一的锁 /** Condition for waiting takes */ private final Condition notEmpty; // 条件1，非空 /** Condition for waiting puts */ private final Condition notFull; // 条件2， 非满 // constructor public ArrayBlockingQueue(int capacity, boolean fair) { if (capacity \u0026lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition(); } 基本上，ArrayBlockingQueue类所有同步方法使用的就是上面的可重入锁（ReentrantLock）及其条件，我们主要观察put(e)和take()方法是如何阻塞和唤醒的：\n// put public void put(E e) throws InterruptedException { checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == items.length) // 没有空间时等待 notFull.await(); enqueue(e); } finally { lock.unlock(); } } private void enqueue(E x) { // assert lock.getHoldCount() == 1; // assert items[putIndex] == null; final Object[] items = this.items; items[putIndex] = x; if (++putIndex == items.length) putIndex = 0; count++; // 唤醒一个等待的take()方法 notEmpty.signal(); } // take public E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == 0) // 没有元素时等待 notEmpty.await(); return dequeue(); } finally { lock.unlock(); } } private E dequeue() { // assert lock.getHoldCount() == 1; // assert items[takeIndex] != null; final Object[] items = this.items; @SuppressWarnings(\u0026#34;unchecked\u0026#34;) E x = (E) items[takeIndex]; items[takeIndex] = null; if (++takeIndex == items.length) takeIndex = 0; count--; if (itrs != null) itrs.elementDequeued(); // 唤醒一个等待的put()方法 notFull.signal(); return x; } 可以看到，阻塞队列的put(e)和take()方法是互相唤醒的，因此是生产——消费模式的绝佳实现。同时也注意到，方法中使用显式锁的可中断获取锁方法，以便在必要的时候中断，避免出现阻塞无法响应的情况。\n同时，ArrayBlockingQueue的put(e)和take()方法使用的是同一个锁对象，这就意味着同一时刻只能有一个任务执行插入或移除元素的操作。\nArrayBlockingQueue的put(e)和take()逻辑可以简单概括为：\nArrayBlockingQueue的put/take方法流程图\nLinkedBlockingQueue # 这是一个基于 linked nodes 的FIFO队列，如果构造时不指定容量，其容量默认为Integer.MAX_VALUE。\n下面列出了LinkedBlockingQueue关于put(e)和take()的主要字段：\n/** Lock held by take, poll, etc */ private final ReentrantLock takeLock = new ReentrantLock(); /** Wait queue for waiting takes */ private final Condition notEmpty = takeLock.newCondition(); /** Lock held by put, offer, etc */ private final ReentrantLock putLock = new ReentrantLock(); /** Wait queue for waiting puts */ private final Condition notFull = putLock.newCondition(); 可以看到，LinkedBlockingQueue的put(e)和take()方法分别拥有一个锁对象，我们不妨看看它们在对应方法中的行为：\n// put public void put(E e) throws InterruptedException { if (e == null) throw new NullPointerException(); // Note: convention in all put/take/etc is to preset local var // holding count negative to indicate failure unless set. int c = -1; Node\u0026lt;E\u0026gt; node = new Node\u0026lt;E\u0026gt;(e); // 使用put锁 final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try { while (count.get() == capacity) { // 满时在put锁上等待 notFull.await(); } enqueue(node); c = count.getAndIncrement(); if (c + 1 \u0026lt; capacity) // 再次检查，若不满，则唤醒其他等待的put任务 // 因为put和take使用的是不同的锁，可能t1在put时进入了等待， // 而t2在put时运行到这一步时，线程t3已经take走了几个元素， // 而此时队列中尚存在多个元素(t1不能被t3唤醒) // 于是t2发现队列存在空间，则t1可以被唤醒 notFull.signal(); } finally { putLock.unlock(); } if (c == 0) // 若c=0，此时count=1，队列中有元素，唤醒等待的take任务 signalNotEmpty(); } private void signalNotEmpty() { final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try { notEmpty.signal(); } finally { takeLock.unlock(); } } // take public E take() throws InterruptedException { E x; int c = -1; final AtomicInteger count = this.count; // 使用take锁 final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try { while (count.get() == 0) { // 空时等待 notEmpty.await(); } x = dequeue(); c = count.getAndDecrement(); if (c \u0026gt; 1) // 唤醒其他的take任务 // 若t1在take时发现队列为空进入等待，t2在take时运行到此时 // 发现队列已经被t3put了多个元素 // 那么t2就可以在此处直接唤醒t1 notEmpty.signal(); } finally { takeLock.unlock(); } if (c == capacity) // 此时已经移除队首元素，队列有1个空间，唤醒等待的put任务 signalNotFull(); return x; } private void signalNotFull() { final ReentrantLock putLock = this.putLock; putLock.lock(); try { notFull.signal(); } finally { putLock.unlock(); } } 相较ArrayBlockingQueue而言，LinkedBlockingQueue的put(e)和take()方法稍显复杂，因为后者使用了2个锁对象，put(e)和take()方法除了被对方唤醒之外，还会被自己唤醒，更为重要的是，使用2个锁对象允许在同一时刻有至多2个任务分别进行put(e)和take()操作。\nLinkedBlockingQueue的put/take方法流程图\nSynchronousQueue # SynchronousQueue是一个比较特殊的阻塞队列，它没有容量，它更像是一种机制：\n当任务a试图向队列中插入元素时，必然要等待另一个任务b从队列中移除元素，反之亦然。\n了解不同的阻塞队列 # 下例展示了不同阻塞队列实例在同一应用中的不同行为2：\npublic class TestBlockingQueue { private BlockingQueue\u0026lt;LiftOff\u0026gt; rockets; private TestBlockingQueue(BlockingQueue\u0026lt;LiftOff\u0026gt; rockets) { this.rockets = rockets; } static TestBlockingQueue getLinkedBlockingQueue() { return new TestBlockingQueue(new LinkedBlockingQueue\u0026lt;\u0026gt;()); } static TestBlockingQueue getArrayBlockedQueue(int capacity) { return new TestBlockingQueue(new ArrayBlockingQueue\u0026lt;\u0026gt;(capacity)); } static TestBlockingQueue getSynchronousQueue() { return new TestBlockingQueue(new SynchronousQueue\u0026lt;\u0026gt;()); } void add() throws InterruptedException { rockets.put(new LiftOff(1)); } LiftOff take() throws InterruptedException { return rockets.take(); } class LiftOffAdder implements Runnable { @Override public void run() { try { while (!Thread.interrupted()) { add(); Thread.yield(); } System.out.println(\u0026#34;Exiting LiftOffAdder\u0026#34;); } catch (InterruptedException e) { System.out.println(\u0026#34;Interrupted during add()\u0026#34;); } } } class LiftOffRunner implements Runnable { @Override public void run() { try { while (!Thread.interrupted()) { LiftOff rocket = take(); // 在此线程上运行 rocket.run(); try { TimeUnit.MILLISECONDS.sleep(100); } catch (InterruptedException e) { System.out.println(\u0026#34;Interrupted during sleep\u0026#34;); // return 语句是必须的，捕获异常后状态被清除了，while循环无法终止 return; } } System.out.println(\u0026#34;Exiting LiftOffRunner\u0026#34;); } catch (InterruptedException e) { System.out.println(\u0026#34;Interrupted during take()\u0026#34;); } } } @SneakyThrows void test(String msg) { System.out.println(msg); ExecutorService pool = Executors.newCachedThreadPool(); LiftOffRunner runner = this.new LiftOffRunner(); LiftOffAdder adder = this.new LiftOffAdder(); pool.execute(runner); pool.execute(adder); TimeUnit.SECONDS.sleep(1); pool.shutdownNow(); System.out.println(\u0026#34;rocket still in queue: \u0026#34; + rockets.size()); } public static void main(String[] args) { getLinkedBlockingQueue().test(\u0026#34;LinkedBlockingQueue\u0026#34;); getArrayBlockedQueue(1).test(\u0026#34;ArrayBlockingQueue\u0026#34;); getSynchronousQueue().test(\u0026#34;SynchronousQueue\u0026#34;); } }/* output(sample) LinkedBlockingQueue #0(LiftOff!), #1(LiftOff!), #2(LiftOff!), #3(LiftOff!), #4(LiftOff!), #5(LiftOff!), #6(LiftOff!), #7(LiftOff!), Exiting LiftOffAdder rocket still in queue: 2087449 Interrupted during sleep ArrayBlockingQueue #2087457(LiftOff!), #2087458(LiftOff!), #2087459(LiftOff!), #2087460(LiftOff!), #2087461(LiftOff!), #2087462(LiftOff!), #2087463(LiftOff!), #2087464(LiftOff!), #2087465(LiftOff!), #2087466(LiftOff!), rocket still in queue: 1 Interrupted during sleep Interrupted during add() SynchronousQueue #2087469(LiftOff!), #2087470(LiftOff!), #2087471(LiftOff!), #2087472(LiftOff!), #2087473(LiftOff!), #2087474(LiftOff!), #2087475(LiftOff!), #2087476(LiftOff!), #2087477(LiftOff!), #2087478(LiftOff!), rocket still in queue: 0 Interrupted during sleep Interrupted during add() *///:~ 在上面的示例中，有一个待发射的“火箭队列”，另有2个任务分别向队列中添加火箭和取出火箭执行发射，其中添加火箭的任务是以无限循环的形式进行的，只有当任务阻塞或者中断时添加任务才结束，而发射火箭的任务每100ms会从队列中取出火箭并发射。示例中有3个不同的阻塞队列实现，除了上面提到的两种之外，还有一个SynchronousQueue，主线程执行1s后通过执行器向所有任务执行中断命令，通过输出观察3个阻塞队列的行为。\n首先是LinkedBlockingQueue，它是一个无界(Integer.MAX_VALUE)队列，我们看到它1s内完成了8次发射任务，这也是符合预期的，因为除了CPU休眠的时间，线程的上下文切换也会消耗部分时间，同时我们可以看到，由于没有容量限制，在短短的1s时间内，队列中的火箭实例竟然多达208万之多，队列的元素如此之多也会对性能有一定影响！最后发送中断命令之后，显而易见发射任务是在休眠时被中断退出的，而添加任务是正常退出的，这是由于没有容量限制，于是不存在让队列的put(e)方法阻塞的条件，添加任务没有被阻塞，而是检测到中断状态而退出。\n接着是一个固定容量为1ArrayBlockingQueue，我们看到其完成了10次发射任务，中断发生之前，队列中还有一个火箭实例，并且两个任务都是被中断的。在最后一次完成发射之后，添加任务被唤醒并执行并在再次执行时由于队列中元素数到达容量上限而进入等待，此时接收到中断命令，于是在休眠中的发射任务直接抛出中断异常，而添加任务也在等待中直接抛出中断异常。\n其次是SynchronousQueue，这是一个特殊的阻塞队列，我们看到它也执行了10次发射任务，中断发生时，队列中没有元素，并且2个任务都是被中断的。这个最容易理解：最后一次发射之后发射任务进入休眠的过程中，由于发射任务的take()方法没有运行，因此添加任务的put(e)也会被阻塞。\n关于其他的阻塞队列，参考 其他重要的并发组件。\n实际测试过程的结果往往相反，而Waiter和Chef同时被中断的情况很少。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLiftOff类参考本系列的第一个 任务实例。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":81,"href":"/zh/docs/note/pys/11_threading/","title":"线程模型","section":"Python","content":" "},{"id":82,"href":"/zh/docs/java/concurrency/6%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97%E4%BD%BF%E7%94%A82%E4%BE%8B/","title":"阻塞队列的使用2例","section":"并发编程","content":" 上一篇文章介绍了juc的几种主要阻塞队列。\n本文使用2个例子，演示了阻塞队列在Java中的应用。\n查找关键字 # 下面的示例从目录及其子目录中查找指定关键字的文件并列出关键字所在的行的信息。我们使用阻塞队列存放目录及其子目录中所有文件，并且使用2个任务分别添加文件和查找文件。\npublic class SearchKeyword { private static final int FILE_QUEUE_SIZE = 10; private static final int SEARCH_THREADS = 100; private static final File DUMMY = new File(\u0026#34;\u0026#34;); /**有界阻塞队列*/ private final BlockingQueue\u0026lt;File\u0026gt; queue = new ArrayBlockingQueue\u0026lt;\u0026gt;(FILE_QUEUE_SIZE); private final static String DIR = \u0026#34;src\u0026#34;; private String keyword; private volatile boolean done = false; public static void main(String[] args) { SearchKeyword sk = new SearchKeyword(); sk.test(); } void test() { // 带资源的try块 try (Scanner in = new Scanner(System.in)) { System.out.print(\u0026#34;Enter keyword (e.g. volatile): \u0026#34;); keyword = in.nextLine(); Producer p = new Producer(); Consumer c = new Consumer(); ExecutorService pool = Executors.newCachedThreadPool(); pool.execute(p); for (int i = 1; i \u0026lt;= SEARCH_THREADS; i++) { // run consumer pool.execute(c); } pool.shutdown(); } } class Producer implements Runnable { @Override public void run() { try { enumerate(new File(DIR)); // 空文件作为结束符 queue.put(DUMMY); } catch (InterruptedException e) { // ignore } } } class Consumer implements Runnable { @Override public void run() { try { while (!done) { File file = queue.take(); if (file == DUMMY) { done = true; } else { search(file, keyword); } // Thread.yield(); } } catch (Exception e) { // ignore } } } /** * Recursively enumerates all files in a given directory and its subdirectories. * * @param directory the directory in which to start */ public void enumerate(File directory) throws InterruptedException { File[] files = directory.listFiles(); for (File file : files) { if (file.isDirectory()) { enumerate(file); } else { queue.put(file); } } } /** * Searches a file for a given keyword and prints all matching lines. * * @param file the file to search * @param keyword the keyword to search for */ public void search(File file, String keyword) throws IOException { try (Scanner in = new Scanner(file, \u0026#34;UTF-8\u0026#34;)) { int lineNumber = 0; while (in.hasNextLine()) { lineNumber++; String line = in.nextLine(); if (line.contains(keyword)) { System.out.printf(\u0026#34;[%s] %s:%d:%s%n\u0026#34;, Thread.currentThread().getName(), file.getPath(), lineNumber, line); } } } } } 上例中用于存放文件的是有界的阻塞队列实现，并且代码没有任何的显式同步控制，程序是线程安全的，这就是阻塞队列在处理生产——消费模型时的优势。\n事实上，我们无需关注队列中元素的插入/移除、以及put/take方法的阻塞情况，阻塞队列会处理好一切。不过，我们可以简单分析程序可能的运行过程：\n若p任务一直占用cpu时间，那么队列很快将到达容量上限，put方法阻塞 此时c任务获得cpu时间及锁，并且能够顺利的移除元素，此时take方法唤醒put方法 但是put方法并没有获取锁，c任务继续执行，由于c任务有很多线程，队列中的元素很快被消耗完，所有执行c任务的线程take方法阻塞 此时p任务重新获得锁，put方法插入元素后唤醒take方法，c任务得以继续执行 \u0026hellip; 插入dummy之后p任务完成 c任务的任一线程读取到dummy之后修改修改标记变量并在下一次循环退出 其他执行c任务的线程读取到标记量并相继退出 实际上程序运行的过程比上面的阐述要复杂的多，不过需要理解的就是阻塞队列在队列满或空的情况下的阻塞是被相互唤醒的。\n面包工厂的阻塞链 # ⚠️此节的内容关于阻塞链的描述部分可能有部分错误。\n假设一个面包工厂有两个加工线，分别加工黄油面包和果酱面包，现在将面包工厂作为生产者，另外我们需要一个消费者，来看看每次都会吃到什么口味的面包\npublic class ToastFactory { private volatile int count; static class Toast { enum Status {DRY, BUTTERED, JAMMED} private Status status = Status.DRY; private final int id; public Toast(int idn) { id = idn; } public void butter() { status = Status.BUTTERED; } public void jam() { status = Status.JAMMED; } public Status getStatus() { return status; } public int getId() { return id; } @Override public String toString() { return \u0026#34;Toast \u0026#34; + id + \u0026#34;: \u0026#34; + status; } } class ToastQueue extends LinkedBlockingQueue\u0026lt;Toast\u0026gt; { } class Toaster implements Runnable { private ToastQueue rawQueue; public Toaster(ToastQueue tq) { rawQueue = tq; } @Override public void run() { try { while (!Thread.interrupted()) { TimeUnit.MILLISECONDS.sleep(100); // Make toast Toast t = new Toast(count++); System.out.println(t); // Insert into queue rawQueue.put(t); } System.out.println(\u0026#34;Toaster off\u0026#34;); } catch (InterruptedException e) { System.out.println(\u0026#34;Toaster interrupted\u0026#34;); } } } /** Apply butter to toast: */ class Butterer implements Runnable { private ToastQueue dryQueue, finishQueue; public Butterer(ToastQueue dry, ToastQueue buttered) { dryQueue = dry; finishQueue = buttered; } @Override public void run() { try { while (!Thread.interrupted()) { // Blocks until next piece of toast is available: Toast t = dryQueue.take(); t.butter(); System.out.println(t); finishQueue.put(t); } System.out.println(\u0026#34;Butterer off\u0026#34;); } catch (InterruptedException e) { System.out.println(\u0026#34;Butterer interrupted\u0026#34;); } } } /** Apply jam to buttered toast: */ class Jammer implements Runnable { private ToastQueue dryQueue, finishQueue; public Jammer(ToastQueue raw, ToastQueue jam) { dryQueue = raw; finishQueue = jam; } @Override public void run() { try { while (!Thread.interrupted()) { // Blocks until next piece of toast is available: Toast t = dryQueue.take(); t.jam(); System.out.println(t); finishQueue.put(t); } System.out.println(\u0026#34;Jammer off\u0026#34;); } catch (InterruptedException e) { System.out.println(\u0026#34;Jammer interrupted\u0026#34;); } } } /** Consume the toast: */ class Eater implements Runnable { private ToastQueue finishQueue; private int counter = 0; public Eater(ToastQueue finishQueue) { this.finishQueue = finishQueue; } @Override public void run() { try { while (!Thread.interrupted()) { // Blocks until next piece of toast is available: Toast toast = finishQueue.take(); // Verify that the toast is coming in order, // and that all pieces are getting jammed: if (toast.getId() != counter++ || toast.getStatus() == Toast.Status.DRY) { System.out.println(\u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt; Error: \u0026#34; + toast); System.exit(1); } else { System.out.println(\u0026#34;Chomp! \u0026#34; + toast); } } System.out.println(\u0026#34;Eater off\u0026#34;); } catch (InterruptedException e) { System.out.println(\u0026#34;Eater interrupted\u0026#34;); } } } public void test() throws InterruptedException { ToastQueue dryQueue = this.new ToastQueue(), finishQueue = this.new ToastQueue(); ExecutorService exec = Executors.newCachedThreadPool(); exec.execute(this.new Toaster(dryQueue)); exec.execute(this.new Butterer(dryQueue, finishQueue)); exec.execute(this.new Jammer(dryQueue, finishQueue)); exec.execute(this.new Eater(finishQueue)); while (true) { if (count \u0026gt; 4) { break; } } exec.shutdownNow(); System.out.println(\u0026#34;toast count: \u0026#34; + count); } public static void main(String[] args) throws Exception { ToastFactory tf = new ToastFactory(); tf.test(); } } /* Toast 0: DRY Toast 0: BUTTERED Chomp! Toast 0: BUTTERED Toast 1: DRY Toast 1: JAMMED Chomp! Toast 1: JAMMED Toast 2: DRY Toast 2: BUTTERED Chomp! Toast 2: BUTTERED Toast 3: DRY Toast 3: JAMMED Chomp! Toast 3: JAMMED Toast 4: DRY Toast 4: BUTTERED Chomp! Toast 4: BUTTERED toast count: 5 Eater interrupted Jammer interrupted Butterer interrupted Toaster interrupted *///:~ 上例有4个任务，分别为生产干面包（记为T1），生产黄油面包（记为T2），生产果酱面包（记为T3），消费面包（记为T4）。黄油/果酱面包只能由干面包加工而成，而T4只能消费加工好的面包\ngraph LR A[开始] --\u003e B(干面包T1) B-- 黄油T2 --\u003eD[生产完成] B-- 果酱T3 --\u003eD D-- 消费T4 --\u003eE[结束] 程序执行流程\n从执行流程上来看，T1会阻塞T2和T3，而T2和T3会阻塞T4，而T4会阻塞T1，这样形成了一个阻塞链，从输出来看也正是如此，面包的生产和消费是有序的：被涂上黄油的面包0被消费，接着是被涂上果酱的面包1被消费\u0026hellip;等等如此有规律的输出。\n仔细想想，这种规律是怎么得到保证的呢？\n从代码来看， 程序使用了2个阻塞队列：rawQueue和finishQueue分别表示干面包和加工完成的面包（黄油/果酱），程序运行时，T1， T2，T3，T4全部是RUNNABLE状态。由于采用的实现是LinkedBlockingQueue，所以rowQueue的put(e)方法无法被阻塞，单从这一点看，就不能保证得到代码示例中的规律输出，此外，T2/T3会随机争用rowQueue的take锁，所以面包被涂黄油还是果酱是无法确定的，完全由cpu随机调度，因此也不可能出现上述示例的规律输出，至于T4就更不用说了，由于T2/T3的随机争用，那么T4的if判断必然会出现错误，从而退出程序，符合逻辑的输出应该是向下面这样的（当然，把主线程的count判断值改大以观察效果）：\n/* ... Chomp! Toast 51: BUTTERED Toast 54: BUTTERED Toast 59: DRY Toast 56: BUTTERED \u0026gt;\u0026gt;\u0026gt;\u0026gt; Error: Toast 53: BUTTERED Toast 55: JAMMED Toast 57: BUTTERED Toast 59: BUTTERED ... */ 既然是rowQueue的put(e)方法无法被阻塞导致的问题，那么使用指定容量为1的ArrayBlockingQueue是否可以满足规律输出呢？\n遗憾的是，也不行1\nclass ToastQueue extends ArrayBlockingQueue\u0026lt;Toast\u0026gt;{ public ToastQueue(int capacity) { super(capacity); } } class Toaster implements Runnable { private ToastQueue rawQueue; public Toaster(ToastQueue tq) { rawQueue = tq; } @Override public void run() { try { while (!Thread.interrupted()) { // 这句休眠是保证阻塞链的根本 // TimeUnit.MILLISECONDS.sleep(100); // Make toast Toast t = new Toast(count++); rawQueue.put(t); } System.out.println(\u0026#34;Toaster off\u0026#34;); } catch (InterruptedException e) { System.out.println(\u0026#34;Toaster interrupted\u0026#34;); } } } /** Apply butter to toast: */ class Butterer implements Runnable { private ToastQueue dryQueue, finishQueue; public Butterer(ToastQueue dry, ToastQueue buttered) { dryQueue = dry; finishQueue = buttered; } @Override public void run() { try { while (!Thread.interrupted()) { // Blocks until next piece of toast is available: Toast t = dryQueue.take(); t.butter(); finishQueue.put(t); } System.out.println(\u0026#34;Butterer off\u0026#34;); } catch (InterruptedException e) { System.out.println(\u0026#34;Butterer interrupted\u0026#34;); } } } /** Apply jam to buttered toast: */ class Jammer implements Runnable { private ToastQueue dryQueue, finishQueue; public Jammer(ToastQueue raw, ToastQueue jam) { dryQueue = raw; finishQueue = jam; } @Override public void run() { try { while (!Thread.interrupted()) { // Blocks until next piece of toast is available: Toast t = dryQueue.take(); t.jam(); finishQueue.put(t); } System.out.println(\u0026#34;Jammer off\u0026#34;); } catch (InterruptedException e) { System.out.println(\u0026#34;Jammer interrupted\u0026#34;); } } } /** Consume the toast: */ class Eater implements Runnable { private ToastQueue finishQueue; private int counter = 0; public Eater(ToastQueue finishQueue) { this.finishQueue = finishQueue; } @Override public void run() { try { while (!Thread.interrupted()) { // Blocks until next piece of toast is available: Toast toast = finishQueue.take(); System.out.println(\u0026#34;Chomp! \u0026#34; + toast); } System.out.println(\u0026#34;Eater off\u0026#34;); } catch (InterruptedException e) { System.out.println(\u0026#34;Eater interrupted\u0026#34;); } } } public void test() throws InterruptedException { ToastQueue dryQueue = this.new ToastQueue(1), finishQueue = this.new ToastQueue(1); ExecutorService exec = Executors.newCachedThreadPool(); exec.execute(this.new Toaster(dryQueue)); exec.execute(this.new Butterer(dryQueue, finishQueue)); exec.execute(this.new Jammer(dryQueue, finishQueue)); exec.execute(this.new Eater(finishQueue)); while (true) { if (count \u0026gt; 14) { break; } } exec.shutdownNow(); System.out.println(\u0026#34;toast count: \u0026#34; + count); } public static void main(String[] args) throws Exception { ToastFactory tf = new ToastFactory(); tf.test(); } /* output (partial sample) ... Chomp! Toast 18: JAMMED Chomp! Toast 20: JAMMED Chomp! Toast 19: BUTTERED Chomp! Toast 22: BUTTERED Chomp! Toast 21: JAMMED Chomp! Toast 24: JAMMED Eater off Butterer interrupted toast count: 28 Toaster interrupted Jammer interrupted *///:~ 可以看到，还是T2/T3的争用问题没有解决，T1的阻塞之后，T2/T3获得运行权之后将面包放入finishQueue时又存在争用情况，尽管大多数情况下都是有序的，但是也存在少数情况下的乱序问题。\n同时，上述代码还暴露了一个问题： volatile变量的局限性，程序计划生产14块面包后结束，而最后的面包数却到了28！主线程和T1对共享变量count进行修改，应该使用同步2。\n实际上，在T1任务开始时使用 休眠来降低面包生产的速度，这样当程序运行时，T1处于休眠状态，/T2/T3/T4都是处于阻塞状态，这和前面讨论的无规律输出是完全不同的局面；当T1休眠超时之后，生产第一片面包并唤醒一个在rawQueue上等待的任务（可能是T2或T3）后又进入休眠（100ms），此时（假如）T2被唤醒，那么T2加工面包之后唤醒T4并随即进入等待（T1任务100ms的休眠足够长时间让rawQueue为空），T4完成之后随即进入等待(同理，100ms足够长)，这样就完成了一轮规律输出3：\n/* Toast 0: DRY Toast 0: BUTTERED Chomp! Toast 0: BUTTERED */ 值得一提的是，关于上面提到的共享变量，并没有使用同步，但是却 意外地 没有出现问题2。这确实令人意外，明明是不满足happens-before原则的，但是却没有出现讹误（或许是测试少，讹误没有发生）。原因就出现在T1的休眠上，由于T1的休眠，T1有足够的时间来接收主线程“滞后”的中断命令，因此看起来就像是主线程的判断没有逻辑上的缺陷一样。\n这是我见过的最强休眠。\n这个代码还存在共享资源的访问讹误问题。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n这是由于在前文中提到的，在使用ArrayBlockingQueue测试时，volatile关键字的局限性显现时意识到的。将count设置为volatile，并且只有线程T1在对其进行修改，主线程读取count的值作为任务中断的依据，看起来似乎不需要额外的同步，即可不出现讹误，但是却出现了。实际上，虽然保证了可见性，但是没有保证有序性，即对count的判断和对count的修改不满足happens-before原则，只有当对count值的读取总是发生在对count值的修改之前时，主线程中对count值的判断逻辑才是可行的，事实上主线程中对count值的判断总是滞后于修改的。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n看起来100ms的休眠好像是一个不太安全的机制，因为不能保证100ms的时间T4一定在T1休眠的时间内完成任务并进入等待。但是在测试过程中将休眠时间设置为1ns(Java能够设置的最小休眠时间)，仍然得到了规律输出，这一点让人费解。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":83,"href":"/zh/docs/java/concurrency/7_1_Executors_and_ExecutorService/","title":"Executors与Executor框架","section":"并发编程","content":"Executors可以称作执行器。Java并发系列的文章到目前为止，虽然没有特别说明，但是使用执行器(Executor(s))的次数已经难以计数了，Executors提供了一些非常方便的静态方法，可以根据需要创建不同的ExecutorService，然后调用其execute(Runnable)或submit(Callable\u0026lt;T\u0026gt;)方法。\n在并发条件下，执行器还有一个非常明显的优势，它使用线程池管理线程，减少了系统创建和销毁线程的开销。在一般的Java并发过程中，也建议使用执行器完成任务而非显式地创建线程。\n本文将从执行器开始，阐述Java中的线程池。\nExecutors类 # java.util.concurrent.Executors类提供了许多静态方法来获取不同类型的 线程池，下表列出其常用方法1：\n方法 概要 newFixedThreadPool 创建固定大小的线程池，线程会一直保留 newCachedThreadPool 创建线程池，该线程池在必要时创建新线程，旧线程也会被重用，线程空闲60s被销毁 newSingleThreadExecutor 相当于newFixedThreadPool(1)，其能保证任务顺序执行 newScheduledThreadPool 创建计划执行一次或周期执行的线程池 newSingleThreadScheduledExecutor 创建计划执行一次或周期执行的单线程池 Executors用于构造线程池的部分方法\n上表中的前3个方法返回ThreadPoolExecutor实例，后面2个方法返回ScheduledExecutorService实例，不管是ThreadPoolExecutor或是ScheduledExecutorService，都是ExecutorService的实现，ExecutorService接口是设计用来处理任务的接口，其顶层接口是java.util.concurrent.Executor，该接口简单地定义了一个执行任务的方法：\npublic interface Executor { /** * Executes the given command at some time in the future. The command * may execute in a new thread, in a pooled thread, or in the calling * thread, at the discretion of the {@code Executor} implementation. * * @param command the runnable task * @throws RejectedExecutionException if this task cannot be * accepted for execution * @throws NullPointerException if command is null */ void execute(Runnable command); } 因此对执行器的讨论最终要回到对Executor及其实现上来。\nJava Executor框架的主要构成 下图展示了Executor框架的执行逻辑2\nflowchart LR A([\"Main Thread\"]) --\u003e|Create| B(Rannable) A --\u003e | Create| C(\"Callable\u003c\\V\u003e\") B --\u003e | execute| D(ExecutorServiceth) B --\u003e |submit| D C --\u003e |submit| D D --\u003e |return| G(Future\u003c\\V\u003e) A --\u003e |get| G A --\u003e | cancel| H subgraph D[\"EcecutorServiceth\"] E(ThreadPoolExecutor) F(ScheduledThreadPoolExecutor) end subgraph G[Future\u003c\\V\u003e] H(FutureTask\u003c\\V\u003e) end 从上面的框架组成图中，可以清晰的看到使用Executors能够构建所有线程池实例，ExecutorService接口定义了一系列和线程池以及任务相关的基本方法，用于检查关闭/关闭线程池，提交任务，执行任务等。\nAbstractExecutorService直接实现了ExecutorService的invokeAny/invokeAll方法。此外，从该类的源码可以清晰地看到，所有的任务都是通过转化为RunnableFuture(FutureTask)而后通过execute(Runnable)方法执行的。\nprotected \u0026lt;T\u0026gt; RunnableFuture\u0026lt;T\u0026gt; newTaskFor(Callable\u0026lt;T\u0026gt; callable) { return new FutureTask\u0026lt;T\u0026gt;(callable); } public \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Callable\u0026lt;T\u0026gt; task) { if (task == null) throw new NullPointerException(); RunnableFuture\u0026lt;T\u0026gt; ftask = newTaskFor(task); execute(ftask); return ftask; } protected \u0026lt;T\u0026gt; RunnableFuture\u0026lt;T\u0026gt; newTaskFor(Runnable runnable, T value) { return new FutureTask\u0026lt;T\u0026gt;(runnable, value); } public Future\u0026lt;?\u0026gt; submit(Runnable task) { if (task == null) throw new NullPointerException(); RunnableFuture\u0026lt;Void\u0026gt; ftask = newTaskFor(task, null); execute(ftask); return ftask; } public \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Runnable task, T result) { if (task == null) throw new NullPointerException(); RunnableFuture\u0026lt;T\u0026gt; ftask = newTaskFor(task, result); execute(ftask); return ftask; } ScheduledExecutorService 接口继承自 ExecutorService， 定义了用于计划执行或周期执行的线程池方法。 ThreadPoolExecutor 继承自 AbstractExecutorService，是线程池重要的实现之一。 ScheduledThreadPoolExecutor 继承自 ScheduledExecutorService，是线程池重要的实现之二。 ForkJoinPool 继承自 AbstractExecutorService，是线程池的重要实现之三，关于它的内容将单独展开。 DelegatedExecutorService 继承自 AbstractExecutorService ，它是 Executors 的内部类， 是一个仅仅实现了 ExecutorService 方法的包装类， 其有两个子类分别是 DelegatedScheduledExecutorServide 和 FinalizableDelegatedExecutorService。 CompletionService 接口有一个子类 ExecutorCompletionService， 该类由执行器实例化，用来管理执行器执行的任务的结果。 ExecutorService接口 # ExecutorService是次顶层接口，定义了线程池操作任务的基本方法。\n// 继承自Executor的方法 void execute(Runnable command); void shutdown(); /*有序地关闭线程池，已经提交（在运行或已经在队列中）的任务不会受到影响，将继续执行， 但线程池不接受新任务的提交 此法不会在当前线程上等待线程池后台任务的执行结果（或者任务执行后的作用），换言之， 如果想要获取任务执行之后的结果，调用此法无法达到目的*/ List\u0026lt;Runnable\u0026gt; shutdownNow(); /*尝试去停止(stop)所有活动的任务，已提交且队列中的中的任务将取消执行，并返回取消的任务队列。 向正在执行的任务发送中断命令，那些无法响应中断命令的任务将无法中止 和shutdown()方法一样，此法不会等待正在执行的任务终止*/ boolean isShutdown(); // 如果线程池已经关闭，返回true boolean isTerminated(); /*如果所有的任务都完成（中止运行或正常运行完成），则返回true 注意，若没有先调用shutdown()或shutdownNow()，此方法不可能返回true*/ boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; /*线程池shutdown请求之后，阻塞当前线程，等待任务执行。当超时，任务执行完毕，或当前线程被中断 任一情况发生时，终止阻塞*/ \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Callable\u0026lt;T\u0026gt; task); // 提交一个有返回结果的Callable任务 \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Runnable task, T result); // 提交一个Runnable并指定其返回result Future\u0026lt;?\u0026gt; submit(Runnable task); /*提交一个Runnable，返回的Future\u0026lt;?\u0026gt;的get方法将返回null，其主要目的是利用Future的其他 方法控制任务的执行*/ \u0026lt;T\u0026gt; List\u0026lt;Future\u0026lt;T\u0026gt;\u0026gt; invokeAll(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks) throws InterruptedException; /*执行集合中包含的任务，并返回一个Future\u0026lt;T\u0026gt;集合，Future\u0026lt;T\u0026gt;集合包含各个任务的执行状态及结果 Future\u0026lt;T\u0026gt;集合中的的顺序和任务集合中的迭代顺序是一致的 这个方法会等待所有的任务执行完成（正常执行或抛出异常），如果任务集合在执行过程中被修改，那么 任务的结果将会变为undefined*/ \u0026lt;T\u0026gt; List\u0026lt;Future\u0026lt;T\u0026gt;\u0026gt; invokeAll(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; /* 执行集合中包含的任务，在所有任务执行完成或超时之前返回一个Future\u0026lt;T\u0026gt;集合。在返回之前， 未能执行的任务将被取消 其他的特征和重载方法一致*/ \u0026lt;T\u0026gt; T invokeAny(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks) throws InterruptedException, ExecutionException; /* 执行给定的任务集合中的任务，返回任何一个成功执行的任务的结果，其他未完成的任务被取消 如果任务集合在执行过程中被修改，那么任务的结果将会变为undefined*/ \u0026lt;T\u0026gt; T invokeAny(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; /* 执行给定的任务集合中的任务，在超时之前返回任何一个成功执行的任务的结果， 其他未完成的任务被取消 如果任务集合在执行过程中被修改，那么任务的结果将会变为undefined*/ 如上所示，ExecutorService定义了线程池的基本方法，其中invokeAny和invokeAll方法在AbstractExecutorService中实现。\n表中没有提及关于构建Fork/Join线程池的方法，这部分内容将在后续补全坑。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n引自《Java并发编程的艺术》方腾飞等著\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":84,"href":"/zh/docs/java/concurrency/7_2_ThreadPoolExecutor1/","title":"ThreadPoolExecutor-1","section":"并发编程","content":" 前文就已经提过，Executors执行器创建的线程池包括不同实现，可以应对不同的场景，那么Java中包含哪些实现呢？\n本问就来讨论这些实现。\nThreadPoolExecutor # 该类是执行器(线程池)的核心类，一般来讲，Java的线程池，指的就是ThreadPoolExecutor实例。\n构造器 # ThreadPoolExecutor提供了4个构造器用来构造线程池实例：\npublic ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue) { ... } public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, ThreadFactory threadFactory) { ... } public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, RejectedExecutionHandler handler) { ... } public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { ... } 从构造器来看呢，要构建一个线程池实例，至少需要提供5个参数，另外2个参数不提供则可以使用默认配置1，这些参数分别是：\n参数 描述 corePoolSize 核心线程池大小 maximumPoolSize 最大线程池大小 keepAliveTime 非核心线程执行完任务后最长的空间等待时间，超时则销毁线程 unit keepAliveTime的单位 workQueue 用于保存待执行任务的队列 threadFactory 用于创建线程的线程工厂 handler 线程池满载（队列无空间，且不能新建线程）后，处理新提交任务的拒绝策略 这些构造器参数就是线程池的核心概念，理解这几个参数在线程池运行过程中的意义便理解了线程池的大半。\n核心概念 # 核心线程池与最大线程池 # 线程池的getPoolSize()方法返回的线程数不应该超过线程池的核心线程池大小（corePoolSize）或 最大线程池大小（maximumPoolSize）。线程池中的工作线程数不可能超过最大线程池大小。若想获得当前的正在执行任务的线程数，需使用getActiveCount()方法。\n当一个任务被提交至线程池后，若：\n当前工作线程数 \u0026lt; corePoolSize，新建一个线程来完成任务——尽管可能有空闲核心线程。 (当工作线程数 \u0026lt; corePoolSize时，任务队列一定是空的) corePoolSize \u0026lt; 当前工作线程数 \u0026lt; maximumPoolSize，并且任务队列已满，那么新建一个非核心线程来完成任务。 当设置corePoolSize=maximumPoolSize时，你将获得一个固定容量的线程池；当将maxPoolSize设置为Integer.MAX_VALUE时，线程数没有限制，这有可能造成内存泄漏。\n本文约定当前工作线程指代线程池中存在的线程（getPoolSize()方法的返回值），其中可能存在部分空闲线程。当工作线程数少于核心线程数时：\n1）当前线程池中的线程全是核心线程；\n2）任务队列一定是空的；\n3）当前某个线程可能是空闲的（执行完任务，在等待队列中的任务（runWorker方法阻塞））。\n尽管在构建线程池实例时要指定corePoolSize和maximumPoolSize，在获得实例之后还可以通过setCorePoolSize(int)和setMaximumPoolSize(int)来对其进行修改。\n类似地，存活时间，线程工厂，拒绝策略其他参数都可以在线程池初始化之后再进行设置。\n默认情况下，当线程池初始化成功之后，池中是没有任何线程的。不过，可以调用prestartCoreThread()和prestartAllCoreThreads()来向线程池中添加一个或所有核心线程。如果你使用一个非空的任务队列初始化线程池，这样做是有用的。\n@SneakyThrows void initPoolWithNonEmptyQueue() { BlockingQueue\u0026lt;Runnable\u0026gt; queue = new ArrayBlockingQueue\u0026lt;Runnable\u0026gt;(2) {{ add(() -\u0026gt; { System.out.println(\u0026#34;1st task done\u0026#34;); }); add(()-\u0026gt;{ System.out.println(\u0026#34;2nd task done\u0026#34;); }); }}; ThreadPoolExecutor.AbortPolicy abortPolicy = new ThreadPoolExecutor.AbortPolicy(); ThreadPoolExecutor poolExecutor = new ThreadPoolExecutor(1, 1, 0, TimeUnit.MILLISECONDS, queue, abortPolicy); poolExecutor.prestartCoreThread(); poolExecutor.shutdown(); } /* output 1st task done 2nd task done *///:~ 使用prestartCoreThread()还有一个好处，它可以保证队列中的任务顺序执行。\n线程工厂 # 线程池中的线程使用线程工厂ThreadFactory创建，如果没有指定，将使用Executors.defaultThreadFactory。如果线程工厂在创建线程时失败而返回null，那么线程池将无法执行任何任务。\n存活时间 # keepAliveTime针对的是非核心线程，非核心线程处理完任务后，若在keepAliveTime内没有新任务添加到队列并被其获取并运行，其将被销毁。这是一种资源保护策略，如果线程池的任务突然增多，可能又会创建非核心线程来完成任务。当corePoolSize = maximumPoolSize时，线程池无法创建非核心线程，此时keepAliveTime参数可能没有意义，一般将其设置为0。\n但凡事并非绝对，ThreadPoolExecutor维护一个布尔型变量allowCoreThreadTimeOut，其默认值是false，用来控制核心线程池的“生命”：\n/** * If false (default), core threads stay alive even when idle. * If true, core threads use keepAliveTime to time out waiting * for work. */ private volatile boolean allowCoreThreadTimeOut; 这个变量的值由allowCoreThreadTimeOut(boolean value)方法修改\npublic void allowCoreThreadTimeOut(boolean value) { if (value \u0026amp;\u0026amp; keepAliveTime \u0026lt;= 0) throw new IllegalArgumentException( \u0026#34;Core threads must have nonzero keep alive times\u0026#34;); if (value != allowCoreThreadTimeOut) { allowCoreThreadTimeOut = value; if (value) interruptIdleWorkers(); } } 可以看到，如果将变量allowCoreThreadTimeOut的值设置为true，那么空闲的核心线程池也将会在keepAliveTime超时之后被销毁(如果没有任务让其执行)。\n任务队列 # 任务队列是一个阻塞队列，一个线程池中只有一个任务队列。任务队列用于存放当前尚没有线程可执行之的任务，其和线程池之间存在如下的交互关系：\n如果当前工作线程 \u0026lt; corePoolSize，线程池将创建新线程执行任务而非将任务放入队列 如果当前工作线程 \u0026gt; corePoolSize，线程池倾向于将任务放入队列而非创建新线程执行之 如果任务无法放入队列（满），并且当前工作线程 \u0026lt; maximumPoolSize，将创建新线程执行之，否则任务将被拒绝 任务队列有3种常见实现：\n直接运行(direct handoffs)，这种情形的任务队列一般由 SynchronousQueue实现，这种队列的实现对线程池的要求严苛，如果没有可用的线程即刻执行任务，那么将任务放入队列将失败。在此情形下，一般将maximumPoolSize设置为Integer.MAX_ VALUE以防止线程池拒绝任务。这种实现可能会导致内存泄漏。\n无界任务队列， 一般由 LinkedBlockingQueue实现，这种情形下，当当前工作线程达到corePoolSize之后，所有新提交的任务都会放入队列中，由于队列无界，就不会再创建新线程了，也不会拒绝任务。因此maximumPoolSize这一设置将无意义。如果任务源源不断地提交，有可能任务积压导致内存泄漏。\n有界队列，一般由 ArrayBlockingQueue实现，使用有界队列可以避免资源耗尽，但是也增加了配置的难度，是应该配置更多的线程数更小的队列还是应该配置更大的队列更少的线程数，往往需要根据具体的任务来考量。\n拒绝策略 # 前面提到，如果线程池满，新提交的任务就会被线程池拒绝执行；同样的，如果线程池关闭了，提交任务也会被拒绝。线程池通过调用RejectedExecutionHandler.rejectedExecution(Runnable, ThreadPoolExecutor)来拒绝任务，ThreadPoolExecutor内建了4种不同的拒绝策略：\nThreadPoolExecutor.AbortPolicy，也是默认的拒绝策略，该策略直接抛出RejectedExecutionException的运行时异常 public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { throw new RejectedExecutionException(\u0026#34;Task \u0026#34; + r.toString() + \u0026#34; rejected from \u0026#34; + e.toString()); } ThreadPoolExecutor.CallerRunsPolicy，如果线程池未关闭，该策略直接在执行execute()方法的线程上运行任务，否则该任务被丢弃 public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { if (!e.isShutdown()) { r.run(); } } ThreadPoolExecutor.DiscardPolicy，该策略直接丢弃不能被执行的任务 public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { } ThreadPoolExecutor.DiscardOldestPolicy，如果线程池未关闭，则将队列头部的任务丢弃，然后继续执行execute(Runnable)方法 public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { if (!e.isShutdown()) { e.getQueue().poll(); e.execute(r); } } Executors构建的实例 # Executors的三个方法(没有包含重载方法)返回该类的实例：\npublic static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;()); } /* 构建一个固定容量的线程池，该线程池的线程都是核心线程，任务队列使用无界队列；当线程数达到 corePoolSize时，新提交的任务都将放入队列，这个线程池不会拒绝任务*/ public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue\u0026lt;Runnable\u0026gt;()); } /* 构建一个corePoolSize为0，maximumPoolSize无限制的线程池，线程池中的线程都是非核心线程， 当线程空闲超过60s后即被销毁，这个线程池的任务队列使用的是SynchronousQueue，因此一旦提交任务， 即会创建一个线程去执行之*/ public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;())); } /* 构建一个corePoolSize = maximumPoolSize = 1的线程池，该线程池只有一个核心线程，任务 队列为无界队列，因此当核心线程已被创建后，所有提交的任务都放入队列，这个线程池不会拒绝任务。与 第一个静态方法不同的是，由于其使用FinalizableDelegatedExecutorService包装 ThreadPoolExecutor，这个线程池一旦初始化，不允许再进行动态配置*/ 如上所示，前2个静态方法构造的都是特殊的ThreadPoolExecutor实例，初始化成功之后，都是可以通过ThreadPoolExecutor的实例方法进行动态配置的。\n第3个静态方法有所不同，其生成了一个容量为1且不可改变的线程池，严格来说，它返回的不是ThreadPoolExecutor实例，而是由ThreadPoolExecutor包装的FinalizableDelegatedExecutorService实例。\nFinalizableDelegatedExecutorService是Executors类（仅具有包访问权限）的内部类，FinalizableDelegatedExecutorService类继自DelegatedExecutorService，这是一个仅仅有ExecutorService接口方法的包装类，因此，当我们调用newSingleThreadExecutor()方法时，仅可以将其声明为ExecutorService。 ExecutorService service = Executors.newSingleThreadExecutor(); // ！非法，不能强制类型转换 ThreadPoolExecutor pool = (ThreadPoolExecutor)Executors.newSingleThreadExecutor(); 正因为其是一个仅仅可以执行ExecutorService接口方法的包装类，其无法在线程池初始化之后再动态配置。\n扩展阅读: ThreadPoolExecutor jdk1.8 Javadoc\n须调用合适的构造器，实际上所有参数必须提供，不过有些由构造器默认提供。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":85,"href":"/zh/docs/java/concurrency/7_3_ThreadPoolExecutor2/","title":"ThreadPoolExecutor-2","section":"并发编程","content":" 前文说过，ThreadPoolExecutor实例代表了Java线程池，前面我们介绍了ThreadPoolExecutor的构造器和几个核心概念，在本节中，我们着重介绍线程池的执行过程以及线程池的关闭。\n线程池的运行状态 # 线程池的运行状态表示了线程池的生命周期，在代码实现中它们使用用一个整数表示：\n状态 描述 RUNNING 接受新任务的提交，执行队列中的任务 SHUTDOWN 不接受新任务的提交，执行队列中的任务 STOP 不接受新任务的提交，不执行队列中的任务，中断正在执行的任务 TIDYING 所有任务终止，workerCount = 0 ，执行terminated()方法 TERMINATED terminated()方法执行完毕 为了方便地判断线程池的运行状态，给上述线程池状态约定了单调的演化关系：\n状态变化 条件 RUNNING -\u0026gt; SHUTDOWN 调用shutdown()方法，或者隐式调用了finalize()1 (RUNNING或SHUTDOWN) -\u0026gt; STOP 调用shutdownNow()方法 SHUTDOWN -\u0026gt; TIDYING 当线程池和任务队列都为空时 STOP -\u0026gt; TIDYING 线程池为空 TIDYING -\u0026gt; TERMINATED 当terminated()方法执行完成 可以看到，线程池的状态是单调演化的，除了RUNNING状态可以接受任务并执行外，其他的状态都将导致线程池资源关闭。ThreadPoolExecutor类中有几个获取线程池状态的方法：\n/** 若线程池的状态不是RUNNING，那么该方法就返回true*/ public boolean isShutdown() { return ! isRunning(ctl.get()); } /** 若线程池的状态不是RUNNING，并且状态没有还没有切换到TERMINATED，该方法就返回true 这个方法返回true说明线程池正处于terminae的过程中*/ public boolean isTerminating() { int c = ctl.get(); return ! isRunning(c) \u0026amp;\u0026amp; runStateLessThan(c, TERMINATED); } /** 若线程的状态为TERMINATED，该方法返回true*/ public boolean isTerminated() { return runStateAtLeast(ctl.get(), TERMINATED); } 线程池中任务的执行过程 # 了解了线程池的工作状态，接下来我们尝试去深入任务是如何在线程池中被执行的，以及线程池中核心线程，任务队列以及非核心线程之间是如何协同工作的。\n在 任务队列中，我们阐述了任务队列与线程池之间存在交互关系，这种交互关系体现了线程池执行任务的重要过程。\n线程池执行流程图 上面的流程图展示了任务提交到线程池到执行或被拒绝的过程，和在任务队列中的描述相当，接下来我们从源码的角度阐述这一过程。 提交任务 # 在介绍 ExecutorService时我们提到了AbstractExecutorService基类，它有两个重要的作用：\n将所有的任务提交转变为执行一个FutureTask 实现了invokeAny/invokeAll方法 了解到这一点之后，我们将线程池的任务执行重心放在ThreadPoolExecutor的execute(Runnable)方法上：\npublic void execute(Runnable command) { if (command == null) throw new NullPointerException(); int c = ctl.get(); // 当前工作线程数 \u0026lt; corePoolSize if (workerCountOf(c) \u0026lt; corePoolSize) { // 直接添加新的工作线程执行之 if (addWorker(command, true)) return; // 若新建失败，则表示rs \u0026gt;= shutdown，任务将会被拒绝 c = ctl.get(); } // 否则将任务放入队列 if (isRunning(c) \u0026amp;\u0026amp; workQueue.offer(command)) { // 线程状态RUNNING，任务已放入队列 // double check int recheck = ctl.get(); // 这里double-check的原因是： if (! isRunning(recheck) \u0026amp;\u0026amp; remove(command)) // 1. 线程池可能被shutdown了，这时候直接从队列移除任务并拒绝之 reject(command); else if (workerCountOf(recheck) == 0) // 2. 若corePoolSize = 0，而非核心线程都完成了任务 // 空闲线程超时被销毁之后，就可能出现workerCount = 0 的情况 // 此时添加一个非核心线程去执行队列中的任务 addWorker(null, false); } // 队列满了，则尝试新建一个非核心线程执行任务，否则拒绝之 else if (!addWorker(command, false)) reject(command); } /**使用Worker包装线程来执行任务*/ private boolean addWorker(Runnable firstTask, boolean core) { // 循环判断，直到满足新建Worker的条件为止 retry: for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. // 解释一下这个return false的逻辑 /* 1. 若rs = runnning，继续添加worker * 2. 若rs \u0026gt;= shutdown * 2.1 rs \u0026gt;= stop 不新建worker(return false) * 2.2 rs = shutdown，firstTask != null， * 不新建worker (shutdown之后不接受新任务提交) * 2.3 rs = shutdown，firstTask = null，workQueue为空，不新建worker */ if (rs \u0026gt;= SHUTDOWN \u0026amp;\u0026amp; ! (rs == SHUTDOWN \u0026amp;\u0026amp; firstTask == null \u0026amp;\u0026amp; ! workQueue.isEmpty())) return false; for (;;) { int wc = workerCountOf(c); if (wc \u0026gt;= CAPACITY || wc \u0026gt;= (core ? corePoolSize : maximumPoolSize)) // 线程数量超限 return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop } } boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try { w = new Worker(firstTask); /* Worker(Runnable firstTask) { setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); } */ final Thread t = w.thread; if (t != null) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); // 状态为RUNNING时可以新建Worker执行任务 // 状态为SHUTDOWN时，任务必须为空(不可提交任务) if (rs \u0026lt; SHUTDOWN || (rs == SHUTDOWN \u0026amp;\u0026amp; firstTask == null)) { if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); // 调整字段值 workers.add(w); int s = workers.size(); if (s \u0026gt; largestPoolSize) largestPoolSize = s; workerAdded = true; } } finally { mainLock.unlock(); } // 运行任务 if (workerAdded) { // 从Worker的构造器来看，线程t的构造器参数是Worker // 因此start()实际上执行的是Worker的run()方法 t.start(); workerStarted = true; } } } finally { // 线程池创建线程失败，清理资源 if (! workerStarted) addWorkerFailed(w); } // 返回true表示线程已创建并启动 // 根据调用参数的不同，启动的线程可能直接执行任务 // 也可能从队列中获取任务执行 return workerStarted; } 线程池添加worker的流程 创建空线程 # 前面介绍 核心概念的时候说到，线程池初始化成功之后，池中是没有活动线程的，不过线程池具有很好的灵活性，可以进行动态配置。使用prestartCoreThread()和prestartAllCoreThreads()方法可以向线程池中添加核心线程，这些线程并没有使用任务初始化，不过其会尝试去队列中获取任务执行，若队列为空，这些线程就会挂起(waiting)2。\n/** 创建一个核心线程*/ public boolean prestartCoreThread() { return workerCountOf(ctl.get()) \u0026lt; corePoolSize \u0026amp;\u0026amp; addWorker(null, true); } /** 创建所有核心线程*/ public int prestartAllCoreThreads() { int n = 0; while (addWorker(null, true)) ++n; return n; } 执行任务 # 线程池创建线程是为了执行任务，addWorker()方法成功时会启动线程，线程则会调用Worker的run()方法。\npublic void run() { runWorker(this); } /**该方法会循环进行，并且在getTask()方法处阻塞*/ final void runWorker(Worker w) { Thread wt = Thread.currentThread(); // 任务即为创建Worker的入参 Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try { // 只要有任务提交或队列不为空，则一直执行 while (task != null || (task = getTask()) != null) { w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt // 如果线程池状态为STOP（调用shutdownNow()），则中断线程 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() \u0026amp;\u0026amp; runStateAtLeast(ctl.get(), STOP))) \u0026amp;\u0026amp; !wt.isInterrupted()) wt.interrupt(); try { // 可扩展方法 beforeExecute(wt, task); Throwable thrown = null; try { task.run(); } catch (RuntimeException x) { thrown = x; throw x; } catch (Error x) { thrown = x; throw x; } catch (Throwable x) { thrown = x; throw new Error(x); } finally { // 可扩展方法 afterExecute(task, thrown); } } finally { task = null; w.completedTasks++; w.unlock(); } } completedAbruptly = false; } finally { // while循环结束后的动作 processWorkerExit(w, completedAbruptly); } } /** 该方法从队列中获取任务，方法会被阻塞(核心线程)或超时阻塞（非核心线程）*/ private Runnable getTask() { boolean timedOut = false; // Did the last poll() time out? for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. // 如果状态为SHUTDOWN，但队列不为空，仍从队列中执行任务 // 如果状态为STOP，则直接return null if (rs \u0026gt;= SHUTDOWN \u0026amp;\u0026amp; (rs \u0026gt;= STOP || workQueue.isEmpty())) { // workerCount - 1 decrementWorkerCount(); return null; } int wc = workerCountOf(c); // Are workers subject to culling? // 当allowCoreThreadTimeOut被设置时，核心线程超时阻塞 boolean timed = allowCoreThreadTimeOut || wc \u0026gt; corePoolSize; if ((wc \u0026gt; maximumPoolSize || (timed \u0026amp;\u0026amp; timedOut)) \u0026amp;\u0026amp; (wc \u0026gt; 1 || workQueue.isEmpty())) { if (compareAndDecrementWorkerCount(c)) return null; continue; } try { // 阻塞队列获取队头任务 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; // 超时未获取到任务 --\u0026gt; line 79 --\u0026gt; return null timedOut = true; } catch (InterruptedException retry) { timedOut = false; } } } 线程池执行任务的流程 可以看到，线程池中的线程初始化之后，其执行任务的过程是阻塞的，也就是说，线程池中的线程一直处于“stand by”状态，除此之外，我们还可以得到以下信息：\n如果没有设置allowCoreThreadTimeOut，核心线程执行任务的过程将一直进行 非核心线程的执行任务的过程将在超时之后，方法不返回，循环再次进行，将在try块之前的if语句块中返回null 当线程池状态为SHUTDOWN时，若队列不为空，仍会去队列中获取任务执行；若状态为STOP，将不会从队列中获取任务 当出现下列任一情况时，getTask()会返回null结束线程运行：\nworkerCount \u0026gt; maximumPoolSize，一般在动配置maximumPoolSize之后出现 线程池状态为STOP 线程池状态为SHUTDOWN，且队列为空 当线程获取队列中的任务超时，且该线程不是队列中的唯一线程或队列为空 前面3点都比较好理解，第4点有点难以理解，我们使用一个corePoolSize=0的线程池特例加以说明：\nvoid cachedPool(){ ThreadPoolExecutor service = (ThreadPoolExecutor) Executors.newCachedThreadPool(); // service 5秒之后即关闭 service.setKeepAliveTime(5,TimeUnit.SECONDS); service.submit(()-\u0026gt;{ System.out.println(\u0026#34;task done\u0026#34;); }); } 我们知道，newCachedThreadPool构建一个corePoolSize=0的线程池，因此池中所有的任务在空闲超时都会被超时销毁，我们不妨来看看这一过程是如何发生的；我们将keepAliveTime重新设置为5s，并且向线程池中提交一个任务。\n线程池首先会新建一个线程执行任务，调用的是addWorker(firstTask, false)方法；\n在runWorker的第二次循环时，由于firstTask已经被执行，将调用getTask()方法去队列中获取任务。我们知道队列中没有任务，超时时间为5s，5s之后getTask()方法将timeout置为true后进入第二次循环；\n注意此次循环：\nif ((wc \u0026gt; maximumPoolSize || (timed \u0026amp;\u0026amp; timedOut)) \u0026amp;\u0026amp; (wc \u0026gt; 1 || workQueue.isEmpty())) { if (compareAndDecrementWorkerCount(c)) return null; continue; } 不难看出来，第一次wc =1 并且timeout=false，显然是不满足if的条件；第二次则不同，timeout此时为true，workQueue.isEmpty为true，if条件满足；\n此时将 wc-1，并且返回null\n返回null之后，runWorker()方法的while循环也会结束，接下来会执行processWorkerExit(w, completedAbruptly)方法：\n/**while循环正常结束，completedAbruptly为false*/ private void processWorkerExit(Worker w, boolean completedAbruptly) { if (completedAbruptly) // If abrupt, then workerCount wasn\u0026#39;t adjusted decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // 统计已经完成的任务数 completedTaskCount += w.completedTasks; // 将Worker从HashSet中移除 workers.remove(w); } finally { mainLock.unlock(); } // 正如其名，「尝试」终止线程池 tryTerminate(); int c = ctl.get(); // 若线程池状态为RUNNING or SHUTDOWN if (runStateLessThan(c, STOP)) { if (!completedAbruptly) { // 线程池中的最小线程数 int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 \u0026amp;\u0026amp; ! workQueue.isEmpty()) //队列非空时，要保证池中有线程运行任务 min = 1; if (workerCountOf(c) \u0026gt;= min) // 池中还有线程，可以安心返回 return; // replacement not needed } // 否则，向池中加入一个线程 addWorker(null, false); } } 在上面方法的最后if条件中，wc=min=0，池中没有线程并且任务队列为空，线程成功完成使命，结束运行。\n综上所述，被创建的线程除了执行被提交的任务之外，还会被阻塞执行队列中的任务，而核心线程和非核心线程在空闲时又会存在处理方式的差异。\n值得一提的是，在上面的newFixedThreadPool()的例子中，线程池提交完任务之后，并没有调用关闭方法，那么线程池能关闭么？\n通过上面的分析，例子中的线程在执行完任务后超时被销毁，此时池中没有线程在运行，队列中也没有任务，那么就意味着所有的逻辑都已经完成，并没有发生阻塞，线程池中的线程数为0，任务队列为空，虽然如此，线程池的状态还是RUNNING！线程池并没有终止，其还可以继续提交任务运行，实际上，线程池回到了初始化 时的状态。\n如何合理地关闭线程池 # ThreadPoolExecutor提供了2个关闭线程池的方法\npublic void shutdown() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // 检查权限 checkShutdownAccess(); // 修改线程池状态为SHUTDOWN advanceRunState(SHUTDOWN); // 中断所有空闲（waiting）的线程 // 在condition.await()上阻塞的线程能够响应中断， // 这就是线程池能够关闭而不阻塞的原因 // 阻塞的线程被中断唤醒后继续在getTask()上继续执行， // 在线程池状态判断时return null而结束 interruptIdleWorkers(); onShutdown(); // hook for ScheduledThreadPoolExecutor } finally { mainLock.unlock(); } // 执行terminated()（空）方法，将线程状态设置为TERMINATED tryTerminate(); } public List\u0026lt;Runnable\u0026gt; shutdownNow() { List\u0026lt;Runnable\u0026gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // 权限检查 checkShutdownAccess(); // 修改线程池状态为STOP advanceRunState(STOP); // 中断所有线程 interruptWorkers(); // 队列中未执行的任务 tasks = drainQueue(); } finally { mainLock.unlock(); } tryTerminate(); return tasks; } final void tryTerminate() { for (;;) { int c = ctl.get(); /*直接返回的条件： * 1. 线程池状态为RUNNING * 2. 线程池状态为 TIDYING 或 TERMINATED * 3. 线程状态为 SHUTDOWN， 且队列不为空 */ if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN \u0026amp;\u0026amp; ! workQueue.isEmpty())) return; // 若工作线程数 \u0026gt; 0 , 中断一个空闲线程并返回 if (workerCountOf(c) != 0) { // Eligible to terminate interruptIdleWorkers(ONLY_ONE); return; } final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // 设置线程池状态为TIDYING if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) { try { // 运行terminated()方法 terminated(); } finally { // 设置线程状态为TERMINATED ctl.set(ctlOf(TERMINATED, 0)); // 唤醒awaitTermination方法 termination.signalAll(); } return; } } finally { mainLock.unlock(); } // else retry on failed CAS } } 从上面的分析，我们可以清晰地看到shutdown()和shutdownNow()的区别，前者只中断了空闲线程，后者中断了所有线程；结合前文getTask()方法的表述，前者未被中断的线程还可继续执行并从任务队列中获取任务执行，而后者已经无法从队列中获取任务执行了，这与本节开头对线程池的 运行状态的描述一致。\nshutdown()和shutdownNow()方法都不能中断正在执行的任务，不过后者对正在执行的任务发送了中断命令，如果任务能够响应中断，即可以作出相应操作。如果想在shutdown()或shutdownNow()执行之后继续获取任务的返回值，只能使用awaitTermination()方法愚蠢地等待。awaitTermination()方法阻塞当前调用该方法的线程，直到任务执行完毕、超时、调用线程被中断3者任一条件发生。\n需要说明的是，如果awaitTermination()阻塞过程中线程池的状态变为TERNMINATD，说明任务执行完毕，返回true；否则返回false或抛出中断异常。\n下面的示例代码演示了shutdown()和shutdownNow()方法的区别：\npublic class ExecutorShutdown { static int pointer = 0; /** 容量为1的线程池，其能保证提交的任务都是序列化执行的 */ ThreadPoolExecutor service = (ThreadPoolExecutor) Executors.newFixedThreadPool(1); @SneakyThrows public static void main(String[] args) { ExecutorShutdown es = new ExecutorShutdown(); es.shutdown(); // es.awaitTermination(1, TimeUnit.SECONDS); } void shutdown() { service.execute(new ComplexTask()); // 对于newFixedThreadPool(1),EasyTask在任务队列中 service.execute(new EasyTask()); service.shutdown(); // shutdown之后，任务并没有执行完成，pointer的值还是0 System.out.println(\u0026#34;pointer:\u0026#34; + pointer); // 获取待任务队列 System.out.println(\u0026#34;workQueue: \u0026#34; + service.getQueue()); // 判断该执行器是否被关闭 System.out.println(\u0026#34;is executor shutdown? \u0026#34; + service.isShutdown()); // 执行器关闭之后所有任务是否都完成 // 如果没有调用shutdown()或shutdownNow()就直接调用isTerminated()，该方法必返回false System.out.println(\u0026#34;is executor terminated? \u0026#34; + service.isTerminated()); System.out.println(\u0026#34;pointer:\u0026#34; + pointer); } void awaitTermination(int timeout, TimeUnit unit) { service.execute(new ComplexTask()); service.execute(new EasyTask()); List\u0026lt;Runnable\u0026gt; tasks; try { if (service.awaitTermination(timeout, unit)) { service.shutdown(); } else { if(!(tasks = service.shutdownNow()).isEmpty()){ System.out.println(\u0026#34;丢弃任务\u0026#34; + tasks); } } } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\u0026#34;workQueue: \u0026#34; + service.getQueue()); System.out.println(\u0026#34;is executor shutdown? \u0026#34; + service.isShutdown()); System.out.println(\u0026#34;is executor terminated? \u0026#34; + service.isTerminated()); } abstract class Task { @Override public String toString() { return getClass().getSimpleName() + \u0026#34;@\u0026#34; + Integer.toHexString(hashCode()); } } class ComplexTask extends Task implements Runnable { @Override public void run() { // 响应中断，调用shutdownNow()可以结束任务 System.out.println(\u0026#34;[\u0026#34; + Thread.currentThread() + \u0026#34;@\u0026#34; + this + \u0026#34;]，开始执行\u0026#34;); // never finish unless interrupted for (; ; ) { if (!Thread.interrupted()) { pointer++; } else { System.out.println(\u0026#34;[\u0026#34; + Thread.currentThread() + \u0026#34;@\u0026#34; + this + \u0026#34;]，被中断\u0026#34;); break; } } } } class EasyTask extends Task implements Runnable { @Override public void run() { System.out.println(\u0026#34;[\u0026#34; + Thread.currentThread() + \u0026#34;@\u0026#34; + this + \u0026#34;]，开始执行\u0026#34;); pointer++; System.out.println(\u0026#34;[\u0026#34; + Thread.currentThread() + \u0026#34;@\u0026#34; + this + \u0026#34;]，执行完成\u0026#34;); } } } /* output 调用shutdown： [Thread[pool-1-thread-1,5,main]@ComplexTask@48d82c9c]，开始执行 pointer:0 workQueue: [EasyTask@14ae5a5] is executor shutdown? true is executor terminated? false pointer:813 调用awaitTermination： [Thread[pool-1-thread-1,5,main]@ComplexTask@7ac59a98]，开始执行 [Thread[pool-1-thread-1,5,main]@ComplexTask@7ac59a98]，被中断 丢弃任务[EasyTask@7f31245a] workQueue: [] is executor shutdown? true is executor terminated? true *///:~ 上例中我们设计了一个可以正常执行的任务EasyTask和一个无限循环执行的任务ComplexTask，后者响应中断，如果不中断线程，ComplexTask将一直运行下去。我们使用一个固定容量为1的线程池运行任务，并且先提交ComplexTask，ComplexTask无法结束运行，那么EasyTask将会放入队列中。\n从运行的结果上来看，使用shutdown()无法结束线程池的运行，虽然主线程结束，但线程池一直在后台运行，同时EasyTask也还在任务队列中，主线程结束后线程池的还没有终止，程序会一直在后台运行。\n当调用awaitTermination(timeout, unit)时，很明显这个方法将超时并返回false，最终执行shutdownNow()，shutdownNow给ComplexTask任务发送中断命令，其在下一次循环检查到中断，结束执行。同时任务队列中的EasyTask被丢弃，任务队列为空，主线程结束后，线程池也成功终止。\n如果ComplexTask在设计时，没有响应中断，而使用死循环执行任务，那么shutdownNow()方法仍然无法终止线程池，这就是官方文档中关于shutdownNow()方法描述的语义：\nThere are no guarantees beyond best-effort attempts to stop processing actively executing tasks. This implementation cancels tasks via {@link Thread#interrupt}, so any task that fails to respond to interrupts may never terminate.\n目前笔者还未找到隐式调用finalize()方法导致线程池关闭的例证\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n若corePoolSize=0，这些方法不会创建线程\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":86,"href":"/zh/docs/java/concurrency/7_4_CompletionService/","title":"CompletionService","section":"并发编程","content":"在提交单个任务时，使用submit()或者execute()方法或许能够满足要求，但如果需要控制多个任务时，依次提交的操作看起来“有些繁琐”，此时我们可以使用ExecutorService提供的invokeAny/invokeAll方法，在介绍CompletionService接口时，我们不妨先看看这两个方法。\n之前介绍AbstractExecutorService时提到，这两个方法是在这个抽象类中实现的，其中前者在获取到一个任务的返回值时便取消其他（未执行或正在执行的任务）任务，而后者需要等待所有的任务执行完成之后才能对任务的返回进行处理，接下来我们分别来看：\ninvokeAll会阻塞等待所有的任务执行完成。\npublic \u0026lt;T\u0026gt; List\u0026lt;Future\u0026lt;T\u0026gt;\u0026gt; invokeAll(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks) throws InterruptedException { if (tasks == null) throw new NullPointerException(); ArrayList\u0026lt;Future\u0026lt;T\u0026gt;\u0026gt; futures = new ArrayList\u0026lt;Future\u0026lt;T\u0026gt;\u0026gt;(tasks.size()); boolean done = false; try { for (Callable\u0026lt;T\u0026gt; t : tasks) { RunnableFuture\u0026lt;T\u0026gt; f = newTaskFor(t); futures.add(f); execute(f); } // 有序迭代 for (int i = 0, size = futures.size(); i \u0026lt; size; i++) { Future\u0026lt;T\u0026gt; f = futures.get(i); if (!f.isDone()) { try { // 阻塞等待任务执行完成 f.get(); } catch (CancellationException ignore) { } catch (ExecutionException ignore) { } } } done = true; return futures; } finally { if (!done) // 处理因异常而未正常执行的任务 for (int i = 0, size = futures.size(); i \u0026lt; size; i++) futures.get(i).cancel(true); } } // invokeAny public \u0026lt;T\u0026gt; T invokeAny(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks) throws InterruptedException, ExecutionException { try { return doInvokeAny(tasks, false, 0); } catch (TimeoutException cannotHappen) { assert false; return null; } } private \u0026lt;T\u0026gt; T doInvokeAny(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks, boolean timed, long nanos) throws InterruptedException, ExecutionException, TimeoutException { if (tasks == null) throw new NullPointerException(); int ntasks = tasks.size(); if (ntasks == 0) throw new IllegalArgumentException(); ArrayList\u0026lt;Future\u0026lt;T\u0026gt;\u0026gt; futures = new ArrayList\u0026lt;Future\u0026lt;T\u0026gt;\u0026gt;(ntasks); ExecutorCompletionService\u0026lt;T\u0026gt; ecs = new ExecutorCompletionService\u0026lt;T\u0026gt;(this); try { // Record exceptions so that if we fail to obtain any // result, we can throw the last exception we got. ExecutionException ee = null; final long deadline = timed ? System.nanoTime() + nanos : 0L; Iterator\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; it = tasks.iterator(); // Start one task for sure; the rest incrementally futures.add(ecs.submit(it.next())); --ntasks; int active = 1; for (;;) { // 并没阻塞第一个任务，此时可能第一个任务还未执行完 Future\u0026lt;T\u0026gt; f = ecs.poll(); if (f == null) { if (ntasks \u0026gt; 0) { --ntasks; // 不等待上一个任务的结果，直接新执行一个任务 futures.add(ecs.submit(it.next())); ++active; } else if (active == 0) break; else if (timed) { f = ecs.poll(nanos, TimeUnit.NANOSECONDS); if (f == null) throw new TimeoutException(); nanos = deadline - System.nanoTime(); } else // 没有可执行的任务了，则等待一个结果 f = ecs.take(); } // 有结果则返回 if (f != null) { --active; try { return f.get(); } catch (ExecutionException eex) { ee = eex; } catch (RuntimeException rex) { ee = new ExecutionException(rex); } } } if (ee == null) ee = new ExecutionException(); throw ee; } finally { for (int i = 0, size = futures.size(); i \u0026lt; size; i++) // 取消还未执行或者执行中的任务 // 中断任务 futures.get(i).cancel(true); } } 可以看到，与invokeAll不同的是，invokeAny方法是在循环的启动任务，直到获取到任一任务的返回值为止，而未执行或正在执行的任务则会被中断。\n下面的示例中，我们修改了 阻塞队列-查找关键字应用，让任务在成功搜寻到含有关键字的文件时就视为任务完成，取消其他任务的执行，这样一种场景之下，我们可以使用invokeAny方法：\npublic class Search1Keyword extends SearchKeyword { String empty = \u0026#34;\u0026#34;; public static void main(String[] args) { Search1Keyword s1k = new Search1Keyword(); s1k.find(); } @Override void find() { // 带资源的try块 try (Scanner in = new Scanner(System.in)) { System.out.print(\u0026#34;Enter keyword (e.g. volatile): \u0026#34;); keyword = in.nextLine(); Producer p = new Producer(); List\u0026lt;Callable\u0026lt;String\u0026gt;\u0026gt; tasks = new ArrayList\u0026lt;\u0026gt;(); ExecutorService pool = Executors.newCachedThreadPool(); for (int i = 1; i \u0026lt;= 10; i++) { // run consumer tasks.add(new Consumer1()); } pool.execute(p); // 此方法并不那么单纯，其结果只取一个，但是任务可能执行了多个 String res = pool.invokeAny(tasks); System.out.println(res); pool.shutdown(); } catch (Exception e) { e.printStackTrace(); } } class Consumer1 implements Callable\u0026lt;String\u0026gt; { @Override public String call() throws Exception { try { while (!done) { File file = queue.take(); if (file == DUMMY) { done = true; } else { String s = search1(file, keyword); if (s.length() \u0026gt; 0) { return s; } } } } catch (Exception e) { // ignore } return empty; } } public String search1(File file, String keyword) throws FileNotFoundException { StringBuilder sb = new StringBuilder(\u0026#34;\u0026#34;); try (Scanner in = new Scanner(file, \u0026#34;UTF-8\u0026#34;)) { int lineNumber = 0; while (in.hasNextLine()) { if (!Thread.interrupted()) { lineNumber++; String line = in.nextLine(); if (line.contains(keyword)) { sb.append(\u0026#34;[\u0026#34;).append(Thread.currentThread().getName()).append(\u0026#34;]: \u0026#34;) .append(file.getPath()).append(lineNumber).append(line).append(\u0026#34;\\n\u0026#34;); } } else { // thread interrupted by future.cancel() System.out.printf(\u0026#34;[%s] %s%n\u0026#34;, Thread.currentThread().getName(), \u0026#34; interrupted\u0026#34;); return empty; } } } return sb.toString(); } } /* output (sample1) Enter keyword (e.g. volatile): take [pool-1-thread-5]: TestBlockingQueue.java39 LiftOff take() throws InterruptedException { [pool-1-thread-5]: TestBlockingQueue.java40 return rockets.take(); [pool-1-thread-5]: TestBlockingQueue.java65 LiftOff rocket = take(); [pool-1-thread-5]: TestBlockingQueue.java78 System.out.println(\u0026#34;Interrupted during take()\u0026#34;); [pool-1-thread-11] interrupted [pool-1-thread-10] interrupted [pool-1-thread-6] interrupted [pool-1-thread-4] interrupted [pool-1-thread-9] interrupted [pool-1-thread-3] interrupted [pool-1-thread-7] interrupted [pool-1-thread-8] interrupted (sample2) Enter keyword (e.g. volatile): take [pool-1-thread-4]: Search1Keyword.java66 File file = queue.take(); [pool-1-thread-2] interrupted [pool-1-thread-10] interrupted [pool-1-thread-8] interrupted [pool-1-thread-5] interrupted [pool-1-thread-11] interrupted [pool-1-thread-7] interrupted [pool-1-thread-9] interrupted */ 我们将对一个包含关键字的文件进行的完整搜寻视为任务结束，虽然还可能有其他文件还有关键字，但是搜寻任务不再执行。从输出可以看到，输出的只包含一个文件的关键字信息。另外，我们使用10个任务，其中sample1中其他9个任务都被中断，而sample2中只有7个任务被interrupt，说明情况1中，所有的任务都开始执行了，而情况2中，还有未开始执行的任务(其永远不能执行了)。\n试着思考一个问题，既然invokeAny只需要获取一个任务的返回值即可，那为什么不直接启动第一个任务然后阻塞获取其返回值，而要启动（那么）多任务呢？启动一个任务不是更加简单么？\n我们分析源码时，发现invokeAny使用了ExecutorCompletionService，这个类继承自接口CompletionService，可以用来管理任务提交之后的Future\u0026lt;T\u0026gt;对象——将已经完成的Future其放在一个阻塞队列中取用，这样我们就可以回答上面的问题了：\ninvokeAny利用ExecutorCompletionService提交任务，并管理任务的返回，这样可以避免单独启动一个任务而需要阻塞很长时间的弊端，启动的多个任务只要有一个任务完成，其放置已完成Future的阻塞队列将变得可用而使invokeAny快速结束。\nExecutorCompletionService的快速用法为:\nExecutorCompletionService\u0026lt;T\u0026gt; ecs = new ExecutorCompletionService\u0026lt;\u0026gt;(executor) ; for(Callable\u0026lt;T\u0026gt; task : tasks){ ecs.submit(task); } for (int i = 0; i \u0026lt; tasks.size() ; i++ ) { // get return value ecs.take().get(); } "},{"id":87,"href":"/zh/docs/java/concurrency/8_1_ScheduledExecutorService1/","title":"ScheduledExecutorService-1","section":"并发编程","content":"除了ThreadPoolExecutor之外，Java执行器（Executor）框架还提供了可以在指定延迟之后执行一次或周期执行任务的接口ScheduledExecutorService，较 java.util.Timer而言，它是更好的选择。\n与 线程池不同的是，用于计划执行的ScheduledThreadPoolExecutor使用ScheduledFutureTask作为任务，使用DelayedWorkQueue作为任务队列，以实现计划（周期）执行的目的。\nScheduledThreadPoolExecutor继承关系图\n从ScheduledThreadPoolExecutor的继承关系图可以看到，其是ThreadPoolExecutor的导出类，其提交任务和执行任务以及关闭线程池的逻辑应和线程池相差无几，其重点差别在于任务对象以及任务队列的封装上，后文将会详述ScheduledThreadPoolExecutor的任务计划执行以及周期执行机制。\nScheduledExecutorService # 继承自ExecutorService接口，其方法定义了一个可以用于在指定延迟之后执行一次或周期执行的ExecutorService，它主要定义了如下4个方法：\n// 继承自ExecutorService 和Executor的方法被省略 \u0026lt;V\u0026gt; ScheduledFuture\u0026lt;V\u0026gt; schedule(Callable\u0026lt;V\u0026gt; callable, long delay, TimeUnit unit) /* 在给定的延迟之后执行Callable任务，立即返回ScheduledFuture\u0026lt;V\u0026gt;， 其可以获取任务的结果或者取消任务*/ ScheduledFuture\u0026lt;?\u0026gt; schedule(Runnable command, long delay, TimeUnit unit) /* 在给定的延迟之后执行Runnable任务， 立即返回ScheduledFuture\u0026lt;?\u0026gt;，其get()方法返回null*/ ScheduledFuture\u0026lt;?\u0026gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit) /* 在给定的初始延迟initialDelay之后执行Runnable任务， 接着在给定的时间间隔period之后再次执行任务， 接着再间隔period之后再次执行任务... 如果某次任务的执行耗时 \u0026gt; period，下次的计划执行将被延后， 并不会同时执行多个任务 如果某次执行抛出异常，那么接下来的执行将被中止。 周期执行的任务只有线程池终止之后才会停止执行，也 就是说周期任务永远不会主动完成 返回值ScheduledFuture\u0026lt;?\u0026gt;代表将要执行的任务， 取消任务时，其get()方法会抛出异常*/ ScheduledFuture\u0026lt;?\u0026gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit) /* 在给定的初始延迟之后执行Runnable任务， 接着在任务完成之后延迟delay之后再次执行，接着在上一个 任务完成之后延迟delay再次执行... 如果某次执行抛出异常，那么接下来的执行将被中止。 周期执行的任务只有线程池终止之后才会停止执行，也 就是说周期任务永远不会主动完成 返回值ScheduledFuture\u0026lt;?\u0026gt;代表将要执行的任务， 取消任务时，其get()方法会抛出异常*/ ScheduledThreadPoolExecutor # 由于其是ThreadPoolExecutor的导出类，故其主要逻辑和其父类一致，本节的讨论着重于二者差异的部分。\n构造器 # ScheduledThreadPoolExecutor的构造器就不再赘述了，基本上是父类的构造参数中抽取了几个便于理解的构造器，将其分列如下：\npublic ScheduledThreadPoolExecutor(int corePoolSize) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue()); } public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory); } public ScheduledThreadPoolExecutor(int corePoolSize, RejectedExecutionHandler handler) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), handler); } public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory, RejectedExecutionHandler handler) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory, handler); } ScheduledThreadPoolExecutor的实例均使用Integer.MAX_VALUE作为最大线程池数，这是否意味着其可以使用无限制的线程去运行任务呢？答案是否定的，ScheduledThreadPoolExecutor保证了其池中的线程数不会超过corePoolSize1。\n域 # 除了构造器中指定的参数之外，ScheduledThreadPoolExecutor还有一些其他参数，这些参数都可以在ScheduledThreadPoolExecutor初始化完成之后再进行动态配置。\n/** 线程池shutdown之后是否继续执行周期任务，true执行，默认为false*/ private volatile boolean continueExistingPeriodicTasksAfterShutdown; /** 线程池shutdown之后是否继续执行计划任务，true执行，默认为true*/ private volatile boolean executeExistingDelayedTasksAfterShutdown = true; /** 取消任务时是否将任务从队列中移除，true移除，默认false*/ private volatile boolean removeOnCancel = false; /** 任务添加的顺序，初始化ScheduledFutureTask时使用*/ private static final AtomicLong sequencer = new AtomicLong(); 方法 # ScheduledThreadPoolExecutor使用最多的还是实现自ScheduledExecutorService接口的4个方法，用于计划（周期）执行任务，其中，作为线程池的execute和submit方法全部直接调用了scheduleXX方法。值得一提的是，ScheduledThreadPoolExecutor覆盖了ThreadPoolExecutor的onShutdown()方法，用于关闭线程池时的额外操作，该方法在父类中是空方法。\n由Executors构建 # 一般地，我们会使用Executors来获取线程池，Executors提供了2个基本方法(不包括重载方法)来获取计划执行任务的线程池。\n/** 构造一个不可动态配置的ScheduledThreadPoolExecutor，其核心线程池数量为1*/ public static ScheduledExecutorService newSingleThreadScheduledExecutor() { return new DelegatedScheduledExecutorService (new ScheduledThreadPoolExecutor(1)); } /** 构造一个核心线程池为1的ScheduledThreadPoolExecutor*/ public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) { return new ScheduledThreadPoolExecutor(corePoolSize); } 我们可以自定义线程工厂(ThreadFactory)来调用其重载方法以自定义线程信息。\n接下来，介绍让ScheduledExecutorService按照计划执行任务的核心，ScheduledFutureTask和 DelayedWorkQueue。\nScheduledFutureTask # private class ScheduledFutureTask\u0026lt;V\u0026gt; extends FutureTask\u0026lt;V\u0026gt; implements RunnableScheduledFuture\u0026lt;V\u0026gt; {...} 提交给ScheduledExecutorService的任务都被包装成ScheduledFutureTask实例，相较FutureTask，其还实现了RunnableScheduledFuture接口，这个接口是RunnableFuture，ScheduledFuture的子接口，也就是Runnable，Future和Delay的实现类。\n实现Delay接口是关键，它保证计划任务能够按时（周期）执行，并且任务能够按照执行顺序或者添加顺序被取出执行。\n域 # // 每一个实例都有一个“序号”，用来维持其在队列中的位置 private final long sequenceNumber; // 任务下一次执行的时间，纳秒表示 private long time; // 任务周期执行的“周期”，纳秒表示，正数表示固定频率执行； // 负数表示固定延迟执行，0表示不是周期执行的任务 private final long period; // 用来重新插入队列中的任务 （周期执行的任务） RunnableScheduledFuture\u0026lt;V\u0026gt; outerTask = this; // 任务在队列中的索引（看出来是一个树） int heapIndex; 构造器 # // 构造一个单次执行的任务 ScheduledFutureTask(Runnable r, V result, long ns) { super(r, result); this.time = ns; this.period = 0; this.sequenceNumber = sequencer.getAndIncrement(); } // 构造单次执行的任务 ScheduledFutureTask(Callable\u0026lt;V\u0026gt; callable, long ns) { super(callable); this.time = ns; this.period = 0; this.sequenceNumber = sequencer.getAndIncrement(); } // 构造周期执行的任务 ScheduledFutureTask(Runnable r, V result, long ns, long period) { super(r, result); this.time = ns; this.period = period; this.sequenceNumber = sequencer.getAndIncrement(); } 前2个构造器构造单次执行的任务，不过使用的任务不同罢了；第三个构造器构造周期执行的任务。每构造一个任务，任务的sequenceNumber便自增1。\n方法 # compareTo # 由于Delay接口实现了Comparable接口，因此实现此方法对任务进行排序，其排序规则是：\n先比较time，先执行的任务在前 若time相等，再比较sequenceNumber，先添加的任务在 setNextRunTime # 设置周期任务下一次执行的时间\nprivate void setNextRunTime() { long p = period; if (p \u0026gt; 0) // 固定周期执行，上一次执行时间+period即可 time += p; else // 固定delay执行 time = triggerTime(-p); } run # 执行任务的核心方法\npublic void run() { // 检查是否周期任务 boolean periodic = isPeriodic(); if (!canRunInCurrentRunState(periodic)) // 当前状态不允许运行任务 cancel(false); else if (!periodic) // 执行单次任务 ScheduledFutureTask.super.run(); // 执行周期任务使用了runAndReset方法 else if (ScheduledFutureTask.super.runAndReset()) { // 周期任务执行完毕一次 // 设置下次执行的时间 setNextRunTime(); // 将任务添加到队列 reExecutePeriodic(outerTask); } } // 将已经执行的任务再次放入任务队列中 void reExecutePeriodic(RunnableScheduledFuture\u0026lt;?\u0026gt; task) { if (canRunInCurrentRunState(true)) { // 再次入队 super.getQueue().add(task); // double check if (!canRunInCurrentRunState(true) \u0026amp;\u0026amp; remove(task)) // 取消任务 task.cancel(false); else // 创建（如果需要）worker，保证有线程执行任务 ensurePrestart(); } } DelayedWorkQueue # ScheduledThreadPoolExecutor使用DeleyedWorkQueue作为任务队列，它是一个特殊的delay queue，其维护一个有序的ScheduledFutureTask任务队列。在本节中，限于数据结构相关知识尚缺，将跳过叙述队列中的元素如何调整其在树中的位置，着重叙述任务入队及出队的逻辑。\nstatic class DelayedWorkQueue extends AbstractQueue\u0026lt;Runnable\u0026gt; implements BlockingQueue\u0026lt;Runnable\u0026gt; { } 该类中，有一个核心概念，它用一个私有域表示：\n// 这个域用来等待队列的队首元素出现 private Thread leader = null; 在delay queue 中，如果没有元素的delay超时，那么你将无法从队列中取出元素。当某个任务A的delay最先超时时，其将优先出队并执行，那么leader将被声明为执行任务A的线程TA，在该任务A超时之前，leader不会被重置，在这一段时间内，其他线程只能等待；若任务A超时出队，leader将被重置，此时线程TA将唤醒等待的其他线程，然后重复重置leader的过程。我们将在任务入队和出队时看到leader域的作用。\n取消任务 # 默认情况下，如果取消一个任务的执行，该任务不会从队列中移除，不过我们可以动态地配置removeOnCancel域，在取消任务时同时将任务从队列中移除。被取消的任务不能继续执行,在线程池关闭的时候将从队列中移除。\nvoid cancelSchedule() { // default false service.setRemoveOnCancelPolicy(false); // task to cancelled service.schedule(this::s, 10, TimeUnit.SECONDS); BlockingQueue\u0026lt;Runnable\u0026gt; queue = service.getQueue(); Runnable task = queue.peek(); if (task instanceof RunnableScheduledFuture) { ((FutureTask\u0026lt;?\u0026gt;) task).cancel(false); } service.schedule(this::s, 1, TimeUnit.SECONDS); TimeUnit.SECONDS.sleep(2); // should be 1 System.out.println(\u0026#34;queue size: \u0026#34; + queue.size()); service.shutdown(); // removed by onShutdown hook method System.out.println(\u0026#34;queue size: \u0026#34; + queue.size()); } public static void main(String[] args) { TestScheduledPoolExecutor ts = new TestScheduledPoolExecutor(0); ts.cancelSchedule(); } /* output Thread[pool-1-thread-1,5,main] 1 queue size: 1 queue size: 0 *///:~ 上例中，可以看到提交了2个任务，只有一个任务执行。首先提交的任务随即被取消了，第一次获取队列大小时，执行完一个任务，但是队列不为空，被取消的任务还在队列中，在线程池shutdown之后，任务随即被移除。如果使用service.setRemoveOnCancelPolicy(true)替换示例中的设置，那么两次获取的队列大小都是0。\n这样的设计有一个好处，如果刻意取消一个任务，特定条件下可以避免重复的销毁和创建工作线程。在前面的讨论中，我们知道，核心线程空闲时是不会被销毁的，它会在任务队列上阻塞；但是非核心线程就不同了，如果队列为空，非核心线程会在 CP1处结束运行，但是如果取消一个任务，并且任务没有从队列中移除的话，那么这个非核心线程就不会被销毁。\n关闭线程池 # 除了继承ThreadPoolExecutor的 线程池关闭的逻辑之外，ScheduledThreadPoolExecutor关闭线程池和其基类还有些许差异，主要是其通过实现onShutdown方法，实现了新的关闭策略。\nonShutDown方法 # 调用shutdown和shutdownNow方法的基本逻辑和基类一致，不过shutdown过程中的onShutdown方法引入了新的关闭策略\n关闭策略由2个布尔值域控制，分别是\nexecuteExistingDelayedTasksAfterShutdown = true; shutdown之后默认执行计划（单次）任务 continueExistingPeriodicTasksAfterShutdown;shutdown之后默认不执行周期任务 这两个域可以在线程池初始化之后进行动态配置，默认情况下，调用shutdown方法之后，\n计划的（one-shot）任务将继续执行； 如果是周期任务，将从任务队列中移除； 已经取消的任务将会从队列中移除 调用shutdownNow方法的逻辑则完全和基类一致，其会中断所有任务，返回丢弃的任务列表\n以下是onShutdown方法的具体实现：\n@Override void onShutdown() { BlockingQueue\u0026lt;Runnable\u0026gt; q = super.getQueue(); boolean keepDelayed = getExecuteExistingDelayedTasksAfterShutdownPolicy(); boolean keepPeriodic = getContinueExistingPeriodicTasksAfterShutdownPolicy(); // 如果shutdown之后既不执行计划任务也不执行周期任务 if (!keepDelayed \u0026amp;\u0026amp; !keepPeriodic) { // 那么取消所有任务的执行，并清空队列 for (Object e : q.toArray()) if (e instanceof RunnableScheduledFuture\u0026lt;?\u0026gt;) ((RunnableScheduledFuture\u0026lt;?\u0026gt;) e).cancel(false); q.clear(); } else { // Traverse snapshot to avoid iterator exceptions for (Object e : q.toArray()) { if (e instanceof RunnableScheduledFuture) { RunnableScheduledFuture\u0026lt;?\u0026gt; t = (RunnableScheduledFuture\u0026lt;?\u0026gt;)e; // 不管是在shutdown之后执行计划任务或者周期任务，都移除已经取消的任务 // 但是不移除计划执行的任务 if ((t.isPeriodic() ? !keepPeriodic : !keepDelayed) || t.isCancelled()) { // also remove if already cancelled if (q.remove(t)) t.cancel(false); } } } } tryTerminate(); } 下面的示例中，我们重新设置了线程池的关闭策略，以观察线程池在关闭时候的行为\n@SneakyThrows void shutdownPolicy() { // 如果任务在shutdown()之后仍在delay，那么将值设置为false可以取消任务的执行 // 其默认值为true service.setExecuteExistingDelayedTasksAfterShutdownPolicy(false); service.schedule(this::s, 1, TimeUnit.MILLISECONDS); // 如果是周期执行的任务，将此值设置为true可以在调用shutdown()之后让其继续执行，否则结束执行 // 其默认值为false service.setContinueExistingPeriodicTasksAfterShutdownPolicy(true); service.scheduleWithFixedDelay(this::s, 2, 1, TimeUnit.SECONDS); service.shutdown(); TimeUnit.SECONDS.sleep(10); // shutdownNow interrupt all tasks service.shutdownNow(); // could be true or false System.out.println(service.isTerminated()); } 在shutDown之后，周期任务仍会一直执行，所以要使用shutDownNow来中止任务的执行\n特殊地，当corePoolSize = 0时，池中仅可允许一个线程执行任务\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":88,"href":"/zh/docs/java/concurrency/8_2_ScheduledExecutorService2/","title":"ScheduledExecutorService-2","section":"并发编程","content":" 引例 # 前文介绍了ScheduledFutureTask和DeleyedWorkQueue这么多，都是为了更好地理解任务执行的流程，在这之前，我们不妨先看如下示例：\npublic class TestScheduledPoolExecutor { private AtomicInteger sequence = new AtomicInteger(0); private ScheduledThreadPoolExecutor service; public TestScheduledPoolExecutor(int poolSize) { this.service = new ScheduledThreadPoolExecutor(poolSize); } private void s() { System.out.println(Thread.currentThread() + \u0026#34; \u0026#34; + sequence.getAndIncrement()); } private void c() { System.out.println(Thread.currentThread() + \u0026#34; c running\u0026#34;); while (true) { // never finish loop unless interrupted if (Thread.interrupted()) { break; } } System.out.println(Thread.currentThread() + \u0026#34;c interrupted\u0026#34;); } @SneakyThrows void basicTest() { service.schedule(this::s, 2, TimeUnit.SECONDS); service.schedule(this::c, 1, TimeUnit.SECONDS); // shutdown无法终止线程池 service.shutdown(); TimeUnit.SECONDS.sleep(5); System.exit(0); } public static void main(String[] args) { TestScheduledPoolExecutor ts = new TestScheduledPoolExecutor(0); ts.basicTest(); } } 在上例中，我们创建了2个任务s和c，前者简单地获取并递增sequence，后者则是一个响应中断的死循环。当我们使用不同数量的corePoolSize去运行任务时，得到的结果不一样:\n当corePoolSize = 0时，输出为 Thread[pool-1-thread-1,5,main] c running 当corePoolSize = 1时，输出为 Thread[pool-1-thread-1,5,main] c running 当corePoolSize \u0026gt; 1时，输出为 Thread[pool-1-thread-1,5,main] c running Thread[pool-1-thread-2,5,main] 1 这种差异驱使我们去探索计划任务的提交与执行方式。\n提交任务 # // 提交单次执行的任务 public ScheduledFuture\u0026lt;?\u0026gt; schedule(Runnable command, long delay, TimeUnit unit) { if (command == null || unit == null) throw new NullPointerException(); // t = new ScheduledFutureTask(..) RunnableScheduledFuture\u0026lt;?\u0026gt; t = decorateTask(command, new ScheduledFutureTask\u0026lt;Void\u0026gt;(command, null, triggerTime(delay, unit))); // 执行任务的核心方法 delayedExecute(t); return t; } // 提交周期执行的任务 public ScheduledFuture\u0026lt;?\u0026gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit) { if (command == null || unit == null) throw new NullPointerException(); if (delay \u0026lt;= 0) throw new IllegalArgumentException(); ScheduledFutureTask\u0026lt;Void\u0026gt; sft = new ScheduledFutureTask\u0026lt;Void\u0026gt;(command, null, triggerTime(initialDelay, unit), unit.toNanos(-delay)); // t = sft RunnableScheduledFuture\u0026lt;Void\u0026gt; t = decorateTask(command, sft); // 任务执行后将再次入队 sft.outerTask = t; delayedExecute(t); return t; } private void delayedExecute(RunnableScheduledFuture\u0026lt;?\u0026gt; task) { if (isShutdown()) // ctl \u0026gt; running，不接受任务提交 reject(task); else { // 非空任务入队 super.getQueue().add(task); // double check if (isShutdown() \u0026amp;\u0026amp; !canRunInCurrentRunState(task.isPeriodic()) \u0026amp;\u0026amp; remove(task)) // 如果任务入队之后，线程池关闭 // 且关闭策略不允许关闭之后继续执行 // 且任务从队列中移除 // 则取消任务 task.cancel(false); else // add worker ensurePrestart(); } } // 此方法保证了即使corePoolSize = 0的情况下也创建worker void ensurePrestart() { // 获取当前工作线程数 int wc = workerCountOf(ctl.get()); if (wc \u0026lt; corePoolSize) // 尚可以新建核心线程 addWorker(null, true); else if (wc == 0) // 新建非核心线程 addWorker(null, false); } ScheduledThreadPoolExecutor任务提交流程图\n我们可以从ScheduledThreadPoolExecutor的任务提交过程中总结几点规律：\n任务一定是先放入任务队列中的 活动线程不可能超过核心线程池大小 若corePoolSize \u0026gt; 0，则池中不可能存在非核心线程 非核心线程只有在corePoolSize = 0且当前工作线程数为0时才可以创建，并且活动的非核心线程只能存在一个 上述规律的第4点容易得出线程池中非核心线程数至多为1的结论，这似乎是很合理的，因为想要创建非核心线程，wc必须为0。结合线程池的相关知识，我们知道非核心线程超时是会被销毁的，我们可以看看非核心线程在执行计划任务时的行为\n@SneakyThrows void howManyThreads() { for (; ; ) { ScheduledFuture\u0026lt;?\u0026gt; schedule = service.schedule(this::s, 0, TimeUnit.MILLISECONDS); // TimeUnit.MILLISECONDS.sleep(5); // uncomment this to create new worker for (; ; ) { if (schedule.isDone()) break; } if (sequence.get() \u0026gt;= 10) { schedule.cancel(false); break; } } System.out.println(\u0026#34;largest pool size: \u0026#34; + service.getLargestPoolSize()); service.shutdown(); } /* output(sample) Thread[pool-1-thread-1,5,main] 1 Thread[pool-1-thread-1,5,main] 2 Thread[pool-1-thread-1,5,main] 3 Thread[pool-1-thread-2,5,main] 4 Thread[pool-1-thread-3,5,main] 5 Thread[pool-1-thread-4,5,main] 6 Thread[pool-1-thread-5,5,main] 7 Thread[pool-1-thread-7,5,main] 8 Thread[pool-1-thread-8,5,main] 9 Thread[pool-1-thread-10,5,main] 10 largest pool size: 2 *///:~ 在上例中，我们保证当前提交的任务在执行完成之后再进行下一次提交，那么下一次的任务应该新建线程执行才对。但实际的情况并非如此，执行上个任务的线程仍然有机会继续执行接下来提交的任务，这是由于任务的执行以及线程的销毁都是耗时操作，可能在线程销毁（执行CP1）之前新的任务已经添加到队列中了。\n除此之外，在所有任务执行完成之后，我们获取了线程池中同时执行任务的最大线程数，按照逻辑，这个值应该始终是1，实际的运行过程中却是一个不确定的数。这让人费解，新线程的创建前提是workerCount==0，即表明了池中是没有正在运行的线程，不过，可以猜测池中出现2个线程的过程大概出现在线程1即将销毁，执行 processWorkerExit方法之前，将要销毁的worker还未从set中移除，而此时addworker读取到的size \u0026gt; 1，于是出现了largestPoolSie\u0026gt;1的情形。\n如果取消上例中的休眠注释，就能规避上述的各种不确定情况，足够时长的休眠可以保证执行任务的线程执行任务并销毁。\n任务入队 # 由于任务提交之后一定是先放入任务队列的，而基于DelayedWorkQueue的任务队列和普通的阻塞队列有些区别。任务队列通过调用offer(Runnable x)方法将任务放入队列中，只有在获取锁的情况下才能调用\npublic boolean offer(Runnable x) { if (x == null) throw new NullPointerException(); RunnableScheduledFuture\u0026lt;?\u0026gt; e = (RunnableScheduledFuture\u0026lt;?\u0026gt;)x; final ReentrantLock lock = this.lock; lock.lock(); try { int i = size; if (i \u0026gt;= queue.length) // 队列扩容 （grow 50%） grow(); size = i + 1; if (i == 0) { queue[0] = e; setIndex(e, 0); } else { siftUp(i, e); } // 入队之前，若队列为空，且没有线程在超时等待 if (queue[0] == e) { leader = null; // 唤醒等待的线程去获取任务执行（并非一定有线程等待） available.signal(); } } finally { lock.unlock(); } return true; } 由于使用无界队列实现，DelayedWorkQueue任务入队的阻塞不会阻塞；但如果入队时队列为空，那么意味着：\n首个任务入队； 所有任务都已经出队； 成功入队之后，将会唤醒一个阻塞的线程(可能没有阻塞的线程)去获取任务执行。\n执行任务 # 与ThreadPoolExecutor不同的是，ScheduledThreadPoolExecutor所有任务都是先添加到任务队列中的，并且任务队列是delay queue，从delay queue中取出任务比简单的阻塞队列稍显复杂。不过其执行任务的基本逻辑和 ThreadPoolExecutor的任务执行过程是一致的\n而关于任务周期执行的机制，前文在阐述 ScheduledFutureTask的run()方法时，已经提及，\n它调用 FutureTask.runAndReset方法执行任务，保证任务可以重复运行； 重新计算任务的下一次运行时间，并且将任务重新入队 任务出队 # 任务出队有主要两个方法，poll(long timeout)和take()，前者用于非核心线程，后者用于核心线程；同样地，只有在获取锁的时候才能出队\npublic RunnableScheduledFuture\u0026lt;?\u0026gt; take() throws InterruptedException { final ReentrantLock lock = this.lock; // 注意此处可以被中断 lock.lockInterruptibly(); try { // 循环执行 for (;;) { // queue[0]是最先超时的任务 RunnableScheduledFuture\u0026lt;?\u0026gt; first = queue[0]; if (first == null) // 队列为空，无限期等待，会被offer()方法唤醒 available.await(); else { long delay = first.getDelay(NANOSECONDS); if (delay \u0026lt;= 0) // 任务已超时，返回该任务 return finishPoll(first); first = null; // don\u0026#39;t retain ref while waiting // 任务未超时 if (leader != null) // 当leader已设置时，当前线程只能无限期等待 // 因为在其之前还有任务未执行 available.await(); else { // 否则将leader设置为当前（执行任务的）线程 Thread thisThread = Thread.currentThread(); leader = thisThread; try { // 等待任务超时 available.awaitNanos(delay); } finally { // 任务超时之后，将leader置空，再次进入循环 // 之后将获取任务并返回 // 此时其他的线程将可以设置leader并进入超时等待 if (leader == thisThread) leader = null; } } } } } finally { if (leader == null \u0026amp;\u0026amp; queue[0] != null) //唤醒其他的线程去获取任务 available.signal(); lock.unlock(); } } public RunnableScheduledFuture\u0026lt;?\u0026gt; poll(long timeout, TimeUnit unit) throws InterruptedException { // nanos如果不进行动态配置，就是0 long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { for (;;) { RunnableScheduledFuture\u0026lt;?\u0026gt; first = queue[0]; if (first == null) { if (nanos \u0026lt;= 0) // 若队列为空，且keepAliveTime\u0026lt;=0，直接返回null return null; else // 否则限时等待之后进入下次循环 nanos = available.awaitNanos(nanos); } else { long delay = first.getDelay(NANOSECONDS); if (delay \u0026lt;= 0) // 运气好正好有任务到期，返回任务 return finishPoll(first); if (nanos \u0026lt;= 0) // 任务未到期且keepAliveTime\u0026lt;=0，返回null return null; first = null; // don\u0026#39;t retain ref while waiting // 以下是设置keepAliveTime的情形 if (nanos \u0026lt; delay || leader != null) // 将nanos置0 nanos = available.awaitNanos(nanos); else { Thread thisThread = Thread.currentThread(); leader = thisThread; try { // 分段等待 long timeLeft = available.awaitNanos(delay); nanos -= delay - timeLeft; } finally { // 重重leader if (leader == thisThread) leader = null; } } } } } finally { if (leader == null \u0026amp;\u0026amp; queue[0] != null) // 唤醒其他线程 available.signal(); lock.unlock(); } } ScheduledThreadPoolExecutor任务出队流程图\n理解了任务的入队与出队，我们就可以解释 本节开头示例中不同corePoolSize引发的差异：\n在分析任务的执行时，要始终留意getTask()方法中的这一段代码，为了方便描述，将其记为CP1\nif ((wc \u0026gt; maximumPoolSize || (timed \u0026amp;\u0026amp; timedOut)) \u0026amp;\u0026amp; (wc \u0026gt; 1 || workQueue.isEmpty())) { if (compareAndDecrementWorkerCount(c)) return null; continue; } 当corePoolSize为0时\n首次提交一个延迟2s的任务a，创建线程t1，显然a超时之前t1无法获取任务，但t1并不会因为keepAlive超时而在CP1处被结束（因为任务队列不为空），它只是一直在循环； 接着提交一个延迟1s的任务b，由于t1未被销毁，所以提交任务b时并未新建线程，池中仍只有一个工作线程t1； 任务b会先于a出队，故1s后b超时执行，由于b是死循环，无法结束，因此没有线程去执行超时的任务a 当corePoolSize为1时，虽然输出结果与corePoolSize为0时一致，但是其执行过程却有很大差别\n首次提交一个延迟2s的任务a，创建线程t1，t1会在take()获取队列时设置leader并进入超时等待状态； 接着提交一个延迟1s的任务b，由于corePoolSize的限制，并未能创建新线程，池中仍只有一个工作线程t1。在任务b入队后，会唤醒阻塞的t1线程； t1被唤醒之后清空leader，重新去队列中获取任务，由于b要比a先出队，此时t1会接着设置leader并在任务b的时间上超时等待； 任务b超时之后开始执行，由于b是死循环，无法结束，因此没有线程去执行超时的任务a 当corePoolSize\u0026gt; 1时，情况又有所不同\n首次提交一个延迟2s的任务a，创建线程t1，t1会在take()获取队列时设置leader并进入超时等待状态； 接着提交一个延迟1s的任务b，创建线程t2，池中有2个工作线程t1、t2。同样地，b入队后，会唤醒阻塞的t1； t1被唤醒之后清空leader，重新去队列中获取任务，由于b要比a先出队，此时t1会接着设置leader并在任务b的时间上超时等待； t1在超时等待时，由于leader已经被设置，t2只能无限阻塞； t1超时后，执行任务b，同时清空leader并唤醒t2，t2设置leader并在任务a的时间上超时等待； t2超时后，执行任务a "},{"id":89,"href":"/zh/docs/java/concurrency/9_1_countdownlatch/","title":"并发组件-CountDownLatch","section":"并发编程","content":" CountDownLatch # 在讨论线程的基本概念时，我们说过join()方法可使当前线程等待调用join方法的线程执行完，可以实现简单的 无锁同步，使用CountDownLatch可以更加简单的实现这一目的。毕竟，join()方法的语义“加入一个线程”不是很容易就能让人理解。相较于join()方法，CountDownLatch的语义就明确多了。\n在有些文档上，将CountDownLatch译为\u0026quot;倒计时门闩【shuān】\u0026quot;，其维护一个计数器，这个计数器在CountDownLatch初始化之后便不能重置。在CountDownLatch上调用countDown()方法来将计数值减1，调用这个方法并不会引起阻塞。不过，在这个计数器为0之前，任何调用CountDownLatch的await()方法的任务都将阻塞。\nCountDownLatch的典型用法是将一个任务分割为n个可以独立解决的部分，并创建一个计数器值为n（n为线程数量）的CountDownLatch，在每个任务完成时，调用countDown()方法将计数器减1，在等待所有任务完成的线程上调用await()方法，将任务阻塞，直到计数器为0之后再继续运行。\n下面的代码演示了CountdownLatch的用法\npublic class CountDownLatchDemo { private static class TaskPortion implements Runnable { private static int counter = 0; private final int id = counter++; private static Random rand = new Random(47); private final CountDownLatch latch; TaskPortion(CountDownLatch latch) { this.latch = latch; } @Override public void run() { try { doWork(); } catch (InterruptedException ex) { // Acceptable way to exit } finally { latch.countDown(); } } void doWork() throws InterruptedException { TimeUnit.MILLISECONDS.sleep(rand.nextInt(2000)); System.out.println(this + \u0026#34;completed\u0026#34;); } @Override public String toString() { return String.format(\u0026#34;%1$-3d \u0026#34;, id); } } /** Waits on the CountDownLatch: */ private static class WaitingTask implements Runnable { private static int counter = 0; private final int id = counter++; private final CountDownLatch latch; WaitingTask(CountDownLatch latch) { this.latch = latch; } @Override public void run() { try { latch.await(); System.out.println(\u0026#34;Latch barrier passed for \u0026#34; + this); } catch (InterruptedException ex) { System.out.println(this + \u0026#34; interrupted\u0026#34;); } } @Override public String toString() { return String.format(\u0026#34;WaitingTask %1$-3d \u0026#34;, id); } } static final int SIZE = 10; public static void main(String[] args) { ExecutorService exec = Executors.newCachedThreadPool(); // 所有任务都必须使用同一个CountDownLatch对象 CountDownLatch latch = new CountDownLatch(SIZE); exec.execute(new WaitingTask(latch)); for (int i = 0; i \u0026lt; SIZE; i++) { exec.execute(new TaskPortion(latch)); } System.out.println(\u0026#34;Launched all tasks\u0026#34;); exec.shutdown(); // Quit when all tasks complete } } /* output (sample) Launched all tasks 7 completed 9 completed 5 completed 8 completed 1 completed 2 completed 6 completed 4 completed 0 completed 3 completed Latch barrier passed for WaitingTask 0 *///:~ 上面的示例中，WaitingTask将会阻塞，直到所有的TaskPortion执行完成，TaskPortion完成之后调用了countDown()方法，注意，countDown()方法是在finally块中调用的，这是为了防止TaskPortion出现异常而导致任务一直阻塞。当计数器为0后，我们看到WaitingTask成功执行。\nawait()还有一个重载方法await(long, TimeUnit)，避免任务让线程一直等待。\n"},{"id":90,"href":"/zh/docs/java/concurrency/9_2_cyclicbarrier/","title":"并发组件-CyclicBarrier","section":"并发编程","content":" CyclicBarrier # CyclicBarrier被称为“同步屏障”，事实上就可以把它理解为一个屏障，多个任务调用屏障的await()方法将被阻塞，直到所有的任务都进入阻塞，那么屏障开启，所有任务继续执行。这看起来和CountDownLatch非常像，不过CountDownLatch只能触发一次，而CyclicBarrier可以多次重用，这是它们的主要区别之一。\n和CountDownLatch一样，CyclicBarrier接受一个整型参数，表示可限制的线程数。除此之外，CyclicBarrier还可以接受一个Runnable作为参数，这个参数称作barrierAction，barrierAction在所有线程到达屏障之后即开始执行，其他任务只能等待barrierAction执行完毕之后才能继续执行，这是CyclicBarrier和CountDownLatch的区别之二。\npublic class TestCyclicBarrier { private static StringBuffer sb = new StringBuffer(); /** CyclicBarrier的构造器任务总是会先执行完毕 */ static CyclicBarrier c = new CyclicBarrier(2, () -\u0026gt; { sb.append(3); }); private static final int ASSERT_VALUE = 312; static int run() { Thread t = new Thread(() -\u0026gt; { try { c.await(); } catch (Exception e) { // ignore; } sb.append(1); }); t.start(); try { c.await(); sb.append(2); t.join(); } catch (Exception e) { // ignore } return Integer.parseInt(sb.toString()) | (sb.delete(0, sb.length())).length(); } public static void main(String[] args) { for (; ; ) { int r; if ((r = run()) != ASSERT_VALUE) { // should be 321 System.out.println(r); return; } } } } 上例中，barrier有一个barrierAction和2个“屏障任务”，main方法的输出大概率为312，小概率为321，不会出现其他结果，所以main方法无论执行多长时间，其总会结束。由于barrierAction总是先执行，故结果总是3xx1，其先执行完毕的原因在源码中很容易找到：\n//... // 所有任务到达屏障 if (index == 0) { // tripped boolean ranAction = false; try { final Runnable command = barrierCommand; //直接在当前线程调用command的run方法 if (command != null) command.run(); ranAction = true; nextGeneration(); // 唤醒所有线程 return 0; } finally { if (!ranAction) breakBarrier(); } } //... 不过，屏障开启后，任务的执行顺序完全是由cpu调度的。同时，本例中的CyclicBarrier是静态域，在main方法重复执行时，并不会重新初始化，因此也直接证明了CyclicBarrier的可重用性——屏障开启后，任务继续执行后调用屏障的await()方法同样会阻塞而等待所有任务到达屏障，依次循环。\n下例的“赛马游戏”2完美地阐述了CyclicBarrier可以多次重用的特点，马每次跑一步，不过不同的马步长不同，等待所有的马都“跑出这一步”后，屏障开启，先确定是否有马到达终点，如有则结束赛跑，否则继续下一轮，直到有马越过终点线，下面是示例代码：\npublic class HorseRace { static class Horse implements Runnable { private static int counter = 0; private final int id = counter++; private int strides = 0; private static Random rand = new Random(47); private static CyclicBarrier barrier; public Horse(CyclicBarrier b) { barrier = b; } public int getStrides() { return strides; } @Override public void run() { try { while (!Thread.interrupted()) { strides += rand.nextInt(3); // Produces 0, 1 or 2 barrier.await(); } } catch (InterruptedException e) { // A legitimate way to exit } catch (BrokenBarrierException e) { // This one we want to know about throw new RuntimeException(e); } } @Override public String toString() { return \u0026#34;Horse \u0026#34; + id + \u0026#34; \u0026#34;; } public String tracks() { StringBuilder s = new StringBuilder(); for (int i = 0; i \u0026lt; getStrides(); i++) { s.append(\u0026#34;*\u0026#34;); } s.append(id); return s.toString(); } } static final int FINISH_LINE = 20; private List\u0026lt;Horse\u0026gt; horses = new ArrayList\u0026lt;\u0026gt;(); private ExecutorService exec = Executors.newCachedThreadPool(); private CyclicBarrier barrier; /** 这是一构造器 */ public HorseRace(int nHorses, final int pause) { barrier = new CyclicBarrier(nHorses, () -\u0026gt; { StringBuilder s = new StringBuilder(); for (int i = 0; i \u0026lt; FINISH_LINE; i++) { s.append(\u0026#34;=\u0026#34;); // The fence on the racetrack } System.out.println(s); for (Horse horse : horses) { System.out.println(horse.tracks()); } for (Horse horse : horses) { if (horse.getStrides() \u0026gt;= FINISH_LINE) { System.out.println(horse + \u0026#34;won!\u0026#34;); exec.shutdownNow(); return; } } try { TimeUnit.MILLISECONDS.sleep(pause); } catch (InterruptedException e) { System.out.println(\u0026#34;barrier-action sleep interrupted\u0026#34;); } }); for (int i = 0; i \u0026lt; nHorses; i++) { Horse horse = new Horse(barrier); horses.add(horse); exec.execute(horse); } } public static void main(String[] args) { int nHorses = 7; int pause = 200; if (args.length \u0026gt; 0) { // Optional argument int n = new Integer(args[0]); nHorses = n \u0026gt; 0 ? n : nHorses; } if (args.length \u0026gt; 1) { // Optional argument int p = new Integer(args[1]); pause = p \u0026gt; -1 ? p : pause; } new HorseRace(nHorses, pause); } } 实际上程序通过获取每匹马的strides域来判断马是否到达终点。在TIJ原书中，对strides域的有关操作做了同步处理，而本例中移除了这些同步，这是否安全？虽然CyclicBarrier的barrierAction和HorseRace都访问了strides域，不过，二者访问域的时间一定是错开的：前者在所有马都到达屏障后开始访问，而此时的马处于阻塞状态，而马获得访问权时，barrierAction一定没在执行3。因此本例中，不使用同步也是安全的。\nCyclicBarrier还有一些特殊方法：\npublic void reset(); 这个方法将CyclicBarrier重置到初始状态 注意，这个方法会导致已经在屏障处等待的线程抛出BrokenBarrierException 如果确实需要一个新的CyclicBarrier来执行操作，新建一个实例是更好的选择 public int getNumberWaiting() ; 这个方法获取在屏障等待的线程数 public int getParties() ; 这个方法获取所有的线程数（用来构建CyclicBarrier实例的int入参） 下面的例子展示了在任务执行时重置CyclicBarrier的操作，这个示例只是为了展示上面几个方法的用法，千万不要在执行任务时贸然去做这样的操作！如果处理不得当将很大可能引发阻塞或其他并发问题。\n笔者本意是计划执行批量任务，这些任务有一个域来计算其运行次数，并可能在某个任务上调用CyclicBarrier的reset()方法，在reset()调用之前和之后的任务其运行次数会有差别，通过这个运行差异在barrierAction中来终结线程池。事实上这个预想完全落空了，reset()之后，如果不再次使所有线程重新到达屏障处等待，barrierAction就不可能执行。\npublic class ResetCyclicBarrier { static void reSetBarrierIf(int parties, int bound) { TaskMayFail[] tasks = new TaskMayFail[parties]; ThreadPoolExecutor exec = (ThreadPoolExecutor) Executors.newCachedThreadPool(); exec.setKeepAliveTime(0, TimeUnit.SECONDS); AtomicInteger ai = new AtomicInteger(); CyclicBarrier c2 = new CyclicBarrier(parties, () -\u0026gt; { // if reset barrier while task is running, the // barrier action can not reach in this cycle // until relaunch all parties to reach at barrier // in next round int i = 0; int r = tasks[i].runtime; while (i \u0026lt; parties) { if (r != tasks[i].runtime) { System.out.println(tasks[i] + \u0026#34;:\u0026#34; + tasks[i].runtime + \u0026#34;: \u0026#34; + r); exec.shutdownNow(); return; } r = tasks[i].runtime; i++; } }); for (int i = 0; i \u0026lt; parties; i++) { TaskMayFail taskMayFail = new TaskMayFail(c2, ai, bound); tasks[i] = taskMayFail; exec.execute(taskMayFail); } } private static class TaskMayFail implements Runnable { static Random rand = new Random(); static int count = 1; final CyclicBarrier cb; final AtomicInteger reSetCount; final int bound; final int id = count++; int runtime = 0; public TaskMayFail(CyclicBarrier cb, AtomicInteger reSetCount, int bound) { this.cb = cb; this.reSetCount = reSetCount; this.bound = bound; } @Override public String toString() { return \u0026#34;[TaskMayFail-\u0026#34; + id + \u0026#34;-runtime-\u0026#34; + runtime + \u0026#34;]\u0026#34;; } @Override public void run() { try { while (!Thread.currentThread().isInterrupted()) { if (rand.nextBoolean()) { // bound值可调整reset的概率 if (rand.nextInt(bound) == 0) { throw new ArithmeticException(); } } runtime++; cb.await(); } } catch (ArithmeticException ae) { reSetCount.incrementAndGet(); while (cb.getNumberWaiting() \u0026lt; (cb.getParties() - reSetCount.intValue())) { // waiting for all parties reach at barrier // or all parties throws exception } // reset barrier cb.reset(); System.out.printf(\u0026#34;%s-%s reset %s%n\u0026#34;, Thread.currentThread().getName(), this, cb); } catch (InterruptedException | BrokenBarrierException ae) { reSetCount.incrementAndGet(); // once barrier reset, other parties wait on barrier // will throw BrokenBarrierException System.out.printf(\u0026#34;%s-%s return by broken barrier.%n\u0026#34;, Thread.currentThread().getName(), this); } finally { Thread.currentThread().interrupt(); } } public static void main(String[] args) { reSetBarrierIf(13, 100); } } } /* output (sample) pool-1-thread-3-[TaskMayFail-3-runtime-19] reset java.util.concurrent.CyclicBarrier@618bfe9a pool-1-thread-4-[TaskMayFail-4-runtime-20] return by broken barrier. pool-1-thread-9-[TaskMayFail-9-runtime-20] return by broken barrier. pool-1-thread-8-[TaskMayFail-8-runtime-20] return by broken barrier. pool-1-thread-5-[TaskMayFail-5-runtime-20] return by broken barrier. pool-1-thread-12-[TaskMayFail-12-runtime-20] return by broken barrier. pool-1-thread-7-[TaskMayFail-7-runtime-20] return by broken barrier. pool-1-thread-13-[TaskMayFail-13-runtime-20] return by broken barrier. pool-1-thread-1-[TaskMayFail-1-runtime-20] return by broken barrier. pool-1-thread-11-[TaskMayFail-11-runtime-20] return by broken barrier. pool-1-thread-2-[TaskMayFail-2-runtime-20] return by broken barrier. pool-1-thread-10-[TaskMayFail-10-runtime-20] return by broken barrier. pool-1-thread-6-[TaskMayFail-6-runtime-19] reset java.util.concurrent.CyclicBarrier@618bfe9a *///:~ 从输出可以看到，CyclicBarrier可以重复使用。上例的设计很巧妙，因为屏障在开启之后，任务可能很快就抛出ArithmeticException而进入reset流程，而此时其他任务可能在屏障处等待或者还未执行，若此时贸然reset，那些等待的线程会抛出BrokenBarrierException并退出，但是未执行的线程并未意识到reset的发生（可以这么表述），依然进入阻塞，如果没有再次任务进入reset流程，程序很快将因为没有足够多的线程到达屏障而阻塞4。\n所以，上例引入一个原子变量，用于跟踪进入reset和已经退出的任务数，那么剩余的线程应该就是到达屏障的线程数，利用这个限制来保证所有的线程都得到处理，以简化问题的复杂性，一旦确定所有的线程都被处理，就可以执行reset()方法。同时reset()之后，barrierAction便无法执行。\n这个示例演化自 《Java并发编程的艺术》方腾飞等.著，第八章8.2节代码清单8-4。不过该书中关于这段代码的运行解释是不正确的，本例也证明了这一点。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n《Thinking in Java》 4th Edition, 第21章21.7.2示例代码。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n虽然是这样，但上述代码并不能保证对strides的内存可见性，main线程获取的可能不是最新值，使用volatail关键字修饰strides域可解决问题。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n就算有任务再次进入了reset流程，也依然可能存在上面描述的问题，这仅仅增加了程序运行的不稳定性。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":91,"href":"/zh/docs/java/concurrency/9_3_semaphore/","title":"并发组件-Semaphore","section":"并发编程","content":" Semaphore # 无论是显式锁还是通过synchronized关键字获取的隐式锁，其在任一时刻都只能让一个任务访问资源，而Semaphore（计数信号量）允许多个任务同时访问资源。可以把Semaphore看作是持有对象访问许可（permits）的“security”。访问对象时，须先通过acquire()获取许可，若此时没有许可可用，那么acquire()将阻塞，否则获取许可，可用许可数-1；使用完资源后，通过release()方法返还许可。事实上，并没有实际上的许可证对象，Semaphore通过协同各个线程工作，来达到目的。\nSemaphore的构造器接受一个“公平性参数”。不传入此参数或传入false时，线程获取许可的顺序无法保证，即使线程阻塞了很久，其仍然可能被刚调用acquire()方法的线程“抢走”许可，这可能会导致线程“饿死”。当传入true时，Semaphore保证线程获取许可的顺序和其调用acquire()方法之后被执行的顺序一致1，也就是先执行的任务先获取许可（FIFO）。需要说明的是，tryAcquire()方法不遵循公平性原则，如果有许可可用，它直接获取之。在使用Semaphore时，一般将其设置为公平的\nSemaphore通常用于限制访问资源的线程数量，典型的例子就是控制“池”的并发访问量。下例中使用Semaphore控制池中的对象方法，当需要使用时，可以将它们“签出”（checkout），使用完毕之后再将其“签入”（checkin），使用泛型类封装功能2。\nclass Pool\u0026lt;T\u0026gt; { private final int size; final List\u0026lt;T\u0026gt; items = new ArrayList\u0026lt;\u0026gt;(); private final boolean[] checkedOut; private final Semaphore available; public Pool(Class\u0026lt;T\u0026gt; classObject, int size) { this.size = size; checkedOut = new boolean[size]; available = new Semaphore(size, true); // Load pool with objects that can be checked out: for (int i = 0; i \u0026lt; size; ++i) { try { // Assumes a default constructor: items.add(classObject.newInstance()); } catch (Exception e) { throw new RuntimeException(e); } } } T checkOut() throws InterruptedException { available.acquire(); return getItem(); } void checkIn(T x) { if (releaseItem(x)) { available.release(); System.out.println(\u0026#34;release \u0026#34; + x); } } void checkAllIn() { available.release(releaseAll()); } private synchronized T getItem() { for (int i = 0; i \u0026lt; size; ++i) { if (!checkedOut[i]) { checkedOut[i] = true; return items.get(i); } } // Semaphore prevents reaching here return null; } private synchronized boolean releaseItem(T item) { int index = items.indexOf(item); if (index == -1) { return false; // Not in the list } if (checkedOut[index]) { checkedOut[index] = false; return true; } // Wasn\u0026#39;t checked out return false; } private synchronized int releaseAll() { int r = 0; for (int i = 0; i \u0026lt; items.size(); i++) { if (checkedOut[i]) { checkedOut[i] = false; ++r; } } return r; } } 这个池使用checkout和checkIn方法来签出和签入对象，在签出对象之前调用acquire()，如果没有可用对象，那么checkOut将阻塞。由于Semaphore的机制，checkOut方法并不需要使用同步，但是getItem方法则需要同步了，Semaphore协同多线程对资源的访问，但是并不能保证多线程对资源修改的并发安全，这是两回事3。checkIn方法则判断给定对象是否被使用，是则签入之，否则不做任何操作，同样的，releaseItem方法也需要使用同步。\nThe semaphore encapsulates the synchronization needed to restrict access to the pool, separately from any synchronization needed to maintain the consistency of the pool itself.\n接下来我们可以测试这个池能否正常工作了:\npublic class SemaphoreDemo { private static class AcquireTask\u0026lt;T\u0026gt; implements Runnable { private static int counter = 0; private final int id = counter++; private final Pool\u0026lt;T\u0026gt; pool; public AcquireTask(Pool\u0026lt;T\u0026gt; pool) { this.pool = pool; } @Override public void run() { try { T item = pool.checkOut(); System.out.println(this + \u0026#34; acquire \u0026#34; + item); } catch (InterruptedException e) { // Acceptable way to terminate } } @Override public String toString() { return \u0026#34;CheckoutTask-\u0026#34; + id; } } private static class ReleaseTask\u0026lt;T\u0026gt; implements Runnable { private static int counter = 0; private final int id = counter++; private final Pool\u0026lt;T\u0026gt; pool; public ReleaseTask(Pool\u0026lt;T\u0026gt; pool) { this.pool = pool; } @Override public void run() { try { List\u0026lt;T\u0026gt; items = pool.items; for (T item : items) { pool.checkIn(item); } } catch (Exception e) { // Acceptable way to terminate } } @Override public String toString() { return \u0026#34;AcquireTask-\u0026#34; + id + \u0026#34; \u0026#34;; } } private static class Fat { private volatile double d; // Prevent optimization private static int counter = 0; private final int id = counter++; public Fat() { // Expensive, interruptible operation: for (int i = 1; i \u0026lt; 10000; i++) { d += (Math.PI + Math.E) / (double) i; } } @Override public String toString() { return \u0026#34;Fat-\u0026#34; + id; } } final static int SIZE = 5; private void test() throws InterruptedException { final Pool\u0026lt;Fat\u0026gt; pool = new Pool\u0026lt;\u0026gt;(Fat.class, SIZE); ExecutorService exec = Executors.newCachedThreadPool(); for (int i = 0; i \u0026lt; SIZE; i++) { exec.execute(new AcquireTask\u0026lt;\u0026gt;(pool)); } exec.execute(new ReleaseTask\u0026lt;\u0026gt;(pool)); List\u0026lt;Fat\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; SIZE; i++) { Fat f = pool.checkOut(); System.out.println(i + \u0026#34;: main() acquire \u0026#34; + f); list.add(f); } Future\u0026lt;?\u0026gt; blocked = exec.submit(() -\u0026gt; { try { // Semaphore prevents additional checkout, // so call is blocked: pool.checkOut(); } catch (InterruptedException e) { System.out.println(\u0026#34;checkOut() Interrupted\u0026#34;); } }); TimeUnit.SECONDS.sleep(2); blocked.cancel(true); // Break out of blocked call // release all items pool.checkAllIn(); for (Fat f : list) { pool.checkIn(f); // Second checkIn ignored } exec.shutdown(); } public static void main(String[] args) throws Exception { SemaphoreDemo semaphoreDemo = new SemaphoreDemo(); semaphoreDemo.test(); } } /* output(sample) AcquireTask-0 acquire Fat-0 AcquireTask-4 acquire Fat-4 AcquireTask-3 acquire Fat-3 AcquireTask-2 acquire Fat-2 AcquireTask-1 acquire Fat-1 release Fat-0 0: main() acquire Fat-0 release Fat-1 1: main() acquire Fat-1 release Fat-2 2: main() acquire Fat-2 release Fat-3 3: main() acquire Fat-3 release Fat-4 4: main() acquire Fat-4 checkOut() Interrupted *///:~ 上例SemaphoreDemo有两个任务，分别用于签入签出对象，程序首先使用AcquireTask签出所有对象，接着使用ReleaseTask签入对象。主线程接着依次签出所有对象，可以看到，主线程的签出过程是被阻塞的，只有对象签入之后，才能被签出。主线程签出所有对象之后，由于没有签入任务，接着的签出任务一定是被阻塞的，主线程休眠2s后中断了阻塞的任务。\n并不能保证先调用acquire()方法的线程就能先获得许可，而是先调用方法的线程先执行内部逻辑的线程优先获取许可。所以有可能线程a先于线程b调用acquire()方法，但是却晚于线程b到达“等待点”。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n这个示例演化自Semaphore的javaDoc: https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Semaphore.html。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n如果使用是个“许可证数”为1的Semaphore，其作用相当于一个独占锁，任意时刻只有一个任务能够获取许可并且对资源进行修改，此时，getItem方法可以不使用同步。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":92,"href":"/zh/docs/java/concurrency/9_4_exchanger/","title":"并发组件-Exchanger","section":"并发编程","content":" Exchanger # Exchanger是在两个任务之间交换对象的栅栏。当这些任务进入栅栏时，各自拥有一个对象，离开时交换它们拥有的对象。栅栏可以用来设计缓存对象，2个任务分别来使用和清空缓存，当缓存空间满时，则在Exchanger上交换缓存，缓存得以重复使用1。\npublic class DataBuffer\u0026lt;T\u0026gt; { private Queue\u0026lt;T\u0026gt; buffer; /** 利用size构造一个有界队列 */ private final int size; public DataBuffer(Class\u0026lt;? extends Queue\u0026lt;T\u0026gt;\u0026gt; cls, int size) throws Exception { this(cls, size, null); } public DataBuffer(Class\u0026lt;? extends Queue\u0026lt;T\u0026gt;\u0026gt; cls, int size, Generator\u0026lt;T\u0026gt; gen) throws Exception { if (cls == null) throw new NullPointerException(); // 检查cls的类型，如果不是队列，则抛出异常 if (!Queue.class.isAssignableFrom(cls)) throw new ClassCastException(); if (size \u0026lt; 0) throw new IllegalArgumentException(); this.size = size; try { Constructor\u0026lt;? extends Queue\u0026lt;T\u0026gt;\u0026gt; c = cls.getConstructor(int.class); c.setAccessible(true); this.buffer = c.newInstance(size); } catch (NoSuchMethodException | SecurityException | InvocationTargetException e) { this.buffer = cls.newInstance(); } if (gen != null) { for (int i = 0; i \u0026lt; size; i++) buffer.offer(gen.next()); } } synchronized boolean isFull() { return buffer.size() \u0026gt;= size; } synchronized boolean isEmpty() { return buffer.isEmpty(); } synchronized int bufferSize() { return buffer.size(); } synchronized public Queue\u0026lt;T\u0026gt; getBuffer() { return buffer; } synchronized boolean addToBuffer(T t) { if (!isFull()) { return buffer.offer(t); } return false; } synchronized T takeFromBuffer() { if (!isEmpty()) { buffer.remove(); } return null; } } DataBuffer接受一个Queue\u0026lt;T\u0026gt;类型参数，用来初始化缓存队列，并且利用size指定了缓存队列的容量，作为是“达到栅栏”的前置条件。\npublic class BufferSwap { private class FillTask\u0026lt;T\u0026gt; implements Runnable { private DataBuffer\u0026lt;T\u0026gt; db; private final Exchanger\u0026lt;DataBuffer\u0026lt;T\u0026gt;\u0026gt; ex; private final Generator\u0026lt;T\u0026gt; gen; public FillTask(DataBuffer\u0026lt;T\u0026gt; db, Generator\u0026lt;T\u0026gt; gen, Exchanger\u0026lt;DataBuffer\u0026lt;T\u0026gt;\u0026gt; ex) { this.db = db; this.gen = gen; this.ex = ex; } @Override public void run() { try { while (db != null) { if (db.isFull()) { db = ex.exchange(db); } else { db.addToBuffer(gen.next()); } } } catch (InterruptedException e) { // right to exit here } } } private class EmptyTask\u0026lt;T\u0026gt; implements Runnable { private DataBuffer\u0026lt;T\u0026gt; db; private final Exchanger\u0026lt;DataBuffer\u0026lt;T\u0026gt;\u0026gt; ex; private final int ecLimit; public EmptyTask(DataBuffer\u0026lt;T\u0026gt; db, Exchanger\u0026lt;DataBuffer\u0026lt;T\u0026gt;\u0026gt; ex, int limit) { this.db = db; this.ex = ex; this.ecLimit = limit; } @Override public void run() { try { while (ec.intValue() \u0026lt; ecLimit) { if (db.isEmpty()) { db = ex.exchange(db); ec.incrementAndGet(); } else { db.takeFromBuffer(); } } } catch (InterruptedException e) { // exit by interrupted } } } /** 交换缓存的次数，用来限制程序的运行 */ private final AtomicInteger ec = new AtomicInteger(); /** * @param size the buffer size * @param limit the exchange time limit */ void test(int size, int limit) { Exchanger\u0026lt;DataBuffer\u0026lt;Fat\u0026gt;\u0026gt; xh = new Exchanger\u0026lt;\u0026gt;(); Generator\u0026lt;Fat\u0026gt; generator = BasicGenerator.create(Fat.class); // ignore class check // can not solve the issue actually... DataBuffer\u0026lt;Fat\u0026gt; fullBuffer, emptyBuffer; try { fullBuffer = new DataBuffer(ArrayBlockingQueue.class, size, generator); emptyBuffer = new DataBuffer(ArrayBlockingQueue.class, size); } catch (Exception e) { System.out.println(\u0026#34;initialization failure\u0026#34;); return; } ExecutorService pool = Executors.newCachedThreadPool(); Future\u0026lt;?\u0026gt; t1 = pool.submit(this.new FillTask(fullBuffer, generator, xh)); Future\u0026lt;?\u0026gt; done = pool.submit(this.new EmptyTask\u0026lt;\u0026gt;(emptyBuffer, xh, limit)); for (; ; ) { if (done.isDone()) { t1.cancel(true); break; } } pool.shutdown(); Queue\u0026lt;Fat\u0026gt; full = fullBuffer.getBuffer(); System.out.print(\u0026#34;fullTask\u0026#39;s buffer: \u0026#34;); for (Fat fat : full) { System.out.printf(\u0026#34;%s\\t\u0026#34;, fat); } System.out.println(); System.ocvnut.println(\u0026#34;++++++++++++++++++++++++++++++++\u0026#34;); Queue\u0026lt;Fat\u0026gt; empty = emptyBuffer.getBuffer(); System.out.print(\u0026#34;emptyTask\u0026#39;s buffer:\u0026#34;); for (Fat fat : empty) { System.out.printf(\u0026#34;%s\\t\u0026#34;, fat); } } public static void main(String[] args) { BufferSwap bs = new BufferSwap(); bs.test(10, 100); } } /* output fillTask\u0026#39;s buffer: Fat-1000\tFat-1001\tFat-1002\tFat-1003\tFat-1004\tFat-1005\tFat-1006\tFat-1007\tFat-1008\tFat-1009 ++++++++++++++++++++++++++++++++ emptyTask\u0026#39;s buffer: Fat-990\tFat-991\tFat-992\tFat-993\tFat-994\tFat-995\tFat-996\tFat-997\tFat-998\tFat-999 *///:~ BufferSwap中有2个任务，FillTask用来使用缓存，当缓存队列未满时，一直向缓存中添加对象，一旦缓存已满，则进入“栅栏”；而EmptyTask用来清空已满的缓存队列，知道缓存队列为空进入”栅栏”，同时为了限制缓存交换的次数，我们在缓存交换达到限制时停止EmptyTask。在test()方法中，我们初始化了2个缓存对象fullBuffer和emptyBuffer，前者会初始化一个满的缓存，后者则会初始化一个空的缓存。本例中传入的类型参数是ArrayBlockingQueue.class，并且忽略了类型检查2。\n之后提交这2个缓存任务，使用Future\u0026lt;?\u0026gt;来检查EmptyTask的状态并适时取消FillTask。这样做时可行的，因为FillTask一定会在最后一次交换之后继续使用而占满缓存空间进入“栅栏”处阻塞，使用Future.cancel()可以中断其阻塞并抛出中断异常，从而结束运行。随后重看2个任务阻塞队列中的对象，输出符合期望3。\n这个示例演化自Exchanger的javaDoc：https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Exchanger.html。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n忽略类型检查的原因是因为尚不能处理泛型编程的所有问题。理论上这里传入任意Queue实现类都是可以的，但是由于示例中所用的实例Fat并没有实现Comparable接口，所以当传入优先级队列时，构造器会抛出初始化异常。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n这里还存在一个潜在问题：EmptyTask完成时取消FillTask，FillTask的状态会影响程序的结果，若后者是在Exchanger处被阻塞时取消，那将抛出中断异常，程序输出如示例中说的那样；若后者在向缓存中添加对象时被中断，shutdown()方法无法立刻中止FillTask的运行，它将继续运行至进入栅栏而抛出异常，但是，主线程中的遍历(在使用普通队列时)就可能会抛出ConcorrentModificationException。解决此问题的方法是在FillTask中分别处理2种取消的情况，或者在主线程中使用awaitTermination等待FillTask抛出异常而终结。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":93,"href":"/zh/docs/java/concurrency/9_5_priorityblockqueue_delayqueue/","title":"并发组件-PBQ/DQ","section":"并发编程","content":" PriorityBlockingQueue # PriorityBlockingQueue就是一个基础的可阻塞的 优先级队列，当队列为空时，从队列中获取元素时被阻塞。其余特性和优先级队列是一致的。\n下例展示了如何构建一个可以放入优先级队列的任务：\npublic class PrioritizedTask implements Runnable, Comparable\u0026lt;PrioritizedTask\u0026gt; { protected static List\u0026lt;PrioritizedTask\u0026gt; sequence = new ArrayList\u0026lt;\u0026gt;(); private Random rand = new Random(47); private static int counter = 0; private final int id = counter++; private final int priority; public PrioritizedTask(int priority) { this.priority = priority; sequence.add(this); } @Override public int compareTo(PrioritizedTask arg) { return priority \u0026lt; arg.priority ? 1 : (priority \u0026gt; arg.priority ? -1 : 0); } @Override public void run() { try { TimeUnit.MILLISECONDS.sleep(rand.nextInt(250)); } catch (InterruptedException e) { // Acceptable way to exit } System.out.println(this); } @Override public String toString() { return String.format(\u0026#34;[%1$-3d]\u0026#34;, priority) + \u0026#34; Task \u0026#34; + id; } public String summary() { return \u0026#34;(\u0026#34; + id + \u0026#34;:\u0026#34; + priority + \u0026#34;)\u0026#34;; } public static class EndSentinel extends PrioritizedTask { private ExecutorService exec; public EndSentinel(ExecutorService e) { super(-1); // Lowest priority in this program exec = e; } @Override public void run() { int count = 0; for (PrioritizedTask pt : sequence) { System.out.print(pt.summary()); if (++count % 5 == 0) System.out.println(); } System.out.println(); System.out.println(this + \u0026#34; Calling shutdownNow()\u0026#34;); exec.shutdownNow(); } } } PrioritizedTask实现了Runnable和Comparable接口，有一个int型priority域，用来表示任务的优先级，在compareTo方法中的逻辑表示，优先级高的将会优先出队。其还有一个静态域，用来记录所有任务被置入队列的顺序。PrioritizedTask有一个静态内部类，也是其子类，它被称作“结束哨兵”，它的优先级为-1，代表它会最后出队，当执行这个任务时，代表任务所有的任务执行完毕，可以关闭线程池资源。\n在接下来的示例中，将模拟生产者和消费者，执行PriorityBlockingQueue中的任务，我们可以从程序的输出观察优先级队列的出队（被执行）的顺序：\npublic class PriorityBlockingQueueDemo { static class PrioritizedTaskProducer implements Runnable { private Random rand = new Random(47); private Queue\u0026lt;Runnable\u0026gt; queue; private ExecutorService exec; public PrioritizedTaskProducer( Queue\u0026lt;Runnable\u0026gt; q, ExecutorService e) { queue = q; exec = e; // Used for EndSentinel } @Override public void run() { // Unbounded queue; never blocks. // Fill it up fast with random priorities: for (int i = 0; i \u0026lt; 20; i++) { queue.add(new PrioritizedTask(rand.nextInt(10))); Thread.yield(); } // Trickle in highest-priority jobs: try { for (int i = 0; i \u0026lt; 10; i++) { TimeUnit.MILLISECONDS.sleep(250); queue.add(new PrioritizedTask(10)); } // Add jobs, lowest priority first: for (int i = 0; i \u0026lt; 10; i++) queue.add(new PrioritizedTask(i)); // A sentinel to stop all the tasks: queue.add(new PrioritizedTask.EndSentinel(exec)); } catch (InterruptedException e) { // Acceptable way to exit } System.out.println(\u0026#34;Finished PrioritizedTaskProducer\u0026#34;); } } static class PrioritizedTaskConsumer implements Runnable { private PriorityBlockingQueue\u0026lt;Runnable\u0026gt; q; public PrioritizedTaskConsumer( PriorityBlockingQueue\u0026lt;Runnable\u0026gt; q) { this.q = q; } @Override public void run() { try { while (!Thread.interrupted()) // Use current thread to run the task: q.take().run(); } catch (InterruptedException e) { // Acceptable way to exit } System.out.println(\u0026#34;Finished PrioritizedTaskConsumer\u0026#34;); } } public static void main(String[] args) throws Exception { ExecutorService exec = Executors.newCachedThreadPool(); PriorityBlockingQueue\u0026lt;Runnable\u0026gt; queue = new PriorityBlockingQueue\u0026lt;\u0026gt;(); exec.execute(new PrioritizedTaskProducer(queue, exec)); exec.execute(new PrioritizedTaskConsumer(queue)); } } /* output(partial) [9 ] Task 5 [9 ] Task 13 [9 ] Task 14 [8 ] Task 10 ... other 15 tasks [0 ] Task 18 [10 ] Task 20 ... other 7 tasks [10 ] Task 28 Finished PrioritizedTaskProducer [10 ] Task 29 ... other 9 tasks [0 ] Task 30 (0:8)(1:5)(2:3)(3:1)(4:1) (5:9)(6:8)(7:0)(8:2)(9:7) (10:8)(11:8)(12:1)(13:9)(14:9) (15:8)(16:8)(17:1)(18:0)(19:8) (20:10)(21:10)(22:10)(23:10)(24:10) (25:10)(26:10)(27:10)(28:10)(29:10) (30:0)(31:1)(32:2)(33:3)(34:4) (35:5)(36:6)(37:7)(38:8)(39:9) (40:-1) [-1 ] Task 40 Calling shutdownNow() Finished PrioritizedTaskConsumer *///:~ PrioritizedTaskProducer任务负责向队列添加40个任务，前20个任务不间断地添加进队，且随机0-10的优先级；后10个任务是间隔固定时间添加优先级为10的任务，最后10个任务不间断添加优先级递增到9的任务，最后添加\u0026quot;结束哨兵\u0026quot;任务，其将打印所有任务添加到队列的顺序。PrioritizedTaskConsumer则是不间断的尝试从队列中取出任务执行。从输出可以看到，队列中如果有优先级高的任务，它一定是先出队的。\n这个例子不需要任何显式同步，因为阻塞队列提供了所需的同步。\nDelayQueue # DelayQueue是一个无界的阻塞队列，利用PriorityQueue实现，用于存放实现Delay接口1的对象，队列中的对象只能在其到期之后才能被取出。同时其还是一个有序队列，即队头的元素将最先到期，若没有任何元素到期，就不会有队头元素，poll()方法将返回null，因此DelayQueue不接受null作为元素。\n实际上，在了解了ScheduledThreadPoolExecutor.ScheduledFutureTask的 出队规则之后，DelayQueue的出队的实现也就不言自明了——当leader被设置时，表明有任务即将出队，其他任务进入等待，该任务出队之后重置leader：\n// Delayqueue.take public E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { for (;;) { E first = q.peek(); if (first == null) available.await(); else { long delay = first.getDelay(NANOSECONDS); if (delay \u0026lt;= 0) return q.poll(); first = null; // don\u0026#39;t retain ref while waiting if (leader != null) available.await(); else { Thread thisThread = Thread.currentThread(); leader = thisThread; try { available.awaitNanos(delay); } finally { if (leader == thisThread) leader = null; } } } } } finally { if (leader == null \u0026amp;\u0026amp; q.peek() != null) available.signal(); lock.unlock(); } } 下例展示了如何构造一个可以放入DelayQueue中的任务：\npublic class DelayQueueDemo { private static class DelayedTask implements Runnable, Delayed { protected static List\u0026lt;DelayedTask\u0026gt; sequence = new ArrayList\u0026lt;\u0026gt;(); private static int counter = 0; private final int id = counter++; private final int delta; /** 到期时间 */ private final long trigger; public DelayedTask(int delayInMilliseconds) { delta = delayInMilliseconds; trigger = System.nanoTime() + NANOSECONDS.convert(delta, MILLISECONDS); sequence.add(this); } @Override public long getDelay(TimeUnit unit) { return unit.convert(trigger - System.nanoTime(), NANOSECONDS); } @Override public int compareTo(Delayed arg) { DelayedTask that = (DelayedTask) arg; if (trigger \u0026lt; that.trigger) return -1; if (trigger \u0026gt; that.trigger) return 1; return 0; } @Override public void run() { System.out.print(this + \u0026#34; \u0026#34;); } @Override public String toString() { return String.format(\u0026#34;[%1$-4d]\u0026#34;, delta) + \u0026#34; Task \u0026#34; + id; } public String summary() { return \u0026#34;(\u0026#34; + id + \u0026#34;:\u0026#34; + delta + \u0026#34;)\u0026#34;; } static class EndSentinel extends DelayedTask { private ExecutorService exec; public EndSentinel(int delay, ExecutorService e) { super(delay); exec = e; } @Override public void run() { System.out.println(); for (DelayedTask pt : sequence) { System.out.print(pt.summary() + \u0026#34; \u0026#34;); } System.out.println(); System.out.println(this + \u0026#34; Calling shutdownNow()\u0026#34;); exec.shutdownNow(); } } } static class DelayedTaskConsumer implements Runnable { private DelayQueue\u0026lt;DelayedTask\u0026gt; q; public DelayedTaskConsumer(DelayQueue\u0026lt;DelayedTask\u0026gt; q) { this.q = q; } @Override public void run() { try { while (!Thread.interrupted()) // Run task with the current thread q.take().run(); } catch (InterruptedException e) { // Acceptable way to exit } System.out.println(\u0026#34;Finished DelayedTaskConsumer\u0026#34;); } } public static void main(String[] args) { Random rand = new Random(47); ExecutorService exec = Executors.newCachedThreadPool(); DelayQueue\u0026lt;DelayedTask\u0026gt; queue = new DelayQueue\u0026lt;\u0026gt;(); // Fill with tasks that have random delays: for (int i = 0; i \u0026lt; 20; i++) queue.put(new DelayedTask(rand.nextInt(5000))); // Set the stopping point queue.add(new DelayedTask.EndSentinel(5000, exec)); exec.execute(new DelayedTaskConsumer(queue)); } } /* output（sample） [128 ] Task 11 [200 ] Task 7 [429 ] Task 5 [520 ] Task 18 [555 ] Task 1 [961 ] Task 4 [998 ] Task 16 [1207] Task 9 [1693] Task 2 [1809] Task 14 [1861] Task 3 [2278] Task 15 [3288] Task 10 [3551] Task 12 [4258] Task 0 [4258] Task 19 [4522] Task 8 [4589] Task 13 [4861] Task 17 [4868] Task 6 (0:4258) (1:555) (2:1693) (3:1861) (4:961) (5:429) (6:4868) (7:200) (8:4522) (9:1207) (10:3288) (11:128) (12:3551) (13:4589) (14:1809) (15:2278) (16:998) (17:4861) (18:520) (19:4258) (20:5000) [5000] Task 20 Calling shutdownNow() Finished DelayedTaskConsumer *///:~ 从输出可以看到，任务入队的顺序和任务出队的顺序没有任何关系，任务是按照超时先后出队的。\nDelay接口实际上继承了Comparable接口。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":94,"href":"/zh/docs/java/concurrency/10_Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B8%8Evolatile%E5%85%B3%E9%94%AE%E5%AD%97/","title":"JMM与volatile关键字(转)","section":"并发编程","content":" Java内存模型与volatile关键字 # 本文转自 Matrix海子，是描述volatile关键字非常好的一篇文章，从Java的内存模型开始，归本溯源的阐述了volatile关键字在并发中的作用与局限\n此文部分内容参照了《深入理解Java虚拟机》\n1 内存模型的相关概念 # 大家都知道，计算机在执行程序时，每条指令都是在CPU中执行的，而执行指令过程中，势必涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了高速缓存。\n也就是，当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。举个简单的例子，比如下面的这段代码：\ni = i + 1; 当线程执行这个语句时，会先从主存当中读取i的值，然后复制一份到高速缓存当中，然后CPU执行指令对i进行加1操作，然后将数据写入高速缓存，最后将高速缓存中i最新的值刷新到主存当中。\n这个代码在单线程中运行是没有任何问题的，但是在多线程中运行就会有问题了。在多核CPU中，每条线程可能运行于不同的CPU中，因此每个线程运行时有自己的高速缓存（对单核CPU来说，其实也会出现这种问题，只不过是以线程调度的形式来分别执行的）。本文我们以多核CPU为例。\n比如同时有2个线程执行这段代码，假如初始时i的值为0，那么我们希望两个线程执行完之后i的值变为2。但是事实会是这样吗？\n可能存在下面一种情况：初始时，两个线程分别读取i的值存入各自所在的CPU的高速缓存当中，然后线程1进行加1操作，然后把i的最新值1写入到内存。此时线程2的高速缓存当中i的值还是0，进行加1操作之后，i的值为1，然后线程2把i的值写入内存。\n最终结果i的值是1，而不是2。这就是著名的缓存一致性问题。通常称这种被多个线程访问的变量为共享变量。\n也就是说，如果一个变量在多个CPU中都存在缓存（一般在多线程编程时才会出现），那么就可能存在缓存不一致的问题。\n为了解决缓存不一致性问题，通常来说有以下2种解决方法：\n1）通过在总线加LOCK#锁的方式\n2）通过缓存一致性协议\n这2种方式都是硬件层面上提供的方式。\n在早期的CPU当中，是通过在总线上加LOCK#锁的形式来解决缓存不一致的问题。因为CPU和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他CPU对其他部件访问（如内存），从而使得只能有一个CPU能使用这个变量的内存。比如上面例子中 如果一个线程在执行 i = i +1，如果在执行这段代码的过程中，在总线上发出了LCOK#锁的信号，那么只有等待这段代码完全执行完毕之后，其他CPU才能从变量i所在的内存读取变量，然后进行相应的操作。这样就解决了缓存不一致的问题。\n但是上面的方式会有一个问题，由于在锁住总线期间，其他CPU无法访问内存，导致效率低下。\n所以就出现了缓存一致性协议。最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。\n2 并发编程中的三个概念 # 在并发编程中，我们通常会遇到以下三个问题：原子性问题，可见性问题，有序性问题。我们先看具体看一下这三个概念：\n2.1 原子性 # 原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。\n一个很经典的例子就是银行账户转账问题：\n比如从账户A向账户B转1000元，那么必然包括2个操作：从账户A减去1000元，往账户B加上1000元。\n试想一下，如果这2个操作不具备原子性，会造成什么样的后果。假如从账户A减去1000元之后，操作突然中止。然后又从B取出了500元，取出500元之后，再执行 往账户B加上1000元 的操作。这样就会导致账户A虽然减去了1000元，但是账户B没有收到这个转过来的1000元。\n所以这2个操作必须要具备原子性才能保证不出现一些意外的问题。\n同样地反映到并发编程中会出现什么结果呢？\n举个最简单的例子，大家想一下假如为一个32位的变量赋值过程不具备原子性的话，会发生什么后果？\ni = 9; 假若一个线程执行到这个语句时，我暂且假设为一个32位的变量赋值包括两个过程：为低16位赋值，为高16位赋值。\n那么就可能发生一种情况：当将低16位数值写入之后，突然被中断，而此时又有一个线程去读取i的值，那么读取到的就是错误的数据。\n2.2 可见性 # 可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。\n举个简单的例子，看下面这段代码：\n//线程1执行的代码 int i = 0; i = 10; //线程2执行的代码 j = i; 假若执行线程1的是CPU1，执行线程2的是CPU2。由上面的分析可知，当线程1执行 i =10这句时，会先把i的初始值加载到CPU1的高速缓存中，然后赋值为10，那么在CPU1的高速缓存当中i的值变为10了，却没有立即写入到主存当中。\n此时线程2执行 j = i，它会先去主存读取i的值并加载到CPU2的缓存当中，注意此时内存当中i的值还是0，那么就会使得j的值为0，而不是10.\n这就是可见性问题，线程1对变量i修改了之后，线程2没有立即看到线程1修改的值。\n2.3 有序性 # 有序性：即程序执行的顺序按照代码的先后顺序执行。举个简单的例子，看下面这段代码：\nint i = 0; boolean flag = false; i = 1; //语句1 flag = true; //语句2 上面代码定义了一个int型变量，定义了一个boolean类型变量，然后分别对两个变量进行赋值操作。从代码顺序上看，语句1是在语句2前面的，那么JVM在真正执行这段代码的时候会保证语句1一定会在语句2前面执行吗？不一定，为什么呢？这里可能会发生指令重排序（Instruction Reorder）。\n下面解释一下什么是指令重排序，一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。\n比如上面的代码中，语句1和语句2谁先执行对最终的程序结果并没有影响，那么就有可能在执行过程中，语句2先执行而语句1后执行。\n但是要注意，虽然处理器会对指令进行重排序，但是它会保证程序最终结果会和代码顺序执行结果相同，那么它靠什么保证的呢？再看下面一个例子：\nint a = 10; //语句1 int r = 2; //语句2 a = a + 3; //语句3 r = a*a; //语句4 这段代码有4个语句，那么可能的一个执行顺序是：\n语句2 -\u0026gt; 语句1 -\u0026gt; 语句3 -\u0026gt; 语句4\n那么可不可能是这个执行顺序呢： 语句2 -\u0026gt; 语句1 -\u0026gt; 语句4 -\u0026gt; 语句3\n不可能，因为处理器在进行重排序时是会考虑指令之间的数据依赖性，如果一个指令Instruction 2必须用到Instruction 1的结果，那么处理器会保证Instruction 1会在Instruction 2之前执行。\n虽然重排序不会影响单个线程内程序执行的结果，但是多线程呢？下面看一个例子：\n//线程1: context = loadContext(); //语句1 inited = true; //语句2 //线程2: while(!inited ){ sleep() } doSomethingwithconfig(context); 上面代码中，由于语句1和语句2没有数据依赖性，因此可能会被重排序。假如发生了重排序，在线程1执行过程中先执行语句2，而此是线程2会以为初始化工作已经完成，那么就会跳出while循环，去执行doSomethingwithconfig(context)方法，而此时context并没有被初始化，就会导致程序出错。\n从上面可以看出，指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。\n也就是说，要想并发程序正确地执行，必须要保证原子性、可见性以及有序性。只要有一个没有被保证，就有可能会导致程序运行不正确。\n3 Java内存模型 # 在前面谈到了一些关于内存模型以及并发编程中可能会出现的一些问题。下面我们来看一下Java内存模型，研究一下Java内存模型为我们提供了哪些保证以及在java中提供了哪些方法和机制来让我们在进行多线程编程时能够保证程序执行的正确性。\n在Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model，JMM）来屏蔽各个硬件平台和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。那么Java内存模型规定了哪些东西呢，它定义了程序中变量的访问规则，往大一点说是定义了程序执行的次序。注意，为了获得较好的执行性能，Java内存模型并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序。也就是说，在java内存模型中，也会存在缓存一致性问题和指令重排序的问题。\nJava内存模型规定所有的变量都是存在主存当中（类似于前面说的物理内存），每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存。\n举个简单的例子：在java中，执行下面这个语句：\ni = 10; 执行线程必须先在自己的工作线程中对变量i所在的缓存行进行赋值操作，然后再写入主存当中。而不是直接将数值10写入主存当中。\n那么Java语言 本身对 原子性、可见性以及有序性提供了哪些保证呢？\n3.1 原子性 # 在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。\n上面一句话虽然看起来简单，但是理解起来并不是那么容易。看下面一个例子i：\n请分析以下哪些操作是原子性操作：\nx = 10; //语句1 y = x; //语句2 x++; //语句3 x = x + 1; //语句4 咋一看，有些朋友可能会说上面的4个语句中的操作都是原子性操作。其实只有语句1是原子性操作，其他三个语句都不是原子性操作。\n语句1是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中。\n语句2实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。\n同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。\n所以上面4个语句只有语句1的操作具备原子性。\n也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。\n不过这里有一点需要注意：在32位平台下，对64位数据的读取和赋值是需要通过两个操作来完成的，不能保证其原子性。但是好像在最新的JDK中，JVM已经保证对64位数据的读取和赋值也是原子性操作了。\n从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。\n3.2 可见性 # 对于可见性，Java提供了volatile关键字来保证可见性。\n当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。\n而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。\n另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。\n3.3 有序性 # 在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。\n在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。\n另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。\n下面就来具体介绍下happens-before原则（先行发生原则）：\n程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作\n锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作\nvolatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作\n传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C\n线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作\n线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生\n线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行\n对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始\n这8条原则摘自《深入理解Java虚拟机》。\n这8条规则中，前4条规则是比较重要的，后4条规则都是显而易见的。\n下面我们来解释一下前4条规则：\n对于程序次序规则来说，我的理解就是一段程序代码的执行在单个线程中看起来是有序的。注意，虽然这条规则中提到“书写在前面的操作先行发生于书写在后面的操作”，这个应该是程序看起来执行的顺序是按照代码顺序执行的，因为虚拟机可能会对程序代码进行指令重排序。虽然进行重排序，但是最终执行的结果是与程序顺序执行的结果一致的，它只会对不存在数据依赖性的指令进行重排序。因此，在单个线程中，程序执行看起来是有序执行的，这一点要注意理解。事实上，这个规则是用来保证程序在单线程中执行结果的正确性，但无法保证程序在多线程中执行的正确性。\n第二条规则也比较容易理解，也就是说无论在单线程中还是多线程中，同一个锁如果出于被锁定的状态，那么必须先对锁进行了释放操作，后面才能继续进行lock操作。\n第三条规则是一条比较重要的规则，也是后文将要重点讲述的内容。直观地解释就是，如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。\n第四条规则实际上就是体现happens-before原则具备传递性。\n4 深入剖析volatile关键字 # 在前面讲述了很多东西，其实都是为讲述volatile关键字作铺垫，那么接下来我们就进入主题。\n4.1 volatile关键字的两层语义 # 一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：\n1）保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。\n2）禁止进行指令重排序。\n先看一段代码，假如线程1先执行，线程2后执行：\n//线程1 boolean stop = false; while(!stop){ doSomething(); } //线程2 stop = true; 这段代码是很典型的一段代码，很多人在中断线程时可能都会采用这种标记办法。但是事实上，这段代码会完全运行正确么？即一定会将线程中断么？不一定，也许在大多数时候，这个代码能够把线程中断，但是也有可能会导致无法中断线程（虽然这个可能性很小，但是只要一旦发生这种情况就会造成死循环了）。\n下面解释一下这段代码为何有可能导致无法中断线程。在前面已经解释过，每个线程在运行过程中都有自己的工作内存，那么线程1在运行的时候，会将stop变量的值拷贝一份放在自己的工作内存当中。\n那么当线程2更改了stop变量的值之后，但是还没来得及写入主存当中，线程2转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。\n但是用volatile修饰之后就变得不一样了：\n第一：使用volatile关键字会强制将修改的值立即写入主存；\n第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）；\n第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。\n那么在线程2修改stop值时（当然这里包括2个操作，修改线程2工作内存中的值，然后将修改后的值写入内存），会使得线程1的工作内存中缓存变量stop的缓存行无效，然后线程1读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。\n那么线程1读取到的就是最新的正确的值。\n4.2 volatile保证原子性吗？ # 从上面知道volatile关键字保证了操作的可见性，但是volatile能保证对变量的操作是原子性吗？\n下面看一个例子：\npublic class Test { public volatile int inc = 0; public void increase() { inc++; } public static void main(String[] args) { final Test test = new Test(); for(int i=0;i\u0026lt;10;i++){ new Thread(){ public void run() { for(int j=0;j\u0026lt;1000;j++) test.increase(); }; }.start(); } while(Thread.activeCount()\u0026gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); } } 大家想一下这段程序的输出结果是多少？也许有些朋友认为是10000。但是事实上运行它会发现每次运行结果都不一致，都是一个小于10000的数字。\n可能有的朋友就会有疑问，不对啊，上面是对变量inc进行自增操作，由于volatile保证了可见性，那么在每个线程中对inc自增完之后，在其他线程中都能看到修改后的值啊，所以有10个线程分别进行了1000次操作，那么最终inc的值应该是1000*10=10000。\n这里面就有一个误区了，volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性。\n在前面已经提到过，自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现：\n假如某个时刻变量inc的值为10，\n线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了；\n然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，所以线程2会直接去主存读取inc的值，发现inc的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。\n然后线程1接着进行加1操作，由于已经读取了inc的值，注意此时在线程1的工作内存中inc的值仍然为10，所以线程1对inc进行加1操作后inc的值为11，然后将11写入工作内存，最后写入主存。\n那么两个线程分别进行了一次自增操作后，inc只增加了1。\n解释到这里，可能有朋友会有疑问，不对啊，前面不是保证一个变量在修改volatile变量时，会让缓存行无效吗？然后其他线程去读就会读到新的值，对，这个没错。这个就是上面的happens-before规则中的volatile变量规则，但是要注意，线程1对变量进行读取操作之后，被阻塞了的话，并没有对inc值进行修改。然后虽然volatile能保证线程2对变量inc的值读取是从内存中读取的，但是线程1没有进行修改，所以线程2根本就不会看到修改的值。\n根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。\n把上面的代码改成以下任何一种都可以达到效果：\n采用synchronized：\npublic class Test { public int inc = 0; public synchronized void increase() { inc++; } public static void main(String[] args) { final Test test = new Test(); for(int i=0;i\u0026lt;10;i++){ new Thread(){ public void run() { for(int j=0;j\u0026lt;1000;j++) test.increase(); }; }.start(); } while(Thread.activeCount()\u0026gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); } } 采用Lock：\npublic class Test { public int inc = 0; Lock lock = new ReentrantLock(); public void increase() { lock.lock(); try { inc++; } finally{ lock.unlock(); } } public static void main(String[] args) { final Test test = new Test(); for(int i=0;i\u0026lt;10;i++){ new Thread(){ public void run() { for(int j=0;j\u0026lt;1000;j++) test.increase(); }; }.start(); } while(Thread.activeCount()\u0026gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); } } 采用AtomicInteger：\npublic class Test { public AtomicInteger inc = new AtomicInteger(); public void increase() { inc.getAndIncrement(); } public static void main(String[] args) { final Test test = new Test(); for(int i=0;i\u0026lt;10;i++){ new Thread(){ public void run() { for(int j=0;j\u0026lt;1000;j++) test.increase(); }; }.start(); } while(Thread.activeCount()\u0026gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); } } 在java 1.5的java.util.concurrent.atomic包下提供了一些原子操作类，即对基本数据类型的 自增（加1操作），自减（减1操作）、以及加法操作（加一个数），减法操作（减一个数）进行了封装，保证这些操作是原子性操作。atomic是利用CAS来实现原子性操作的（Compare And Swap），CAS实际上是利用处理器提供的CMPXCHG指令实现的，而处理器执行CMPXCHG指令是一个原子性操作。\n4.3 volatile能保证有序性吗？ # 在前面提到volatile关键字能禁止指令重排序，所以volatile能在一定程度上保证有序性。\nvolatile关键字禁止指令重排序有两层意思：\n1）当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行；\n2）在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。\n可能上面说的比较绕，举个简单的例子：\n//x、y为非volatile变量 //flag为volatile变量 x = 2; //语句1 y = 0; //语句2 flag = true; //语句3 x = 4; //语句4 y = -1; //语句5 由于flag变量为volatile变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。\n并且volatile关键字能保证，执行到语句3时，语句1和语句2必定是执行完毕了的，且语句1和语句2的执行结果对语句3、语句4、语句5是可见的。\n那么我们回到前面举的一个例子：\n//线程1: context = loadContext(); //语句1 inited = true; //语句2 //线程2: while(!inited ){ sleep() } doSomethingwithconfig(context); 前面举这个例子的时候，提到有可能语句2会在语句1之前执行，那么久可能导致context还没被初始化，而线程2中就使用未初始化的context去进行操作，导致程序出错。\n这里如果用volatile关键字对inited变量进行修饰，就不会出现这种问题了，因为当执行到语句2时，必定能保证context已经初始化完毕。\n4.4 volatile的原理和实现机制 # 前面讲述了源于volatile关键字的一些使用，下面我们来探讨一下volatile到底如何保证可见性和禁止指令重排序的。\n下面这段话摘自《深入理解Java虚拟机》：\n“观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令”\nlock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能：\n1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；\n2）它会强制将对缓存的修改操作立即写入主存；\n3）如果是写操作，它会导致其他CPU中对应的缓存行无效。\n5 使用volatile关键字的场景 # synchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件：\n1）对变量的写操作不依赖于当前值\n2）该变量没有包含在具有其他变量的不变式中\n实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。\n事实上，我的理解就是上面的2个条件需要保证操作是原子性操作，才能保证使用volatile关键字的程序在并发时能够正确执行。\n下面列举几个Java中使用volatile的几个场景。\n5.1 状态标记量 # volatile boolean flag = false; while(!flag){ doSomething(); } public void setFlag() { flag = true; } // another demo volatile boolean inited = false; //线程1: context = loadContext(); inited = true; //线程2: while(!inited ){ sleep() } doSomethingwithconfig(context); 5.2 双重检查 # class Singleton{ private volatile static Singleton instance = null; private Singleton() { } public static Singleton getInstance() { if(instance==null) { synchronized (Singleton.class) { if(instance==null) instance = new Singleton(); } } return instance; } } 至于为何需要这么写请参考：\n《Java 中的双重检查（Double-Check）》\n本文完\n"},{"id":95,"href":"/zh/posts/18_macOS12%E6%9B%B4%E6%96%B0%E8%AE%B0%E5%BD%95/","title":"macOS12 Monterey更新","section":"Blog","content":"原本计划MBP2018就在BigSur 11.7 养老算了，实际上已经苟了3年，并且计划一直苟下去的😂\u0026hellip;但是有几个征兆，最终还是在7月份，更新了12。以下为主要原因:\n自带的应用商店出现了最低支持12的应用——削弱了老11用户的使用体验 oneDrive自动更新之后不支持老版本，但是旧版本又不好找。（最后只能删除plist阻止其自动更新） 部分破解软件的旧版本也不好找了 docker竟然也\u0026hellip;😅 brew也\u0026hellip;太慢了(升级之后好多了) 实际使用差别不大，感觉不到更新。大部分软件也都能正常工作。\n除了alfred实在是太老了，更新下新版本就可以了。至于parallels用的不多，直接卸载就可以了😎。\n其他的一些破解软件都可以完美运行，很好。\n其他的没差。\nsafari还是一样的垃圾。\n本来说用用看的，老机器chrome吃内存吃的厉害（播放弹幕视频cpu占用飙升导致卡顿），想说safari可能会好点，但是更新之后safari退出无痕窗口后就报错闪退。\n也试了firefox，确实不太行（慢）。不过这三个浏览器都还支持旧版本的1p自动填充。edge可以滚了😂\n不过这三个浏览器不能同步书签，有点不方便。\n不妨试试 raindrop.io？\n总体来讲，更新没什么雷，还算平顺。如果有软件卡macOS12的建议更新。\n系统更新里可能显示最新的版本，不是12，至于如何更新指定版本的macOS，看这里: https://support.apple.com/zh-cn/102662 "},{"id":96,"href":"/zh/posts/16_update-homebrew-packages/","title":"更新使用Homebrew安装的软件包","section":"Blog","content":"使用Homebrew安装的软件包，安装完成之后，可能几年都不会去管一眼。不过么，等到几年后要升级的时候，还是会有点麻烦。主要是Homebrew慢（:\u0026ndash;汗😓️。\n如果网络OK的话，只需要执行\nbrew update \u0026amp;\u0026amp; brew upgrade \u0026lt;your package name\u0026gt; 就可以了。\n第一个命令，brew update用来获取可供安装的软件包的最新版本，下次安装的时候，就能安装最新的版本。\n第二个命令，brew upgrade \u0026lt;package\u0026gt; 用来更新指定的软件包。\n你以为这样就行了？对于有些软件包可能是的。不过，很有可能并不是这样的。\n以python为例，Homebrew的可供安装的软件包是以小版本打包的，如python 3 可供安装的包有python@3.8，python@3.9，python@3.10等等。\n上述brew upgrade@3.9命令，可能只是将python 3.9.14升级到3.9.19，并不会升级到3.10。所以要更新到python 3.10，你需要直接安装。\nbrew install python@3.10 你妈，一个小时，安装个python还没完事。\n没问题的话，brew会处理好/usr/local/bin中python3的命令链接，此时python3已经指向更新的3.10了。\n安装完成后系统会存在3个版本的python（实际上macOS 11.7系统自带一个老版本的python2.7，macOS 12自带python3.9）。\n卸载旧版本的python：\nbrew uninstall python@3.9 后续可以运行brew doctor检查以下brew的状况，根据提示，可以运行brew cleanup清理homebrew。\n如果Homebrew真的慢到不能工作，可以试试 使用国内的镜像，尽管可能没什么用，值得一试，不是么？\n运行brew doctor后，homebrew提示不再对macOS 11提供支持（还可以使用），墙裂建议使用者更新macOS。\n我更新了macOS 12，于是安装成功了python@3.12。\n也算Callback了前面的吐槽😂\n"},{"id":97,"href":"/zh/posts/15_%E4%BD%BF%E7%94%A8PythonAnywhere%E6%89%98%E7%AE%A1%E7%94%B5%E6%8A%A5%E6%9C%BA%E5%99%A8%E4%BA%BA/","title":"使用Pythonanywhere托管Telegram机器人","section":"Blog","content":"基于Coze的收费策略，在上面免费使用Gemini的可能性不大了(每日20次gemini-1.5-flash请求)。于是尝试看看，是否可以自己接入并部署玩玩看。\nGitHub上有关Telegram机器人的项目不少，并且使用python并接入google Gemini AI的也不在少数。随即 clone了一个，查看文档之后，便可上手。\n本地调试遇到的问题\nDocker镜像build不成功\n原计划按照项目文档，找 Zeabur来托管docker 容器，但是由于前一阵国内各镜像加速纷纷停止对docker-hub的支持，导致Docker build一直在失败，本地调试一直request time out。无奈作罢。\n照理讲，安装文档直接部署就可以了，不过有一种本地跑不起来不部署的执念😅。\n这几天试试搞个本地的镜像吧。\n吐槽一句，在国内，想玩点东西，第一步往往都是和墙作斗争，太难了。\n本地运行py\n不出意外，本地跑肯定是会遇到问题的。问题有3:\n1）机器人Token的问题。由于之前telegram机器人的token在Coze上配置过，虽然Coze收费之后一怒之下删掉了bot，但是telegram机器人的webhook已经被设置了，不能再重复使用。此时配置项目并运行，会出现webhook冲突。处理办法是在telegram botFather处revoke token，重新设置后即可。\n2）proxy的问题。又回到老生常谈的问题了，众所周知，telegram和google都是被禁止在大陆地区使用的，所以想要本地调试必须要走代理。所以需要额外配置二者的代理：\nimport os # google api proxy os.environ[\u0026#39;http_proxy\u0026#39;]=\u0026#39;http://127.0.0.1:7890\u0026#39; os.environ[\u0026#39;https_proxy\u0026#39;]=\u0026#39;http://127.0.0.1:7890\u0026#39; os.environ[\u0026#39;all_proxy\u0026#39;]=\u0026#39;socks5://127.0.0.1:7890\u0026#39; # use proxy when running locally # https://www.pythonanywhere.com/forums/topic/32151/ from telebot import asyncio_helper asyncio_helper.proxy = \u0026#39;http://127.0.0.1:7890\u0026#39; 另外，gemini-api 不支持香港地区，所以香港的🪜没用😂。\n幸运的是，处理完上面的问题，脚本正常跑起来了。\n如何部署？\nZeabur最快的方式是从你的github拉取项目并自动构建，由于是测试性质，并且docker方式并没有在本地调试成功（这里除了镜像加速的问题，上述代理问题，容器运行之后一样会遇到）。就不在github创建仓库了。😅\npythonanywhere可以分配用户一定的免费资源1，并且带有python解释器，可以 直接运行脚本，简直是完美的选择。\n静态配置参数telegram token和gemini api-key，直接运行脚本即可成功创建 机器人。\n每天100s的处理器时间以及，总共512MB的磁盘空间。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":98,"href":"/zh/posts/14_get-perpetual-fallback-license-for-jetbrains-ides/","title":" 获取JetBrains IDE的永久回退授权","section":"Blog","content":"⚠️本人并不鼓励使用破解软件！\n⚠️如果经济允许，请购买正版软件，以支持开发者并体验最新的功能。\n⚠️此文仅作记录，请勿转载。\n说的那么绕，其实就是破解版本，还是要委婉一些的。\n实在是白嫖成瘾（囊中羞涩），之前嫖的学生免费使用过期之后，就一直使用的破解版本。其中经历诸多曲折，不说也罢。\n其实，只要购买过指定版本的IDE一年，就可以获得永久回退授权，也就是不能再享受更新，IDE高级功能是可以用的。\n以下是针对没有购买过正版IDE的用户，2024年07月01日前还可行的操作方法：\n访问 神奇网站\n这个网站列出了可用的站点，选择一个进去即可。\n下载一个神奇的zip文件\n按照第一步，选择网站进入之后，可以看到jetbra.zip文件的下载链接。下载文件并解压。 查看网站上支持的IDE版本，一般会较最新版本落后。如当前显示2023.2.x（最新为2024.1），去 官网下载历史版本号为2023.2.x的IDE版本，并安装。 在终端进入第一步下载的jetbra文件夹，运行 bash scripts/install.sh，会自动配置。如果是windows用户，直接双击运行.bat脚本文件（具体查看readme.txt文件的NEW部分）。 在第2步打开的网站上，找到你要破解的IDE，复制激活码，打开IDE，使用激活码激活即可。你会获得一个有过期时间但是永久回退的授权，不用关心过期时间，也不要更新IDE。\n如果还需要激活其他IDE，重复操作第3步即可，注意下载第2步中网页上显示的可激活的版本，不同的IDE可以激活的版本可能会有差异。\n此过程中不要登录jetbrains账户，完成之后可以登录。\n⚠️⚠️⚠️特殊说明\n如果遇到IDE无法打开的情况，或者授权失效的情况，可能是网站的内容有更新。 请到网站查看最新的内容。\n如果最新的内容更新后还是失败，注意查看用户目录下是否存在.jetbrains隐藏文件夹，如果存在，则使用新的jetbra.zip解压后的文件替换之。\n"},{"id":99,"href":"/zh/posts/13_use-coze-plugin-and-workflow/","title":"使用Coze的插件和工作流创建自定义AI工具","section":"Blog","content":" Coze是一个提供AI机器人的HUB，利用它市场上提供的Bot，可以很方便地使用AI机器人工作或娱乐。除了市场上五花八门的AI机器人之外，Bot还提供了自定义工作流，插件等功能，用来创建自己的AI工具。\n⚠️2024年07月03日起，创建的Coze机器人需要 购买套餐才能继续使用了，最便宜需要$9/M，看来字节也被薅羊毛薅到顶不住了😭️。\n目前免费用户有每日免费使用GPT-3.5-turbo模型100次的限制，其他的模型免费次数太少，基本不能碰了。\n这个改动对于免费用户来说，使用复杂工作流基本上属于流产，工作流一次调用可能需要使用多次LLM😅。\n本来使用Coze可以完成如下的工作，特别是工作流，有一些可玩性。\n创建工作流 使用大模型分析输入（prompt and persona） 拼装参数 调用能力 （plugin or workflow） 处理结果 创建插件 接入 Kimi AI 与电报机器人整合 不过开始收费之后，一切都变了。\n简单来讲，当日只能使用100次GPT-3.5-turbo的额度（含调试），所以在Coze上调试Genimi是不可行了，这样子很快就会使用完额度。\n所以就有了接下来的尝试。\n本文结束。\n以下是且还能用的利用Coze，基于GPT-3.5-turbo 制作的几个简单telegram机器人。\nfkubot：综合机器人 googy：谷歌搜索机器人 kimi：Kimi聊天机器人 "},{"id":100,"href":"/zh/posts/12_%E4%B8%BB%E5%8A%A8%E6%89%98%E7%AE%A1Clash%E9%85%8D%E7%BD%AE/","title":"主动管理Clash的代理配置","section":"Blog","content":"自己搭建了这么多年的shadowsocks服务，经历了2次续年费后服务器ip被加黑名单之后，算是彻底放弃了（心痛100刀😭），说的就是帮瓦工。vultr的服务器虽然稳定，但是延迟比较高，糟糕的时候甚至连油管的高清视频都卡顿，不过大部分时间都是轻度搜索场景，也就还能使用。那时候也知道“机场”的概念，不过自己搭的服务用着放心么不是，机场随时跑路的，就一直没用。而且vultr的服务器，5刀/月，价格也在可接受的范围内。\n不过浸淫了那么久，发现机场的速度和稳定性确实要好过自建服务。\n一来稳定的机场每天都有维护，自建的服务半年都不见得上去看一眼； 二来身边有用机场的人，机场经过了时间的检验，可靠性有保证了； 三来如果不是定制化或者要求非常高，机场的价格比自建服务器便宜。 综上，还是转用机场吧，别再自己折腾了。\n以上为引。\n机场购买套餐后，一般会提供订阅链接，clash可以直接托管配置，用起来相当方便。不过机场提供的订阅使用起来，还有如下缺点：\n机场提供的订阅配置一般都是一大坨，不同机场的配置也有较大差异，在切换配置文件后，往往需要调整规则，或者需要测速后手动选择低延迟的节点 不能自定义，部分机场缺乏对某些地址的分流规则，可能需要手动添加，但是，机场的托管配置更新之后会覆盖用户添加的内容 机场有些“凑数”节点，不好用也基本上用不到，但是在选择节点总是展示，不够有条理 实际上，只要稍微使用一段时间的clash，这些问题都不难发现。如果能够自己写规则，并管理机场提供的节点的话，以上问题都能解决。\nclash配置文件的结构 # “head” 头部配置，主要是代理端口，模式，日志级别等基础配置 proxy-providers 核心配置，代理集，用来管理机场的节点 proxy-groups 核心配置，代理组，用来管理分流 proxies 核心配置，上述两个配置好之后，可以不配置此项，机场订阅链接一般配置此项 rule-providers 核心配置，用来订阅分流规则 rules 核心配置，控制分流规则，机场订阅仅用此来分流 说起来也很简单，主要是2部分核心配置\nproxy 即指代服务节点 rule 即指代分流规则，即哪个网站走哪个节点 自定义的话，只需要配置proxy-providers、proxy-groups、rule-providers和rules配置就行了，至于头部配置，随便抄一个就行了：\nport: 7890 socks-port: 7891 redir-port: 7892 mixed-port: 7893 allow-lan: false mode: rule log-level: warn external-controller: \u0026#39;127.0.0.1:9090\u0026#39; proxy-providers # 这是核心配置，用来管理（多个）机场的订阅，并且可以将节点分类到不同的订阅组。以下是配置示例：\nproxy-providers: ChinaG-tw: type: http #类型，使用http从订阅地址拉取配置 path: ./proxyset/ChinaG.yaml # 拉取的配置文件存放地址 url: \u0026#34;机场提供的订阅地址\u0026#34; interval: 1800 # 配置更新间隔 30分钟 filter: \u0026#39;TW\u0026#39; # 节点过滤，根据机场提供的名字来，这里过滤含有‘TW’两个字母的节点 health-check: # 健康检查 enable: true url: http://www.gstatic.com/generate_204 # 健康检查地址 interval: 300 # 检查间隔 5分钟 ChinaG-hk: type: file # 从本地配置文件读取节点 path: ./proxyset/ChinaG.yaml # 这里是将上面机场的节点分组，故直接使用上面拉取的配置 interval: 3600 filter: \u0026#39;HK|SG\u0026#39; # 节点过滤 这里过滤含有\u0026#39;HK\u0026#39;或者\u0026#39;SG\u0026#39;的节点 health-check: enable: true url: http://www.gstatic.com/generate_204 interval: 300 以上就是2种不同的配置proxy-providers方式。\n有时候，机场提供的订阅地址可能无法顺利拉取下来，这时候可能需要一点特殊的处理，一般是对订阅地址进行 urlEncode后，通过subconverter拉取。具体过程参照引文2。\nproxy-groups # proxy-groups理解为策略组，也就是单击clash图标后，显示的那些选择节点的配置。这些配置一般机场都会提供，开箱即用的。手撸之后的好处就是，不用忍受不同机场的配置差异，总是一样的选单。\n以下是proxy-groups配置示例：\nproxy-groups: - name: 🎯境外流量 # 策略组名字 type: select # 类型 自动选择 use: # 使用哪些proxy-providers - ChinaG-tw # 上一步配置的代理集名字 - ChinaG-hk - Coffee-hk proxies: # 使用哪些代理 - DIRECT # clash自带的，直连 - 🥤亚洲咖啡 # 下面配置的策略组 - name: 🥤亚洲咖啡 type: url-test # 自动测速并选择节点 url: http://www.gstatic.com/generate_204 # 测速地址 interval: 300 # 测速间隔 use: - Coffee-asia rule-providers # 一般机场提供的配置不会配置此项目，而是把所有的ip/域名规则一股脑全塞进rules配置里，差一点的，整个配置文件几千行，良心一点的机场，配置文件动辄几万行。虽然功能相同，但是确实看着累人。\nrule-providers相当于是从互联网拉取分流规则，这些规则有人维护，并且持续更新，这样方便多了。\n以下是rule-providers配置示例：\nYouTube: behavior: classical # 用于yaml结尾的url type: http url: https://cdn.jsdelivr.net/gh/ACL4SSR/ACL4SSR@master/Clash/Providers/Ruleset/YouTube.yaml # 规则地址 interval: 86400 # 更新间隔 1个月 path: ./ruleset/YouTube.yaml # 存放地址 google: type: http behavior: domain # 用于txt结尾的url url: \u0026#34;https://cdn.jsdelivr.net/gh/Loyalsoldier/clash-rules@release/google.txt\u0026#34; path: ./ruleset/google.yaml interval: 86400 拉取下来的实际上是rules的子集，这样是方便管理，简化配置。\nrules # 分流规则的核心配置。既然配置了rule-providers，那么rules的配置自然是要按照上面的配置来。\n以下是配置示例:\n- DOMAIN-SUFFIX,bing.com,🥤亚洲咖啡 # 自定义规则 bing.com走代理访问国际版 # 规则集 对应的规则集名字 对应的proxy-groups名字 - RULE-SET,YouTube,🎬️Youtube #YouTube规则集里的流量都走🎬️Youtube出 - RULE-SET,google,🎯境外流量 # google规则集的流量都走🎯境外流量出 - GEOIP,LAN,DIRECT # 局域网直连 - GEOIP,CN,DIRECT # 国内ip直连 - MATCH,🐟漏网之鱼 # 白名单模式 未匹配上的域名走🐟漏网之鱼代理组出 以上就是手撸clash配置的全部内容。\n使用gist实现远程订阅 # 实际上，这一步并没有什么必要，如果是本地使用的话。不过如果想多端使用，可以使用gist托管配置然后远程订阅。\n实现也很简单，创建新的私密gist，把配置文件贴上去。点击raw查看配置文件，复制地址栏的链接，去掉链接中raw到文件名 中间的字符串，剩下的部分可以直接使用clash订阅。\n参考 # 机场规则优化-v2ex 你的订阅地址无法读取？试试这个 适用于clash的测速地址 clash rules规则集 clash分流的终极方法 "},{"id":101,"href":"/zh/posts/11_%E6%9B%B4%E6%8D%A2%E5%8D%9A%E5%AE%A2%E4%B8%BB%E9%A2%98/","title":"更换个人博客主题","section":"Blog","content":"想换一个更加简洁的博客主题，也是觉得原来的 Zzo主题两侧的留白过于浪费空间，且配色，有些腻了。\n不过，这主题用了很久了，且hugo版本也更新得不像样子了，新主题与旧版本的hugo并不兼容，故一并更新了hugo和主题的版本，这一顿折腾，应该又能撑2年吧。\n更新hugo至最新版 # brew upgrade hugo 如果并没有更新hugo到最新版本，试试brew update先更新homebrew。\n开始前先给zzo来个照片作为留恋吧⏳\n版本更新之后，有些东西，必定要被丢弃的。\n新主题的组织形式不同于前者，配置简化许多，目录格式的需求也不一致，因此，不可能是两者兼容的了。\n引入新选定的主题 # 此次选中的主题是 hugo-book，琢磨一阵子这个主题后，发现它更加合适用作文档页😂。不过没关系，足够简洁就行了。\n值得诟病的一点是，这个主题没有对原生 mermaid的支持，必须使用它指定的格式（称作feature），这样一来，后续如果要换主题的话，又是一顿改改改。\n不过话说回来，如果这次闹腾完后，博客不怎么更新的话，这主题就随着一起入土吧❗️\n依旧把主题作为新的Git子模块引入：\ngit submodule add https://github.com/alex-shpak/hugo-book themes/hugo-book 接下来就是配置了，主要是文件目录组织结构。hugo.yaml配置有现成的，没什么可说的。目录结构参考 exampleSite琢磨琢磨也差不多了。\n使用这个主题的话，页面的front matter可以简洁一点：\ntitle: \u0026#34; \u0026#34; date: 2019-08-31 author: \u0026#34;wangy325\u0026#34; weight: 5 draft: description: \u0026#34;\u0026#34; bookHidden: bookToC: bookComments: 一般使用前4个标签就行了，weight用来控制列表顺序，越小越靠前。后面的标签根据喜好添加。\n其次需要自己捣鼓的就是每个“标签”下的_index.md文件。\n总体使用是非常简单的。\n使用到的一些小技巧 # 主页的元素 # 主页的元素使用了 spotify-github-profile这个项目提供的API，直接引入的代码。\n指定页面隐藏页脚 # 主页不同于其他页面，不需要展示gitInfo，但是全局开启了这个功能，且主题并没有提供单独的开关来控制是否加载partial代码片段。 不过，可以自定义一个参数，来实现这个功能。复制主题的layouts/_default目录到博客目录下，然后修改baseof.html文件，在里面加载 页脚的代码里添加自定义参数即可。\n{{ if default true (default .Site.Params.BookFooter .Params.BookFooter)}} \u0026lt;footer class=\u0026#34;book-footer\u0026#34;\u0026gt; {{ template \u0026#34;footer\u0026#34; . }} \u0026lt;!-- Footer under page content --\u0026gt; {{ partial \u0026#34;docs/inject/footer\u0026#34; . }} \u0026lt;/footer\u0026gt; {{ end }} 如上，添加了一个参数BookFooter来控制是否加载页脚。\n参考 # Hugo: remove footer and header "},{"id":102,"href":"/zh/posts/10_Rime%E4%B8%AD%E5%B7%9E%E9%9F%BB%E8%BC%B8%E5%85%A5%E5%BC%95%E6%93%8E%E5%AE%89%E8%A3%9D%E8%88%87%E7%B0%A1%E5%96%AE%E8%AA%BF%E6%95%99/","title":"Rime中州韻輸入引擎安裝與輸入方案定製指北","section":"Blog","content":"由于未知的原因很有可能是配置文件错误，使用几年多的Rime（squirrel）输入法发生异常。主要表现为小鹤双拼的键位映射异常（如键入‘budv’的候选词是‘病毒’而不是‘不对’。），检查了许久的配置文件，并没有发现明显异常。距离上次配置Rime已许久，很多细节都已经丢失。一番纠结后，决定再重新调试一下Rime，并作此记录。\n卸载Rime输入法 # 为了排除一些不必要的影响，从0开始，首先就要卸载掉Mac（11.7.2）上原本的Rime。卸载的方法也很简单。只是删除几个配置/文件即可：\n找到系统偏好设置-\u0026gt;键盘-\u0026gt;输入法，删除鼠须管 从系统设置中移除鼠须管 删除配置文件夹 sudo rm -rf ~/Library/Rime 删除主应用程序 sudo rm -rf /Lirary/Input Method/Squirrel.app 重启电脑。\n若遇到Squirrel.app正在使用中，无法删除，则可能需要多次重启电脑。\n安装Rime输入法 # 这里没有直接使用〔东风破〕，而是使用brew安装：\nbrew install --cast squirrel\n完成后需要重新登入mac。\n此方式安装的squirrel版本是0.15.2，squirrel对MacOS 13以下支持的最高版本是0.16.2\n如果需要更新squirrel，参考 更新homebrew的安装包\n安装完成后的鼠须管没有任何配置，默认使用「朙月拼音」中文输入。\n此时的Rime是可用的状态，但是还没有恢复到之前的使用状态。配置文件夹也是空空如也。\n初始化状态下的squirrel配置文件夹 Rime的基本配置文件 # 这时候就需要使用〔东风破〕来安装配置文件了。\n首先需要安装基础配置以及基础词汇\ngit clone --depth 1 https://github.com/rime/plum.git cd plum bash rime-install prelude bash rime-install essay bash rime-install luna-pinyin essay可以不用安装，里面的有些词汇〔很奇怪〕。后续会使用搜狗的词库。\n克隆「东风破」项目到本地，进入项目文件夹。接下来分别安装：\n基础配置文件 预设词汇和语言模型 朙月拼音（为了更好的输入体验，小鹤双拼依赖朙月拼音的词库） 接下来安装双拼配置文件：\nbash rime-install double-pinyin\n一直到这里都并没有定制化。\n不过，通过〔东风破〕，鼠须管增加了很多默认配置文件，这些配置文件在自定义输入方案的时候，都不要去更改。接下来的部分，才是定制化输入法的内容。\n定制化 # 用户数据同步 # 编辑Rime配置文件夾下的installation.yaml，在文件最后加入以下内容：\nsync_dir: '/absolute/path/you/want/to/sync'\n手动创建sync文件夹，重新部署之后，即可同步用户数据。\n同步文件夾可以在硬盘任何地方，上述只是用作演示。\n同步鼠须管用户配置 定制化包括两部分，一是应用程序的配置，二是输入方案的配置。\n应用程序配置 # 📌Squirrel的配置支持「补丁」的方式，意即不用修改通过「plum」安装的默认配置，而是通过创建新的配置文件，以补丁的方式对其进行个性化设置。这样可以避免对默认配置文件作出修改而导致一系列难以排查的问题。\nSquirrel的配置文件通常以some_config.yaml命名，如果要定制化，只需要新创建一个some_config.custom.yaml配置文件，然后以patch为开头，进行配置即可。\nsquirrel.yaml文件主要配置了鼠鬚管輸入法的一些基本配置，如候選詞的排布方向，字体大小，配色方案等等，是最基础的配置。\n以下配置片段截取了一些重要的，仅供参考。\npatch: us_keyboard_layout: true # 鍵盤選項：應用美式鍵盤佈局 # 狀態通知，默認裝有Growl時顯示，也可設爲全開（always）全關（never） # show_notifications_when: growl_is_running style/horizontal: true # 候選窗横向顯示 # style/inline_preedit: false # 非內嵌編碼行 # style/font_face: \u0026#34;儷黑 Pro\u0026#34; # 我喜歡的字體名稱 style/font_point: 14 # 字號 # style/corner_radius: 10 # 窗口圓角半徑 # style/border_height: 0 # 窗口邊界高度，大於圓角半徑才有效果 # style/border_width: 0 # 窗口邊界寬度，大於圓角半徑才有效果 style/label_font_point: 14 # 候选词序号字号 建议和候选词字号一致 style/comment_font_point: 14 # 候选词的注释字号，建议一样或者小于候选词字号 style/color_scheme: cheese_blue # 選擇配色方案 style/corner_radius: 5 # 候选框圆角半径 如果安装完成squirrel之后，并没有发现squirrel.yaml这个配置文件，可以在安装包中找到。安装包的位置在/Library/Input Method/Squirrel.app，显示包内容就可拷贝一份放在配置文件夹里了（不拷贝也并无影响）。\n自定义squirrel的这些基础配置只需要创建squirrel.custom.yaml配置文件，并修改部分默认配置就行了。\n例如若觉得默认/自带的配色方案都不太喜欢，定制一份「专属」的配色方案也很简单，热心的社区提供了易用的 调色板 。\n实际上，上面的cheese_blue，就是我使用调色板自己捣鼓出来的。😁️\n某些特定的应用程序界面，可能只需要英文输入模式即可「如终端」，可以使用app_options标签对特定程序的输入方案进行定制：\napp_options: com.apple.Spotlight: ascii_mode: true com.alfredapp.Alfred: ascii_mode: true com.apple.Terminal: ascii_mode: true no_inline: true #... 上述配置已经包含在默认squirrel.yaml配置文件里了。\n输入方案默认配置 # default.yaml配置文件定义了输入方案选单、热键、候选字数量、punctuator〔谓句读处理器〕、recognizer〔谓规则匹配器〕等配置。\n以下列出了default.yaml的配置项（部分）\n# Rime default settings # encoding: utf-8 config_version: \u0026#39;0.40\u0026#39; schema_list: #输入方案列表 - schema: luna_pinyin - schema: luna_pinyin_simp - schema: luna_pinyin_fluency - schema: bopomofo switcher: # 切换输入方案的快捷键 caption: 〔方案選單〕 hotkeys: - Control+grave # ctrl + ` - Control+Shift+grave - F4 save_options: - full_shape - ascii_punct - simplification fold_options: true abbreviate_options: true option_list_separator: \u0026#39;／\u0026#39; menu: page_size: 5 #候选词数目 punctuator: # 自定义符号输入 full_shape: __include: punctuation:/full_shape half_shape: __include: punctuation:/half_shape key_binder: # 按键绑定 bindings: __patch: - key_bindings:/emacs_editing - key_bindings:/move_by_word_with_tab # 输入识别与匹配，一般用来连贯地输入含有字母和数字的组合，如id、邮箱等 # 一般来说，如果在中文输入模式下，想输入「mamba24」，就需要先输入「mamba」 # 然后「回车键」上屏，接着使用小键盘输入24， # 使用特定的模式匹配，可以连贯地输入mamba24 recognizer: patterns: email: \u0026#34;^[A-Za-z][-_.0-9A-Za-z]*@.*$\u0026#34; uppercase: \u0026#34;[A-Z][-_+.\u0026#39;0-9A-Za-z]*$\u0026#34; url: \u0026#34;^(www[.]|https?:|ftp[.:]|mailto:|file:).*$|^[a-z]+[.].+$\u0026#34; ascii_composer: # 设置caps、shift、control等键的作用 good_old_caps_lock: true switch_key: Shift_L: inline_ascii Shift_R: commit_text Control_L: noop Control_R: noop Caps_Lock: clear Eisu_toggle: clear 定制化的主要配置集中在：\nschema_list：配置输入方案 switcher/hotkeys：配置方案切换的快捷键 ascii_composer/switch_key：配置中/英切换的快捷键 menu/page_size：配置候选词数目 以下是default.custom.yaml配置示例：\n# 以补丁方式配置 patch: schema_list: - schema: double_pinyin_flypy # 仅保留小鹤双拼 # - schema: luna_pinyin # 全拼 # - schema: double_pinyin # 自然码 switcher: hotkeys: #输入选单切换快捷键 - \u0026#34;Control+grave\u0026#34; # 注意是control+`，不是command+` - \u0026#34;Shift+F4\u0026#34; # 避免按键冲突 save_options: - full_shape - ascii_punct - simplification - zh_hans - emoji_suggestion menu: page_size: 6 #候选字6个 ascii_composer: # 设置caps、shift、control等键的作用 good_old_caps_lock: false # 若为true，caps只切换大小写 switch_key: Caps_Lock: noop # 仅仅切换大小写 Shift_L: commit_code # 使用shift切换中英文 Shift_R: noop # MAC系统无法区分Shift/Control_L和R，因此都是L Control_L: noop Control_R: noop Eisu_toggle: clear mac原生输入法支持使用caps按键支持中/英切换，如若使用鼠须管，可以关闭这一偏好，让其仅作大小写切换。鼠须管使用shift切换〔中/英〕输入。\n小鹤双拼输入方案配置 # 上文提到的配置都算是输入引擎的通用性配置，如果想真正定制输入法，还得从double_pinyin_flypy.schema.yaml入手，这是小鹤双拼的配置项。稍作「补丁」，便可以让它更好为输入服务。\n关于schema.yaml内各配置项的具体解释，可以参照 schema.yaml释义，或者 输入法引擎与功能组件\n通俗地讲，输入法引擎获取键盘的输入，通过一系列的分析、匹配、处理，找到合适的规则，然后根据规则显示最匹配的候选字。而输入引擎里，所谓的「processors」、「segmentors」、「translators」和「filters」不过是处理键盘输入的先后流程罢了。\n而大部分的流程，都无需关心，需要处理的，仅仅是小部分。\n此文对小鹤双拼的定制化，主要集中在4个方面：\nemoji的支持 中英文混输，这是很多网络输入法自带的功能 模糊音，南方人太需要这个了😳 自定义短语，可以快速输入邮箱之类 日期和时间快速输入（小插件） 快速输入emoji # 使用「plum」安装指定输入法对emoji的支持 # bash rime-install emoji:customize:double_pinyin_flypy\n上述命令对〔小鹤双拼〕输入法安装了对emoji的支持，透过安装日志，其实可以看到实际上就是对double_pinyin_flypy.custom.yaml打上补丁。\nplum安装对小鹤双拼的emoji支持 查看配置文件，可以看到多了如下配置：\n# Rx: emoji:customize:schema=double_pinyin_flypy { #emoji支持 - patch/+: __include: emoji_suggestion:/patch # } 并且可以看到配置目录多了emoji_suggestion.yaml文件夹以及opencc文件夹里的「emoji词典」。\n此时，输入法的选单有一些小小的变化，即加入了emoji建议的开关：\nemoji支持安装完成后的输入法选单变化 调出此选单，按「6」可以选择开启或者关闭emoji建议。\n这要得益于emoji_suggestion.yaml的配置，这个配置是通过上述「patch」成为了double_pinyin_flypy.custom.yaml的配置。\n基于这种方式，也可以很方便地为其他输入方案引入emoji输入的支持。\n重新部署后，就可以直接在候选词中输入emoji：\n上图使用的小鹤双拼输入法，不过拼音显示的内容是全拼，这个〔缺陷〕会在后续配置中优化。\n需要注意的是，不同版本的系统可能对emoji的支持不同，可能会出现部分乱码，这样的候选字很影响输入体验。\n直接的处理方法，就是在opencc文件夹里面，找到对应的emoji字典，删掉里面乱码的内容🤭。\nemoji字典中可能会存在部分乱码的内容 自定义符号上屏 # 除了上面的方法之外，还有一个可以快速输入emoji的功能，就是借助于「punctuator」和「recognizer」以及symbols.yaml\n「punctuator」是「句讀處理器，將單個字符按鍵直接映射爲文字符號」，简单来讲，它可以快速让符号上屏。\n「recognizer」可以认作「匹配器」，用于匹配特定的输入码，使用的正则表达式进行匹配。\n因此，配合使用，可以获得如下的效果：\n即输入/tq，即可出现和「天气」有关的候选项。\n如何做呢，首先需要如下配置：\npatch: punctuator: import_preset: symbols #自定义表情输入 更多参见symbols.custom.yaml recognizer: patterns: punct: \u0026#34;^/([a-z]+|[0-9]0?)$\u0026#34; # 自定义符号上屏 默认地，symbols.yaml里定义了很多快速输入的符号，但是，我们可以定义更多，并且覆盖一些「略显繁琐」的默认配置。\n在自定义的symbols.custom.yaml配置文件中，还可以做更多的定制：\npatch: punctuator/import_preset: symbols punctuator/full_shape/+: \u0026#39;/\u0026#39; : [ ／, ÷ ] punctuator/half_shape/+: \u0026#39;/\u0026#39; : [ \u0026#39;/\u0026#39;, ÷ ] \u0026#39;@\u0026#39; : \u0026#39;@\u0026#39; punctuator/symbols/+: \u0026#34;/fs\u0026#34;: [½, ‰, ¼, ⅓, ⅔, ¾, ⅒ ] \u0026#34;/xh\u0026#34;: [ ＊, ×, ✱, ★, ☆, ✩, ✧, ❋, ❊, ❉, ❈, ❅, ✿, ✲] \u0026#34;/dq\u0026#34;: [🌍,🌎,🌏,🌐,🌑,🌒,🌓,🌔,🌕,🌖,🌗,🌘] \u0026#34;/sg\u0026#34;: [🍇,🍉,🍌,🍍,🍎,🍏,🍑,🍒,🍓,🍊,🍋,🫐,🍈,🥭,🥝] recognizer/patterns/punct: \u0026#39;^/([0-9]0?|[A-Za-z]+)$\u0026#39; 首先做的一件事情，就是覆盖了原来对于/符号的提示，默认的设置，输入/会显示、，､， /， ／〔全角〕， ÷候选项，可以根据喜好添加删除候选项即可。其次就是可以通过/xx的方式快捷输入emoji表情符号，对于常用emoji的人来说，这无异于天降甘霖啦😄️。\n中英文混输 # 通常，在中文模式下，直接输入英文并带补全「提示」是非常有必要的功能。幸好，使用插件解决可以满足这个功能：\nbash rime-install BlindingDark/rime-easy-en:customize:schema=double_pinyin_flypy 和emoji的支持一样，「东风破」的安装命令会在配置文件上打上「补丁」。\n# Rx: BlindingDark/rime-easy-en:customize:schema=double_pinyin_flypy #中英文混输 Typing English when using Chinese input-method __patch: - patch/+: __include: easy_en:/patch # 避免矫枉过正，true会把所有的字母组合当作英文作为候选词 easy_en/enable_sentence: false easy_en/enable_sentence开关的作用是，将任何输入的字符都作为英文候选，这样有点「过分敏感」了，通常需要将其设置为false。\n重新部署后，即可在中文输入模式下，实现英文输入：\n模糊音 # 模糊音若是用的多了，候选词往往会更混乱。但是对于前后鼻音拎不清的南方人来讲，没有模糊音，输入后鼻音真的好模糊😭️！所以还是想想怎样让鼠须管支持模糊音吧。\npatch: speller/algebra: #模糊音配置（部分），使用哪个就取消注释 - erase/^xx$/ # 第一行保留 #- derive/^([zcs])h/$1/ # zh, ch, sh =\u0026gt; z, c, s #- derive/^([zcs])([^h])/$1h$2/ # z, c, s =\u0026gt; zh, ch, sh # - derive/([aei])n$/$1ng/ # an =\u0026gt; ang en =\u0026gt; eng, in =\u0026gt; ing # - derive/([aei])ng$/$1n/ # ang =\u0026gt; an eng =\u0026gt; en, ing =\u0026gt; in # - derive/([u])an$/$1ang/ # uan =\u0026gt; uang # - derive/([u])ang$/$1an/ # uang =\u0026gt; uan 模糊音的配置项应位于〔拼写算法〕里，意为将在拼写时将a认作b。上面的配置文件列出了典型的模糊音配置。\n由于双拼有自己的键位映射，所以在配置模糊音时，需要将模糊音配置在键位映射（全拼转双拼）之前，这样模糊音才能生效，并且需要 在custom配置里，模糊音配置之后，重新「抄写」一遍双拼的键盘映射配置。\n具体的模糊音处理，参考 模糊音定製模板。\n自定义词典 # 在鼠须管中使用自定义词典也非常简单。只需要在对应输入方案的xxx.custom.yaml配置文件中添加如下配置即可：\n###使用自定义词典 custom_phrase.txt patch: custom_phrase: dictionary: \u0026#34;\u0026#34; user_dict: custom_phrase db_class: stabledb enable_completion: false #关闭逐键提示，精确匹配输入码的候选字即可 enable_sentence: false # 关闭输入法连打，此配置对双拼方案无效 initial_quality: 1 # 在translators列表配置第5项中加入配置，启用自定义词典 \u0026#34;engine/translators/@5\u0026#34;: table_translator@custom_phrase 上述配置中的@5意思是@n，意思是在列表项目配置中的第n个元素位设定新的值。常用用@last，表示在列表配置项最后加入配置。\n此外，还需要一个名字为custom_phrase.txt的用户字典（在鼠须管的配置文件目录下），字典的内容格式为〔候选字\\tab输入码\\tab权重（可省略）〕，\\tab表示各项以制表符（tab）分隔。\n重新部署后，既可以使用自定义短语。自定义短语用来快速输入邮箱📮️地址非常有用。\n日期时间动态输入 # 需要使用 这个拓展。\n具体的使用方法是：\nclone项目，找到项目中的sample文件夹，将lua文件夹和rime.lua文件拷贝到User/xxx/Library/Rime目录下。 修改使用的输入方案的配置文件，本文讨论的是double_pinyin_flypy.custom.yaml文件，添加如下配置： engine/translators/+: - lua_translator@date_translator # 日期候选 - lua_translator@time_translator # 时间候选 # 还有一些函数可以调用，参见rime.lua 重新部署后，就可以在输入选框中快速键入当前日期和时间了。\n其他杂项 # 双拼显示双拼码，不解析为全拼 # 在默认配置下，即使使用小鹤双拼方案，在键入输入码之后，屏上显示的依然是全拼，就像这样：\n对于习惯双拼上屏的用户来说，可能有一点别扭，此时，需要额外的配置，来使屏上直接显示键入码，而不「翻译」为全拼：\npatch: translator/preedit_format: [] #双拼显示双拼码，不解析为全拼 重新部署后生效。\n快速输入id，网址、邮箱等 # 前文已经提到过，recognizer/patterns可以用来匹配输入码，适合进行快速处理。利用这个机制，除了可以通过使用/bq快速输入表情之外，还可以做一些特别的事情：\npatch: recognizer: patterns: punct: \u0026#34;^/([a-z]+|[0-9]0?)$\u0026#34; # 自定义符号上屏 email: \u0026#34;^[A-Za-z][-_.0-9A-Za-z]*@.*$\u0026#34; # email快速上屏 uppercase: \u0026#34;[A-Z][-_+.\u0026#39;0-9A-Za-z]*$\u0026#34; # 大写英文直接上屏 #网址快速上屏 url: \u0026#34;^(www[.]|https?:|ftp[.:]|mailto:|file:).*$|^[a-z]+[.].+$\u0026#34; mypattern: \u0026#34;^icool[0-9]+$\u0026#34; # 直接输入id，而不需要先上屏icool 在中文输入模式下，如果要输入网址，邮箱等全英文的「字符串」，在不切换为英文输入模式的情况下，一般需要多次上屏操作，往往不能一次性连续的输入。而借助recognizer/patterns，则可以实现连续输入一次上屏。\n还可以自定义匹配模式，比如带数字的id，比如icool123，上面的最后一项自定义配置即可快速输入，不需要2次上屏。\n在注释掉上述url pattern后，在中文模式下不能快速输入网址，在输入www之后，接.会直接上屏：\n输入www。则会直接上屏 而在取消注释（即启用pattern）后，在中文输入模式下，可以直接输入网址：\n启用模式匹配后，输入www。会匹配模式而不上屏 其他匹配模式效果一致，不再一一例证。\n使用拓展词库 # 由于自带的luna_pinyin.dict.yaml词库实在有些贫瘠，我们可以使用拓展词库，以搜狗细胞词库为最佳。\n本文不讨论如何自己动手制作细胞词库了，感兴趣可以参考 Rime配置指南。\n使用起来也很简单，只需要先 从这里搞个现成的词库luna_pinyin.sogou.dict.yaml，放在Rime的配置目录下，然后在对应的自定义输入方案中使用该词库即可，本例中对应的配置文件是double_pinyin_flypy.custom.yaml，在其中添加如下配置：\ntranslator/dictionary: luna_pinyin.extended #使用拓充词库 如上所示，我们还需要一个luna_pinyin.extend.yaml配置，如下：\nname: luna_pinyin.extended # 词库名 version: \u0026#34;2021.02.07\u0026#34; sort: by_weight use_preset_vocabulary: true import_tables: - luna_pinyin - luna_pinyin.sogou #引入搜狗词库 重新部署即可。\n查看部署的日志 # 如果想知道配置自定义配置为什么没有生效，查看部署日志文件或许是一个可行的办法。\n以macOS 11.7.2为例，日志文件存放在/var/folders/9v/v3ws_2g90cg9_ntr7rmc8kpc0000gn/T目录下。 三个日志文件分别是：\nrime.squirrel.ERROR， 错误日志，主要查看 rime.squirrel.INFO， 信息级别，记录内容较多 rime.squirrel.WARNING，警告级别，可能会记录一些不影响使用的警告信息，如自定义配置缺失等 可以通过echo $TMPDIR来快速定位日志文件的目录。\n此次配置文件同步在 https://github.com/wangy325/squirrel_config，感兴趣的朋友可以自行下载使用。\nReferences:\n如何卸载Rime输入法 东风破 安装Rime squirrel.custom配置样例 squirrel-调色板 中英文混输 模糊音配置参考 日期动态输入 schema.yaml配置文件解释 Rime方案設計（中階） 鼠须管的部署日志 开箱即用的Rime配置 "},{"id":103,"href":"/zh/posts/2_%E6%9C%8D%E5%8A%A1%E5%99%A8OOM%E6%95%85%E9%9A%9C/","title":"一次服务器OOM故障","section":"Blog","content":"使用idm下载y2b视频导致服务器内存溢出，内核强制关闭了服务进程。\n通过系统日志定位原因，并介绍了服务器维护的几个相关命令。\n1 Linux系统日志 # 系统服务日志地址： /var/log/messages\nFeb 19 16:02:12 vultr kernel: oom-kill:constraint=CONSTRAINT_NONE,nodemask=(null),cpuset=/,mems_allowed=0,global_oom,task_memcg=/,task=firewalld,pid=1626,uid=0 Feb 19 16:02:12 vultr kernel: Out of memory: Killed process 1626 (firewalld) total-vm:358420kB, anon-rss:22096kB, file-rss:4kB, shmem-rss:0kB Feb 19 16:02:12 vultr kernel: oom_reaper: reaped process 1626 (firewalld), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB Feb 19 16:02:12 vultr systemd: firewalld.service: main process exited, code=killed, status=9/KILL Feb 19 16:02:12 vultr systemd: Unit firewalld.service entered failed state. Feb 19 16:02:12 vultr systemd: firewalld.service failed. 日志说明的很清楚了，内存溢出，系统杀掉了部分进程。\n至于是否网络请求占用了太多的系统资源，还需要进一步认证\n2 设置服务器时区 tzselect # 由于并非使用国内的服务器，也一直懒于管理，导致服务器的时区并非GMT+8，日志看起来非常的别扭，因此，将服务器时区顺道进行一番设置。\n设置时区的多种方法其中一种 参考：https://www.cnblogs.com/dead-trap-ramble/p/3462448.html\n服务器时区为+0，需要将其改为+8，这样系统日志的时间能够对应上。\n使用date -R命令查看当前系统时间/时区信息\n使用tzselect命令选择时区，中国大陆根据命令提示选择Asia/China/Beijing即可。\n命令执行完毕之后，还会提醒你将TZ='Asia/Shanghai'; export TZ写入到profile中，一般为根目录下的.bash_profile文件：\necho \u0026#34;TZ=\u0026#39;Asia/Shanghai\u0026#39;; export TZ\u0026#34; \u0026gt;\u0026gt; .bash_profile 随即使用\nsource .bash_profile 命令刷新配置文件，再使用date -R命令查看日期，已经和中国大陆时间同步。\n另外，为了防止服务器重启之后，配置失效[^没有实测]，可以覆盖系统的配置文件：\ncp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 这条命令会有一条警告信息，覆盖即可。\n3 查看并设置系统自启动服务 # 使用命令systemctl list-unit-files | grep enabled可以查看当前系统开机启动的服务信息。\n实际上，再centOS中，使用chkconfig --list命令也可以获取使用systemctl...命令的提示：\n# chkconfg --list Note: This output shows SysV services only and does not include native systemd services. SysV configuration data might be overridden by native systemd configuration. If you want to list systemd services use \u0026#39;systemctl list-unit-files\u0026#39;. To see services enabled on particular target use \u0026#39;systemctl list-dependencies [target]\u0026#39;. denyhosts 0:off 1:off 2:on 3:on 4:on 5:on 6:off netconsole 0:off 1:off 2:off 3:off 4:off 5:off 6:off network 0:off 1:off 2:on 3:on 4:on 5:on 6:off 可以简单的通过systemctl enable nginx将nginx服务加入到自启动服务列表里面去。\nlinux确实是通过配置文件控制服务的启动，此处尚且不展开这部分内容，更详细的内容可以参考：\nLinux中设置服务自启动的三种方式 linux开机启动服务的修改与查看 4 top命令是一个交互命令 # 控制台输入top可以查看当前系统的一些信息，并且这些信息是动态刷新的。\ntop命令是一个可交互的命令，可以通过快捷键指令进行交互，有一些常见的快捷指令：\nM：按照内存占用排序进程 m：切换内存占用的显示方式 P：按照cpu占用排序进程 更多的快捷指令可以参考：https://man.linuxde.net/top\n除了top之外，还有一个ps命令：http://c.biancheng.net/view/1062.html， 记住ps aux | grep xxx就行了^_^。\n"},{"id":104,"href":"/zh/docs/note/translations/guide-to-logback-cn/","title":"使用Logback记录日志","section":"翻译文章","content":" Logback是Java应用中使用最广的日志框架之一，它是 其前辈框架Log4j的替代者。相比Log4j，Logback在日志处理速度、配置多样性、对旧日志文件的处理灵活性上均要优于Log4j。\n这篇文章将介绍Logback的主要组成结构并指导你使用Logback构建更好的程序。\n1 Logback的组成结构 # Logback的主要组成结构有3部分：Logger、Appender、Layout。\nLogger指示日志信息的上下文背景（context）。Java应用会根据Logger去记录日志文件。\nAppender将日志文件保存到指定的位置。一个Logger可以配置多个Appender。我们一般认为Appender的功能就是将日志写成文本文件里，但是Logback能做的可不止这些。\nLayout决定日志的格式化信息。Logback的日志格式信息配置非常丰富，此外，Logback还支持自定义日志格式信息。\n2 配置Logback # 2.1 引入Maven依赖 # Logback使用SLF4j（Simple Logging Facade for Java）作为其原生接口。在开始之前，我们需要在pom.xml引入Logback和Slf4j的依赖。\n可能你的项目中已经引入了这两个依赖，因为spring/其他第三方jar很可能就使用Logback记录日志。\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;ch.qos.logback\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;logback-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.30\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 在Maven中央仓库中很容易找到这最新依赖：\nlogback-core： slf4j-api： 2.2 类路径 # 除了上述的logback-core和slf4j之外，Logback运行时还还需要在类路径中依赖logback-classic.jar\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;ch.qos.logback\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;logback-classic\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3 基础配置示例 # 我们先从一个快速开始开始吧。\n首先，我们需要一个配置文件。创建一个配置文件logback.xml并将其放在classpath resource中，并在配置文件中作如下简单配置：\n\u0026lt;configuration\u0026gt; \u0026lt;appender name=\u0026#34;STDOUT\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;root level=\u0026#34;debug\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;STDOUT\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt; 接下来，我们写一个简单的测试类：\npublic class Example { private static final Logger logger = LoggerFactory.getLogger(Example.class); public static void main(String[] args) { logger.info(\u0026#34;Example log from {}\u0026#34;, Example.class.getSimpleName()); } } 类Example创建了一个Logger，并且在main方法中调用了info()方法，以此来生成日志。\n当运行Example时，可以在控制台看到日志信息：\n20:34:22.136 [main] INFO Example - Example log from Example 你看，不到几分钟，Logback的使用就搞定了，知道Logback为什么这么流行了吧（笑）。\n别高兴，我们还是回头看看log.xml这个配置文件干了些啥吧：\n我们定义了一个Appender：STDOUT，引用的类是ConsoleAppender。 我们定义了日志信息输出格式模版。 Examlple类创建了一个Logger，我们通过info()方法将日志信息传递给它处理。 4 Logger上下文 # 4.1 创建Logger # 为了使用Logback记录日志，首先使用SLF4J创建一个Logger实例：\nprivate static final Logger logger = LoggerFactory.getLogger(Example.class); 随即我们就可以这样使用它：\nlogger.info(\u0026#34;Example log from {}\u0026#34;, Example.class.getSimpleName()); 上例中我们创建的Logger就是日志上下文。通过传递当前类对象给LoggerFactory的静态方法getLogger(Example.class)，即可获得当前类的日志上下文对象logger。当然，除了使用class作为参数之外，还可以使用字符串作为参数。\n日志上下文有等级（继承）关系，这点和Java的对象的继承关系很像：\n当一个Logger的名字后面跟随有点(.)时，其是一个祖Logger，点和其后的名字组成了子Logger。 当一个Logger没有既没有父Logger也没有Logger时，它自己就是一个就是一个父Logger。 例如在包com.baeldung.logback包中有一个类Example，其子包com.baeldung.logback.appenders中，有一个类ExampleAppender，那么ExampleAppender的Logger就是Example的子Logger。\n所有的Logger都是系统预定义的root Logger的子Logger。\nLogger拥有日志级别level，日志级别可以通过配置文件配置，也可以通过代码Logger.setLevel配置。在代码中的配置会覆盖配置文件中的配置。\n一般来说，日志级别按照优先级从低到高依次为：TRACE，DEBUG，INFO，WARN和ERROR。每个级别都有对应的处理日志的方法。\n如果一个Logger没有显式地配置日志级别，它从其最近的父Logger中继承日志级别。root Logger的默认级别是DEBUG。下文将展示如何配置并使用日志上下文。\n4.2 如何使用日志上下文 # 下面的示例展示了日志上下文的等级关系：\nch.qos.logback.classic.Logger parentLogger = (ch.qos.logback.classic.Logger) LoggerFactory.getLogger(\u0026#34;com.baeldung.logback\u0026#34;); parentLogger.setLevel(Level.INFO); Logger childlogger = (ch.qos.logback.classic.Logger)LoggerFactory.getLogger(\u0026#34;com.baeldung.logback.tests\u0026#34;); parentLogger.warn(\u0026#34;This message is logged because WARN \u0026gt; INFO.\u0026#34;); parentLogger.debug(\u0026#34;This message is not logged because DEBUG \u0026lt; INFO.\u0026#34;); childlogger.info(\u0026#34;INFO == INFO\u0026#34;); childlogger.debug(\u0026#34;DEBUG \u0026lt; INFO\u0026#34;); 运行程序，我们看到如下输出：\n20:31:29.586 [main] WARN com.baeldung.logback - This message is logged because WARN \u0026gt; INFO. 20:31:29.594 [main] INFO com.baeldung.logback.tests - INFO == INFO 首先我们创建一个名为com.baeldung.logback的parentLogger，并将其类型转换为ch.qos.logback.classic.Logger。\n日志上下文创建之后就要设置其日志级别，由于SLF4j的抽象Logger没有实现setLevel()方法，这也是我们在创建时候进行类型转换的原因。\n将日志上下文的日志级别设置为INFO，接下来创建一个名为com.baeldung.logback.tests的childLogger，由上面的表述可知，这个Logger是名为com.baeldung.logback的子Logger。\n每个Logger上下文都输出2个日志信息，Logback过滤了DEBUG日志，打印了WARN和INFO级别的日志。\n接下来，我们看看root logger的行为：\nch.qos.logback.classic.Logger logger = (ch.qos.logback.classic.Logger)LoggerFactory.getLogger(\u0026#34;com.baeldung.logback\u0026#34;); logger.debug(\u0026#34;Hi there!\u0026#34;); Logger rootLogger = (ch.qos.logback.classic.Logger)LoggerFactory.getLogger(org.slf4j.Logger.ROOT_LOGGER_NAME); logger.debug(\u0026#34;This message is logged because DEBUG == DEBUG.\u0026#34;); rootLogger.setLevel(Level.ERROR); logger.warn(\u0026#34;This message is not logged because WARN \u0026lt; ERROR.\u0026#34;); logger.error(\u0026#34;This is logged.\u0026#34;); 运行程序，我们看到如下输出：\n20:44:44.241 [main] DEBUG com.baeldung.logback - Hi there! 20:44:44.243 [main] DEBUG com.baeldung.logback - This message is logged because DEBUG == DEBUG. 20:44:44.243 [main] ERROR com.baeldung.logback - This is logged. 首先我们使用com.baeldung.logback的Logger输出DEBUG日志（其继承自root Logger的日志级别）。\n然后，我们通过静态域直接获取root Logger，并且将root Logger的日志级别改为ERROR。\n最后，我们看到Logback过滤了任何级别低于ERROR的日志。\n4.3 参数化日志输出 # 和上述使用的简单示例不同，大多数日志框架在打印日志信息时，都需要进行字符串拼接或者对象序列化操作，，这些操作都需要进行内存分配，和（可能的）垃圾回收操作。\n考虑下面的示例：\nlog.debug(\u0026#34;Current count is \u0026#34; + count); 这个示例增加了拼接信息的开销——无论这个消息是否被Logback过滤，都需要先进行消息拼接。\nLogback通过参数化消息提供了一个替代方案：\nlog.debug(\u0026#34;Current count is {}\u0026#34;, count); 大括号{}接收任何对象（Object），并且在确认这个消息会被使用后，才调用其toString()方法构建消息。\nLogback还支持其他形式的参数输出：\nString message = \u0026#34;This is a String\u0026#34;; Integer zero = 0; try { logger.debug(\u0026#34;Logging message: {}\u0026#34;, message); logger.debug(\u0026#34;Going to divide {} by {}\u0026#34;, 42, zero); int result = 42 / zero; } catch (Exception e) { logger.error(\u0026#34;Error dividing {} by {} \u0026#34;, 42, zero, e); } 以上片段将输出：\n21:32:10.311 [main] DEBUG com.baeldung.logback.LogbackTests - Logging message: This is a String 21:32:10.316 [main] DEBUG com.baeldung.logback.LogbackTests - Going to divide 42 by 0 21:32:10.316 [main] ERROR com.baeldung.logback.LogbackTests - Error dividing 42 by 0 java.lang.ArithmeticException: / by zero at com.baeldung.logback.LogbackTests.givenParameters_ValuesLogged(LogbackTests.java:64) ... 上面的示例展示了使用字符串，整型（int/Integer）作为日志输出参数。\n此外，当向日志方法传递Exception实例时，Logback将会打印异常的堆栈信息。\n5 Logback详细配置 # 在 第4节中，Logback仅仅使用了11行的基础配置，即可完成工作。这是Logback的默认行为，如果Logback没有发现配置文件，它将配置一个ConsoleAppender并将其和root logger关联。\n5.1 定位配置文件 # Logback的配置文件可以放置在classpath中，并且以logback.xml或者logback-test.xml命名。\nLogback发现配置文件的步骤如下：\n按序依次在classpath中在查找logback-test.xml,logback.groovy,logback.xml; 若没有发现上述文件，Logback将使用Java ServiceLoader加载com.qos.logback.classic.spi.Configurator的实现； 配置Logback的控制台日志输出 当前Logback版本不支持Groovy配置。？？\n5.2 基础配置 # 我们不妨重新看看第4节中的基础配置：\n\u0026lt;configuration\u0026gt; \u0026lt;appender name=\u0026#34;STDOUT\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;root level=\u0026#34;debug\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;STDOUT\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt; 所有Logback配置都置于\u0026lt;configuration\u0026gt;标签中。\n注意\u0026lt;appender\u0026gt;标签，我们将其指定为ConsoleAppender，并将其命名为STDOUT。其内部有一个\u0026lt;encoder\u0026gt;标签，该标签内部定义了\u0026lt;pattern\u0026gt;\u0026ndash;这是日志的输出格式。\n接下来是一个\u0026lt;root\u0026gt;标签，这个标签设置root logger的日志级别为DEBUG，并且将其输出与appender STDOUT相关联。\n5.3 配置文件定位BUG # Logback的配置文件有时候会相当复杂，因此Logback集成了一些机制来进行问题检测。\n如果想查看Logback处理日志时的debug信息，可以开启debug logging:\n\u0026lt;configuration debug=\u0026#34;true\u0026#34;\u0026gt; ... \u0026lt;/configuration\u0026gt; 如此做，Logback会在控制台打印加载配置文件时的状态信息：\n23:54:23,040 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Found resource [logback-test.xml] at [file:/Users/egoebelbecker/ideaProjects/logback-guide/out/test/resources/logback-test.xml] 23:54:23,230 |-INFO in ch.qos.logback.core.joran.action.AppenderAction - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender] 23:54:23,236 |-INFO in ch.qos.logback.core.joran.action.AppenderAction - Naming appender as [STDOUT] 23:54:23,247 |-INFO in ch.qos.logback.core.joran.action.NestedComplexPropertyIA - Assuming default type [ch.qos.logback.classic.encoder.PatternLayoutEncoder] for [encoder] property 23:54:23,308 |-INFO in ch.qos.logback.classic.joran.action.RootLoggerAction - Setting level of ROOT logger to DEBUG 23:54:23,309 |-INFO in ch.qos.logback.core.joran.action.AppenderRefAction - Attaching appender named [STDOUT] to Logger[ROOT] 23:54:23,310 |-INFO in ch.qos.logback.classic.joran.action.ConfigurationAction - End of configuration. 23:54:23,313 |-INFO in ch.qos.logback.classic.joran.JoranConfigurator@5afa04c - Registering current configuration as safe fallback point 若读取配置文件时出现警告或错误信息，Logback会将其状态信息输出到控制台。\n除了debug logging之外，还有另一种方式可以打印Logback的状态信息：\n\u0026lt;configuration\u0026gt; \u0026lt;statusListener class=\u0026#34;ch.qos.logback.core.status.OnConsoleStatusListener\u0026#34; /\u0026gt; ... \u0026lt;/configuration\u0026gt; StatusListener在Logback进行配置和程序运行时拦截状态信息，并将其输出。\n所有配置文件的状态信息都将输出，这样就很容易定位问题。\n5.4 自动重载配置文件 # 应用程序运行时自动重新加载配置文件往往能有助于定位程序bug。Logback通过scan参数来配置自动加载配置文件：\n\u0026lt;configuration scan=\u0026#34;true\u0026#34;\u0026gt; ... \u0026lt;/configuration\u0026gt; 默认情况下，Logback每60s扫描一次配置文件，通过scanPeriod参数改变这一配置：\n\u0026lt;configuration scan=\u0026#34;true\u0026#34; scanPeriod=\u0026#34;15 seconds\u0026#34;\u0026gt; ... \u0026lt;/configuration\u0026gt; 注意scanPeriod的赋值，其带有一个指示时间单位的字符串，其值可以是 milliseconds，seconds， minutes和hours。\n5.5 配置Loggers # 在之前的简单配置中，我们配置了root logger的日志级别，并将其与STDOUT（console Appender）相关联。\n实际上，我们可以设置任意多个logger:\n\u0026lt;configuration\u0026gt; \u0026lt;appender name=\u0026#34;STDOUT\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;logger name=\u0026#34;com.baeldung.logback\u0026#34; level=\u0026#34;INFO\u0026#34; /\u0026gt; \u0026lt;logger name=\u0026#34;com.baeldung.logback.tests\u0026#34; level=\u0026#34;WARN\u0026#34; /\u0026gt; \u0026lt;root level=\u0026#34;debug\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;STDOUT\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt; 使用如下代码片段测试此配置：\nLogger foobar = (ch.qos.logback.classic.Logger) LoggerFactory.getLogger(\u0026#34;com.baeldung.foobar\u0026#34;); Logger logger = (ch.qos.logback.classic.Logger) LoggerFactory.getLogger(\u0026#34;com.baeldung.logback\u0026#34;); Logger testslogger = (ch.qos.logback.classic.Logger) LoggerFactory.getLogger(\u0026#34;com.baeldung.logback.tests\u0026#34;); foobar.debug(\u0026#34;This is logged from foobar\u0026#34;); logger.debug(\u0026#34;This is not logged from logger\u0026#34;); logger.info(\u0026#34;This is logged from logger\u0026#34;); testslogger.info(\u0026#34;This is not logged from tests\u0026#34;); testslogger.warn(\u0026#34;This is logged from tests\u0026#34;); 输出的结果很容易预测，如果你没有猜中，那么有必要回头看看第5节Logger相关的内容。\n此测试的输出为：\n00:29:51.787 [main] DEBUG com.baeldung.foobar - This is logged from foobar 00:29:51.789 [main] INFO com.baeldung.logback - This is logged from logger 00:29:51.789 [main] WARN com.baeldung.logback.tests - This is logged from tests 若没有显式地配置logger，就像上例中的foobar一样，配置文件会自动配置它们，com.baeldung.foobar实际上继承了root logger的DEBUG日志级别。\nloggers还可以从root logger继承appender-ref，我们在接下来的配置中能够看到这点。\n5.6 定义属性变量 # Logback的配置文件支持配置变量，变量可以配置在\u0026lt;configuration\u0026gt;标签内的的任何地方。\n下例配置FileAppender时用到了变量：\n\u0026lt;property name=\u0026#34;LOG_DIR\u0026#34; value=\u0026#34;/var/log/application\u0026#34; /\u0026gt; \u0026lt;appender name=\u0026#34;FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.FileAppender\u0026#34;\u0026gt; \u0026lt;file\u0026gt;${LOG_DIR}/tests.log\u0026lt;/file\u0026gt; \u0026lt;append\u0026gt;true\u0026lt;/append\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%-4relative [%thread] %-5level %logger{35} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; 在配置appender之前，我们定义了一个属性变量LOG_DIR，接下来，在配置appender的文件地址时用到了这个变量。\n变量除了配置在\u0026lt;property\u0026gt;标签内部，还可以从外部源中获取\u0026ndash;例如从系统属性（system properties）中。如果忽略上面示例中的\u0026lt;property\u0026gt;标签配置，我们还可以这样使用它：\n$ java -DLOG_DIR=/var/log/application com.baeldung.logback.LogbackTests 通过系统属性指定变量键值对，在Logback配置文件中通过${propertyName}的方式即可获取变量的值。\n6 Appenders # loggers传递日志事件（logging events）给appenders。日志输出（记录）工作实际上是由appender完成的。通常我们认为“日志”就是在控制台或者日志文件中呈现一些内容，但是Logback能做的更多。Logback-core提供了几个有用的appender。\n6.1 控制台日志 # 此文到这里，ConsoleAppender相信你已经不再陌生了。ConsoleAppender主要用来向System.out或System.err追加信息。\n它使用OutputStreamWriter来缓冲I/O[^so directing it to System.err does not result in unbuffered writing]。\n6.2 文件日志 # FileAppender将日志信息追加到系统文件。它的配置相对复杂，让我们先试试在之前的配置文件中增加一个FileAppender配置：\n\u0026lt;configuration debug=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;appender name=\u0026#34;STDOUT\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;!-- encoders are assigned the type ch.qos.logback.classic.encoder.PatternLayoutEncoder by default --\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;appender name=\u0026#34;FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.FileAppender\u0026#34;\u0026gt; \u0026lt;file\u0026gt;tests.log\u0026lt;/file\u0026gt; \u0026lt;append\u0026gt;true\u0026lt;/append\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%-4relative [%thread] %-5level %logger{35} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;logger name=\u0026#34;com.baeldung.logback\u0026#34; level=\u0026#34;INFO\u0026#34; /\u0026gt; \u0026lt;logger name=\u0026#34;com.baeldung.logback.tests\u0026#34; level=\u0026#34;WARN\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;FILE\u0026#34; /\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;root level=\u0026#34;debug\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;STDOUT\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt; FilesAppender通过\u0026lt;file\u0026gt;标签来配置日志文件地址。\n\u0026lt;append\u0026gt;标签配置布尔值true，意味着追加日志信息到文件，而不是抹掉之前的信息。若我们多次运行，会发现日志文件记录了所有的运行日志。\n注意logger com.baeldung.logback.tests的配置：上例中将其日志级别设置为WARN，并且将其和FILE appender关联，这意味着此logger WARN级别以上的日志将会在日志文件test.log中记录。同时，由于其本身继承自root logger，所以控制台会输出其DEBUG级别的日志，如此，便记录了重复的日志。\nLogback可以改变子logger的行为，使其和root logger独立工作：\n\u0026lt;logger name=\u0026#34;com.baeldung.logback.tests\u0026#34; level=\u0026#34;WARN\u0026#34; additivity=\u0026#34;false\u0026#34; \u0026gt; \u0026lt;appender-ref ref=\u0026#34;FILE\u0026#34; /\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;root level=\u0026#34;debug\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;STDOUT\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; 通过将additivity属性设置为false，可以改变logger的默认行为，logger com.baeldung.logback.tests及其导出logger的日志将不再显示在控制台。\n6.3 滚动文件日志 # 多数时候，将日志文件记录到一个文件中并不是我们期待的（可能会记录一个达几个G的文本文件）。我们常希望日志文件能够基于日期、文件大小、或二者联合配置来“滚动”记录。\n因此，Logback提供了RollingFileAppender：\n\u0026lt;property name=\u0026#34;LOG_FILE\u0026#34; value=\u0026#34;LogFile\u0026#34; /\u0026gt; \u0026lt;appender name=\u0026#34;FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.rolling.RollingFileAppender\u0026#34;\u0026gt; \u0026lt;file\u0026gt;${LOG_FILE}.log\u0026lt;/file\u0026gt; \u0026lt;rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.TimeBasedRollingPolicy\u0026#34;\u0026gt; \u0026lt;!-- daily rollover --\u0026gt; \u0026lt;fileNamePattern\u0026gt;${LOG_FILE}.%d{yyyy-MM-dd}.gz\u0026lt;/fileNamePattern\u0026gt; \u0026lt;!-- keep 30 days\u0026#39; worth of history capped at 3GB total size --\u0026gt; \u0026lt;maxHistory\u0026gt;30\u0026lt;/maxHistory\u0026gt; \u0026lt;totalSizeCap\u0026gt;3GB\u0026lt;/totalSizeCap\u0026gt; \u0026lt;/rollingPolicy\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%-4relative [%thread] %-5level %logger{35} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; RollingFileAppender需要配置滚动策略（rolling policy），上面的示例配置中，我们配置了TimeBasedRollingPolicy。\n和FileAppender类似，RollingFileAppender首先需要配置文件名，上例使用了占位符变量填充的方式配置文件名，这种方式前文已经说过了。\n让我看看\u0026lt;rollingPolicy\u0026gt;标签的配置，\u0026lt;fileNamePattern\u0026gt;的配置值不仅仅定义了日志文件的名字，还定义了其滚动策略。TimeBasedRollingPolicy检查fileNamePattern并且按照友好的方式滚动日志文件。\n例如：\n\u0026lt;property name=\u0026#34;LOG_FILE\u0026#34; value=\u0026#34;LogFile\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;LOG_DIR\u0026#34; value=\u0026#34;/var/logs/application\u0026#34; /\u0026gt; \u0026lt;appender name=\u0026#34;FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.rolling.RollingFileAppender\u0026#34;\u0026gt; \u0026lt;file\u0026gt;${LOG_DIR}/${LOG_FILE}.log\u0026lt;/file\u0026gt; \u0026lt;rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.TimeBasedRollingPolicy\u0026#34;\u0026gt; \u0026lt;fileNamePattern\u0026gt;${LOG_DIR}/%d{yyyy/MM}/${LOG_FILE}.gz\u0026lt;/fileNamePattern\u0026gt; \u0026lt;totalSizeCap\u0026gt;3GB\u0026lt;/totalSizeCap\u0026gt; \u0026lt;/rollingPolicy\u0026gt; ... 上述配置中，当前活动的配置文件是/var/logs/application/LogFile，这个文件在每月开始即滚动至 /Current Year/Current Month/LogFile.gz，之后，RollingFileAppender会再创建一个新的活动日志文件LogFile。\n当所有日志文件大小达到3GB之后，RollingFileAppender会删除最早的日志文件。\n滚动周期的设置很灵活，可以是月，周，日，时，分，秒，甚至毫秒。\nRollingFileAppender还支持日志文件压缩，上例中，由于使用了.gz的文件后缀，滚动日志文件将被压缩。\n需要说明的是，TimeBasedRollingPolicy并不是滚动日志的唯一选择，Logback同时还提供了SizeAndTimeBasedRollingPolicy，它能够同时根据当前日志文件大小和时间来决定日志的滚动策略。此外，Logback还提供FixedWindowRollingPolicy，其在每次日志系统启动的时候滚动日志。\n此外，Logback还支持自定义日志滚动策略，具体细节可以参考：https://logback.qos.ch/manual/appenders.html#onRollingPolicies\n6.4 自定义Appender # 通过继承Logback的任一基础appender类，就可以自定义我们自己的appender了， 这里有一个示例。\n7 日志输出格式 # 虽然日志输出格式能够 自定义，不过，由于可选参数组合太多，往往花费时间反而得不到想要的效果。实际上，默认的输出格式能够满足大多数应用的需求。\n目前示例中使用的输出格式是：\n\u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; 这段配置脚本配置了PatternLayoutEncoder，通过向Appender传递Encoder，Encoder中配置的pattern将会应用到日志输出格式上。\n输出模式（PatternLayout）通过大量转换以及格式修饰符来决定日志输出的格式。\n我们不妨拆解一下上面的pattern，Logback PatternLayout通过%前缀来识别转换符，所以上述配置中的转换符有：\n%d{HH:mm:ss.SSS}，包含时分秒、毫秒的时间戳； [%thread]，使用方括号包括的生成日志的线程名； %-5level，日志级别，padded to 5 characters； %logger{36}，logger名字，压缩至36个字符内； %msg%n，日志信息+系统换行符 如此配置之后，我们可以看到类似这样的日志输出：\n21:32:10.311 [main] DEBUG com.baeldung.logback.LogbackTests - Logging message: This is a String 完整的转换以及格式修饰符可以查看 这里的官方文档。\n8 总结 # 这篇教程总结了Logback的基础用法。\n文章介绍了Logback架构中的3个主要构件：loggers，appenders和layout。Logback配置文件功能丰富强大，通过其可以控制日志的过滤以及格式化规则。此外，本文还介绍了2个经常使用的appender，通过appender配置，Logback可以按照需求进行日志的创建、滚动、组织和压缩。\n原文地址: https://www.baeldung.com/logback\n"},{"id":105,"href":"/zh/posts/17_xxl-sharding-job/","title":"在xxl-job中使用分片任务","section":"Blog","content":"本文介绍在如何在 xxl-job中使用创建并使用分片任务。\nxxl-job是国内开源的一款轻量级分布式任务调度平台，开发者是大众点评的工程师，其目前维护一个 开源社区，里面还有很多已经发布或尚在孵化的开源项目。\n任务分片是一个以空间换时间的概念，旨在将耗时任务进行拆分，然后同时执行，拆分之后执行的结果对任务任务原来不分片执行的结果没有影响。\n比如要核对id从1-1000的用户的邮箱信息，找出无效的邮箱信息。可以将id分成合适的多小段，1-100，101-200，\u0026hellip;，901-1000，然后交给不同的任务去执行。这就是任务分片的简单模型。\n在阅读此文之前，需要理解xxl-job的基本模型与工作流程，其核心概念有2:\n调度中心\n负责管理调度信息，按照调度配置发出调度请求，自身不承担业务代码。调度系统与任务解耦，提高了系统可用性和稳定性，同时调度系统性能不再受限于任务模块；\n支持可视化、简单且动态的管理调度信息，包括任务新建，更新，删除，GLUE开发和任务报警等，所有上述操作都会实时生效，同时支持监控调度结果以及执行日志，支持执行器Failover。\n执行器\n负责接收调度请求并执行任务逻辑。任务模块专注于任务的执行等操作，开发和维护更加简单和高效；接收“调度中心”的执行请求、终止请求和日志请求等。\n调度中心自动发现并注册执行器，并且通过执行器提供的api对任务进行调度（执行/终止等操作）。\n本文测试所使用的xxl-job所有模块基于最新的迭代版本v2.3.0，此次迭代中配置分片任务的方式与之前版本有些许不同：\n【新增】新增任务辅助工具 XxlJobHelper：提供统一任务辅助能力，包括：任务上下文信息维护获取（任务参数、任务ID、分片参数）、日志输出、任务结果设置……等； ShardingUtil 组件废弃：改用 XxlJobHelper.getShardIndex()/getShardTotal(); 获取分片参数； XxlJobLogger 组件废弃：改用 XxlJobHelper.log 进行日志输出； 其他更新日志可以查看该版本的 RELEASE NOTE\n在xxl-job中，可以通过两种方式实现分片任务：\n单实例多任务执行分片，等效于前文中的例子，将一个大任务拆分成多个小任务； 多实例单任务执行分片，将任务按照一定的方式分配到多个实例上去运行——以多个实例上配置相同的任务为前提； 模拟需要完成的工作 # 在开始之前，我们先模拟需要完成的工作：有100个账户，每个账户有随机1-10条数据需要处理。代码片段如下\nprivate final static Random RAND = new Random(47); /** * 100 ids */ private static final List\u0026lt;Integer\u0026gt; CITY_ID_LIST = new ArrayList\u0026lt;Integer\u0026gt;() {{ for (int i = 1; i \u0026lt;= 100; i++) { add(i); } }}; /** * task num for each id */ private static int task_num_per_id; /** * 任务数据库 */ private static final Map\u0026lt;Integer, List\u0026lt;String\u0026gt;\u0026gt; TASKS; static { TASKS = new HashMap\u0026lt;\u0026gt;(); CITY_ID_LIST.forEach(city -\u0026gt; { task_num_per_id = RAND.nextInt(10); List\u0026lt;String\u0026gt; cityTasks = new ArrayList\u0026lt;\u0026gt;(task_num_per_id); IntStream.rangeClosed(1, task_num_per_id).forEach(index -\u0026gt; { String orderInfo = city + \u0026#34;------NO.\u0026#34; + index; cityTasks.add(orderInfo); }); TASKS.put(city, cityTasks); }); } 单实例多任务分片 # 当使用单执行器实例时，我们可以在调度中心创建多个任务，通过分配不同的任务参数来实现任务的分片。任务的实现代码如下所示：\n@XxlJob(\u0026#34;singleExecutorMultiThreads\u0026#34;) public void singleExecutorMultiThreadsCityJob() throws Exception { // 当不配置参数时，此方法返回空字符串\u0026#34;\u0026#34; String shards = XxlJobContext.getXxlJobContext().getJobParam(); XxlJobHelper.log(\u0026#34;XXL-JOB, 单机分片任务开始. 分片参数：{}\u0026#34;, shards); if (StringUtils.isEmpty(shards)) { // XxlJobHelper.handleFail(\u0026#34;任务参数不能为空！\u0026#34;); // 不分片，全量执行 IntStream.range(0, CITY_ID_LIST.size()) .forEach(i -\u0026gt; { int cityId = CITY_ID_LIST.get(i); List\u0026lt;String\u0026gt; task = TASKS.get(cityId); task.forEach(t -\u0026gt; XxlJobHelper.log(\u0026#34;【{}】执行【{}】， 任务内容为：{}\u0026#34;, Thread.currentThread().getName(), cityId, t)); }); } else { // 分片执行 Arrays.stream(shards.split(\u0026#34;,\u0026#34;)) .map(String::trim) .filter(StringUtils::isNotBlank) .map(Integer::parseInt) .forEach(cityId -\u0026gt; { List\u0026lt;String\u0026gt; task = TASKS.get(cityId); Optional.ofNullable(task).ifPresent(todoTasks -\u0026gt; { todoTasks.forEach(t -\u0026gt; XxlJobHelper.log(\u0026#34;【{}】执行【{}】， 任务内容为：{}\u0026#34;, Thread.currentThread().getName(), cityId, t)); }); }); } } 在调度中心，我们可以像这样创建分片任务：\n可以根据情况创建任务数，来进行单实例复杂任务的分片。\n配置完成后的任务列表看起来像这样：\n这2个任务使用不同的任务参数，其他配置可以大体相同甚至完全一致。\n这里需要说明的是， 当前版本对于任务参数的处理做了修改，JobHandler中的方法不再直接直接调用含有参数的任务方法，而是通过XxlJobContext.getXxlJobContext().getJobParam()直接在任务中获取分片参数。\n配置完成之后，我们执行任务，即可以看到调度日志（部分）：\n可以看到，执行器开启了不同的线程分别执行分片任务，这样可以节省任务执行的时间开销。\n这就是xxl-job的单实例分片任务创建方法。\n需要说明的是，上面的任务如果不设置分片参数，那么将会执行全部的任务。\n多实例分片广播 # 在多执行器实例的情况下，分片任务有多种路由策略，此处暂且不讨论路由策略，在分片广播的模式下进行测试。分片任务的实现代码如下：\n@XxlJob(\u0026#34;multiExecutorsSharding\u0026#34;) public void multiExecutorShardingCityJob() throws Exception { XxlJobHelper.log(\u0026#34;XXL-JOB, 多实例分片任务开始.\u0026#34;); int shardIndex = XxlJobHelper.getShardIndex(); int shardTotal = XxlJobHelper.getShardTotal(); IntStream.range(0, CITY_ID_LIST.size()).forEach(i -\u0026gt; { if (i % shardTotal == shardIndex) { int cityId = CITY_ID_LIST.get(i); List\u0026lt;String\u0026gt; task = TASKS.get(cityId); Optional.ofNullable(task).ifPresent(todoTasks -\u0026gt; { todoTasks.forEach(t -\u0026gt; XxlJobHelper.log(\u0026#34;实例【{}】执行【{}】， 任务内容为：{}\u0026#34;, shardIndex, cityId, t)); }); } }); } 可以看到，实际上是通过对所有执行器实例id取模的方式，将任务均匀地分配到所有的执行器上去执行。\n调度中心创建任务像这样：\n在这个模式下，任务并没有设置分片参数，不过我们需要额外启动一个执行器实例：\njava -jar -Dserver.port=8082 -Dxxl.job.executor.port=9998 xxl-job-executor-sample-springboot-2.3.0-SNAPSHOT.jar 上述指定的端口需要和之前的实例不同即可。\n运行任务成功之后，我们可以看到调度日志（部分）：\n从日志可以看出，任务被规律地分配到了2个执行器实例上。\n参考 # XXL-JOB任务分片-伊布拉西莫-csdn "},{"id":106,"href":"/zh/docs/note/translations/how2use-printf/","title":"使用printf格式化输出","section":"翻译文章","content":"这篇文章介绍了几种常见的使用printf()方法进行格式化输出的方法。\nprintf()方法隶属于java.io.PrintStream类，提供了和C语言中相似的格式化字符串输出的方法。\n1 语法 # printf()有一些重载方法，可以用来格式化输出：\nSystem.out.printf(format, arguments); System.out.printf(locale, format, arguments); format参数1用来指定格式化规则，一般以百分号%开头。\n在进一步剖析格式化规则之前，不妨看一个简单的例子：\nSystem.out.printf(\u0026#34;Hello %s!%n\u0026#34;, \u0026#34;World\u0026#34;); 上面的代码输出如下内容：\nHello World! 如上所示，格式化参数包含一个字符串（Hello）和2个格式化规则。第一个规则（%s）用来格式化字符串参数（World），第二个规则（%n）则表示在末尾添加一个换行符。\n1.1 格式化规则 # 格式化参数由纯字符串以及格式化标志符组成，其中格式化标志符包括标记（flags）、宽度、精度、转换字符组成：\n%[flags][width][.precision]conversion-character\nSpecifiers in the brackets are optional. 方括号内的标识符是可选的。\n实际上，printf()使用 java.util.Formatter类来转换格式字符串并进行输出。完整的格式化选项可以从Formatter的 Javadoc中获取。\n1.2 转换字符 # The conversion-character is required and determines how the argument is formatted. Conversion characters are only valid for certain data types. Some common ones are: 转换字符是必须的，其决定如何格式化传入的字符串参数。转换字符对应指定的数据类型，一些常见的转换字符有：\ns – 用来格式化字符串 d –用来格式化小数 f – 用来格式化浮点数 t– 用来格式化日期/时间类型 下文会详细解释这些和一些其他转换字符。\n2.3 可选修饰符 # The [flags] define standard ways to modify the output and are most common for formatting integers and floating point numbers. [flags]定义了修改输出的标准方法，是用来格式化整数和浮点数的最常用方法。\nThe [width] specifies the field width for outputting the argument. It represents the minimum number of characters written to the output. [width]约定了输出参数的宽度（占位），它约定的是输出的最小字符数。\nThe [.precision] specifies the number of digits of precision when outputting floating-point values. Additionally, we can use it to define the length of a substring to extract from a String. [.precision]约定了浮点数的数据精度，此外，还可以通过其来约定格式化时字符串的长度。\n2 换行符 # 使用%n来将字符串换行：\nSystem.out.printf(\u0026#34;baeldung%nline%nterminator\u0026#34;); 上述代码的输出像这样：\nbaeldung line terminator printf()方法中的%n会自动插入当前系统中的换行符2。\n3 布尔值的格式化 # printf()使用%b来格式化布尔值，当传入的值（？）是true，其输出true，否则输出false。\n参考下例：\nSystem.out.printf(\u0026#34;%b%n\u0026#34;, null); System.out.printf(\u0026#34;%B%n\u0026#34;, false); System.out.printf(\u0026#34;%B%n\u0026#34;, 5.3); System.out.printf(\u0026#34;%b%n\u0026#34;, \u0026#34;random text\u0026#34;); 上面的输出为：\nfalse FALSE TRUE true 可以%B来使printf输出大写。\n4 字符串格式化 # printf()使用%s来格式化字符串。同样地，%S用于输出大写。\n如代码\nprintf(\u0026#34;\u0026#39;%s\u0026#39; %n\u0026#34;, \u0026#34;baeldung\u0026#34;); printf(\u0026#34;\u0026#39;%S\u0026#39; %n\u0026#34;, \u0026#34;baeldung\u0026#34;); 输出:\n'baeldung' 'BAELDUNG' 前文提过，可以使用[width]来约定字符串的最小长度：\nprintf(\u0026#34;\u0026#39;%15s\u0026#39; %n\u0026#34;, \u0026#34;baeldung\u0026#34;); printf(\u0026#34;\u0026#39;%1s\u0026#39; %n\u0026#34;, \u0026#34;baeldung\u0026#34;); 输出为:\n' baeldung' 'baeldung' 从输出可知，默认格式为右对齐，并且当字符串长度大于约定的最小长度时，witdh配置无效。\n如果想使输出左对齐，可以添加-标记（flags）\n如\nprintf(\u0026#34;\u0026#39;%-10s\u0026#39; %n\u0026#34;, \u0026#34;baeldung\u0026#34;); 将输出:\n'baeldung ' 此外，可以通过[.precision]控制输出字符串的字符数：\nSystem.out.printf(\u0026#34;%2.2s\u0026#34;, \u0026#34;Hi there!\u0026#34;); System.out.printf(\u0026#34;%10.2s\u0026#34;, \u0026#34;Hi there!\u0026#34;); System.out.printf(\u0026#34;%1.2s\u0026#34;, \u0026#34;Hi there!\u0026#34;); %x.ys 格式中的\u0026rsquo;x\u0026rsquo;代表width，\u0026lsquo;y\u0026rsquo;代表precision。\n所以，上例中的输出为：\nHi Hi Hi 可以看到，precision参数控制着输出字符的个数。\n5 字符格式化 # The result of %c is a Unicode character: printf()使用%c来格式化Unicode字符。同样地，%C用于输出大写。\nSystem.out.printf(\u0026#34;%c%n\u0026#34;, \u0026#39;s\u0026#39;); System.out.printf(\u0026#34;%C%n\u0026#34;, \u0026#39;s\u0026#39;); 输出:\ns S 值得一提的是，如果传入无效参数，将会抛出IllegalFormatConversionException。\n6 数字格式化 # 6.1 整数格式化 # printf() 方法使用%d来格式化整型，其接受所有Java语言的整数： byte、short、 int、 long以及BigInteger。\nSystem.out.printf(\u0026#34;simple integer: %d%n\u0026#34;, 10000L); 在\u0026rsquo;d\u0026rsquo;的作用下，上例的输出为：\nsimple integer: 10000 有时候，可能需要千位分隔符来使较大的数据更易读，可以使用,标记。并且可以根据不同地区的使用规范来使用不同的分隔符：\nSystem.out.printf(Locale.US, \u0026#34;%,d %n\u0026#34;, 10000); System.out.printf(Locale.ITALY, \u0026#34;%,d %n\u0026#34;, 10000); 如我们所见，美国和印度锁使用的千位分隔符是不同的：\n10,000 10.000 6.2 浮点数和双精度浮点数格式化 # 使用 %f 来格式化浮点数:\nSystem.out.printf(\u0026#34;%f%n\u0026#34;, 5.1473); 输出:\n5.147300 看到这个输出，我们首先想到的就是控制精度：\nSystem.out.printf(\u0026#34;\u0026#39;%5.2f\u0026#39;%n\u0026#34;, 5.1473); 上例中，我们约定了数字占用字符宽度[width]为5，小数部分的长度[.precision]为2:\n' 5.15' 可以看到，输出的数字开头存在1个字符的空白填充——由于约定的宽度为5。\n此外，为了获取科学计数法输出，只需要使用%e转换字符即可：\nSystem.out.printf(\u0026#34;\u0026#39;%5.2e\u0026#39;%n\u0026#34;, 5.1473); 将输出：\n'5.15e+00' 7 日期和时间格式化 # 至于日期和时间的格式化，需要使用t或T加上一些特殊含义的后缀组合。下面的示例中展示了一些常用的日期时间格式化的后缀字符。\n实际上，Java8提供了更加完整易用的 DateTimeFormatter来进行日期时间的格式化3。\n7.1 时间格式化 # 首先介绍关于常用时间格式化的后缀字符及其含义：\nH, M, S – 时/分/秒 L, N – 毫秒/纳秒 p – 上午/下午（am/pm） z – 时区 接下来，试试格式化输出日期：\nDate date = new Date(); System.out.printf(\u0026#34;%tT%n\u0026#34;, date); \u0026lsquo;%tT\u0026rsquo; 格式输出如下所示：\n13:51:15 如果需要更详细的输出，不妨看看使用上面的后缀字符：\nSystem.out.printf(\u0026#34;hours %tH: minutes %tM: seconds %tS%n\u0026#34;, date, date, date); 通过使用‘H’，‘M’，‘S’，得到如下输出：\nhours 13: minutes 51: seconds 15 你肯定会觉得要获取一个时间单位，就要传入一个date实例很麻烦，Java的设计者也是这么认为，所以，可以通过使用参数索引字符1$来规避掉需要重复传递的参数：\nSystem.out.printf(\u0026#34;%1$tH:%1$tM:%1$tS %1$tp %1$tL %1$tN %1$tz %n\u0026#34;, date); 看，借助1$，传入一个date实例就获取了所有的信息：\n13:51:15 pm 061 061000000 +0400 7.2 日期格式化 # 和时间格式化类似，日期格式化也有特定的字符后缀：\nA – 输出星期全名 d – 输出2位数的日期 B – 输出完整的月份名称 m – 输出2位数的月份 Y – 输出4位数的年份 y – 输出2位数的年份 如果我们想打印星期，可以这样做：\nSystem.out.printf(\u0026#34;%1$tA, %1$tB %1$tY %n\u0026#34;, date); 输出：\nThursday, November 2018 也可以获得数字形式的输出：\nSystem.out.printf(\u0026#34;%1$td.%1$tm.%1$ty %n\u0026#34;, date); 输出：\n22.11.18 8 总结 # 此文讨论了printf()的常见用法，介绍了使用printf()对常见数据类型进行格式化输出的方法。\n原文地址 Formatting with printf() in Java 下文统称为格式化参数，其本身也是一个字符串。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nwindows系统的默认换行符为\u0026rsquo;\\r\\n\u0026rsquo;（回车换行），linux/unix下为\u0026rsquo;\\n\u0026rsquo;。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n关于Java8的新日期时间库，也可以参考 这篇文章\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":107,"href":"/zh/posts/0_%E5%AE%89%E8%A3%85%E5%8D%95%E6%9C%BA%E7%89%88fdfs%E6%9C%8D%E5%8A%A1%E7%9A%84%E9%97%AE%E9%A2%98/","title":"单机版fdfs服务遇到的问题","section":"Blog","content":" 此文章记录的内容已经过时，现在有更好的文件存储方案，如 minIO。 简单记录了2个在安装单机版fdfs服务遇到的问题，虽然报错信息不同，但是问题出在同一个地方：\nnginx版本与ngx_http_fastdfs_module版本 nginx版本1.16.1 module版本1.20\n这个版本的混用会导致编译和配置时分别遇到致命错误\nnginx1.12编译出现 /usr/include/fastdfs/fdfs_define.h:15:27: fatal error: common_define.h: No such file or directory\n按照1法解决编译问题之后，紧接着会出现配置文件错误 unknown directive \u0026quot;ngx_http_fastdfs_module\u0026quot;，个人推测虽然在解决第一个问题（通过修改fdfs_module的配置文件使得编译通过）时，nginx的模块实际上没有安装成功\n模块安装成功的标志是\n[root@shell ~]# nginx -V nginx version: nginx/1.12.1 built by gcc 4.8.5 20150623 (Red Hat 4.8.5-36) (GCC) configure arguments: --add-module=/opt/fdfs/fastdfs-nginx-module-revise/src 最后使用nginx-1.12.0以及\n# 这里为啥这么长一串呢，因为最新版的master与当前nginx有些版本问题 # wget https://github.com/happyfish100/fastdfs-nginx-module/archive/5e5f3566bbfa57418b5506aaefbe107a42c9fcb1.zip # 解压 # unzip 5e5f3566bbfa57418b5506aaefbe107a42c9fcb1.zip # 重命名 # mv fastdfs-nginx-module-5e5f3566bbfa57418b5506aaefbe107a42c9fcb1 fastdfs-nginx-module-master 解决问题：\ncentOS上安装nginx有2种方式1\n通过包管理器（yum命令）安装（未测试） 通过源码安装 这里说一下通过源码安装的几个点：\n网络上的其他教程说的比较细致了，几个依赖一定要先安装\nyum install gcc-c++ yum install -y pcre pcre-devel yum install -y zlib zlib-devel yum install -y openssl openssl-devel 如果./configure命令后面不接 任何参数的话，nginx默认安装在/usr/local/nginx下，以及nginx启动需要的作用资源均在此目录下\n[root@shell nginx-1.12.1]# ./configure --help --help print this message --prefix=PATH set installation prefix --sbin-path=PATH set nginx binary pathname --modules-path=PATH set modules path --conf-path=PATH set nginx.conf pathname --error-log-path=PATH set error log pathname --pid-path=PATH set nginx.pid pathname --lock-path=PATH set nginx.lock pathname ...省略内容 ... 如上可以自定义编译nginx的参数，这也是能为nginx添加ngx_http_fastdfs_modul模块的原因。\n题外：如果安装过程完全参照 这篇文章的话，或许就不会有这个问题了\n使用 nginx官网推荐的方式安装最方便\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":108,"href":"/zh/posts/3_%E5%85%B3%E4%BA%8Eforever%E5%90%AF%E5%8A%A8node%E6%9C%8D%E5%8A%A1%E7%9A%84%E9%97%AE%E9%A2%98/","title":"关于forever启动node服务的问题","section":"Blog","content":"在使用jenkins自动构建node.js项目的时候，由于对forever的不熟悉，构建脚本一直存在一点小问题。\n现在简单记录下整个node环境搭建以及部署的流程。\n1. node环境的安装 # 最简单的方法是直接使用node已经编译好的可执行文件, 解压之后，将可执行文件链接到$PATH中：\nwget https://nodejs.org/dist/v10.16.3/node-v10.16.3-linux-x64.tar.xz # unarchive file to /usr/local tar -xf node-v10.16.3-linux-x64.tar.xz -C /usr/local # create link, so you can run node everywhere ln -sf /usr/local/node-v10.16.3-linux-x64/bin/node /usr/bin ln -sf /usr/local/node-v10.16.3-linux-x64/bin/npm /usr/bin # check whether node install successful node 10.16.3 2. 安装forever # npm install forever -g ln -sf /usr/local/node-v10.16.3-linux-x64/bin/forever /usr/bin 说明：直接全局安装forever之后，运行forever会出现command not found错误，同上，执行ln ..就可以了。\n3. 使用forever启动脚本 # forever start -l /locate/of/log/alog.log -a /locate/of/startScript/satrt.js 上述命令可以使用相对路径。\n启动成功后，我们看一下后台进程和forever的list：\nps aux | grep node root 25573 0.0 0.9 571244 35412 ? Ssl 15:50 0:00 /usr/local/node-v10.15.3-linux x64/bin/node /usr/local/node-v10.15.3-linux-x64/lib/node_modules/forever/bin/monitor ./bin/dev.js root 25580 0.0 0.8 604868 34252 ? Sl 15:50 0:01 /usr/local/node-v10.15.3-linux-x64/bin/node /opt/webManager/bin/dev.js root 26236 0.0 0.0 112708 984 pts/1 S+ 17:43 0:00 grep --color=auto node forever list info: Forever processes running data: uid command script forever pid id logfile uptime data: [0] UNdQ /*/node bin/dev.js 25573 25580 /*/a.log 0:2:18:18 可以看到一个node进程和一个monitor进程。\n我们在重新构建的时候，一般会选择杀掉服务进程，然后重启服务。此时，面对2个进程，只杀掉一个进程，是不行的。\n如果单独杀掉monitor进程，node进程还在，也就是说项目并没有停止运行，此时，如果再次使用forever启动，脚本也不会启动。此时，forever list显示的uptime 为 STOPED 如果单独杀掉node进程， forever monitor会自动重新启动脚本 因此，在重新构建时，应该杀掉monitor和node两个进程。\nEDIT：或者可以直接使用forever安全 停止脚本\nforever stop 0 "},{"id":109,"href":"/zh/posts/5_%E6%AF%94%E8%BE%83%E5%99%A8%E7%9A%84%E9%80%80%E5%8C%96/","title":"比较器的「退化」","section":"Blog","content":" Java「语法糖」越来越牛逼了哈。\n在使用匿名内部类比较器的时候，idea提供了几个层次的比较器代码优化，给👴整懵逼了。\nHere is the original code:\n// sort by time barList.sort(new Comparator\u0026lt;MarketDataBar\u0026gt;() { @Override public int compare(MarketDataBar o1, MarketDataBar o2) { if (o1.getTime().getTime() \u0026gt; o2.getTime().getTime()) { return 1; } if (o1.getTime().getTime() \u0026lt; o2.getTime().getTime()) { return -1; } return 0; } }); Firstly, we could use Long.compare() to replace the if statement, it looks like:\n// sort by time barList.sort(new Comparator\u0026lt;MarketDataBar\u0026gt;() { @Override public int compare(MarketDataBar o1, MarketDataBar o2) { return Long.compare(o1.getTime().getTime(), o2.getTime().getTime()); } }); So far, the code is much simplified then before.\nBut also, we coulde use lamda replace anonymous innner class, after doing that, it looks like:\n// sort by time barList.sort((o1, o2) -\u0026gt; Long.compare(o1.getTime().getTime(), o2.getTime().getTime())); though we used lambda, we could replace the comparator with Comparator.comparingLong:\n// sort by time barList.sort(Comparator.comparingLong(o -\u0026gt; o.getTime().getTime())); this is the ultimate version of a comparator, a \u0026lsquo;one line compartor\u0026rsquo;.\n"},{"id":110,"href":"/zh/posts/4_Java-Script%E4%B8%AD%E7%9A%84%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0/","title":"Java Script中的构造函数","section":"Blog","content":"函数作为JavaScript中的一个特殊数据类型（特殊对象的一种，另一种是数组），有一些特性值得思考与讨论。\nJavaScript中的函数的声明 # 一般来讲，可以通过3种方式声明函数：\nfunction关键字 函数表达式 Function构造函数 function关键字声明函数 # \u0026gt; function foo(){ return \u0026#39;foo\u0026#39;; } \u0026gt; foo(); \u0026lt; \u0026#34;foo\u0026#34; 上述方式为最常见声明函数**（Function Declaration）**的方式，通过foo()即可调用函数。\n函数表达式声明函数 # \u0026gt; var foo = function(){ return \u0026#39;foo\u0026#39;; } \u0026gt; foo(); \u0026lt; \u0026#34;foo\u0026#34; 此处，变量foo的右侧是一个匿名函数**（Function Expression）**，这是一个函数表达式，因为，等号右边只能是表达式。\n若使用函数表达式时，等号右侧不是函数表达式（匿名函数），其实变量也是可以正常使用的：\n\u0026gt; var foo = function fo(){ return fo.name; } \u0026gt; foo(); \u0026lt; \u0026#34;fo\u0026#34; \u0026gt; fo(); \u0026lt; VM771:1 Uncaught ReferenceError: fo is not defined at \u0026lt;anonymous\u0026gt;:1:1 但是，若试图调用function关键字后的函数，会得到一个报错信息。同时，需要说明的是，function关键字后面的函数在Function Declaration中是可以使用的。\n函数表达式实际上是将函数赋值给变量，这个变量可以像操作其他js对象一样操作\nFunction构造函数声明函数 # js中亦存在构造函数的概念\n\u0026gt; var func = new Function(\u0026#39;x\u0026#39;,\u0026#39;y\u0026#39;, \u0026#39;return x + y\u0026#39;); \u0026gt; func(1,2); \u0026lt; 3 // 等价于 \u0026gt; var func = function(x,y){return x+y}; new Function()构造器会将传入的最后一个参数作为函数的返回体，其他的参数均作为函数的参数。这存在一个很大的弊端，就是不利于编写业务逻辑，因此，此法极少使用。\n将函数看作对象 # 函数与对象 # js中的对象，对象的属性字段可以在对象初始化完成后再进行赋值\n\u0026gt; var obj = {}; \u0026gt; obj.name = \u0026#34;jay\u0026#34;; \u0026gt; obj.name; \u0026lt; \u0026#34;jay\u0026#34; 函数作为js中的一个特殊对象，也可以进行类似操作\n\u0026gt; var car = function(){}; \u0026gt; car.brand = \u0026#39;ford\u0026#39;; \u0026gt; car.brand; \u0026lt; \u0026#34;ford\u0026#34; 事实上，如果需要封装一个对象（类）的时候，往往需要为对象封装一些属性，可以利用函数，让代码更优雅。\nnew 运算符 # \u0026gt; var foo = function(){}; \u0026gt; var bar = foo(); \u0026gt; var tar = new foo(); \u0026gt; console.log(typeof(foo) + \u0026#39;,\u0026#39; + typeof(bar) + \u0026#39;,\u0026#39; + typeof(tar)); \u0026lt; \u0026#34;function\u0026#34;,\u0026#34;undefined\u0026#34;,\u0026#34;object\u0026#34; 从结果上来看，foo是function类型；bar是foo函数的返回类型，但是函数表达式没有返回语句，即返回void(undefined)；tar则是对象类型。\nnew 运算符创建一个用户定义的对象类型的实例或具有构造函数的内置对象的实例。new 关键字会进行如下的操作：\n创建一个空的简单JavaScript对象（即{}）； 链接该对象（即设置该对象的构造函数）到另一个对象 ； 将步骤1新创建的对象作为this的上下文 ； 如果该函数没有返回对象，则返回this。 如此一来，上例中的tar对象就是一个空的JsavaScript对象\n\u0026gt; tar; \u0026lt; {} "},{"id":111,"href":"/zh/posts/%E5%B8%B8%E8%A7%81cron%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%A4%BA%E4%BE%8B/","title":"cron表达式速查","section":"Blog","content":"cron表达式常用于配置定时任务。cron表达式实际上是由七个子表达式组成。这些表达式之间用空格分隔：\nSeconds （秒） Minutes（分） Hours（小时） Day-of-Month （天） Month（月） Day-of-Week （周） Year（年） 例：表达式0 0 12 ? \\* WED 意思是：每个星期三的中午12点执行。\n个别子表达式可以包含范围或者列表。例如：上面例子中的WED可以换成MON-FRI，MON,WED,FRI\u0026quot;，甚至MON-WED,SAT\n下表列出了Cron子表达式的取值范围：\nSeconds 0~59 Minutes 0~59 Hours 0~23 Day-of-Month 1~31,但是要注意有些月份没有31天 Month (0~11，或者JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, NOV,DEC Day-of-Week 1~7,或者SUN(=1), MON, TUE, WED, THU, FRI, SAT Year 1970~2099 格式 # Cron表达式的格式：秒 分 时 日 月 周 年(可选)\n字段名 允许的值 允许的特殊字符 秒 0-59 , - * / 分 0-59 , - * / 时 0-23 , - * / 日 1-31 , - * ? / L W C 月 1-12 or JAN-DEC , - * / 周几 1-7 or SUN-SAT , - * ? / L C # 年（可选） empty 1970-2099 , - * / 通配/特殊字符的含义 # * ：代表所有可能的值。因此，*在Month中表示每个月，在Day-of-Month中表示每天，在Hours表示每小时。\n- ：表示指定范围。\n, ：表示列出枚举值。例如：在Minutes子表达式中，5,20表示在5分钟和20分钟触发。\n/ ：被用于指定增量。例如：在Minutes子表达式中，0/15表示从0分钟开始，每15分钟执行一次；3/20表示从第三分钟开始， 每20分钟执行一次，和3,23,43（表示第3，23，43分钟触发）的含义一样。\n? ：用在Day-of-Month和Day-of-Week中，指没有具体的值。当两个子表达式其中一个被指定了值以后，为了避免冲突， 需要将另外一个的值设为?。例如：想在每月20日触发调度，不管20号是星期几，只能用如下写法：0 0 0 20 * ?， 其中最后一位只能用?，而不能用*。\nL ：用在Day-of-Month和Day-of-Week字串中。它是单词“last”的缩写。它在两个子表达式中的含义是不同的。 在Day-of-Month中，L表示一个月的最后一天，如1月31号，3月30号。 在Day-of-Week中，L表示一个星期的最后一天，也就是“7”或者“SAT”。 但是如果L前有具体内容，它就有其他的含义了。例如：6L表示这个月的倒数第六天。FRIL表示这个月的最后一个星期五。 注意：在使用L参数时，不能指定列表或者范围，这样会出现问题。\nW ：Weekday的缩写。只能用在Day-of-Month字段。用来描叙最接近指定天的工作日（周一到周五）。 例如：在Day-of-Month字段用15W指最接近这个月第15天的工作日，即如果这个月第15天是周六，那么触发器将会在这个月第14天即周五触发； 如果这个月第15天是周日，那么触发器将会在这个月第 16天即周一触发；如果这个月第15天是周二，那么就在触发器这天触发。 注意一点：这个用法只会在当前月计算值，不会越过当前月。W字符仅能在 Day-of-Month指明一天，不能是一个范围或列表。 也可以用LW来指定这个月的最后一个工作日，即最后一个星期五。\n# ：只能用在Day-of-Week字段。用来指定这个月的第几个周几。例：在Day-of-Week字段用6#3 or FRI#3指这个月第3个周五（6指周五，3指第3个）。如果指定的日期不存在，触发器就不会触发。\n常见表达式示例 # 0 * * * * ? 每1分钟触发一次\n0 0 * * * ? 每天每1小时触发一次\n0 0 10 * * ? 每天10点触发一次\n0 * 14 * * ? 在每天下午2点到下午2:59期间的每1分钟触发\n0 30 9 1 * ? 每月1号上午9点半\n0 15 10 15 * ? 每月15日上午10:15触发\n*/5 * * * * ? 每隔5秒执行一次\n0 */1 * * * ? 每隔1分钟执行一次\n0 0 5-15 * * ? 每天5-15点整点触发\n0 0/3 * * * ? 每三分钟触发一次\n0 0-5 14 * * ? 在每天下午2点到下午2:05期间的每1分钟触发\n0 0/5 14 * * ? 在每天下午2点到下午2:55期间的每5分钟触发\n0 0/5 14,18 * * ? 在每天下午2点到2:55期间和下午6点到6:55期间的每5分钟触发\n0 0/30 9-17 * * ? 朝九晚五工作时间内每半小时\n0 0 10,14,16 * * ? 每天上午10点，下午2点，4点\n0 0 12 ? * WED 表示每个星期三中午12点\n0 0 17 ? * TUES,THUR,SAT 每周二、四、六下午五点\n0 10,44 14 ? 3 WED 每年三月的星期三的下午2:10和2:44触发\n0 15 10 ? * MON-FRI 周一至周五的上午10:15触发\n0 0 23 L * ? 每月最后一天23点执行一次\n0 15 10 L * ? 每月最后一日的上午10:15触发\n0 15 10 ? * 6L 每月的最后一个星期五上午10:15触发\n0 15 10 * * ? 2005 2005年的每天上午10:15触发\n0 15 10 ? * 6L 2002-2005 2002年至2005年的每月的最后一个星期五上午10:15触发\n0 15 10 ? * 6#3 每月的第三个星期五上午10:15触发\n"},{"id":112,"href":"/zh/docs/craft/design_pattern/structure/proxy/","title":"代理模式","section":"结构型","content":"代理可以简单理解为，B类托管A类的功能，并根据需求，对A类的访问作控制，这里的控制可以理解为对A类方法执行的流程的影响，包括但不限于：\n在方法执行之前，先做其他事（前置通知） 在方法执行之后，再做某事（后置通知） 决定方法是否执行（环绕通知） \u0026hellip;\njava中代理的主要应用体现在权限控制,日志管理,事务控制等\njava 代理模式简单图解\n静态代理 # 静态代理的作用，可扩展性，可维护性相对较差。典型的静态代理可以通过继承和包装器两种方式来实现，包装器方式比起继承方式稍方便。\n继承方式的静态代理 # /** * @author:wangy * @date: 2018/9/21 / 15:15 * @description: 通过继承的方式实现java静态代理, 主要在于理解所谓\u0026#34;代理\u0026#34;的概念 */ public interface CellPhone { void sendMessage(); } /** * 模拟被代理类对象 */ public class Iphone5 implements CellPhone { @Override public void sendMessage() { System.out.println(\u0026#34;the sending message is in the air.\u0026#34;); } } /** * 模拟代理类对象 */ public class Iphone5S extends Iphone5 { @Override public void sendMessage() { System.out.println(\u0026#34;you need to unlock your phone first.\u0026#34;); super.sendMessage(); // 模拟短信发送 try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\u0026#34;message sent successful.\u0026#34;); } } /** *客户端 */ public class Client { public static void main(String[] args) { CellPhone phone = new Iphone5S(); phone.sendMessage(); } } ///:~ you need to unlock your phone first. the sending message is in the air. message sent successful. 上例中，Iphone5S 类继承了Iphone5，并对5的功能“加了点椰果”，这就是最简单的代理模式。但是，如果我还想“加点奶油”，那么就需要再创建一个类，给5“加奶油”，如果有很多手机，要加很多功能，只能通过“硬编码”来完成，这样显然是不合适的。\n包装器方式的静态代理 # /** * @author:wangy * @date: 2018/9/21 / 15:15 * @description: 通过包装器的方式实现java静态代理 */ public interface IceCream { void iceCreamMaker(); } /** * 模拟被代理类对象 */ public class BerryCream implements IceCream { @Override public void iceCreamMaker() { System.out.println(\u0026#34;this is a IceCream with blueberry juice.\u0026#34;); } } /** * 模拟代理类对象 */ public class Jelly implements IceCream { // 代理对象中封装了被代理对象 private BerryCream berryCream; public Jelly(BerryCream berryCream) { this.berryCream = berryCream; } @Override public void iceCreamMaker() { System.out.println(\u0026#34;add Grass jelly into Berry IceCream\u0026#34;); berryCream.iceCreamMaker(); System.out.println(\u0026#34;now it\u0026#39;s a Grass-jelly-Berry-IceCream\u0026#34;); } } /** * 模拟客户端 */ public class Client { public static void main(String[] args) { IceCream iceCream = new Jelly(new BerryCream()); iceCream.iceCreamMaker(); } } /* add Grass jelly into Berry IceCream this is a IceCream with blueberry juice. now it\u0026#39;s a Grass-jelly-Berry-IceCream *///:~ 在包装器模型中，被代理类对象被封装在代理类对象中。通过这种形式，如果我需要在“莓派冰激凌”上加上“烧仙草”和“珍珠果”，只需要将代码作一些改动，并且，其相对于继承模式的又是在于：继承是类似于一个链式的叠加，并且对于功能的改动比较麻烦（比如想先加珍珠果再加烧仙草，就需要改动继承关系）。而包装器设计就相对比较灵活了，只需要作简单改动：\n// 将代理类对象1的封装类直接改为接口 public class Jelly implements IceCream { private IceCream iceCream; public Jelly(IceCream iceCream) { this.iceCream = iceCream; } @Override public void iceCreamMaker() { System.out.println(\u0026#34;add Grass jelly into Berry IceCream\u0026#34;); iceCream.iceCreamMaker(); System.out.println(\u0026#34;now it\u0026#39;s a Grass-jelly-Berry-IceCream\u0026#34;); } } // 添加代理对象2 public class Pearl implements IceCream { private IceCream iceCream; public Pearl(IceCream iceCream) { this.iceCream = iceCream; } @Override public void iceCreamMaker() { System.out.println(\u0026#34;add pearl fruit into Berry Ice Cream.\u0026#34;); iceCream.iceCreamMaker(); System.out.println(\u0026#34;now it\u0026#39;s a what a icecream!\u0026#34;); } } // 测试类 public class Client { public static void main(String[] args) { // 如果想改变“加料”的顺序，只需要改变对象初始化的顺序就ok IceCream iceCream = new BerryCream(); Pearl pearl = new Pearl(iceCream); Jelly jelly = new Jelly(pearl); jelly.iceCreamMaker(); } } ///:~ add Grass jelly into Berry IceCream add pearl fruit into Berry Ice Cream. this is a IceCream with blueberry juice. now it\u0026#39;s a what a icecream! now it\u0026#39;s a Grass-jelly-Berry-IceCream 动态代理 # 相较于静态代理，动态代理带来的好处是：一个代理工具（或者叫代理处理程序），能够有效地实现对不同委托类的代理，这样使代码更加灵活。代理模式一定程度上可以看作“功能增强”，而“功能增强”的需求本质上就是相对灵活的，这和动态代理的初衷相契合。\nJDK 动态代理 # JDK 动态代理是比较常见的代理模式。其实现方法可大致总结为:\n1.创建一个实现接口InvocationHandler的类，它必须实现invoke方法 2.创建被代理的类以及接口 3.通过Proxy的静态方法 newProxyInstance(ClassLoaderloader, Class[] interfaces, InvocationHandler h)创建一个代理类实例 4.通过代理类实例调用委托类方法 1. 动态代理需要一个接口 # 这个接口供所有需要被代理的类实现\npublic interface Subject { void sayHallo(); } 2. 和一个简单的实现类 # public class RealSubject implements Subject { @Override public void sayHallo() { System.out.println(\u0026#34;大家好!\u0026#34;); } } 3. 自定义代理处理程序，须实现 InvocationHandler 接口 # public class MyProxyHandler implements InvocationHandler { private Subject subject; MyProxyHandler() { } MyProxyHandler(Subject subject) { this.subject = subject; } /** * 此方法用于生成一个指定接口的代理类实例, 该接口可以将方法调用指派到 [指定的调用处理程序], * 这个所谓的 [调用处理程序] 就是 InvocationHandler的invoke()方法 * * @param subject 需要被代理的类的实例对象(被代理接口的实现类) * @return 一个指定接口的代理类实例 * 这里, 指定接口就是说的是 Subject 接口, 常说的JDK动态代理需要有一个接口,就是这个原因 */ Object bind(Subject subject) { this.subject = subject; return Proxy.newProxyInstance(subject.getClass().getClassLoader(), subject.getClass().getInterfaces(), this); // 此Proxy类的静态方法等价于 /*try { // 获取实现指定接口的被代理类实例对象 Class\u0026lt;?\u0026gt; proxyClass = Proxy.getProxyClass(Subject.class.getClassLoader(), Subject.class.getInterfaces()); // 获取指定的 [调用处理程序对象] 的构造器 Constructor\u0026lt;?\u0026gt; proxyClassConstructor = proxyClass.getConstructor(MyProxyHandler.class); // 通过指定的InvocationHandler实例创建实现指定接口的代理类实例对象 return proxyClassConstructor.newInstance(new MyProxyHandler(subject)); }catch(Exception e){ e.printStackTrace(); }*/ } /* ******************************************** * java.lang.reflect.Proxy [extends Object implements Serializable] 类 * -- 该类提供用于创建动态代理类和实例的静态方法, 它是由这些静态方法创建的动态代理类的超类 * -- 动态代理类(以下称为代理类)是一个实现 [在创建类时在运行时指定的接口列表] 的类 * -- 代理接口(Subject)是代理类实现的一个接口 * -- 代理实例是代理类的一个实例, 每个代理实例都有一个关联的 [调用处理程序] 对象, 其实现接口 InvocationHandler * -- 代理实例调用方法(sayHallo())时, 会被指派到 [调用处理程序] 对象的 invoke() 方法 * ********************************************/ /** * @param proxy 代理类对象 * @param method 被代理类的方法实例 * @param args 被代理类对象(subject)的方法实例method的参数 * @return null * @throws Throwable */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(\u0026#34;before...\u0026#34;); method.invoke(subject, args); System.out.println(\u0026#34;after...\u0026#34;); return null; } } 4. 客户端生成代理类对象并且调用委托类的方法 # 这个client介绍了3种创建动态代理类的方法\npublic class Client { /** * 被代理类对象(接口) */ private static Subject subject = new RealSubject(); /** * 代理实例关联的调用处理程序对象实例 */ private static InvocationHandler handler = new MyProxyHandler(subject); /** * 代理实例关联的调用处理程序对象, 一般是自定义的InvocationHandler类的实现类 */ private static MyProxyHandler my_proxy = new MyProxyHandler(); public static void main(String[] args) { m1(); m2(); m3(); } /** * 通过 [代理类实例] 调用 [被代理类] 实例的指定方法时, 会被[自定义代理类处理程序]指派给 [调用处理程序](即invoke()方法),并且执行invoke方法的增强代码 */ private static void m3() { Subject proxySubject = (Subject) my_proxy.bind(subject); proxySubject.sayHallo(); } private static void m2() { Subject proxy_subject = (Subject) Proxy.newProxyInstance(subject.getClass().getClassLoader(), subject.getClass().getInterfaces(), handler); proxy_subject.sayHallo(); } private static void m1() { Subject proxySubject = null; try { Class\u0026lt;?\u0026gt; proxyClass = Proxy.getProxyClass(Subject.class.getClassLoader(), Subject.class); Constructor\u0026lt;?\u0026gt; constructor = proxyClass.getConstructor(InvocationHandler.class); proxySubject = (Subject) constructor.newInstance(handler); } catch (Exception e) { e.printStackTrace(); } proxySubject.sayHallo(); } cglib 动态代理 # 与JDK动态代理不同的是，cglib动态代理不需要委托类实现某个接口，其生成的代理类是委托类的子类。当然，cglib也有其局限：\nfinal 类不能通过cglib代理 final 修饰的方法不能通过cglib作增强处理 cglib实现动态代理可简单地归纳为：\n1.创建委托类对象 2.创建[自定义代理类生成程序]类，该类须实现MethodInterceptor 3.通过Enhancer来创建代理类实例 4.通过代理类实例调用委托类方法 1.创建委托类 # public class Flower { public void bloom(){ System.out.println(\u0026#34;the flower will bloom...\u0026#34;); } } 2. 自定义代理类生成程序 # public class ProxyInterceptor implements MethodInterceptor { private Enhancer enhancer = new Enhancer(); Object getProxyClass(Class clazz){ enhancer.setSuperclass(clazz); enhancer.setCallback(this); return enhancer.create(); } @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable { System.out.println(\u0026#34;after you fertilized...\u0026#34;); methodProxy.invokeSuper(o, objects); System.out.println(\u0026#34;and you will have a harvest.\u0026#34;); return null; } } 3. 客户端 # public class Client { private static ProxyInterceptor proxyInterceptor = new ProxyInterceptor(); public static void main(String[] args) { Flower proxyClass = (Flower) proxyInterceptor.getProxyClass(Flower.class); proxyClass.bloom(); } } JDK动态代理和cglib动态代理的区别 # 代理 特点 优点 缺点 JDK 代理类与委托类实现同一接口，主要是通过代理类实现InvocationHandler并重写invoke方法来进行动态代理的，在invoke方法中将对方法进行增强处理，底层使用反射机制进行方法的调用 不需要硬编码接口，代码复用率高 只能够代理实现了接口的委托类 cglib 代理类将委托类作为自己的父类并为其中的非final委托方法创建两个方法，一个是与委托方法签名相同的方法，它在方法中会通过super调用委托方法；另一个是代理类独有的方法。在代理方法中，它会判断是否存在实现了MethodInterceptor接口的对象，若存在则将调用intercept方法对委托方法进行代理，底层将方法全部存入一个数组中，通过数组索引直接进行方法调用 可以在运行时对类或者是接口进行增强操作，且委托类无需实现接口 不能对final类以及final方法进行代理 *JDK和cglib动态代理的简易区别，引自[jianshu.com@EakonZhao](https://www.jianshu.com/p/9a61af393e41?from=timeline\u0026amp;isappinstalled=0)* 解析JDK动态代理 # "},{"id":113,"href":"/zh/posts/3_%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84SQL%E4%BC%98%E5%8C%96%E7%9A%84%E4%BE%8B%E5%AD%90/","title":"一个简单的sql优化示例","section":"Blog","content":"例如，我在执行以下sql语句的时候\nSELECT projectId FROM lywl_equip_package WHERE salesId in ( SELECT t1.id FROM cmp_datapackage_user t1 LEFT JOIN cmp_datapackage t2 ON t1.datapackage_id = t2.id WHERE t1.sales_cycle \u0026gt; 1 AND t1.is_valid = 1 AND t1.is_share = 0 AND t1.sales_price \u0026lt;\u0026gt; 9999 AND t1.sales_name REGEXP \u0026#39;移动.*/(季度|半年|年)\u0026#39; AND t2.operator =1 AND t2.is_share = 1 AND t2.datapackage_cycle = 1 ) 以上sql查询的是订购移动跨月销售品的设备id, 查询耗时 6.462s。\n由于 lywl_equip_package 数据量比较大, in 查询每次都将 lywl_equip_package 的数据与in 语句中的匹配, 耗时较为严重。\n但是作如下改动之后,sql的查询效率就快很多：\nSELECT tt2.projectId FROM ( SELECT t1.id FROM cmp_datapackage_user t1 LEFT JOIN cmp_datapackage t2 ON t1.datapackage_id = t2.id WHERE t1.sales_cycle \u0026gt; 1 AND t1.is_valid = 1 AND t1.is_share = 0 AND t1.sales_price \u0026lt;\u0026gt; 9999 AND t1.sales_name REGEXP \u0026#39;移动.*/(季度|半年|年)\u0026#39; AND t2.operator =1 AND t2.is_share = 1 AND t2.datapackage_cycle = 1 ) tt1 LEFT JOIN lywl_equip_package tt2 ON tt2.salesId = tt1.id 查询时间 0.246s\n以上的操作在于, 将IN查询中的结果储存为一张临时表,然后将其作为主表,左连接lywl_equip_package.以数据少的表作为主表,可以提升查询效率。\n"},{"id":114,"href":"/zh/posts/Java%E6%8E%A5%E5%8F%A3%E5%9B%9E%E8%B0%83/","title":"Java接口回调","section":"Blog","content":"回调模式在web开发中用的较多，本文简单介绍了Java的回调机制，理解此文可以在生产中写出适应业务的回调模型。\n模块之间的调用 # 在一个应用系统中，必然存在模块之间的调用，调用的方式有几种:\n1. 同步调用 # 同步调用 方法A()调用方法B(),并且等待方法B()的返回,然后A()再执行下一步操作。\n此方法适用于B()方法执行的时间不长，如若不然，那么A()方法会长时间等待B()方法执行完成而处于阻塞状态，如此，可能会导致整个流程的阻塞。\n2. 异步调用 # 异步调用 为了解决A()方法调用B()方法造成流程阻塞而出现的，最典型的方式就是开启新线程。这样的话，A()方法不必等待B()方法的返回而继续执行。\n但是这种方法存在一个问题：如果A()需要知道B()的执行结果(根据业务需求，有些操作如异步线程刷新缓存、推送通知等等不需要，而有些如更改状态的操作则需要)，则需要通过某种方式对B()的执行结果进行监听，在Java中可以通过 Future+Callable来实现。\n3. 回调 # 回调模式 在回调模式中，\nA()方法调用B()方法 B()方法执行完毕之后，调用A类的AA()方法（回调方法），将执行结果返回给A\n要实现这个需求，有几点问题需要思考：\nA类中如何调用B类的方法（这个简单，字段注入即可） B类的方法执行完成之后，如何调用A类的callback方法（被调用的B类的方法，必须有A类对象作为形参） 如何提升代码的可复用性及可扩展性？（面向接口） 一个简单的例子 # 场景描述：男孩需要向女孩表白，但羞于表达，只好借助神父传达心意， 神父知道男孩的请求之后，将要对女孩说的话告诉男孩。 /** * @author:wangy * @date: 2018/8/30 / 20:37 * @description: 这是那个男孩 * java 回调机制的引入 A--调用--\u0026gt;B(c) ---调用--\u0026gt;A(d) d 方法称之为回调方法 * 使用场景: A想完成某事, 但A不能独立完成,需要借助B的力量, B完成之后, * 要将结果通知给A(通过调用A的方法实现) */ public class Kidd { private String name; private GodFather godFather; public Kidd(String name,GodFather godFather) { this.name = name; this.godFather = godFather; } public void askGodFather(){ godFather.witness(this); } public void confess(String voice){ System.out.println(this.name+\u0026#34;:\u0026#34;+ voice); } } 男孩类有两个方法：\naskGodFather() 方法用于调用神父类的witness()方法\nconfess()方法用于让神父类回调\n/** * @author:wangy * @date: 2018/8/30 / 20:45 * @description: 这是神父类 */ public class GodFather { public void witness(Kidd kidd) { kidd.confess(\u0026#34;the moon light is gorgeous tonight\u0026#34;); } } 神父类比较简单,只有一个方法witness()，它有一个Kidd对象作为形参,这个对象用于回调男孩类的回调方法\n// 测试类 public class Test { public static void main(String[] args) { new Kidd(\u0026#34;Alex\u0026#34;,new GodFather()).askGodFather(); } } 返回:\nAlex:the moon light is gorgeous tonight 以上是一个最简单的Java 回调机制的模型，该模型还存在一些不限于以下列出的问题：\nB类的方法形参单一，上例中形参为Kidd对象，那么，换成Cat对象便又要写一个“神父类”； 同理，A类调用的B类方法单一，上例中需求的是“表白神父”*（功能A），如果换成“免灾神父”（功能B），又要写一个神父； 总结起来，就是通过‘类’的方式实现回调，代码的扩展性和可复用性较差 一个相对健壮的回调机制应该是这样的 # 完整的回调模式 以上的UML图解释了Java回调的实质：\nA类和B类分别为接口的实现类，这样代码的扩展性一下就提升了\n另一个简单的例子 # 场景描述:老师课堂点名学生回答问题，学生解答完毕之后回答老师 回调接口(A类需实现):\n/** * @author wangy * @desc 先定义一个回调接口,所有的A类要实现结果回调,必需实现该类并覆写回调方法,供B类调用 */ public interface Callback { /** * 回调接口是供B类来调用的,所以它的形参中必须包含A类调用B方法时候的返回值(对象) * @param a B类方法的返回值 * @param student 根据功能需求传递其他参数 */ void tellAnswer(Student student , int a); } B类的接口:\n/** * @author wangy * @desc B 类, 抽象为一个接口,方便A类对不同实现类(不同功能需求)的回调 */ public interface Student { /** * 方法接收一个callback参数,用于指示B类执行方法之后,向谁\u0026#34;汇报\u0026#34; * @param callback */ void resolveAnswer(Callback callback); String getName(); } A类实体:\n/** * @author:wangy * @date: 2018/9/18 / 10:17 * @description: A类, 实现回调接口并覆写方法 */ public class Teacher implements Callback { /** * 接口作为属性字段,便于扩展 */ private Student student; public Teacher(Student student) { this.student = student; } /** * askQuestion() 方法用于调用B类的方法 */ public void askQuestion() { student.resolveAnswer(this); } /** * 覆写的回调方法,用于供B类调用,以便通知执行结果 * * @param a */ @Override public void tellAnswer(Student student , int a) { System.out.println(\u0026#34;嗯,\u0026#34;+student.getName()+\u0026#34; 完成任务花了 \u0026#34; + a + \u0026#34; 秒\u0026#34;); } } A类实体有2个方法\naskQuestion() 用于调用B类的方法 覆写的tellAnswer()方法,用于接收回调结果\nB类实体:\n/** * @author:wangy * @version:1.0 * @date: 2018/9/18 / 10:20 * @description: B类的(某种特殊功能)实现类 */ public class Rookie implements Student { private String name; public Rookie(String name) { this.name = name; } @Override public String getName() { return name; } @Override public void resolveAnswer(Callback callback) { // 模拟方法执行过程 try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } // 回调,给指定callback的实现类 callback.tellAnswer(this, 3); } } B类实体有一个方法resolveAnswer(Callback callback)，接收一个callback参数，该参数用于调用A类的回调方法\n测试类:\npublic class Test { public static void main(String[] args) { Teacher teacher = new Teacher(new Rookie(\u0026#34;alan\u0026#34;)); teacher.askQuestion(); } } 返回:\n嗯,alan 完成任务花了 3 秒 分析 # 上面的例子中，对A类和B类分别进行了抽象，这样做的好处就是：\n抽象了A类之后，对于B类来说，不必要关心是“哪位老师”叫B类完成任务，只需要完成任务就好了，也就是说我B类的方法，可以复用； 抽象了B类之后，对于A类来说，相对更加灵活，其调用B类的方法不仅仅只限于“one-by-one”这种模式，而是一次可以对“多个学生”进行提问，只需要将A类中的字段修改为List即可。 回调的核心就是回调方将本身即this传递给调用方，调用方接着调用回调方的方法告诉它想要知道的信息。回调是一种思想、是一种机制，至于具体如何实现，如何通过代码将回调实现得优雅、实现得可扩展性比较高，一看开发者的个人水平，二看开发者对业务的理解程度。 同步回调与异步回调 # 上述的例子是一个典型的同步回调的示例。同步回调顾名思义就是A()调用B()之后，等待B()执行完成并且调用A()的回调函数，程序再继续执行。\n异步回调就是在A()调用B()的过程中，开启一个新线程，不等待B()方法执行完成并回调之后再执行后续操作。\n修改上例子中的A类中的方法，将其修改为异步回调\npublic class Teacher implements Callback { /** * 接口作为属性字段,便于扩展 */ private Student student; public Teacher(Student student) { this.student = student; } /** * askQuestion() 方法用于调用B类的方法 */ public void askQuestion() { // 异步回调 new Thread(new Runnable() { @Override public void run() { student.resolveAnswer(Teacher.this); } }).start(); } @Override public void tellAnswer(Student student , int a) { System.out.println(\u0026#34;知道了,\u0026#34;+student.getName()+\u0026#34; 完成任务花了 \u0026#34; + a + \u0026#34; 秒\u0026#34;); } } 同步回调和异步回调的选择要结合具体的业务场景，比如充值服务，要将充值的结果返回给用户，调用充值服务之后必须要等待充值接口的返回；但是如果是批量的处理（如退订业务），这时候可以用异步回调，主程序完成之后（或者页面app先返回数据给用户），后台业务逻辑继续执行，最后才业务执行的结果，可以作异步处理；\n"},{"id":115,"href":"/zh/posts/1_mybatis%E4%B8%ADtrim%E6%A0%87%E7%AD%BE%E5%8A%A8%E6%80%81%E6%8B%BC%E6%8E%A5SQL/","title":"MyBatis的trim标签","section":"Blog","content":"trim标记是一个格式化的标记，可以完成set或者是where标记的功能。\n样例一 # select * from user \u0026lt;trim prefix=\u0026#34;WHERE\u0026#34; prefixoverride=\u0026#34;AND |OR\u0026#34;\u0026gt; \u0026lt;if test=\u0026#34;name != null and name.length()\u0026gt;0\u0026#34;\u0026gt; AND name=#{name}\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;gender != null and gender.length()\u0026gt;0\u0026#34;\u0026gt; AND gender=#{gender}\u0026lt;/if\u0026gt; \u0026lt;/trim\u0026gt; 假如说name和gender的值都不为null的话打印的SQL为：select * from user where name = 'xx' and gender = 'xx'\n在红色标记的地方是不存在第一个and的，上面两个属性的意思如下：\nprefix：前缀\nprefixoverride：去掉第一个and或者是or\n样例二 # update user \u0026lt;trim prefix=\u0026#34;set\u0026#34; suffixoverride=\u0026#34;,\u0026#34; suffix=\u0026#34; where id = #{id} \u0026#34;\u0026gt; \u0026lt;if test=\u0026#34;name != null and name.length()\u0026gt;0\u0026#34;\u0026gt; name=#{name} , \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;gender != null and gender.length()\u0026gt;0\u0026#34;\u0026gt; gender=#{gender} , \u0026lt;/if\u0026gt; \u0026lt;/trim\u0026gt; 假如说name和gender的值都不为null的话打印的SQL为：update user set name='xx' , gender='xx' where id='x'\n在红色标记的地方不存在逗号，而且自动加了一个set前缀和where后缀，上面三个属性的意义如下，其中prefix意义如上：\nsuffixoverride：去掉最后一个逗号（也可以是其他的标记，就像是上面前缀中的and一样）\nsuffix：后缀\n实例:\ninsert into yd_submit_fail \u0026lt;trim prefix=\u0026#34;(\u0026#34; suffix=\u0026#34;)\u0026#34; suffixOverrides=\u0026#34;,\u0026#34; \u0026gt; \u0026lt;if test=\u0026#34;id != null\u0026#34; \u0026gt; id, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;createTime != null\u0026#34; \u0026gt; createTime, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;updateTime != null\u0026#34; \u0026gt; updateTime, \u0026lt;/if\u0026gt; \u0026lt;/trim\u0026gt; \u0026lt;trim prefix= \u0026#34;values (\u0026#34; suffix =\u0026#34;)\u0026#34; suffixOverrides=\u0026#34;,\u0026#34;\u0026gt; \u0026lt;if test=\u0026#34;id != null\u0026#34; \u0026gt; {#id}, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;createTime != null\u0026#34; \u0026gt; {#createTime}, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;updateTime != null\u0026#34; \u0026gt; {#updateTime}, \u0026lt;/if\u0026gt; \u0026lt;/trim\u0026gt; "},{"id":116,"href":"/zh/posts/Git%E5%85%A5%E9%97%A82/","title":"Git合并与分支管理","section":"Blog","content":" 此文的操作背景在本次工作空间的master分支下, 并且追踪远程master分支 部分内容参考自 yibai.com\n常用操作速查说到, git版本控制的基本原型与操作逻辑. 如果出现两台机器(比如公司和家)上同时更改\u0026rsquo;本地仓库\u0026rsquo;内容并且push到远程库中,那么必然会导致另一个版本库中的文件低于远程库,如果是有效的改动, 必然涉及到本地库和远程库同步的问题, 这涉及到3个关键词: fetch, merge, pull\ngit fetch # 从一个或多个其他存储库中获取分支和/或标签(统称为“引用”)以及完成其历史所必需的对象\n通俗地讲, 如果想将远程仓库master分支的版本信息下载(同步)到本地仓库, 就可以简单地使用\n$ git fetch origin master 命令. git fetch 命令会默认拉取所有分支信息. 但是仅仅这样, 本地的文件并没有更新, 因为这一操作仅仅\u0026rsquo;检查到有可用更新\u0026rsquo;, 要\u0026rsquo;更新\u0026rsquo;本地仓库工作空间的文件,还需要另一个命令: git merge\ngit merge # 命令用于将两个或两个以上的开发历史加入(合并)一起\n实际上, 在执行了git fetch origin master 之后, 再执行git branch, 会出现两个分支信息:\n$ git fetch origin master Warning: Permanently added the RSA host key for IP address \u0026#39;52.74.223.119\u0026#39; to the list of known hosts. Enter passphrase for key \u0026#39;/c/Users/mayn/.ssh/id_rsa\u0026#39;: remote: Enumerating objects: 19, done. remote: Counting objects: 100% (19/19), done. remote: Compressing objects: 100% (3/3), done. remote: Total 10 (delta 5), reused 10 (delta 5), pack-reused 0 Unpacking objects: 100% (10/10), done. From github.com:wangy325/demoLite * branch master -\u0026gt; FETCH_HEAD 276f33d..78beaa6 master -\u0026gt; origin/master $ git branch -a * master remotes/origin/master 其中master分支是当前工作分支, 而remotes/origin/master是执行fetch命令之后下载的版本信息. 如果想将版本库中的分支合并到当前工作分支,可以使用命令:\n$ git merge origin/master 注意：上述命令会自动将合并后的结果提交(commit), 如果想要对合并进行进一步更改时, 可以使用 --no-commit 选项\ngit pull # 取回远程主机某个分支的更新(fetch)，再与本地的指定分支合并(merge)\n因此, pull可以看作是fetch和merge命令的集合, 如果想要将远程master分支与本地master分支合并, 可使用如下命令:\n$ git pull origin master:master 如果当前工作分支是master分支, 那么命令也可以简写为:\n$ git pull origin master 实际上我们发现, 以上命令相当于先取回origin/master分支, 再将其与当前分支合并, 这是一个先做git fetch, 后做git merge操作的过程:\n$ git fetch origin master $ git merge origin/master 分支追踪关系 # 一般地, Git会自动在本地分支和远程分支之间建立一种追踪关系(tracking). 建立追踪关系的分支之间可以建立更加简便的操作.\n比如，在git clone的时候，所有本地分支默认与远程主机的同名分支，建立追踪关系，也就是说，本地的master分支自动”追踪”origin/master分支\n可以通过 git branch -vv 查看当前本地分支与远程分支的追踪关系:\n$ git branch -vv * master 78beaa6 [origin/master] revise code 也可以手动建立追踪关系:\n// 将本地master分支与远程master分支建立追踪关系 $ git branch --set-upstream master origin/master 建立追踪关系之后, git pull 就可以省略远程名, git 自动从当前分支追踪的远程分支中获取更新并且拉取到本地工作空间\n// 现在自动从远程仓库(origin)中拉取当前分支追踪的远程分支的更新 $ git pull origin // 若当前分支只有一个追踪分支, 甚至可以省略主机名 $ git pull git fetch和git pull的区别 # git fetch : 从远程获取最新的版本到本地, 但是不会自动合并 git pull : 从远程获取最新版本并且合并到本地 // 从远程origin的master分支拉取最新版本到origin/master分支 $ git fetch origin master // 比较本地master和origin/master分支的区别 $ git log -p master.. origin/master // 合并 origin/master 到当前分支(master) $ git merge origin/master 上述过程可以更加简便地表述为\n$ git fetch origin master:tmp $ git diff tmp $ git merge tmp TODO:\ngit rabase "},{"id":117,"href":"/zh/posts/Git%E5%85%A5%E9%97%A81/","title":"Git常用命令速查","section":"Blog","content":"本文简单介绍了Git本地仓库的构建，与远程仓库的关联。\n安装Git # ubuntu下安装：\nsudo apt install git windows 下安装，需 下载安装包\nGit 本地仓库的创建 # 通俗地讲，本地任何一个目录都可以是本地仓库。只需要启动Terminal(ubuntu)或Git Bash(windows)，cd进入指定目录，运行\ngit init 即可以初始化一个空的本地仓库。此时，该目录下会多出一个.git子目录，它是Git用来跟踪管理版本库的。当然，如果你想取消版本管理，删除这个目录即可。\nGit 不同于 Subversion 的地方在于，Git是分布式的版本管理系统，没有中央服务器。这大概解释了Git可以创建本地仓库的原因，而Subversion的使用必须要借助互联网。\n关于集中式与分布式的讨论，此处不作多的说明，没有使用经验支撑，那些优劣列出来，没有什么意义。\nGit 关联GitHub远程仓库 # Git支持基于SSH和https关联远程仓库，但推荐使用SSH方式，它 更加安全。在本地仓库要想和GitHub远程仓库关联，首先需要在GitHub中配置SSH and GPG keys。\n通过\nssh-keygen -t rsa -C \u0026#34;wangy325@qq.com\u0026#34; 获取ssh密钥文件，操作过程中会提示确认保存文件的位置以及要求输入密码，以下是命令输出(windows 平台)。\nGenerating public/private rsa key pair. Enter file in which to save the key (/c/Users/mayn/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /c/Users/mayn/.ssh/id_rsa. Your public key has been saved in /c/Users/mayn/.ssh/id_rsa.pub. The key fingerprint is: SHA256:Yy7sS0KnY+iaQDLldwI43znocIboZhDbD5ZPwjzMybU wangy325@qq.com The key\u0026#39;s randomart image is: +---[RSA 2048]----+ | | | . | |+ o . | |./ B o | |O.^ E o S | |=B @ B o . | |.+o B + . | |+o . = . | |o.. o. | +----[SHA256]-----+ 命令执行完成之后，会在 c/Users/mayn/ 下生成一个.ssh目录，里面包含了密钥信息。\n然后在GitHub页面添加新的ssh key，配置完成以后，便可以将本地仓库和远程仓库关联，并将本地文件上传到远程（通常，你需要先add并且commit文件到本地版本库）：\ngit remote add origin git@github.com:wangy325/repositoryName.git git push -u origin master Git的工作模式简单介绍 # 工作区(workspace)：即当前工作目录 暂存区(stage/index):.log目录下的的index文件中，暂存区域保存的是本地已add但未commit的改动 版本库(local repository):本地版本库，commit之后文件信息变保存在其中 远程仓库(remote repository):远程版本库，push推送本地文件到远程版本库，fetch从远程版本库拉取 资源 版本信息，pull从远程版本库中拉取资源 Git本地工作区，暂存区，版本库的概念，图引自 易百教程\nGit 版本控制的一些主要概念：\n3个步骤： add命令只添加文件到暂存区 commit命令将文件添加到本地版本库 push命令将本地版本库的内容推送到远程仓库 4个区： workingAera：当前工作空间 stage：暂存区，已修改并add的文件在此区 local repository：本地仓库 remote repository：远程仓库 5种状态 origin：被git追踪但未作任何修改 modified：已修改但未add到暂存区 staged：已修改并add到暂存区 committed：已提交到本地仓库 pushed：已推送到远程仓库 常用命令 # git command --help 可以打开帮助文档\ngit config --global credential.helper store 保存用户凭证，避免每次push/pull都需要输入密码\n添加文件到暂存区 # git add file1 ... 提交文件到仓库之前，需要配置用户名和电子邮件\ngit config --global user.name \u0026#34;wangy325\u0026#34; git config --global user.email \u0026#34;wangy325@qq.com\u0026#34; 提交文件到仓库 # git commit -m \u0026#34;commit comment\u0026#34; 查看当前仓库的状态 # $ git status On branch master Your branch is up to date with \u0026#39;origin/master\u0026#39;. Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git checkout -- \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: readme.md Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) Main.java no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) 查看某个文件的差异信息 # git diff 查看暂未`add`到暂存区的改动，也就是状态为`modified`的文件， 如果文件已经`staged`，则此命令不会显示差异信息 git diff --cached 查看已经`add`到暂存区的改动，也就是状态为`staged`的文件， 如果文件处于`modified`状态，则此命令不会显示差异信息 git diff HEAD 查看已暂存和未暂存的所有改动 git diff --stat 显示差异的摘要信息 git diff master origin/master 显示本地仓库和远程仓库之间的文件的差异信息，即`committed`和`pushed`两个状态之间的差异 git diff versionCode1 versionCode2 显示两个版本(号)之间的差异信息，`less`打开 $ git diff readme.md warning: LF will be replaced by CRLF in readme.md. The file will have its original line endings in your working directory. diff --git a/readme.md b/readme.md index bb8298f..222e2da 100644 --- a/readme.md +++ b/readme.md @@ -6,3 +6,5 @@ - Java的回调机制 - idea的多线程调试 - 拦截器 + +\u0026gt; you can\u0026#39;t live your life based on other people\u0026#39;s point of view. 查看提交日志 # git log [\u0026lt;options\u0026gt;] [\u0026lt;revision-range\u0026gt;] [[--] \u0026lt;path\u0026gt;...] $ git log commit cf3d291b043457536f5851c3517c94f6f50d4c94 (HEAD -\u0026gt; master, origin/master) Author: wangy325 \u0026lt;wangy325@qq.com\u0026gt; Date: Wed Sep 19 12:11:13 2018 +0800 update readme.md ... 上面的日志显示 HEAD 的版本号为cf3d291b043457536f5851c3517c94f6f50d4c94，括号内显示，本地仓库和远程仓库的文件是一致的（最新的），以下是commit但是没有push到远程仓库的日志记录：\ncommit f67ec47c9df0f0f8351413ef64494e908d7183a0 (HEAD -\u0026gt; master) Author: wangy325 \u0026lt;wangy325@qq.com\u0026gt; Date: Thu Sep 20 17:29:09 2018 +0800 add motto commit cf3d291b043457536f5851c3517c94f6f50d4c94 (origin/master) ... 上面的日志显示，本地HEAD最新的版本号和远程仓库的版本号不一致，暗示本地仓库的改动还未提交到远程仓库。\n由于可视化工具的强大，现在很少直接使用git log命令来查看提交日志，如果想查看，可以使用如下常用命令：\ngit log --oneline 仅展示hash和提交信息 git log --pretty=format:\u0026quot;%h - %an, %ar : %s\u0026quot; 按格式展示提交信息 git log --pretty=:\u0026quot;%h: %an %s\u0026quot; --graph 按格式展示提交信息，--graph表示合并信息 git log --oneline --decorate --graph --all 展示提交历史，分支指向及分支分叉情况 撤销修改 # 如果使用命令行操作Git，往往能够得到不错的操作提示。Git的有几种方式支持撤消操作，分别对应不同的使用情景。\n漏提交了几个文件\n有时候，我们可能不小心，漏提交了几个文件，或者提交信息写错了，可以使用--amend来挽回〔损失〕。\ngit commit --amend 这时候，Git会弹出一个Vim操作界面，让你修改提交信息。\n取消暂存的文件\n更多时候，可能由于“手滑”，需要取消添加到暂存区的文件，这个时候，就需要git restore命令了。\ngit restore --staged \u0026lt;file\u0026gt; ... git restore还有个不带--storage参数的版本，用来恢复对工作区未暂存文件的修改：\ngit restore \u0026lt;file\u0026gt;... 这个操作要谨慎，对于Git来说，未提交的修改，一旦撤消，就不可恢复。而已经提交的修改，都是可以恢复的。 此外，get reset命令也可以完成同样的操作：\ngit reset HEAD \u0026lt;file\u0026gt; git reset命令很强大，使用要谨慎。 丢弃已经提交的修改\n要撤消对文件的修改，将其恢复成为修改前的样子，方法就是使用git restore命令。此外，还可以使用git checkout命令。\n一般认为，git checkout用来切换分支。\ngit checkout -- \u0026lt;file\u0026gt;... 同样地，checkout也是一个⚠️危险的命令。 从工作区和索引中删除文件 # git rm [-f|--force][-n][-r][--cached][--ignore-unmatch][--quiet][--] \u0026lt;file\u0026gt;… 1 git rm \u0026lt;file\u0026gt;\n从当前工作目录中删除文件，这个文件将会从工作空间物理删除，然后commit，版本库中的改文件信息会被删除\n$ git rm text2.md rm \u0026#39;text2.md\u0026#39; $ git status On branch master Your branch is ahead of \u0026#39;origin/master\u0026#39; by 5 commits. (use \u0026#34;git push\u0026#34; to publish your local commits) Changes to be committed: (use \u0026#34;git reset HEAD \u0026lt;file\u0026gt;...\u0026#34; to unstage) deleted: text2.md $ git commit -m \u0026#34;aaa\u0026#34; [master d0ba06d] aaa 1 file changed, 1 deletion(-) delete mode 100644 text2.md 2 git rm -f \u0026lt;file\u0026gt;\n如果当前文件已经在暂存区，则将其从暂存区和工作空间中移除（移除版本信息），commit 之后，其将不在版本库中\n$ git add t3.md warning: LF will be replaced by CRLF in t3.md. The file will have its original line endings in your working directory. $ git rm t3.md error: the following file has changes staged in the index: t3.md (use --cached to keep the file, or -f to force removal) $ git rm -f t3.md rm \u0026#39;t3.md\u0026#39; $ git status On branch master Your branch is ahead of \u0026#39;origin/master\u0026#39; by 6 commits. (use \u0026#34;git push\u0026#34; to publish your local commits) nothing to commit, working tree clean 3 git rm --cached \u0026lt;file\u0026gt;\n如果当前文件改动已经add到暂存区，使用该命令从暂存区中移除版本信息，但是工作空间中还存在，commit之后，其将不在版本库中\n$ git add t3.md warning: LF will be replaced by CRLF in t3.md. The file will have its original line endings in your working directory. $ git rm --cached t3.md rm \u0026#39;t3.md\u0026#39; $ ls me/ readme.md t3.md $ git status On branch master Your branch is ahead of \u0026#39;origin/master\u0026#39; by 7 commits. (use \u0026#34;git push\u0026#34; to publish your local commits) Changes to be committed: (use \u0026#34;git reset HEAD \u0026lt;file\u0026gt;...\u0026#34; to unstage) deleted: t3.md Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) t3.md "},{"id":118,"href":"/zh/posts/100_index/","title":"关于...","section":"Blog","content":" 这首Things left unsaid出自 Pink Floyd 2014年的专辑endless river，自私地用作博客名字。那时想找点摇滚来听，恰逢Pink Floyd这张专辑发行，也是我第一次接触计算机\u0026quot;技术\u0026quot;，准确点说，是接触Ubuntu。我想，Pink Floyd我想我会一直听，技术之路，也会一直走。\n和Ubuntu的关系维持到16年开始着手毕业论文，这一段时间回想起来是非常失败的。究其原因，仅仅是把Ubuntu作为兴趣，止步于猎奇而未深究，就连鸟叔的课文也才看了一半。这也是我长期以来缺乏规划和长远思考的必然结果。\n回头想想自己，缺乏的是高屋建瓴的思考，往往想学而不知如何开始，而又觉得要学的东西太多而萌生放弃的想法——放弃的念头一起，那力量就很强大。我最终还是放弃了Ubuntu，留下了打印出来剩下一半未看的资料，不是我要放弃，是我发现，盯着linux系统的书籍看，可能几年都没有工作了。我当时的想法是，要转计算机，那至少得会一高级编程语言。\n这个想法其实是正确的。可一旦这样，意味着我放弃了我所有的教育履历，和千千万万想进入互联网行业的人一样，从0开始。\n行么？\n读书以来，靠着完全的“自我管理”，混到了一个华南某985的硕士学历。现在回头看看，我的自我管理是在是太糟糕了，就像是没有脑子的圈养动物一样。\n18年是我自我剥削的第一年，像教徒般虔诚，加班到深夜，将知识运用到生产中的快感使我满足，我喜欢这样的感觉。但同时我也一度抑郁，这种抑郁来自于行业的隔阂，匆忙学到的那点知识，我深知离科班生太远了。\n“得益”于求学期间糟糕的自我管理，我不得不重头开始。\n这个博客是19年搭建的，可能较多的内容类似于学习笔记，毕竟还是打基础的阶段，此目的在于系统化知识体系；其次在于记录一些问题，简单则寥寥数语，复杂则深入剖析；再次用于记录平淡的生活感悟。\n望持之以恒。\n"},{"id":119,"href":"/zh/docs/","title":"Docs","section":"Home","content":""},{"id":120,"href":"/zh/docs/java/spring/list/","title":"List","section":"Spring","content":" # spring-amqp\nspring-web-flux\nspring-cloud-open-feign\nspring-cloud-hystrix\nspring-data-redis/ spring-data-redis-reactive\nspring-websocket/ stomp\nspring-logging\nspring-security\n"},{"id":121,"href":"/zh/friend/","title":"Links","section":"Home","content":" 🔗️ 自我麻痹 博客仓库 示例代码\n📔️ 技术博客 阮一峰的个人站 廖雪峰 森亮号航海见识 谢益辉 Java·并发编程 周志明\n🌊️ 有趣的事\n赫赫文王 落网 琼・岗鉴 独影\n"}]