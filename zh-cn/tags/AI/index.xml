<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on Endless River</title><link>https://wangy325.github.io/zh-cn/tags/AI/</link><description>Recent content in AI on Endless River</description><generator>Hugo</generator><language>zh-CN</language><lastBuildDate>Wed, 07 Aug 2024 16:20:46 +0800</lastBuildDate><atom:link href="https://wangy325.github.io/zh-cn/tags/AI/index.xml" rel="self" type="application/rss+xml"/><item><title>使用Pythonanywhere托管Telegram机器人</title><link>https://wangy325.github.io/zh-cn/posts/15_%E4%BD%BF%E7%94%A8PythonAnywhere%E6%89%98%E7%AE%A1%E7%94%B5%E6%8A%A5%E6%9C%BA%E5%99%A8%E4%BA%BA/</link><pubDate>Mon, 08 Jul 2024 00:00:00 +0800</pubDate><guid>https://wangy325.github.io/zh-cn/posts/15_%E4%BD%BF%E7%94%A8PythonAnywhere%E6%89%98%E7%AE%A1%E7%94%B5%E6%8A%A5%E6%9C%BA%E5%99%A8%E4%BA%BA/</guid><description>&lt;p>基于Coze的收费策略，在上面免费使用Gemini的可能性不大了(每日20次&lt;code>gemini-1.5-flash&lt;/code>请求)。于是尝试看看，是否可以自己接入并部署玩玩看。&lt;/p>
&lt;p>GitHub上有关Telegram机器人的项目不少，并且使用python并接入google Gemini AI的也不在少数。随即
 &lt;a href="https://github.com/H-T-H/Gemini-Telegram-Bot.git">clone&lt;/a>了一个，查看文档之后，便可上手。&lt;/p></description></item><item><title>使用Coze的插件和工作流创建自定义AI工具</title><link>https://wangy325.github.io/zh-cn/posts/13_use-coze-plugin-and-workflow/</link><pubDate>Fri, 21 Jun 2024 00:00:00 +0800</pubDate><guid>https://wangy325.github.io/zh-cn/posts/13_use-coze-plugin-and-workflow/</guid><description>&lt;p>
 &lt;a href="https://www.coze.com/docs/guides/welcome?_lang=zh">Coze&lt;/a>是一个提供AI机器人的HUB，利用它市场上提供的Bot，可以很方便地使用AI机器人工作或娱乐。除了市场上五花八门的AI机器人之外，Bot还提供了自定义工作流，插件等功能，用来创建自己的AI工具。&lt;/p>
&lt;blockquote>
&lt;p>⚠️2024年07月03日起，创建的Coze机器人需要
 &lt;a href="https://www.coze.com/docs/guides/subscription?_lang=zh">购买套餐&lt;/a>才能继续使用了，最便宜需要$9/M，看来字节也被薅羊毛薅到顶不住了😭️。&lt;/p>
&lt;p>目前免费用户有每日免费使用GPT-3.5-turbo模型100次的限制，其他的模型免费次数太少，基本不能碰了。&lt;/p>
&lt;p>这个改动对于免费用户来说，使用复杂工作流基本上属于流产，工作流一次调用可能需要使用多次LLM😅。&lt;/p>
&lt;/blockquote></description></item></channel></rss>